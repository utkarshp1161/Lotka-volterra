{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non-linear pde- prey predator model - lotka volterra\n",
    " dx/dt = ax - bxy\n",
    "\n",
    " dy/dt = cxy - dy              initial cond : x= 10, y= 1, find y and x\n",
    "\n",
    " a = 0.1\n",
    "\n",
    " b = 0.4\n",
    "\n",
    " c = 0.1\n",
    " \n",
    " d = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = torch.nn.LeakyReLU(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net_x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_x, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(1,1)\n",
    "        #self.hidden_layer2 = nn.Linear(5,5)\n",
    "        #self.hidden_layer3 = nn.Linear(5,5)\n",
    "        #self.hidden_layer4 = nn.Linear(5,5)\n",
    "        #self.hidden_layer5 = nn.Linear(5,5)\n",
    "        self.output_layer = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self,t):\n",
    "        inputs = torch.cat([t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n",
    "        layer1_out = lr(self.hidden_layer1(inputs))\n",
    "        #layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        #layer2_int = layer1_out + layer2_out\n",
    "        #layer3_out = torch.sigmoid(self.hidden_layer3(layer2_int))\n",
    "        #layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        #layer4_int = layer3_out + layer4_out\n",
    "        #layer5_out = torch.sigmoid(self.hidden_layer5(layer4_int))\n",
    "        # output_ = torch.relu(layer1_out)\n",
    "        output_ = self.output_layer(layer1_out) ## For regression, no activation is used in output layer\n",
    "        output = torch.relu(output_) + 1\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net_y(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_y, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(1,1)\n",
    "        #self.hidden_layer2 = nn.Linear(5,5)\n",
    "        #self.hidden_layer3 = nn.Linear(5,5)\n",
    "        #self.hidden_layer4 = nn.Linear(5,5)\n",
    "        #self.hidden_layer5 = nn.Linear(5,5)\n",
    "        self.output_layer = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, t):\n",
    "        inputs = torch.cat([t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n",
    "        layer1_out = lr(self.hidden_layer1(inputs))\n",
    "        #layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        #layer2_int = layer1_out + layer2_out\n",
    "        #layer3_out = torch.sigmoid(self.hidden_layer3(layer2_int))\n",
    "        #layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        #layer4_int = layer3_out + layer4_out\n",
    "        #layer5_out = torch.sigmoid(self.hidden_layer5(layer4_int))\n",
    "        output = torch.relu(self.output_layer(layer1_out)) ## For regression, no activation is used in output layer\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net_y_(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_y, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(1,5)\n",
    "        self.hidden_layer2 = nn.Linear(5,5)\n",
    "        self.hidden_layer3 = nn.Linear(5,5)\n",
    "        self.hidden_layer4 = nn.Linear(5,5)\n",
    "        self.hidden_layer5 = nn.Linear(5,5)\n",
    "        self.output_layer = nn.Linear(5,1)\n",
    "\n",
    "    def forward(self, t):\n",
    "        inputs = torch.cat([t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n",
    "        layer1_out = torch.sigmoid(self.hidden_layer1(inputs))\n",
    "        layer2_out = torch.sigmoid(self.hidden_layer2(layer1_out))\n",
    "        layer3_out = torch.sigmoid(self.hidden_layer3(layer2_out))\n",
    "        layer4_out = torch.sigmoid(self.hidden_layer4(layer3_out))\n",
    "        layer5_out = torch.sigmoid(self.hidden_layer5(layer4_out))\n",
    "        output = self.output_layer(layer5_out) ## For regression, no activation is used in output layer\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### (2) Model\n",
    "net_x = Net_x()\n",
    "net_y = Net_y()\n",
    "net_x = net_x.to(device)\n",
    "net_y = net_y.to(device)\n",
    "mse_cost_function = torch.nn.MSELoss() # Mean squared error\n",
    "optimizer = torch.optim.Adam(list(net_x.parameters())+ list(net_y.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDE as loss function. Thus would use the network which we call as u_theta\n",
    "def f(t, net_x, net_y):\n",
    "    u = net_x(t) # the dependent variable u is given by the network based on independent variables x,t\n",
    "    v = net_y(t)\n",
    "    \n",
    "    u_t = torch.autograd.grad(u.sum(), t, create_graph=True)[0]\n",
    "    v_t = torch.autograd.grad(v.sum(), t, create_graph=True)[0]\n",
    "    \n",
    "\n",
    "    pde_1 = u_t - 1.1*u + 0.4*u*v\n",
    "    pde_2 =v_t - 0.1*u*v + 0.4*v\n",
    "    \n",
    "    return pde_1, pde_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b.c ==> u(0) = 2000   and v(0) = 6000\n",
    "t_bc = np.zeros((500,1))\n",
    "u_bc = 10*np.ones((500,1))\n",
    "v_bc = 1*np.ones((500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.],\n",
       "       [10.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Traning Loss: tensor(7614.0654)\n",
      "2 Traning Loss: tensor(7421.2627)\n",
      "3 Traning Loss: tensor(7228.4917)\n",
      "4 Traning Loss: tensor(7044.2295)\n",
      "5 Traning Loss: tensor(6895.7842)\n",
      "6 Traning Loss: tensor(6776.8379)\n",
      "7 Traning Loss: tensor(6679.5010)\n",
      "8 Traning Loss: tensor(6597.8970)\n",
      "9 Traning Loss: tensor(6527.7783)\n",
      "10 Traning Loss: tensor(6466.1270)\n",
      "11 Traning Loss: tensor(6410.7793)\n",
      "12 Traning Loss: tensor(6360.1855)\n",
      "13 Traning Loss: tensor(6313.2261)\n",
      "14 Traning Loss: tensor(6269.0889)\n",
      "15 Traning Loss: tensor(6227.1719)\n",
      "16 Traning Loss: tensor(6187.0332)\n",
      "17 Traning Loss: tensor(6148.3311)\n",
      "18 Traning Loss: tensor(6110.8115)\n",
      "19 Traning Loss: tensor(6074.2783)\n",
      "20 Traning Loss: tensor(6038.5767)\n",
      "21 Traning Loss: tensor(6003.5884)\n",
      "22 Traning Loss: tensor(5969.2188)\n",
      "23 Traning Loss: tensor(5935.3877)\n",
      "24 Traning Loss: tensor(5902.0400)\n",
      "25 Traning Loss: tensor(5869.1221)\n",
      "26 Traning Loss: tensor(5836.5947)\n",
      "27 Traning Loss: tensor(5804.4277)\n",
      "28 Traning Loss: tensor(5772.5889)\n",
      "29 Traning Loss: tensor(5741.0566)\n",
      "30 Traning Loss: tensor(5709.8125)\n",
      "31 Traning Loss: tensor(5678.8403)\n",
      "32 Traning Loss: tensor(5648.1260)\n",
      "33 Traning Loss: tensor(5617.6572)\n",
      "34 Traning Loss: tensor(5587.4248)\n",
      "35 Traning Loss: tensor(5557.4180)\n",
      "36 Traning Loss: tensor(5527.6299)\n",
      "37 Traning Loss: tensor(5498.0547)\n",
      "38 Traning Loss: tensor(5468.6855)\n",
      "39 Traning Loss: tensor(5439.5176)\n",
      "40 Traning Loss: tensor(5410.5439)\n",
      "41 Traning Loss: tensor(5381.7651)\n",
      "42 Traning Loss: tensor(5353.1748)\n",
      "43 Traning Loss: tensor(5324.7695)\n",
      "44 Traning Loss: tensor(5296.5469)\n",
      "45 Traning Loss: tensor(5268.5044)\n",
      "46 Traning Loss: tensor(5240.6396)\n",
      "47 Traning Loss: tensor(5212.9482)\n",
      "48 Traning Loss: tensor(5185.4302)\n",
      "49 Traning Loss: tensor(5158.0825)\n",
      "50 Traning Loss: tensor(5130.9048)\n",
      "51 Traning Loss: tensor(5103.8936)\n",
      "52 Traning Loss: tensor(5077.0464)\n",
      "53 Traning Loss: tensor(5050.3643)\n",
      "54 Traning Loss: tensor(5023.8438)\n",
      "55 Traning Loss: tensor(4997.4854)\n",
      "56 Traning Loss: tensor(4971.2866)\n",
      "57 Traning Loss: tensor(4945.2451)\n",
      "58 Traning Loss: tensor(4919.3613)\n",
      "59 Traning Loss: tensor(4893.6333)\n",
      "60 Traning Loss: tensor(4868.0596)\n",
      "61 Traning Loss: tensor(4842.6396)\n",
      "62 Traning Loss: tensor(4817.3735)\n",
      "63 Traning Loss: tensor(4792.2568)\n",
      "64 Traning Loss: tensor(4767.2910)\n",
      "65 Traning Loss: tensor(4742.4751)\n",
      "66 Traning Loss: tensor(4717.8062)\n",
      "67 Traning Loss: tensor(4693.2856)\n",
      "68 Traning Loss: tensor(4668.9111)\n",
      "69 Traning Loss: tensor(4644.6826)\n",
      "70 Traning Loss: tensor(4620.5977)\n",
      "71 Traning Loss: tensor(4596.6572)\n",
      "72 Traning Loss: tensor(4572.8589)\n",
      "73 Traning Loss: tensor(4549.2021)\n",
      "74 Traning Loss: tensor(4525.6865)\n",
      "75 Traning Loss: tensor(4502.3105)\n",
      "76 Traning Loss: tensor(4479.0732)\n",
      "77 Traning Loss: tensor(4455.9746)\n",
      "78 Traning Loss: tensor(4433.0127)\n",
      "79 Traning Loss: tensor(4410.1875)\n",
      "80 Traning Loss: tensor(4387.4976)\n",
      "81 Traning Loss: tensor(4364.9419)\n",
      "82 Traning Loss: tensor(4342.5195)\n",
      "83 Traning Loss: tensor(4320.2314)\n",
      "84 Traning Loss: tensor(4298.0757)\n",
      "85 Traning Loss: tensor(4276.0508)\n",
      "86 Traning Loss: tensor(4254.1567)\n",
      "87 Traning Loss: tensor(4232.3911)\n",
      "88 Traning Loss: tensor(4210.7549)\n",
      "89 Traning Loss: tensor(4189.2466)\n",
      "90 Traning Loss: tensor(4167.8662)\n",
      "91 Traning Loss: tensor(4146.6118)\n",
      "92 Traning Loss: tensor(4125.4834)\n",
      "93 Traning Loss: tensor(4104.4780)\n",
      "94 Traning Loss: tensor(4083.5991)\n",
      "95 Traning Loss: tensor(4062.8430)\n",
      "96 Traning Loss: tensor(4042.2092)\n",
      "97 Traning Loss: tensor(4021.6968)\n",
      "98 Traning Loss: tensor(4001.3064)\n",
      "99 Traning Loss: tensor(3981.0356)\n",
      "100 Traning Loss: tensor(3960.8838)\n",
      "101 Traning Loss: tensor(3940.8516)\n",
      "102 Traning Loss: tensor(3920.9365)\n",
      "103 Traning Loss: tensor(3901.1401)\n",
      "104 Traning Loss: tensor(3881.4590)\n",
      "105 Traning Loss: tensor(3861.8940)\n",
      "106 Traning Loss: tensor(3842.4438)\n",
      "107 Traning Loss: tensor(3823.1079)\n",
      "108 Traning Loss: tensor(3803.8862)\n",
      "109 Traning Loss: tensor(3784.7773)\n",
      "110 Traning Loss: tensor(3765.7803)\n",
      "111 Traning Loss: tensor(3746.8945)\n",
      "112 Traning Loss: tensor(3728.1196)\n",
      "113 Traning Loss: tensor(3709.4541)\n",
      "114 Traning Loss: tensor(3690.8987)\n",
      "115 Traning Loss: tensor(3672.4517)\n",
      "116 Traning Loss: tensor(3654.1128)\n",
      "117 Traning Loss: tensor(3635.8813)\n",
      "118 Traning Loss: tensor(3617.7559)\n",
      "119 Traning Loss: tensor(3599.7373)\n",
      "120 Traning Loss: tensor(3581.8237)\n",
      "121 Traning Loss: tensor(3564.0146)\n",
      "122 Traning Loss: tensor(3546.3091)\n",
      "123 Traning Loss: tensor(3528.7070)\n",
      "124 Traning Loss: tensor(3511.2080)\n",
      "125 Traning Loss: tensor(3493.8110)\n",
      "126 Traning Loss: tensor(3476.5146)\n",
      "127 Traning Loss: tensor(3459.3201)\n",
      "128 Traning Loss: tensor(3442.2251)\n",
      "129 Traning Loss: tensor(3425.2288)\n",
      "130 Traning Loss: tensor(3408.3315)\n",
      "131 Traning Loss: tensor(3391.5332)\n",
      "132 Traning Loss: tensor(3374.8320)\n",
      "133 Traning Loss: tensor(3358.2275)\n",
      "134 Traning Loss: tensor(3341.7197)\n",
      "135 Traning Loss: tensor(3325.3076)\n",
      "136 Traning Loss: tensor(3308.9902)\n",
      "137 Traning Loss: tensor(3292.7676)\n",
      "138 Traning Loss: tensor(3276.6382)\n",
      "139 Traning Loss: tensor(3260.6030)\n",
      "140 Traning Loss: tensor(3244.6602)\n",
      "141 Traning Loss: tensor(3228.8091)\n",
      "142 Traning Loss: tensor(3213.0498)\n",
      "143 Traning Loss: tensor(3197.3818)\n",
      "144 Traning Loss: tensor(3181.8037)\n",
      "145 Traning Loss: tensor(3166.3157)\n",
      "146 Traning Loss: tensor(3150.9165)\n",
      "147 Traning Loss: tensor(3135.6062)\n",
      "148 Traning Loss: tensor(3120.3838)\n",
      "149 Traning Loss: tensor(3105.2495)\n",
      "150 Traning Loss: tensor(3090.2026)\n",
      "151 Traning Loss: tensor(3075.2422)\n",
      "152 Traning Loss: tensor(3060.3667)\n",
      "153 Traning Loss: tensor(3045.5771)\n",
      "154 Traning Loss: tensor(3030.8721)\n",
      "155 Traning Loss: tensor(3016.2510)\n",
      "156 Traning Loss: tensor(3001.7144)\n",
      "157 Traning Loss: tensor(2987.2612)\n",
      "158 Traning Loss: tensor(2972.8892)\n",
      "159 Traning Loss: tensor(2958.6006)\n",
      "160 Traning Loss: tensor(2944.3931)\n",
      "161 Traning Loss: tensor(2930.2673)\n",
      "162 Traning Loss: tensor(2916.2217)\n",
      "163 Traning Loss: tensor(2902.2566)\n",
      "164 Traning Loss: tensor(2888.3711)\n",
      "165 Traning Loss: tensor(2874.5649)\n",
      "166 Traning Loss: tensor(2860.8369)\n",
      "167 Traning Loss: tensor(2847.1873)\n",
      "168 Traning Loss: tensor(2833.6152)\n",
      "169 Traning Loss: tensor(2820.1201)\n",
      "170 Traning Loss: tensor(2806.7021)\n",
      "171 Traning Loss: tensor(2793.3599)\n",
      "172 Traning Loss: tensor(2780.0938)\n",
      "173 Traning Loss: tensor(2766.9023)\n",
      "174 Traning Loss: tensor(2753.7856)\n",
      "175 Traning Loss: tensor(2740.7437)\n",
      "176 Traning Loss: tensor(2727.7756)\n",
      "177 Traning Loss: tensor(2714.8801)\n",
      "178 Traning Loss: tensor(2702.0583)\n",
      "179 Traning Loss: tensor(2689.3086)\n",
      "180 Traning Loss: tensor(2676.6304)\n",
      "181 Traning Loss: tensor(2664.0244)\n",
      "182 Traning Loss: tensor(2651.4890)\n",
      "183 Traning Loss: tensor(2639.0242)\n",
      "184 Traning Loss: tensor(2626.6301)\n",
      "185 Traning Loss: tensor(2614.3057)\n",
      "186 Traning Loss: tensor(2602.0503)\n",
      "187 Traning Loss: tensor(2589.8643)\n",
      "188 Traning Loss: tensor(2577.7466)\n",
      "189 Traning Loss: tensor(2565.6965)\n",
      "190 Traning Loss: tensor(2553.7146)\n",
      "191 Traning Loss: tensor(2541.7991)\n",
      "192 Traning Loss: tensor(2529.9507)\n",
      "193 Traning Loss: tensor(2518.1687)\n",
      "194 Traning Loss: tensor(2506.4531)\n",
      "195 Traning Loss: tensor(2494.8020)\n",
      "196 Traning Loss: tensor(2483.2168)\n",
      "197 Traning Loss: tensor(2471.6956)\n",
      "198 Traning Loss: tensor(2460.2393)\n",
      "199 Traning Loss: tensor(2448.8467)\n",
      "200 Traning Loss: tensor(2437.5176)\n",
      "201 Traning Loss: tensor(2426.2517)\n",
      "202 Traning Loss: tensor(2415.0488)\n",
      "203 Traning Loss: tensor(2403.9080)\n",
      "204 Traning Loss: tensor(2392.8291)\n",
      "205 Traning Loss: tensor(2381.8115)\n",
      "206 Traning Loss: tensor(2370.8550)\n",
      "207 Traning Loss: tensor(2359.9597)\n",
      "208 Traning Loss: tensor(2349.1245)\n",
      "209 Traning Loss: tensor(2338.3496)\n",
      "210 Traning Loss: tensor(2327.6343)\n",
      "211 Traning Loss: tensor(2316.9778)\n",
      "212 Traning Loss: tensor(2306.3809)\n",
      "213 Traning Loss: tensor(2295.8428)\n",
      "214 Traning Loss: tensor(2285.3621)\n",
      "215 Traning Loss: tensor(2274.9399)\n",
      "216 Traning Loss: tensor(2264.5747)\n",
      "217 Traning Loss: tensor(2254.2673)\n",
      "218 Traning Loss: tensor(2244.0159)\n",
      "219 Traning Loss: tensor(2233.8210)\n",
      "220 Traning Loss: tensor(2223.6821)\n",
      "221 Traning Loss: tensor(2213.5989)\n",
      "222 Traning Loss: tensor(2203.5715)\n",
      "223 Traning Loss: tensor(2193.5991)\n",
      "224 Traning Loss: tensor(2183.6816)\n",
      "225 Traning Loss: tensor(2173.8179)\n",
      "226 Traning Loss: tensor(2164.0088)\n",
      "227 Traning Loss: tensor(2154.2534)\n",
      "228 Traning Loss: tensor(2144.5513)\n",
      "229 Traning Loss: tensor(2134.9021)\n",
      "230 Traning Loss: tensor(2125.3052)\n",
      "231 Traning Loss: tensor(2115.7610)\n",
      "232 Traning Loss: tensor(2106.2690)\n",
      "233 Traning Loss: tensor(2096.8286)\n",
      "234 Traning Loss: tensor(2087.4399)\n",
      "235 Traning Loss: tensor(2078.1023)\n",
      "236 Traning Loss: tensor(2068.8154)\n",
      "237 Traning Loss: tensor(2059.5791)\n",
      "238 Traning Loss: tensor(2050.3933)\n",
      "239 Traning Loss: tensor(2041.2570)\n",
      "240 Traning Loss: tensor(2032.1710)\n",
      "241 Traning Loss: tensor(2023.1338)\n",
      "242 Traning Loss: tensor(2014.1453)\n",
      "243 Traning Loss: tensor(2005.2054)\n",
      "244 Traning Loss: tensor(1996.3140)\n",
      "245 Traning Loss: tensor(1987.4709)\n",
      "246 Traning Loss: tensor(1978.6755)\n",
      "247 Traning Loss: tensor(1969.9277)\n",
      "248 Traning Loss: tensor(1961.2267)\n",
      "249 Traning Loss: tensor(1952.5732)\n",
      "250 Traning Loss: tensor(1943.9659)\n",
      "251 Traning Loss: tensor(1935.4055)\n",
      "252 Traning Loss: tensor(1926.8909)\n",
      "253 Traning Loss: tensor(1918.4221)\n",
      "254 Traning Loss: tensor(1909.9987)\n",
      "255 Traning Loss: tensor(1901.6207)\n",
      "256 Traning Loss: tensor(1893.2876)\n",
      "257 Traning Loss: tensor(1884.9993)\n",
      "258 Traning Loss: tensor(1876.7556)\n",
      "259 Traning Loss: tensor(1868.5557)\n",
      "260 Traning Loss: tensor(1860.3998)\n",
      "261 Traning Loss: tensor(1852.2876)\n",
      "262 Traning Loss: tensor(1844.2190)\n",
      "263 Traning Loss: tensor(1836.1936)\n",
      "264 Traning Loss: tensor(1828.2104)\n",
      "265 Traning Loss: tensor(1820.2705)\n",
      "266 Traning Loss: tensor(1812.3729)\n",
      "267 Traning Loss: tensor(1804.5164)\n",
      "268 Traning Loss: tensor(1796.7021)\n",
      "269 Traning Loss: tensor(1788.9294)\n",
      "270 Traning Loss: tensor(1781.1985)\n",
      "271 Traning Loss: tensor(1773.5084)\n",
      "272 Traning Loss: tensor(1765.8594)\n",
      "273 Traning Loss: tensor(1758.2504)\n",
      "274 Traning Loss: tensor(1750.6819)\n",
      "275 Traning Loss: tensor(1743.1537)\n",
      "276 Traning Loss: tensor(1735.6650)\n",
      "277 Traning Loss: tensor(1728.2161)\n",
      "278 Traning Loss: tensor(1720.8066)\n",
      "279 Traning Loss: tensor(1713.4364)\n",
      "280 Traning Loss: tensor(1706.1056)\n",
      "281 Traning Loss: tensor(1698.8130)\n",
      "282 Traning Loss: tensor(1691.5588)\n",
      "283 Traning Loss: tensor(1684.3430)\n",
      "284 Traning Loss: tensor(1677.1647)\n",
      "285 Traning Loss: tensor(1670.0242)\n",
      "286 Traning Loss: tensor(1662.9214)\n",
      "287 Traning Loss: tensor(1655.8560)\n",
      "288 Traning Loss: tensor(1648.8274)\n",
      "289 Traning Loss: tensor(1641.8362)\n",
      "290 Traning Loss: tensor(1634.8816)\n",
      "291 Traning Loss: tensor(1627.9630)\n",
      "292 Traning Loss: tensor(1621.0809)\n",
      "293 Traning Loss: tensor(1614.2346)\n",
      "294 Traning Loss: tensor(1607.4243)\n",
      "295 Traning Loss: tensor(1600.6495)\n",
      "296 Traning Loss: tensor(1593.9099)\n",
      "297 Traning Loss: tensor(1587.2056)\n",
      "298 Traning Loss: tensor(1580.5363)\n",
      "299 Traning Loss: tensor(1573.9017)\n",
      "300 Traning Loss: tensor(1567.3015)\n",
      "301 Traning Loss: tensor(1560.7358)\n",
      "302 Traning Loss: tensor(1554.2041)\n",
      "303 Traning Loss: tensor(1547.7065)\n",
      "304 Traning Loss: tensor(1541.2426)\n",
      "305 Traning Loss: tensor(1534.8121)\n",
      "306 Traning Loss: tensor(1528.4150)\n",
      "307 Traning Loss: tensor(1522.0510)\n",
      "308 Traning Loss: tensor(1515.7198)\n",
      "309 Traning Loss: tensor(1509.4215)\n",
      "310 Traning Loss: tensor(1503.1560)\n",
      "311 Traning Loss: tensor(1496.9226)\n",
      "312 Traning Loss: tensor(1490.7214)\n",
      "313 Traning Loss: tensor(1484.5522)\n",
      "314 Traning Loss: tensor(1478.4146)\n",
      "315 Traning Loss: tensor(1472.3088)\n",
      "316 Traning Loss: tensor(1466.2345)\n",
      "317 Traning Loss: tensor(1460.1912)\n",
      "318 Traning Loss: tensor(1454.1792)\n",
      "319 Traning Loss: tensor(1448.1980)\n",
      "320 Traning Loss: tensor(1442.2479)\n",
      "321 Traning Loss: tensor(1436.3279)\n",
      "322 Traning Loss: tensor(1430.4382)\n",
      "323 Traning Loss: tensor(1424.5787)\n",
      "324 Traning Loss: tensor(1418.7491)\n",
      "325 Traning Loss: tensor(1412.9495)\n",
      "326 Traning Loss: tensor(1407.1794)\n",
      "327 Traning Loss: tensor(1401.4387)\n",
      "328 Traning Loss: tensor(1395.7275)\n",
      "329 Traning Loss: tensor(1390.0453)\n",
      "330 Traning Loss: tensor(1384.3921)\n",
      "331 Traning Loss: tensor(1378.7677)\n",
      "332 Traning Loss: tensor(1373.1718)\n",
      "333 Traning Loss: tensor(1367.6042)\n",
      "334 Traning Loss: tensor(1362.0654)\n",
      "335 Traning Loss: tensor(1356.5547)\n",
      "336 Traning Loss: tensor(1351.0714)\n",
      "337 Traning Loss: tensor(1345.6161)\n",
      "338 Traning Loss: tensor(1340.1886)\n",
      "339 Traning Loss: tensor(1334.7886)\n",
      "340 Traning Loss: tensor(1329.4158)\n",
      "341 Traning Loss: tensor(1324.0702)\n",
      "342 Traning Loss: tensor(1318.7515)\n",
      "343 Traning Loss: tensor(1313.4597)\n",
      "344 Traning Loss: tensor(1308.1945)\n",
      "345 Traning Loss: tensor(1302.9561)\n",
      "346 Traning Loss: tensor(1297.7440)\n",
      "347 Traning Loss: tensor(1292.5579)\n",
      "348 Traning Loss: tensor(1287.3979)\n",
      "349 Traning Loss: tensor(1282.2644)\n",
      "350 Traning Loss: tensor(1277.1561)\n",
      "351 Traning Loss: tensor(1272.0735)\n",
      "352 Traning Loss: tensor(1267.0168)\n",
      "353 Traning Loss: tensor(1261.9854)\n",
      "354 Traning Loss: tensor(1256.9790)\n",
      "355 Traning Loss: tensor(1251.9978)\n",
      "356 Traning Loss: tensor(1247.0413)\n",
      "357 Traning Loss: tensor(1242.1099)\n",
      "358 Traning Loss: tensor(1237.2028)\n",
      "359 Traning Loss: tensor(1232.3204)\n",
      "360 Traning Loss: tensor(1227.4620)\n",
      "361 Traning Loss: tensor(1222.6281)\n",
      "362 Traning Loss: tensor(1217.8181)\n",
      "363 Traning Loss: tensor(1213.0322)\n",
      "364 Traning Loss: tensor(1208.2703)\n",
      "365 Traning Loss: tensor(1203.5315)\n",
      "366 Traning Loss: tensor(1198.8165)\n",
      "367 Traning Loss: tensor(1194.1246)\n",
      "368 Traning Loss: tensor(1189.4563)\n",
      "369 Traning Loss: tensor(1184.8113)\n",
      "370 Traning Loss: tensor(1180.1892)\n",
      "371 Traning Loss: tensor(1175.5897)\n",
      "372 Traning Loss: tensor(1171.0131)\n",
      "373 Traning Loss: tensor(1166.4590)\n",
      "374 Traning Loss: tensor(1161.9275)\n",
      "375 Traning Loss: tensor(1157.4182)\n",
      "376 Traning Loss: tensor(1152.9314)\n",
      "377 Traning Loss: tensor(1148.4664)\n",
      "378 Traning Loss: tensor(1144.0236)\n",
      "379 Traning Loss: tensor(1139.6024)\n",
      "380 Traning Loss: tensor(1135.2031)\n",
      "381 Traning Loss: tensor(1130.8258)\n",
      "382 Traning Loss: tensor(1126.4697)\n",
      "383 Traning Loss: tensor(1122.1349)\n",
      "384 Traning Loss: tensor(1117.8214)\n",
      "385 Traning Loss: tensor(1113.5291)\n",
      "386 Traning Loss: tensor(1109.2573)\n",
      "387 Traning Loss: tensor(1105.0068)\n",
      "388 Traning Loss: tensor(1100.7771)\n",
      "389 Traning Loss: tensor(1096.5680)\n",
      "390 Traning Loss: tensor(1092.3794)\n",
      "391 Traning Loss: tensor(1088.2114)\n",
      "392 Traning Loss: tensor(1084.0636)\n",
      "393 Traning Loss: tensor(1079.9358)\n",
      "394 Traning Loss: tensor(1075.8281)\n",
      "395 Traning Loss: tensor(1071.7407)\n",
      "396 Traning Loss: tensor(1067.6730)\n",
      "397 Traning Loss: tensor(1063.6249)\n",
      "398 Traning Loss: tensor(1059.5966)\n",
      "399 Traning Loss: tensor(1055.5878)\n",
      "400 Traning Loss: tensor(1051.5984)\n",
      "401 Traning Loss: tensor(1047.6283)\n",
      "402 Traning Loss: tensor(1043.6775)\n",
      "403 Traning Loss: tensor(1039.7458)\n",
      "404 Traning Loss: tensor(1035.8330)\n",
      "405 Traning Loss: tensor(1031.9392)\n",
      "406 Traning Loss: tensor(1028.0642)\n",
      "407 Traning Loss: tensor(1024.2078)\n",
      "408 Traning Loss: tensor(1020.3699)\n",
      "409 Traning Loss: tensor(1016.5505)\n",
      "410 Traning Loss: tensor(1012.7496)\n",
      "411 Traning Loss: tensor(1008.9670)\n",
      "412 Traning Loss: tensor(1005.2025)\n",
      "413 Traning Loss: tensor(1001.4559)\n",
      "414 Traning Loss: tensor(997.7274)\n",
      "415 Traning Loss: tensor(994.0168)\n",
      "416 Traning Loss: tensor(990.3240)\n",
      "417 Traning Loss: tensor(986.6487)\n",
      "418 Traning Loss: tensor(982.9912)\n",
      "419 Traning Loss: tensor(979.3512)\n",
      "420 Traning Loss: tensor(975.7284)\n",
      "421 Traning Loss: tensor(972.1229)\n",
      "422 Traning Loss: tensor(968.5346)\n",
      "423 Traning Loss: tensor(964.9634)\n",
      "424 Traning Loss: tensor(961.4094)\n",
      "425 Traning Loss: tensor(957.8721)\n",
      "426 Traning Loss: tensor(954.3517)\n",
      "427 Traning Loss: tensor(950.8480)\n",
      "428 Traning Loss: tensor(947.3608)\n",
      "429 Traning Loss: tensor(943.8904)\n",
      "430 Traning Loss: tensor(940.4364)\n",
      "431 Traning Loss: tensor(936.9986)\n",
      "432 Traning Loss: tensor(933.5771)\n",
      "433 Traning Loss: tensor(930.1721)\n",
      "434 Traning Loss: tensor(926.7830)\n",
      "435 Traning Loss: tensor(923.4097)\n",
      "436 Traning Loss: tensor(920.0526)\n",
      "437 Traning Loss: tensor(916.7114)\n",
      "438 Traning Loss: tensor(913.3856)\n",
      "439 Traning Loss: tensor(910.0757)\n",
      "440 Traning Loss: tensor(906.7814)\n",
      "441 Traning Loss: tensor(903.5024)\n",
      "442 Traning Loss: tensor(900.2393)\n",
      "443 Traning Loss: tensor(896.9912)\n",
      "444 Traning Loss: tensor(893.7582)\n",
      "445 Traning Loss: tensor(890.5405)\n",
      "446 Traning Loss: tensor(887.3378)\n",
      "447 Traning Loss: tensor(884.1505)\n",
      "448 Traning Loss: tensor(880.9776)\n",
      "449 Traning Loss: tensor(877.8198)\n",
      "450 Traning Loss: tensor(874.6768)\n",
      "451 Traning Loss: tensor(871.5483)\n",
      "452 Traning Loss: tensor(868.4344)\n",
      "453 Traning Loss: tensor(865.3350)\n",
      "454 Traning Loss: tensor(862.2502)\n",
      "455 Traning Loss: tensor(859.1797)\n",
      "456 Traning Loss: tensor(856.1234)\n",
      "457 Traning Loss: tensor(853.0814)\n",
      "458 Traning Loss: tensor(850.0535)\n",
      "459 Traning Loss: tensor(847.0398)\n",
      "460 Traning Loss: tensor(844.0399)\n",
      "461 Traning Loss: tensor(841.0541)\n",
      "462 Traning Loss: tensor(838.0820)\n",
      "463 Traning Loss: tensor(835.1237)\n",
      "464 Traning Loss: tensor(832.1791)\n",
      "465 Traning Loss: tensor(829.2482)\n",
      "466 Traning Loss: tensor(826.3306)\n",
      "467 Traning Loss: tensor(823.4265)\n",
      "468 Traning Loss: tensor(820.5361)\n",
      "469 Traning Loss: tensor(817.6587)\n",
      "470 Traning Loss: tensor(814.7946)\n",
      "471 Traning Loss: tensor(811.9438)\n",
      "472 Traning Loss: tensor(809.1061)\n",
      "473 Traning Loss: tensor(806.2816)\n",
      "474 Traning Loss: tensor(803.4700)\n",
      "475 Traning Loss: tensor(800.6710)\n",
      "476 Traning Loss: tensor(797.8850)\n",
      "477 Traning Loss: tensor(795.1119)\n",
      "478 Traning Loss: tensor(792.3513)\n",
      "479 Traning Loss: tensor(789.6035)\n",
      "480 Traning Loss: tensor(786.8683)\n",
      "481 Traning Loss: tensor(784.1455)\n",
      "482 Traning Loss: tensor(781.4351)\n",
      "483 Traning Loss: tensor(778.7372)\n",
      "484 Traning Loss: tensor(776.0515)\n",
      "485 Traning Loss: tensor(773.3781)\n",
      "486 Traning Loss: tensor(770.7168)\n",
      "487 Traning Loss: tensor(768.0679)\n",
      "488 Traning Loss: tensor(765.4308)\n",
      "489 Traning Loss: tensor(762.8057)\n",
      "490 Traning Loss: tensor(760.1926)\n",
      "491 Traning Loss: tensor(757.5911)\n",
      "492 Traning Loss: tensor(755.0017)\n",
      "493 Traning Loss: tensor(752.4240)\n",
      "494 Traning Loss: tensor(749.8578)\n",
      "495 Traning Loss: tensor(747.3033)\n",
      "496 Traning Loss: tensor(744.7605)\n",
      "497 Traning Loss: tensor(742.2290)\n",
      "498 Traning Loss: tensor(739.7090)\n",
      "499 Traning Loss: tensor(737.2003)\n",
      "500 Traning Loss: tensor(734.7028)\n",
      "501 Traning Loss: tensor(732.2168)\n",
      "502 Traning Loss: tensor(729.7420)\n",
      "503 Traning Loss: tensor(727.2783)\n",
      "504 Traning Loss: tensor(724.8256)\n",
      "505 Traning Loss: tensor(722.3839)\n",
      "506 Traning Loss: tensor(719.9532)\n",
      "507 Traning Loss: tensor(717.5334)\n",
      "508 Traning Loss: tensor(715.1243)\n",
      "509 Traning Loss: tensor(712.7263)\n",
      "510 Traning Loss: tensor(710.3387)\n",
      "511 Traning Loss: tensor(707.9622)\n",
      "512 Traning Loss: tensor(705.5960)\n",
      "513 Traning Loss: tensor(703.2406)\n",
      "514 Traning Loss: tensor(700.8956)\n",
      "515 Traning Loss: tensor(698.5610)\n",
      "516 Traning Loss: tensor(696.2369)\n",
      "517 Traning Loss: tensor(693.9232)\n",
      "518 Traning Loss: tensor(691.6198)\n",
      "519 Traning Loss: tensor(689.3265)\n",
      "520 Traning Loss: tensor(687.0436)\n",
      "521 Traning Loss: tensor(684.7708)\n",
      "522 Traning Loss: tensor(682.5079)\n",
      "523 Traning Loss: tensor(680.2551)\n",
      "524 Traning Loss: tensor(678.0123)\n",
      "525 Traning Loss: tensor(675.7795)\n",
      "526 Traning Loss: tensor(673.5565)\n",
      "527 Traning Loss: tensor(671.3435)\n",
      "528 Traning Loss: tensor(669.1403)\n",
      "529 Traning Loss: tensor(666.9467)\n",
      "530 Traning Loss: tensor(664.7627)\n",
      "531 Traning Loss: tensor(662.5884)\n",
      "532 Traning Loss: tensor(660.4237)\n",
      "533 Traning Loss: tensor(658.2686)\n",
      "534 Traning Loss: tensor(656.1229)\n",
      "535 Traning Loss: tensor(653.9868)\n",
      "536 Traning Loss: tensor(651.8599)\n",
      "537 Traning Loss: tensor(649.7424)\n",
      "538 Traning Loss: tensor(647.6342)\n",
      "539 Traning Loss: tensor(645.5353)\n",
      "540 Traning Loss: tensor(643.4456)\n",
      "541 Traning Loss: tensor(641.3649)\n",
      "542 Traning Loss: tensor(639.2935)\n",
      "543 Traning Loss: tensor(637.2310)\n",
      "544 Traning Loss: tensor(635.1776)\n",
      "545 Traning Loss: tensor(633.1333)\n",
      "546 Traning Loss: tensor(631.0977)\n",
      "547 Traning Loss: tensor(629.0710)\n",
      "548 Traning Loss: tensor(627.0531)\n",
      "549 Traning Loss: tensor(625.0441)\n",
      "550 Traning Loss: tensor(623.0438)\n",
      "551 Traning Loss: tensor(621.0522)\n",
      "552 Traning Loss: tensor(619.0695)\n",
      "553 Traning Loss: tensor(617.0950)\n",
      "554 Traning Loss: tensor(615.1294)\n",
      "555 Traning Loss: tensor(613.1721)\n",
      "556 Traning Loss: tensor(611.2234)\n",
      "557 Traning Loss: tensor(609.2833)\n",
      "558 Traning Loss: tensor(607.3513)\n",
      "559 Traning Loss: tensor(605.4278)\n",
      "560 Traning Loss: tensor(603.5126)\n",
      "561 Traning Loss: tensor(601.6055)\n",
      "562 Traning Loss: tensor(599.7068)\n",
      "563 Traning Loss: tensor(597.8163)\n",
      "564 Traning Loss: tensor(595.9340)\n",
      "565 Traning Loss: tensor(594.0597)\n",
      "566 Traning Loss: tensor(592.1935)\n",
      "567 Traning Loss: tensor(590.3353)\n",
      "568 Traning Loss: tensor(588.4850)\n",
      "569 Traning Loss: tensor(586.6429)\n",
      "570 Traning Loss: tensor(584.8085)\n",
      "571 Traning Loss: tensor(582.9820)\n",
      "572 Traning Loss: tensor(581.1633)\n",
      "573 Traning Loss: tensor(579.3525)\n",
      "574 Traning Loss: tensor(577.5495)\n",
      "575 Traning Loss: tensor(575.7541)\n",
      "576 Traning Loss: tensor(573.9665)\n",
      "577 Traning Loss: tensor(572.1864)\n",
      "578 Traning Loss: tensor(570.4139)\n",
      "579 Traning Loss: tensor(568.6490)\n",
      "580 Traning Loss: tensor(566.8917)\n",
      "581 Traning Loss: tensor(565.1418)\n",
      "582 Traning Loss: tensor(563.3994)\n",
      "583 Traning Loss: tensor(561.6644)\n",
      "584 Traning Loss: tensor(559.9366)\n",
      "585 Traning Loss: tensor(558.2163)\n",
      "586 Traning Loss: tensor(556.5033)\n",
      "587 Traning Loss: tensor(554.7977)\n",
      "588 Traning Loss: tensor(553.0992)\n",
      "589 Traning Loss: tensor(551.4078)\n",
      "590 Traning Loss: tensor(549.7236)\n",
      "591 Traning Loss: tensor(548.0465)\n",
      "592 Traning Loss: tensor(546.3766)\n",
      "593 Traning Loss: tensor(544.7137)\n",
      "594 Traning Loss: tensor(543.0579)\n",
      "595 Traning Loss: tensor(541.4091)\n",
      "596 Traning Loss: tensor(539.7670)\n",
      "597 Traning Loss: tensor(538.1320)\n",
      "598 Traning Loss: tensor(536.5038)\n",
      "599 Traning Loss: tensor(534.8826)\n",
      "600 Traning Loss: tensor(533.2681)\n",
      "601 Traning Loss: tensor(531.6604)\n",
      "602 Traning Loss: tensor(530.0594)\n",
      "603 Traning Loss: tensor(528.4652)\n",
      "604 Traning Loss: tensor(526.8777)\n",
      "605 Traning Loss: tensor(525.2969)\n",
      "606 Traning Loss: tensor(523.7225)\n",
      "607 Traning Loss: tensor(522.1549)\n",
      "608 Traning Loss: tensor(520.5938)\n",
      "609 Traning Loss: tensor(519.0392)\n",
      "610 Traning Loss: tensor(517.4911)\n",
      "611 Traning Loss: tensor(515.9494)\n",
      "612 Traning Loss: tensor(514.4142)\n",
      "613 Traning Loss: tensor(512.8854)\n",
      "614 Traning Loss: tensor(511.3630)\n",
      "615 Traning Loss: tensor(509.8469)\n",
      "616 Traning Loss: tensor(508.3371)\n",
      "617 Traning Loss: tensor(506.8334)\n",
      "618 Traning Loss: tensor(505.3362)\n",
      "619 Traning Loss: tensor(503.8451)\n",
      "620 Traning Loss: tensor(502.3601)\n",
      "621 Traning Loss: tensor(500.8814)\n",
      "622 Traning Loss: tensor(499.4088)\n",
      "623 Traning Loss: tensor(497.9422)\n",
      "624 Traning Loss: tensor(496.4819)\n",
      "625 Traning Loss: tensor(495.0275)\n",
      "626 Traning Loss: tensor(493.5790)\n",
      "627 Traning Loss: tensor(492.1367)\n",
      "628 Traning Loss: tensor(490.7002)\n",
      "629 Traning Loss: tensor(489.2697)\n",
      "630 Traning Loss: tensor(487.8449)\n",
      "631 Traning Loss: tensor(486.4261)\n",
      "632 Traning Loss: tensor(485.0132)\n",
      "633 Traning Loss: tensor(483.6060)\n",
      "634 Traning Loss: tensor(482.2047)\n",
      "635 Traning Loss: tensor(480.8089)\n",
      "636 Traning Loss: tensor(479.4190)\n",
      "637 Traning Loss: tensor(478.0348)\n",
      "638 Traning Loss: tensor(476.6562)\n",
      "639 Traning Loss: tensor(475.2834)\n",
      "640 Traning Loss: tensor(473.9161)\n",
      "641 Traning Loss: tensor(472.5545)\n",
      "642 Traning Loss: tensor(471.1984)\n",
      "643 Traning Loss: tensor(469.8478)\n",
      "644 Traning Loss: tensor(468.5027)\n",
      "645 Traning Loss: tensor(467.1631)\n",
      "646 Traning Loss: tensor(465.8289)\n",
      "647 Traning Loss: tensor(464.5002)\n",
      "648 Traning Loss: tensor(463.1769)\n",
      "649 Traning Loss: tensor(461.8589)\n",
      "650 Traning Loss: tensor(460.5464)\n",
      "651 Traning Loss: tensor(459.2393)\n",
      "652 Traning Loss: tensor(457.9373)\n",
      "653 Traning Loss: tensor(456.6407)\n",
      "654 Traning Loss: tensor(455.3493)\n",
      "655 Traning Loss: tensor(454.0631)\n",
      "656 Traning Loss: tensor(452.7822)\n",
      "657 Traning Loss: tensor(451.5063)\n",
      "658 Traning Loss: tensor(450.2357)\n",
      "659 Traning Loss: tensor(448.9703)\n",
      "660 Traning Loss: tensor(447.7098)\n",
      "661 Traning Loss: tensor(446.4545)\n",
      "662 Traning Loss: tensor(445.2043)\n",
      "663 Traning Loss: tensor(443.9591)\n",
      "664 Traning Loss: tensor(442.7190)\n",
      "665 Traning Loss: tensor(441.4837)\n",
      "666 Traning Loss: tensor(440.2535)\n",
      "667 Traning Loss: tensor(439.0282)\n",
      "668 Traning Loss: tensor(437.8079)\n",
      "669 Traning Loss: tensor(436.5924)\n",
      "670 Traning Loss: tensor(435.3817)\n",
      "671 Traning Loss: tensor(434.1760)\n",
      "672 Traning Loss: tensor(432.9750)\n",
      "673 Traning Loss: tensor(431.7790)\n",
      "674 Traning Loss: tensor(430.5876)\n",
      "675 Traning Loss: tensor(429.4011)\n",
      "676 Traning Loss: tensor(428.2192)\n",
      "677 Traning Loss: tensor(427.0421)\n",
      "678 Traning Loss: tensor(425.8697)\n",
      "679 Traning Loss: tensor(424.7020)\n",
      "680 Traning Loss: tensor(423.5390)\n",
      "681 Traning Loss: tensor(422.3804)\n",
      "682 Traning Loss: tensor(421.2266)\n",
      "683 Traning Loss: tensor(420.0774)\n",
      "684 Traning Loss: tensor(418.9327)\n",
      "685 Traning Loss: tensor(417.7925)\n",
      "686 Traning Loss: tensor(416.6569)\n",
      "687 Traning Loss: tensor(415.5257)\n",
      "688 Traning Loss: tensor(414.3991)\n",
      "689 Traning Loss: tensor(413.2769)\n",
      "690 Traning Loss: tensor(412.1591)\n",
      "691 Traning Loss: tensor(411.0458)\n",
      "692 Traning Loss: tensor(409.9368)\n",
      "693 Traning Loss: tensor(408.8322)\n",
      "694 Traning Loss: tensor(407.7321)\n",
      "695 Traning Loss: tensor(406.6363)\n",
      "696 Traning Loss: tensor(405.5446)\n",
      "697 Traning Loss: tensor(404.4575)\n",
      "698 Traning Loss: tensor(403.3745)\n",
      "699 Traning Loss: tensor(402.2958)\n",
      "700 Traning Loss: tensor(401.2214)\n",
      "701 Traning Loss: tensor(400.1511)\n",
      "702 Traning Loss: tensor(399.0851)\n",
      "703 Traning Loss: tensor(398.0232)\n",
      "704 Traning Loss: tensor(396.9655)\n",
      "705 Traning Loss: tensor(395.9120)\n",
      "706 Traning Loss: tensor(394.8626)\n",
      "707 Traning Loss: tensor(393.8173)\n",
      "708 Traning Loss: tensor(392.7761)\n",
      "709 Traning Loss: tensor(391.7388)\n",
      "710 Traning Loss: tensor(390.7058)\n",
      "711 Traning Loss: tensor(389.6767)\n",
      "712 Traning Loss: tensor(388.6517)\n",
      "713 Traning Loss: tensor(387.6306)\n",
      "714 Traning Loss: tensor(386.6135)\n",
      "715 Traning Loss: tensor(385.6004)\n",
      "716 Traning Loss: tensor(384.5912)\n",
      "717 Traning Loss: tensor(383.5859)\n",
      "718 Traning Loss: tensor(382.5845)\n",
      "719 Traning Loss: tensor(381.5870)\n",
      "720 Traning Loss: tensor(380.5934)\n",
      "721 Traning Loss: tensor(379.6037)\n",
      "722 Traning Loss: tensor(378.6178)\n",
      "723 Traning Loss: tensor(377.6356)\n",
      "724 Traning Loss: tensor(376.6573)\n",
      "725 Traning Loss: tensor(375.6828)\n",
      "726 Traning Loss: tensor(374.7120)\n",
      "727 Traning Loss: tensor(373.7451)\n",
      "728 Traning Loss: tensor(372.7817)\n",
      "729 Traning Loss: tensor(371.8221)\n",
      "730 Traning Loss: tensor(370.8663)\n",
      "731 Traning Loss: tensor(369.9141)\n",
      "732 Traning Loss: tensor(368.9656)\n",
      "733 Traning Loss: tensor(368.0207)\n",
      "734 Traning Loss: tensor(367.0794)\n",
      "735 Traning Loss: tensor(366.1418)\n",
      "736 Traning Loss: tensor(365.2078)\n",
      "737 Traning Loss: tensor(364.2774)\n",
      "738 Traning Loss: tensor(363.3505)\n",
      "739 Traning Loss: tensor(362.4272)\n",
      "740 Traning Loss: tensor(361.5074)\n",
      "741 Traning Loss: tensor(360.5911)\n",
      "742 Traning Loss: tensor(359.6783)\n",
      "743 Traning Loss: tensor(358.7690)\n",
      "744 Traning Loss: tensor(357.8633)\n",
      "745 Traning Loss: tensor(356.9609)\n",
      "746 Traning Loss: tensor(356.0620)\n",
      "747 Traning Loss: tensor(355.1665)\n",
      "748 Traning Loss: tensor(354.2745)\n",
      "749 Traning Loss: tensor(353.3858)\n",
      "750 Traning Loss: tensor(352.5005)\n",
      "751 Traning Loss: tensor(351.6186)\n",
      "752 Traning Loss: tensor(350.7401)\n",
      "753 Traning Loss: tensor(349.8648)\n",
      "754 Traning Loss: tensor(348.9930)\n",
      "755 Traning Loss: tensor(348.1243)\n",
      "756 Traning Loss: tensor(347.2591)\n",
      "757 Traning Loss: tensor(346.3970)\n",
      "758 Traning Loss: tensor(345.5382)\n",
      "759 Traning Loss: tensor(344.6827)\n",
      "760 Traning Loss: tensor(343.8304)\n",
      "761 Traning Loss: tensor(342.9814)\n",
      "762 Traning Loss: tensor(342.1356)\n",
      "763 Traning Loss: tensor(341.2929)\n",
      "764 Traning Loss: tensor(340.4534)\n",
      "765 Traning Loss: tensor(339.6170)\n",
      "766 Traning Loss: tensor(338.7839)\n",
      "767 Traning Loss: tensor(337.9538)\n",
      "768 Traning Loss: tensor(337.1269)\n",
      "769 Traning Loss: tensor(336.3031)\n",
      "770 Traning Loss: tensor(335.4824)\n",
      "771 Traning Loss: tensor(334.6647)\n",
      "772 Traning Loss: tensor(333.8502)\n",
      "773 Traning Loss: tensor(333.0387)\n",
      "774 Traning Loss: tensor(332.2302)\n",
      "775 Traning Loss: tensor(331.4248)\n",
      "776 Traning Loss: tensor(330.6224)\n",
      "777 Traning Loss: tensor(329.8230)\n",
      "778 Traning Loss: tensor(329.0265)\n",
      "779 Traning Loss: tensor(328.2330)\n",
      "780 Traning Loss: tensor(327.4425)\n",
      "781 Traning Loss: tensor(326.6549)\n",
      "782 Traning Loss: tensor(325.8703)\n",
      "783 Traning Loss: tensor(325.0886)\n",
      "784 Traning Loss: tensor(324.3098)\n",
      "785 Traning Loss: tensor(323.5338)\n",
      "786 Traning Loss: tensor(322.7608)\n",
      "787 Traning Loss: tensor(321.9907)\n",
      "788 Traning Loss: tensor(321.2234)\n",
      "789 Traning Loss: tensor(320.4590)\n",
      "790 Traning Loss: tensor(319.6974)\n",
      "791 Traning Loss: tensor(318.9387)\n",
      "792 Traning Loss: tensor(318.1827)\n",
      "793 Traning Loss: tensor(317.4296)\n",
      "794 Traning Loss: tensor(316.6793)\n",
      "795 Traning Loss: tensor(315.9316)\n",
      "796 Traning Loss: tensor(315.1868)\n",
      "797 Traning Loss: tensor(314.4447)\n",
      "798 Traning Loss: tensor(313.7054)\n",
      "799 Traning Loss: tensor(312.9688)\n",
      "800 Traning Loss: tensor(312.2349)\n",
      "801 Traning Loss: tensor(311.5037)\n",
      "802 Traning Loss: tensor(310.7752)\n",
      "803 Traning Loss: tensor(310.0494)\n",
      "804 Traning Loss: tensor(309.3263)\n",
      "805 Traning Loss: tensor(308.6058)\n",
      "806 Traning Loss: tensor(307.8880)\n",
      "807 Traning Loss: tensor(307.1728)\n",
      "808 Traning Loss: tensor(306.4602)\n",
      "809 Traning Loss: tensor(305.7502)\n",
      "810 Traning Loss: tensor(305.0429)\n",
      "811 Traning Loss: tensor(304.3381)\n",
      "812 Traning Loss: tensor(303.6359)\n",
      "813 Traning Loss: tensor(302.9363)\n",
      "814 Traning Loss: tensor(302.2392)\n",
      "815 Traning Loss: tensor(301.5447)\n",
      "816 Traning Loss: tensor(300.8527)\n",
      "817 Traning Loss: tensor(300.1632)\n",
      "818 Traning Loss: tensor(299.4762)\n",
      "819 Traning Loss: tensor(298.7918)\n",
      "820 Traning Loss: tensor(298.1099)\n",
      "821 Traning Loss: tensor(297.4304)\n",
      "822 Traning Loss: tensor(296.7534)\n",
      "823 Traning Loss: tensor(296.0788)\n",
      "824 Traning Loss: tensor(295.4067)\n",
      "825 Traning Loss: tensor(294.7371)\n",
      "826 Traning Loss: tensor(294.0699)\n",
      "827 Traning Loss: tensor(293.4050)\n",
      "828 Traning Loss: tensor(292.7427)\n",
      "829 Traning Loss: tensor(292.0826)\n",
      "830 Traning Loss: tensor(291.4250)\n",
      "831 Traning Loss: tensor(290.7697)\n",
      "832 Traning Loss: tensor(290.1169)\n",
      "833 Traning Loss: tensor(289.4664)\n",
      "834 Traning Loss: tensor(288.8182)\n",
      "835 Traning Loss: tensor(288.1724)\n",
      "836 Traning Loss: tensor(287.5289)\n",
      "837 Traning Loss: tensor(286.8877)\n",
      "838 Traning Loss: tensor(286.2488)\n",
      "839 Traning Loss: tensor(285.6122)\n",
      "840 Traning Loss: tensor(284.9779)\n",
      "841 Traning Loss: tensor(284.3460)\n",
      "842 Traning Loss: tensor(283.7162)\n",
      "843 Traning Loss: tensor(283.0887)\n",
      "844 Traning Loss: tensor(282.4636)\n",
      "845 Traning Loss: tensor(281.8406)\n",
      "846 Traning Loss: tensor(281.2198)\n",
      "847 Traning Loss: tensor(280.6013)\n",
      "848 Traning Loss: tensor(279.9849)\n",
      "849 Traning Loss: tensor(279.3709)\n",
      "850 Traning Loss: tensor(278.7590)\n",
      "851 Traning Loss: tensor(278.1493)\n",
      "852 Traning Loss: tensor(277.5417)\n",
      "853 Traning Loss: tensor(276.9363)\n",
      "854 Traning Loss: tensor(276.3330)\n",
      "855 Traning Loss: tensor(275.7320)\n",
      "856 Traning Loss: tensor(275.1330)\n",
      "857 Traning Loss: tensor(274.5363)\n",
      "858 Traning Loss: tensor(273.9415)\n",
      "859 Traning Loss: tensor(273.3490)\n",
      "860 Traning Loss: tensor(272.7585)\n",
      "861 Traning Loss: tensor(272.1701)\n",
      "862 Traning Loss: tensor(271.5839)\n",
      "863 Traning Loss: tensor(270.9998)\n",
      "864 Traning Loss: tensor(270.4176)\n",
      "865 Traning Loss: tensor(269.8375)\n",
      "866 Traning Loss: tensor(269.2595)\n",
      "867 Traning Loss: tensor(268.6835)\n",
      "868 Traning Loss: tensor(268.1096)\n",
      "869 Traning Loss: tensor(267.5377)\n",
      "870 Traning Loss: tensor(266.9678)\n",
      "871 Traning Loss: tensor(266.4000)\n",
      "872 Traning Loss: tensor(265.8342)\n",
      "873 Traning Loss: tensor(265.2703)\n",
      "874 Traning Loss: tensor(264.7084)\n",
      "875 Traning Loss: tensor(264.1485)\n",
      "876 Traning Loss: tensor(263.5906)\n",
      "877 Traning Loss: tensor(263.0346)\n",
      "878 Traning Loss: tensor(262.4806)\n",
      "879 Traning Loss: tensor(261.9285)\n",
      "880 Traning Loss: tensor(261.3784)\n",
      "881 Traning Loss: tensor(260.8302)\n",
      "882 Traning Loss: tensor(260.2839)\n",
      "883 Traning Loss: tensor(259.7395)\n",
      "884 Traning Loss: tensor(259.1971)\n",
      "885 Traning Loss: tensor(258.6565)\n",
      "886 Traning Loss: tensor(258.1178)\n",
      "887 Traning Loss: tensor(257.5810)\n",
      "888 Traning Loss: tensor(257.0461)\n",
      "889 Traning Loss: tensor(256.5131)\n",
      "890 Traning Loss: tensor(255.9819)\n",
      "891 Traning Loss: tensor(255.4525)\n",
      "892 Traning Loss: tensor(254.9250)\n",
      "893 Traning Loss: tensor(254.3994)\n",
      "894 Traning Loss: tensor(253.8756)\n",
      "895 Traning Loss: tensor(253.3535)\n",
      "896 Traning Loss: tensor(252.8334)\n",
      "897 Traning Loss: tensor(252.3150)\n",
      "898 Traning Loss: tensor(251.7985)\n",
      "899 Traning Loss: tensor(251.2837)\n",
      "900 Traning Loss: tensor(250.7707)\n",
      "901 Traning Loss: tensor(250.2595)\n",
      "902 Traning Loss: tensor(249.7501)\n",
      "903 Traning Loss: tensor(249.2424)\n",
      "904 Traning Loss: tensor(248.7365)\n",
      "905 Traning Loss: tensor(248.2323)\n",
      "906 Traning Loss: tensor(247.7299)\n",
      "907 Traning Loss: tensor(247.2292)\n",
      "908 Traning Loss: tensor(246.7302)\n",
      "909 Traning Loss: tensor(246.2330)\n",
      "910 Traning Loss: tensor(245.7375)\n",
      "911 Traning Loss: tensor(245.2436)\n",
      "912 Traning Loss: tensor(244.7516)\n",
      "913 Traning Loss: tensor(244.2611)\n",
      "914 Traning Loss: tensor(243.7723)\n",
      "915 Traning Loss: tensor(243.2853)\n",
      "916 Traning Loss: tensor(242.7999)\n",
      "917 Traning Loss: tensor(242.3161)\n",
      "918 Traning Loss: tensor(241.8341)\n",
      "919 Traning Loss: tensor(241.3537)\n",
      "920 Traning Loss: tensor(240.8749)\n",
      "921 Traning Loss: tensor(240.3978)\n",
      "922 Traning Loss: tensor(239.9223)\n",
      "923 Traning Loss: tensor(239.4484)\n",
      "924 Traning Loss: tensor(238.9762)\n",
      "925 Traning Loss: tensor(238.5055)\n",
      "926 Traning Loss: tensor(238.0365)\n",
      "927 Traning Loss: tensor(237.5690)\n",
      "928 Traning Loss: tensor(237.1032)\n",
      "929 Traning Loss: tensor(236.6390)\n",
      "930 Traning Loss: tensor(236.1763)\n",
      "931 Traning Loss: tensor(235.7153)\n",
      "932 Traning Loss: tensor(235.2557)\n",
      "933 Traning Loss: tensor(234.7978)\n",
      "934 Traning Loss: tensor(234.3415)\n",
      "935 Traning Loss: tensor(233.8866)\n",
      "936 Traning Loss: tensor(233.4333)\n",
      "937 Traning Loss: tensor(232.9816)\n",
      "938 Traning Loss: tensor(232.5313)\n",
      "939 Traning Loss: tensor(232.0827)\n",
      "940 Traning Loss: tensor(231.6355)\n",
      "941 Traning Loss: tensor(231.1899)\n",
      "942 Traning Loss: tensor(230.7457)\n",
      "943 Traning Loss: tensor(230.3031)\n",
      "944 Traning Loss: tensor(229.8620)\n",
      "945 Traning Loss: tensor(229.4223)\n",
      "946 Traning Loss: tensor(228.9842)\n",
      "947 Traning Loss: tensor(228.5475)\n",
      "948 Traning Loss: tensor(228.1122)\n",
      "949 Traning Loss: tensor(227.6786)\n",
      "950 Traning Loss: tensor(227.2462)\n",
      "951 Traning Loss: tensor(226.8154)\n",
      "952 Traning Loss: tensor(226.3861)\n",
      "953 Traning Loss: tensor(225.9582)\n",
      "954 Traning Loss: tensor(225.5316)\n",
      "955 Traning Loss: tensor(225.1066)\n",
      "956 Traning Loss: tensor(224.6830)\n",
      "957 Traning Loss: tensor(224.2607)\n",
      "958 Traning Loss: tensor(223.8400)\n",
      "959 Traning Loss: tensor(223.4206)\n",
      "960 Traning Loss: tensor(223.0026)\n",
      "961 Traning Loss: tensor(222.5860)\n",
      "962 Traning Loss: tensor(222.1708)\n",
      "963 Traning Loss: tensor(221.7570)\n",
      "964 Traning Loss: tensor(221.3446)\n",
      "965 Traning Loss: tensor(220.9335)\n",
      "966 Traning Loss: tensor(220.5239)\n",
      "967 Traning Loss: tensor(220.1155)\n",
      "968 Traning Loss: tensor(219.7086)\n",
      "969 Traning Loss: tensor(219.3030)\n",
      "970 Traning Loss: tensor(218.8988)\n",
      "971 Traning Loss: tensor(218.4959)\n",
      "972 Traning Loss: tensor(218.0943)\n",
      "973 Traning Loss: tensor(217.6942)\n",
      "974 Traning Loss: tensor(217.2953)\n",
      "975 Traning Loss: tensor(216.8977)\n",
      "976 Traning Loss: tensor(216.5014)\n",
      "977 Traning Loss: tensor(216.1065)\n",
      "978 Traning Loss: tensor(215.7129)\n",
      "979 Traning Loss: tensor(215.3206)\n",
      "980 Traning Loss: tensor(214.9296)\n",
      "981 Traning Loss: tensor(214.5399)\n",
      "982 Traning Loss: tensor(214.1514)\n",
      "983 Traning Loss: tensor(213.7643)\n",
      "984 Traning Loss: tensor(213.3784)\n",
      "985 Traning Loss: tensor(212.9938)\n",
      "986 Traning Loss: tensor(212.6105)\n",
      "987 Traning Loss: tensor(212.2285)\n",
      "988 Traning Loss: tensor(211.8477)\n",
      "989 Traning Loss: tensor(211.4682)\n",
      "990 Traning Loss: tensor(211.0899)\n",
      "991 Traning Loss: tensor(210.7129)\n",
      "992 Traning Loss: tensor(210.3371)\n",
      "993 Traning Loss: tensor(209.9625)\n",
      "994 Traning Loss: tensor(209.5892)\n",
      "995 Traning Loss: tensor(209.2171)\n",
      "996 Traning Loss: tensor(208.8462)\n",
      "997 Traning Loss: tensor(208.4765)\n",
      "998 Traning Loss: tensor(208.1081)\n",
      "999 Traning Loss: tensor(207.7408)\n",
      "1000 Traning Loss: tensor(207.3748)\n",
      "1001 Traning Loss: tensor(207.0100)\n",
      "1002 Traning Loss: tensor(206.6463)\n",
      "1003 Traning Loss: tensor(206.2838)\n",
      "1004 Traning Loss: tensor(205.9225)\n",
      "1005 Traning Loss: tensor(205.5624)\n",
      "1006 Traning Loss: tensor(205.2035)\n",
      "1007 Traning Loss: tensor(204.8457)\n",
      "1008 Traning Loss: tensor(204.4892)\n",
      "1009 Traning Loss: tensor(204.1338)\n",
      "1010 Traning Loss: tensor(203.7794)\n",
      "1011 Traning Loss: tensor(203.4264)\n",
      "1012 Traning Loss: tensor(203.0744)\n",
      "1013 Traning Loss: tensor(202.7236)\n",
      "1014 Traning Loss: tensor(202.3739)\n",
      "1015 Traning Loss: tensor(202.0253)\n",
      "1016 Traning Loss: tensor(201.6779)\n",
      "1017 Traning Loss: tensor(201.3316)\n",
      "1018 Traning Loss: tensor(200.9865)\n",
      "1019 Traning Loss: tensor(200.6424)\n",
      "1020 Traning Loss: tensor(200.2995)\n",
      "1021 Traning Loss: tensor(199.9576)\n",
      "1022 Traning Loss: tensor(199.6169)\n",
      "1023 Traning Loss: tensor(199.2773)\n",
      "1024 Traning Loss: tensor(198.9388)\n",
      "1025 Traning Loss: tensor(198.6014)\n",
      "1026 Traning Loss: tensor(198.2650)\n",
      "1027 Traning Loss: tensor(197.9298)\n",
      "1028 Traning Loss: tensor(197.5956)\n",
      "1029 Traning Loss: tensor(197.2625)\n",
      "1030 Traning Loss: tensor(196.9305)\n",
      "1031 Traning Loss: tensor(196.5996)\n",
      "1032 Traning Loss: tensor(196.2697)\n",
      "1033 Traning Loss: tensor(195.9409)\n",
      "1034 Traning Loss: tensor(195.6131)\n",
      "1035 Traning Loss: tensor(195.2864)\n",
      "1036 Traning Loss: tensor(194.9608)\n",
      "1037 Traning Loss: tensor(194.6361)\n",
      "1038 Traning Loss: tensor(194.3125)\n",
      "1039 Traning Loss: tensor(193.9900)\n",
      "1040 Traning Loss: tensor(193.6685)\n",
      "1041 Traning Loss: tensor(193.3481)\n",
      "1042 Traning Loss: tensor(193.0286)\n",
      "1043 Traning Loss: tensor(192.7102)\n",
      "1044 Traning Loss: tensor(192.3928)\n",
      "1045 Traning Loss: tensor(192.0764)\n",
      "1046 Traning Loss: tensor(191.7610)\n",
      "1047 Traning Loss: tensor(191.4466)\n",
      "1048 Traning Loss: tensor(191.1332)\n",
      "1049 Traning Loss: tensor(190.8209)\n",
      "1050 Traning Loss: tensor(190.5095)\n",
      "1051 Traning Loss: tensor(190.1991)\n",
      "1052 Traning Loss: tensor(189.8897)\n",
      "1053 Traning Loss: tensor(189.5812)\n",
      "1054 Traning Loss: tensor(189.2738)\n",
      "1055 Traning Loss: tensor(188.9673)\n",
      "1056 Traning Loss: tensor(188.6618)\n",
      "1057 Traning Loss: tensor(188.3573)\n",
      "1058 Traning Loss: tensor(188.0538)\n",
      "1059 Traning Loss: tensor(187.7512)\n",
      "1060 Traning Loss: tensor(187.4496)\n",
      "1061 Traning Loss: tensor(187.1489)\n",
      "1062 Traning Loss: tensor(186.8492)\n",
      "1063 Traning Loss: tensor(186.5504)\n",
      "1064 Traning Loss: tensor(186.2525)\n",
      "1065 Traning Loss: tensor(185.9557)\n",
      "1066 Traning Loss: tensor(185.6597)\n",
      "1067 Traning Loss: tensor(185.3647)\n",
      "1068 Traning Loss: tensor(185.0706)\n",
      "1069 Traning Loss: tensor(184.7775)\n",
      "1070 Traning Loss: tensor(184.4853)\n",
      "1071 Traning Loss: tensor(184.1940)\n",
      "1072 Traning Loss: tensor(183.9036)\n",
      "1073 Traning Loss: tensor(183.6140)\n",
      "1074 Traning Loss: tensor(183.3255)\n",
      "1075 Traning Loss: tensor(183.0378)\n",
      "1076 Traning Loss: tensor(182.7511)\n",
      "1077 Traning Loss: tensor(182.4652)\n",
      "1078 Traning Loss: tensor(182.1803)\n",
      "1079 Traning Loss: tensor(181.8962)\n",
      "1080 Traning Loss: tensor(181.6130)\n",
      "1081 Traning Loss: tensor(181.3307)\n",
      "1082 Traning Loss: tensor(181.0493)\n",
      "1083 Traning Loss: tensor(180.7688)\n",
      "1084 Traning Loss: tensor(180.4891)\n",
      "1085 Traning Loss: tensor(180.2104)\n",
      "1086 Traning Loss: tensor(179.9325)\n",
      "1087 Traning Loss: tensor(179.6554)\n",
      "1088 Traning Loss: tensor(179.3793)\n",
      "1089 Traning Loss: tensor(179.1040)\n",
      "1090 Traning Loss: tensor(178.8295)\n",
      "1091 Traning Loss: tensor(178.5559)\n",
      "1092 Traning Loss: tensor(178.2832)\n",
      "1093 Traning Loss: tensor(178.0113)\n",
      "1094 Traning Loss: tensor(177.7402)\n",
      "1095 Traning Loss: tensor(177.4700)\n",
      "1096 Traning Loss: tensor(177.2006)\n",
      "1097 Traning Loss: tensor(176.9321)\n",
      "1098 Traning Loss: tensor(176.6644)\n",
      "1099 Traning Loss: tensor(176.3976)\n",
      "1100 Traning Loss: tensor(176.1315)\n",
      "1101 Traning Loss: tensor(175.8663)\n",
      "1102 Traning Loss: tensor(175.6019)\n",
      "1103 Traning Loss: tensor(175.3383)\n",
      "1104 Traning Loss: tensor(175.0756)\n",
      "1105 Traning Loss: tensor(174.8136)\n",
      "1106 Traning Loss: tensor(174.5525)\n",
      "1107 Traning Loss: tensor(174.2922)\n",
      "1108 Traning Loss: tensor(174.0327)\n",
      "1109 Traning Loss: tensor(173.7740)\n",
      "1110 Traning Loss: tensor(173.5160)\n",
      "1111 Traning Loss: tensor(173.2589)\n",
      "1112 Traning Loss: tensor(173.0026)\n",
      "1113 Traning Loss: tensor(172.7471)\n",
      "1114 Traning Loss: tensor(172.4923)\n",
      "1115 Traning Loss: tensor(172.2383)\n",
      "1116 Traning Loss: tensor(171.9852)\n",
      "1117 Traning Loss: tensor(171.7327)\n",
      "1118 Traning Loss: tensor(171.4811)\n",
      "1119 Traning Loss: tensor(171.2303)\n",
      "1120 Traning Loss: tensor(170.9801)\n",
      "1121 Traning Loss: tensor(170.7308)\n",
      "1122 Traning Loss: tensor(170.4823)\n",
      "1123 Traning Loss: tensor(170.2345)\n",
      "1124 Traning Loss: tensor(169.9875)\n",
      "1125 Traning Loss: tensor(169.7412)\n",
      "1126 Traning Loss: tensor(169.4957)\n",
      "1127 Traning Loss: tensor(169.2509)\n",
      "1128 Traning Loss: tensor(169.0068)\n",
      "1129 Traning Loss: tensor(168.7636)\n",
      "1130 Traning Loss: tensor(168.5211)\n",
      "1131 Traning Loss: tensor(168.2792)\n",
      "1132 Traning Loss: tensor(168.0382)\n",
      "1133 Traning Loss: tensor(167.7979)\n",
      "1134 Traning Loss: tensor(167.5583)\n",
      "1135 Traning Loss: tensor(167.3194)\n",
      "1136 Traning Loss: tensor(167.0813)\n",
      "1137 Traning Loss: tensor(166.8438)\n",
      "1138 Traning Loss: tensor(166.6071)\n",
      "1139 Traning Loss: tensor(166.3712)\n",
      "1140 Traning Loss: tensor(166.1359)\n",
      "1141 Traning Loss: tensor(165.9014)\n",
      "1142 Traning Loss: tensor(165.6676)\n",
      "1143 Traning Loss: tensor(165.4344)\n",
      "1144 Traning Loss: tensor(165.2020)\n",
      "1145 Traning Loss: tensor(164.9703)\n",
      "1146 Traning Loss: tensor(164.7393)\n",
      "1147 Traning Loss: tensor(164.5090)\n",
      "1148 Traning Loss: tensor(164.2794)\n",
      "1149 Traning Loss: tensor(164.0504)\n",
      "1150 Traning Loss: tensor(163.8222)\n",
      "1151 Traning Loss: tensor(163.5947)\n",
      "1152 Traning Loss: tensor(163.3678)\n",
      "1153 Traning Loss: tensor(163.1417)\n",
      "1154 Traning Loss: tensor(162.9162)\n",
      "1155 Traning Loss: tensor(162.6914)\n",
      "1156 Traning Loss: tensor(162.4673)\n",
      "1157 Traning Loss: tensor(162.2438)\n",
      "1158 Traning Loss: tensor(162.0210)\n",
      "1159 Traning Loss: tensor(161.7989)\n",
      "1160 Traning Loss: tensor(161.5775)\n",
      "1161 Traning Loss: tensor(161.3567)\n",
      "1162 Traning Loss: tensor(161.1366)\n",
      "1163 Traning Loss: tensor(160.9172)\n",
      "1164 Traning Loss: tensor(160.6984)\n",
      "1165 Traning Loss: tensor(160.4803)\n",
      "1166 Traning Loss: tensor(160.2628)\n",
      "1167 Traning Loss: tensor(160.0460)\n",
      "1168 Traning Loss: tensor(159.8298)\n",
      "1169 Traning Loss: tensor(159.6143)\n",
      "1170 Traning Loss: tensor(159.3994)\n",
      "1171 Traning Loss: tensor(159.1852)\n",
      "1172 Traning Loss: tensor(158.9715)\n",
      "1173 Traning Loss: tensor(158.7586)\n",
      "1174 Traning Loss: tensor(158.5463)\n",
      "1175 Traning Loss: tensor(158.3346)\n",
      "1176 Traning Loss: tensor(158.1235)\n",
      "1177 Traning Loss: tensor(157.9131)\n",
      "1178 Traning Loss: tensor(157.7032)\n",
      "1179 Traning Loss: tensor(157.4941)\n",
      "1180 Traning Loss: tensor(157.2855)\n",
      "1181 Traning Loss: tensor(157.0776)\n",
      "1182 Traning Loss: tensor(156.8703)\n",
      "1183 Traning Loss: tensor(156.6636)\n",
      "1184 Traning Loss: tensor(156.4575)\n",
      "1185 Traning Loss: tensor(156.2520)\n",
      "1186 Traning Loss: tensor(156.0471)\n",
      "1187 Traning Loss: tensor(155.8429)\n",
      "1188 Traning Loss: tensor(155.6392)\n",
      "1189 Traning Loss: tensor(155.4362)\n",
      "1190 Traning Loss: tensor(155.2337)\n",
      "1191 Traning Loss: tensor(155.0319)\n",
      "1192 Traning Loss: tensor(154.8306)\n",
      "1193 Traning Loss: tensor(154.6299)\n",
      "1194 Traning Loss: tensor(154.4299)\n",
      "1195 Traning Loss: tensor(154.2304)\n",
      "1196 Traning Loss: tensor(154.0316)\n",
      "1197 Traning Loss: tensor(153.8332)\n",
      "1198 Traning Loss: tensor(153.6355)\n",
      "1199 Traning Loss: tensor(153.4384)\n",
      "1200 Traning Loss: tensor(153.2419)\n",
      "1201 Traning Loss: tensor(153.0459)\n",
      "1202 Traning Loss: tensor(152.8504)\n",
      "1203 Traning Loss: tensor(152.6556)\n",
      "1204 Traning Loss: tensor(152.4614)\n",
      "1205 Traning Loss: tensor(152.2678)\n",
      "1206 Traning Loss: tensor(152.0747)\n",
      "1207 Traning Loss: tensor(151.8821)\n",
      "1208 Traning Loss: tensor(151.6902)\n",
      "1209 Traning Loss: tensor(151.4987)\n",
      "1210 Traning Loss: tensor(151.3079)\n",
      "1211 Traning Loss: tensor(151.1176)\n",
      "1212 Traning Loss: tensor(150.9279)\n",
      "1213 Traning Loss: tensor(150.7387)\n",
      "1214 Traning Loss: tensor(150.5501)\n",
      "1215 Traning Loss: tensor(150.3620)\n",
      "1216 Traning Loss: tensor(150.1745)\n",
      "1217 Traning Loss: tensor(149.9875)\n",
      "1218 Traning Loss: tensor(149.8011)\n",
      "1219 Traning Loss: tensor(149.6152)\n",
      "1220 Traning Loss: tensor(149.4299)\n",
      "1221 Traning Loss: tensor(149.2451)\n",
      "1222 Traning Loss: tensor(149.0608)\n",
      "1223 Traning Loss: tensor(148.8771)\n",
      "1224 Traning Loss: tensor(148.6939)\n",
      "1225 Traning Loss: tensor(148.5112)\n",
      "1226 Traning Loss: tensor(148.3291)\n",
      "1227 Traning Loss: tensor(148.1475)\n",
      "1228 Traning Loss: tensor(147.9664)\n",
      "1229 Traning Loss: tensor(147.7859)\n",
      "1230 Traning Loss: tensor(147.6059)\n",
      "1231 Traning Loss: tensor(147.4264)\n",
      "1232 Traning Loss: tensor(147.2474)\n",
      "1233 Traning Loss: tensor(147.0690)\n",
      "1234 Traning Loss: tensor(146.8910)\n",
      "1235 Traning Loss: tensor(146.7136)\n",
      "1236 Traning Loss: tensor(146.5367)\n",
      "1237 Traning Loss: tensor(146.3603)\n",
      "1238 Traning Loss: tensor(146.1844)\n",
      "1239 Traning Loss: tensor(146.0090)\n",
      "1240 Traning Loss: tensor(145.8342)\n",
      "1241 Traning Loss: tensor(145.6598)\n",
      "1242 Traning Loss: tensor(145.4859)\n",
      "1243 Traning Loss: tensor(145.3126)\n",
      "1244 Traning Loss: tensor(145.1398)\n",
      "1245 Traning Loss: tensor(144.9674)\n",
      "1246 Traning Loss: tensor(144.7955)\n",
      "1247 Traning Loss: tensor(144.6241)\n",
      "1248 Traning Loss: tensor(144.4533)\n",
      "1249 Traning Loss: tensor(144.2829)\n",
      "1250 Traning Loss: tensor(144.1130)\n",
      "1251 Traning Loss: tensor(143.9436)\n",
      "1252 Traning Loss: tensor(143.7747)\n",
      "1253 Traning Loss: tensor(143.6063)\n",
      "1254 Traning Loss: tensor(143.4383)\n",
      "1255 Traning Loss: tensor(143.2708)\n",
      "1256 Traning Loss: tensor(143.1038)\n",
      "1257 Traning Loss: tensor(142.9373)\n",
      "1258 Traning Loss: tensor(142.7713)\n",
      "1259 Traning Loss: tensor(142.6057)\n",
      "1260 Traning Loss: tensor(142.4407)\n",
      "1261 Traning Loss: tensor(142.2760)\n",
      "1262 Traning Loss: tensor(142.1119)\n",
      "1263 Traning Loss: tensor(141.9482)\n",
      "1264 Traning Loss: tensor(141.7850)\n",
      "1265 Traning Loss: tensor(141.6223)\n",
      "1266 Traning Loss: tensor(141.4600)\n",
      "1267 Traning Loss: tensor(141.2982)\n",
      "1268 Traning Loss: tensor(141.1368)\n",
      "1269 Traning Loss: tensor(140.9759)\n",
      "1270 Traning Loss: tensor(140.8155)\n",
      "1271 Traning Loss: tensor(140.6555)\n",
      "1272 Traning Loss: tensor(140.4960)\n",
      "1273 Traning Loss: tensor(140.3369)\n",
      "1274 Traning Loss: tensor(140.1783)\n",
      "1275 Traning Loss: tensor(140.0201)\n",
      "1276 Traning Loss: tensor(139.8624)\n",
      "1277 Traning Loss: tensor(139.7051)\n",
      "1278 Traning Loss: tensor(139.5483)\n",
      "1279 Traning Loss: tensor(139.3919)\n",
      "1280 Traning Loss: tensor(139.2360)\n",
      "1281 Traning Loss: tensor(139.0805)\n",
      "1282 Traning Loss: tensor(138.9254)\n",
      "1283 Traning Loss: tensor(138.7708)\n",
      "1284 Traning Loss: tensor(138.6167)\n",
      "1285 Traning Loss: tensor(138.4629)\n",
      "1286 Traning Loss: tensor(138.3096)\n",
      "1287 Traning Loss: tensor(138.1567)\n",
      "1288 Traning Loss: tensor(138.0043)\n",
      "1289 Traning Loss: tensor(137.8523)\n",
      "1290 Traning Loss: tensor(137.7007)\n",
      "1291 Traning Loss: tensor(137.5495)\n",
      "1292 Traning Loss: tensor(137.3988)\n",
      "1293 Traning Loss: tensor(137.2485)\n",
      "1294 Traning Loss: tensor(137.0986)\n",
      "1295 Traning Loss: tensor(136.9492)\n",
      "1296 Traning Loss: tensor(136.8001)\n",
      "1297 Traning Loss: tensor(136.6515)\n",
      "1298 Traning Loss: tensor(136.5033)\n",
      "1299 Traning Loss: tensor(136.3555)\n",
      "1300 Traning Loss: tensor(136.2082)\n",
      "1301 Traning Loss: tensor(136.0612)\n",
      "1302 Traning Loss: tensor(135.9147)\n",
      "1303 Traning Loss: tensor(135.7685)\n",
      "1304 Traning Loss: tensor(135.6228)\n",
      "1305 Traning Loss: tensor(135.4774)\n",
      "1306 Traning Loss: tensor(135.3326)\n",
      "1307 Traning Loss: tensor(135.1881)\n",
      "1308 Traning Loss: tensor(135.0440)\n",
      "1309 Traning Loss: tensor(134.9003)\n",
      "1310 Traning Loss: tensor(134.7570)\n",
      "1311 Traning Loss: tensor(134.6141)\n",
      "1312 Traning Loss: tensor(134.4716)\n",
      "1313 Traning Loss: tensor(134.3295)\n",
      "1314 Traning Loss: tensor(134.1878)\n",
      "1315 Traning Loss: tensor(134.0465)\n",
      "1316 Traning Loss: tensor(133.9055)\n",
      "1317 Traning Loss: tensor(133.7650)\n",
      "1318 Traning Loss: tensor(133.6249)\n",
      "1319 Traning Loss: tensor(133.4852)\n",
      "1320 Traning Loss: tensor(133.3458)\n",
      "1321 Traning Loss: tensor(133.2068)\n",
      "1322 Traning Loss: tensor(133.0683)\n",
      "1323 Traning Loss: tensor(132.9301)\n",
      "1324 Traning Loss: tensor(132.7923)\n",
      "1325 Traning Loss: tensor(132.6548)\n",
      "1326 Traning Loss: tensor(132.5178)\n",
      "1327 Traning Loss: tensor(132.3811)\n",
      "1328 Traning Loss: tensor(132.2448)\n",
      "1329 Traning Loss: tensor(132.1089)\n",
      "1330 Traning Loss: tensor(131.9733)\n",
      "1331 Traning Loss: tensor(131.8382)\n",
      "1332 Traning Loss: tensor(131.7034)\n",
      "1333 Traning Loss: tensor(131.5690)\n",
      "1334 Traning Loss: tensor(131.4349)\n",
      "1335 Traning Loss: tensor(131.3012)\n",
      "1336 Traning Loss: tensor(131.1680)\n",
      "1337 Traning Loss: tensor(131.0350)\n",
      "1338 Traning Loss: tensor(130.9024)\n",
      "1339 Traning Loss: tensor(130.7702)\n",
      "1340 Traning Loss: tensor(130.6384)\n",
      "1341 Traning Loss: tensor(130.5069)\n",
      "1342 Traning Loss: tensor(130.3758)\n",
      "1343 Traning Loss: tensor(130.2451)\n",
      "1344 Traning Loss: tensor(130.1147)\n",
      "1345 Traning Loss: tensor(129.9846)\n",
      "1346 Traning Loss: tensor(129.8549)\n",
      "1347 Traning Loss: tensor(129.7256)\n",
      "1348 Traning Loss: tensor(129.5966)\n",
      "1349 Traning Loss: tensor(129.4680)\n",
      "1350 Traning Loss: tensor(129.3398)\n",
      "1351 Traning Loss: tensor(129.2119)\n",
      "1352 Traning Loss: tensor(129.0843)\n",
      "1353 Traning Loss: tensor(128.9571)\n",
      "1354 Traning Loss: tensor(128.8302)\n",
      "1355 Traning Loss: tensor(128.7037)\n",
      "1356 Traning Loss: tensor(128.5776)\n",
      "1357 Traning Loss: tensor(128.4517)\n",
      "1358 Traning Loss: tensor(128.3262)\n",
      "1359 Traning Loss: tensor(128.2011)\n",
      "1360 Traning Loss: tensor(128.0763)\n",
      "1361 Traning Loss: tensor(127.9519)\n",
      "1362 Traning Loss: tensor(127.8277)\n",
      "1363 Traning Loss: tensor(127.7040)\n",
      "1364 Traning Loss: tensor(127.5805)\n",
      "1365 Traning Loss: tensor(127.4574)\n",
      "1366 Traning Loss: tensor(127.3346)\n",
      "1367 Traning Loss: tensor(127.2122)\n",
      "1368 Traning Loss: tensor(127.0901)\n",
      "1369 Traning Loss: tensor(126.9683)\n",
      "1370 Traning Loss: tensor(126.8469)\n",
      "1371 Traning Loss: tensor(126.7258)\n",
      "1372 Traning Loss: tensor(126.6050)\n",
      "1373 Traning Loss: tensor(126.4846)\n",
      "1374 Traning Loss: tensor(126.3644)\n",
      "1375 Traning Loss: tensor(126.2446)\n",
      "1376 Traning Loss: tensor(126.1252)\n",
      "1377 Traning Loss: tensor(126.0060)\n",
      "1378 Traning Loss: tensor(125.8872)\n",
      "1379 Traning Loss: tensor(125.7687)\n",
      "1380 Traning Loss: tensor(125.6505)\n",
      "1381 Traning Loss: tensor(125.5326)\n",
      "1382 Traning Loss: tensor(125.4151)\n",
      "1383 Traning Loss: tensor(125.2979)\n",
      "1384 Traning Loss: tensor(125.1809)\n",
      "1385 Traning Loss: tensor(125.0643)\n",
      "1386 Traning Loss: tensor(124.9480)\n",
      "1387 Traning Loss: tensor(124.8321)\n",
      "1388 Traning Loss: tensor(124.7164)\n",
      "1389 Traning Loss: tensor(124.6011)\n",
      "1390 Traning Loss: tensor(124.4860)\n",
      "1391 Traning Loss: tensor(124.3713)\n",
      "1392 Traning Loss: tensor(124.2569)\n",
      "1393 Traning Loss: tensor(124.1428)\n",
      "1394 Traning Loss: tensor(124.0290)\n",
      "1395 Traning Loss: tensor(123.9155)\n",
      "1396 Traning Loss: tensor(123.8022)\n",
      "1397 Traning Loss: tensor(123.6894)\n",
      "1398 Traning Loss: tensor(123.5768)\n",
      "1399 Traning Loss: tensor(123.4645)\n",
      "1400 Traning Loss: tensor(123.3525)\n",
      "1401 Traning Loss: tensor(123.2408)\n",
      "1402 Traning Loss: tensor(123.1294)\n",
      "1403 Traning Loss: tensor(123.0183)\n",
      "1404 Traning Loss: tensor(122.9076)\n",
      "1405 Traning Loss: tensor(122.7971)\n",
      "1406 Traning Loss: tensor(122.6869)\n",
      "1407 Traning Loss: tensor(122.5770)\n",
      "1408 Traning Loss: tensor(122.4674)\n",
      "1409 Traning Loss: tensor(122.3580)\n",
      "1410 Traning Loss: tensor(122.2490)\n",
      "1411 Traning Loss: tensor(122.1403)\n",
      "1412 Traning Loss: tensor(122.0319)\n",
      "1413 Traning Loss: tensor(121.9237)\n",
      "1414 Traning Loss: tensor(121.8158)\n",
      "1415 Traning Loss: tensor(121.7083)\n",
      "1416 Traning Loss: tensor(121.6010)\n",
      "1417 Traning Loss: tensor(121.4940)\n",
      "1418 Traning Loss: tensor(121.3872)\n",
      "1419 Traning Loss: tensor(121.2808)\n",
      "1420 Traning Loss: tensor(121.1746)\n",
      "1421 Traning Loss: tensor(121.0688)\n",
      "1422 Traning Loss: tensor(120.9632)\n",
      "1423 Traning Loss: tensor(120.8578)\n",
      "1424 Traning Loss: tensor(120.7528)\n",
      "1425 Traning Loss: tensor(120.6480)\n",
      "1426 Traning Loss: tensor(120.5436)\n",
      "1427 Traning Loss: tensor(120.4394)\n",
      "1428 Traning Loss: tensor(120.3354)\n",
      "1429 Traning Loss: tensor(120.2318)\n",
      "1430 Traning Loss: tensor(120.1284)\n",
      "1431 Traning Loss: tensor(120.0253)\n",
      "1432 Traning Loss: tensor(119.9225)\n",
      "1433 Traning Loss: tensor(119.8199)\n",
      "1434 Traning Loss: tensor(119.7176)\n",
      "1435 Traning Loss: tensor(119.6156)\n",
      "1436 Traning Loss: tensor(119.5138)\n",
      "1437 Traning Loss: tensor(119.4124)\n",
      "1438 Traning Loss: tensor(119.3111)\n",
      "1439 Traning Loss: tensor(119.2102)\n",
      "1440 Traning Loss: tensor(119.1095)\n",
      "1441 Traning Loss: tensor(119.0091)\n",
      "1442 Traning Loss: tensor(118.9089)\n",
      "1443 Traning Loss: tensor(118.8091)\n",
      "1444 Traning Loss: tensor(118.7094)\n",
      "1445 Traning Loss: tensor(118.6100)\n",
      "1446 Traning Loss: tensor(118.5109)\n",
      "1447 Traning Loss: tensor(118.4121)\n",
      "1448 Traning Loss: tensor(118.3135)\n",
      "1449 Traning Loss: tensor(118.2152)\n",
      "1450 Traning Loss: tensor(118.1171)\n",
      "1451 Traning Loss: tensor(118.0193)\n",
      "1452 Traning Loss: tensor(117.9217)\n",
      "1453 Traning Loss: tensor(117.8244)\n",
      "1454 Traning Loss: tensor(117.7274)\n",
      "1455 Traning Loss: tensor(117.6306)\n",
      "1456 Traning Loss: tensor(117.5341)\n",
      "1457 Traning Loss: tensor(117.4378)\n",
      "1458 Traning Loss: tensor(117.3417)\n",
      "1459 Traning Loss: tensor(117.2460)\n",
      "1460 Traning Loss: tensor(117.1504)\n",
      "1461 Traning Loss: tensor(117.0551)\n",
      "1462 Traning Loss: tensor(116.9601)\n",
      "1463 Traning Loss: tensor(116.8653)\n",
      "1464 Traning Loss: tensor(116.7708)\n",
      "1465 Traning Loss: tensor(116.6765)\n",
      "1466 Traning Loss: tensor(116.5824)\n",
      "1467 Traning Loss: tensor(116.4886)\n",
      "1468 Traning Loss: tensor(116.3950)\n",
      "1469 Traning Loss: tensor(116.3017)\n",
      "1470 Traning Loss: tensor(116.2086)\n",
      "1471 Traning Loss: tensor(116.1158)\n",
      "1472 Traning Loss: tensor(116.0232)\n",
      "1473 Traning Loss: tensor(115.9308)\n",
      "1474 Traning Loss: tensor(115.8387)\n",
      "1475 Traning Loss: tensor(115.7469)\n",
      "1476 Traning Loss: tensor(115.6552)\n",
      "1477 Traning Loss: tensor(115.5638)\n",
      "1478 Traning Loss: tensor(115.4726)\n",
      "1479 Traning Loss: tensor(115.3817)\n",
      "1480 Traning Loss: tensor(115.2910)\n",
      "1481 Traning Loss: tensor(115.2006)\n",
      "1482 Traning Loss: tensor(115.1103)\n",
      "1483 Traning Loss: tensor(115.0204)\n",
      "1484 Traning Loss: tensor(114.9306)\n",
      "1485 Traning Loss: tensor(114.8411)\n",
      "1486 Traning Loss: tensor(114.7518)\n",
      "1487 Traning Loss: tensor(114.6627)\n",
      "1488 Traning Loss: tensor(114.5739)\n",
      "1489 Traning Loss: tensor(114.4853)\n",
      "1490 Traning Loss: tensor(114.3969)\n",
      "1491 Traning Loss: tensor(114.3087)\n",
      "1492 Traning Loss: tensor(114.2208)\n",
      "1493 Traning Loss: tensor(114.1331)\n",
      "1494 Traning Loss: tensor(114.0456)\n",
      "1495 Traning Loss: tensor(113.9583)\n",
      "1496 Traning Loss: tensor(113.8713)\n",
      "1497 Traning Loss: tensor(113.7845)\n",
      "1498 Traning Loss: tensor(113.6979)\n",
      "1499 Traning Loss: tensor(113.6116)\n",
      "1500 Traning Loss: tensor(113.5255)\n",
      "1501 Traning Loss: tensor(113.4395)\n",
      "1502 Traning Loss: tensor(113.3539)\n",
      "1503 Traning Loss: tensor(113.2684)\n",
      "1504 Traning Loss: tensor(113.1831)\n",
      "1505 Traning Loss: tensor(113.0981)\n",
      "1506 Traning Loss: tensor(113.0133)\n",
      "1507 Traning Loss: tensor(112.9287)\n",
      "1508 Traning Loss: tensor(112.8443)\n",
      "1509 Traning Loss: tensor(112.7601)\n",
      "1510 Traning Loss: tensor(112.6761)\n",
      "1511 Traning Loss: tensor(112.5924)\n",
      "1512 Traning Loss: tensor(112.5089)\n",
      "1513 Traning Loss: tensor(112.4256)\n",
      "1514 Traning Loss: tensor(112.3424)\n",
      "1515 Traning Loss: tensor(112.2596)\n",
      "1516 Traning Loss: tensor(112.1769)\n",
      "1517 Traning Loss: tensor(112.0944)\n",
      "1518 Traning Loss: tensor(112.0121)\n",
      "1519 Traning Loss: tensor(111.9301)\n",
      "1520 Traning Loss: tensor(111.8483)\n",
      "1521 Traning Loss: tensor(111.7666)\n",
      "1522 Traning Loss: tensor(111.6852)\n",
      "1523 Traning Loss: tensor(111.6040)\n",
      "1524 Traning Loss: tensor(111.5229)\n",
      "1525 Traning Loss: tensor(111.4421)\n",
      "1526 Traning Loss: tensor(111.3615)\n",
      "1527 Traning Loss: tensor(111.2811)\n",
      "1528 Traning Loss: tensor(111.2009)\n",
      "1529 Traning Loss: tensor(111.1209)\n",
      "1530 Traning Loss: tensor(111.0411)\n",
      "1531 Traning Loss: tensor(110.9615)\n",
      "1532 Traning Loss: tensor(110.8822)\n",
      "1533 Traning Loss: tensor(110.8030)\n",
      "1534 Traning Loss: tensor(110.7240)\n",
      "1535 Traning Loss: tensor(110.6452)\n",
      "1536 Traning Loss: tensor(110.5666)\n",
      "1537 Traning Loss: tensor(110.4882)\n",
      "1538 Traning Loss: tensor(110.4100)\n",
      "1539 Traning Loss: tensor(110.3320)\n",
      "1540 Traning Loss: tensor(110.2542)\n",
      "1541 Traning Loss: tensor(110.1766)\n",
      "1542 Traning Loss: tensor(110.0992)\n",
      "1543 Traning Loss: tensor(110.0220)\n",
      "1544 Traning Loss: tensor(109.9450)\n",
      "1545 Traning Loss: tensor(109.8681)\n",
      "1546 Traning Loss: tensor(109.7915)\n",
      "1547 Traning Loss: tensor(109.7151)\n",
      "1548 Traning Loss: tensor(109.6388)\n",
      "1549 Traning Loss: tensor(109.5628)\n",
      "1550 Traning Loss: tensor(109.4869)\n",
      "1551 Traning Loss: tensor(109.4113)\n",
      "1552 Traning Loss: tensor(109.3358)\n",
      "1553 Traning Loss: tensor(109.2605)\n",
      "1554 Traning Loss: tensor(109.1853)\n",
      "1555 Traning Loss: tensor(109.1105)\n",
      "1556 Traning Loss: tensor(109.0357)\n",
      "1557 Traning Loss: tensor(108.9612)\n",
      "1558 Traning Loss: tensor(108.8868)\n",
      "1559 Traning Loss: tensor(108.8126)\n",
      "1560 Traning Loss: tensor(108.7387)\n",
      "1561 Traning Loss: tensor(108.6648)\n",
      "1562 Traning Loss: tensor(108.5912)\n",
      "1563 Traning Loss: tensor(108.5178)\n",
      "1564 Traning Loss: tensor(108.4445)\n",
      "1565 Traning Loss: tensor(108.3715)\n",
      "1566 Traning Loss: tensor(108.2986)\n",
      "1567 Traning Loss: tensor(108.2259)\n",
      "1568 Traning Loss: tensor(108.1533)\n",
      "1569 Traning Loss: tensor(108.0810)\n",
      "1570 Traning Loss: tensor(108.0088)\n",
      "1571 Traning Loss: tensor(107.9368)\n",
      "1572 Traning Loss: tensor(107.8650)\n",
      "1573 Traning Loss: tensor(107.7934)\n",
      "1574 Traning Loss: tensor(107.7220)\n",
      "1575 Traning Loss: tensor(107.6507)\n",
      "1576 Traning Loss: tensor(107.5796)\n",
      "1577 Traning Loss: tensor(107.5087)\n",
      "1578 Traning Loss: tensor(107.4380)\n",
      "1579 Traning Loss: tensor(107.3674)\n",
      "1580 Traning Loss: tensor(107.2970)\n",
      "1581 Traning Loss: tensor(107.2268)\n",
      "1582 Traning Loss: tensor(107.1568)\n",
      "1583 Traning Loss: tensor(107.0869)\n",
      "1584 Traning Loss: tensor(107.0172)\n",
      "1585 Traning Loss: tensor(106.9477)\n",
      "1586 Traning Loss: tensor(106.8783)\n",
      "1587 Traning Loss: tensor(106.8091)\n",
      "1588 Traning Loss: tensor(106.7401)\n",
      "1589 Traning Loss: tensor(106.6713)\n",
      "1590 Traning Loss: tensor(106.6026)\n",
      "1591 Traning Loss: tensor(106.5341)\n",
      "1592 Traning Loss: tensor(106.4657)\n",
      "1593 Traning Loss: tensor(106.3976)\n",
      "1594 Traning Loss: tensor(106.3296)\n",
      "1595 Traning Loss: tensor(106.2618)\n",
      "1596 Traning Loss: tensor(106.1941)\n",
      "1597 Traning Loss: tensor(106.1266)\n",
      "1598 Traning Loss: tensor(106.0592)\n",
      "1599 Traning Loss: tensor(105.9921)\n",
      "1600 Traning Loss: tensor(105.9251)\n",
      "1601 Traning Loss: tensor(105.8583)\n",
      "1602 Traning Loss: tensor(105.7916)\n",
      "1603 Traning Loss: tensor(105.7251)\n",
      "1604 Traning Loss: tensor(105.6588)\n",
      "1605 Traning Loss: tensor(105.5926)\n",
      "1606 Traning Loss: tensor(105.5266)\n",
      "1607 Traning Loss: tensor(105.4607)\n",
      "1608 Traning Loss: tensor(105.3950)\n",
      "1609 Traning Loss: tensor(105.3295)\n",
      "1610 Traning Loss: tensor(105.2641)\n",
      "1611 Traning Loss: tensor(105.1989)\n",
      "1612 Traning Loss: tensor(105.1338)\n",
      "1613 Traning Loss: tensor(105.0689)\n",
      "1614 Traning Loss: tensor(105.0042)\n",
      "1615 Traning Loss: tensor(104.9396)\n",
      "1616 Traning Loss: tensor(104.8752)\n",
      "1617 Traning Loss: tensor(104.8110)\n",
      "1618 Traning Loss: tensor(104.7468)\n",
      "1619 Traning Loss: tensor(104.6829)\n",
      "1620 Traning Loss: tensor(104.6191)\n",
      "1621 Traning Loss: tensor(104.5554)\n",
      "1622 Traning Loss: tensor(104.4920)\n",
      "1623 Traning Loss: tensor(104.4286)\n",
      "1624 Traning Loss: tensor(104.3655)\n",
      "1625 Traning Loss: tensor(104.3024)\n",
      "1626 Traning Loss: tensor(104.2396)\n",
      "1627 Traning Loss: tensor(104.1768)\n",
      "1628 Traning Loss: tensor(104.1143)\n",
      "1629 Traning Loss: tensor(104.0518)\n",
      "1630 Traning Loss: tensor(103.9896)\n",
      "1631 Traning Loss: tensor(103.9275)\n",
      "1632 Traning Loss: tensor(103.8655)\n",
      "1633 Traning Loss: tensor(103.8037)\n",
      "1634 Traning Loss: tensor(103.7420)\n",
      "1635 Traning Loss: tensor(103.6805)\n",
      "1636 Traning Loss: tensor(103.6192)\n",
      "1637 Traning Loss: tensor(103.5580)\n",
      "1638 Traning Loss: tensor(103.4969)\n",
      "1639 Traning Loss: tensor(103.4360)\n",
      "1640 Traning Loss: tensor(103.3752)\n",
      "1641 Traning Loss: tensor(103.3146)\n",
      "1642 Traning Loss: tensor(103.2541)\n",
      "1643 Traning Loss: tensor(103.1938)\n",
      "1644 Traning Loss: tensor(103.1336)\n",
      "1645 Traning Loss: tensor(103.0735)\n",
      "1646 Traning Loss: tensor(103.0136)\n",
      "1647 Traning Loss: tensor(102.9539)\n",
      "1648 Traning Loss: tensor(102.8943)\n",
      "1649 Traning Loss: tensor(102.8348)\n",
      "1650 Traning Loss: tensor(102.7755)\n",
      "1651 Traning Loss: tensor(102.7163)\n",
      "1652 Traning Loss: tensor(102.6573)\n",
      "1653 Traning Loss: tensor(102.5984)\n",
      "1654 Traning Loss: tensor(102.5396)\n",
      "1655 Traning Loss: tensor(102.4810)\n",
      "1656 Traning Loss: tensor(102.4225)\n",
      "1657 Traning Loss: tensor(102.3642)\n",
      "1658 Traning Loss: tensor(102.3060)\n",
      "1659 Traning Loss: tensor(102.2480)\n",
      "1660 Traning Loss: tensor(102.1900)\n",
      "1661 Traning Loss: tensor(102.1322)\n",
      "1662 Traning Loss: tensor(102.0746)\n",
      "1663 Traning Loss: tensor(102.0171)\n",
      "1664 Traning Loss: tensor(101.9597)\n",
      "1665 Traning Loss: tensor(101.9025)\n",
      "1666 Traning Loss: tensor(101.8455)\n",
      "1667 Traning Loss: tensor(101.7885)\n",
      "1668 Traning Loss: tensor(101.7317)\n",
      "1669 Traning Loss: tensor(101.6750)\n",
      "1670 Traning Loss: tensor(101.6185)\n",
      "1671 Traning Loss: tensor(101.5621)\n",
      "1672 Traning Loss: tensor(101.5058)\n",
      "1673 Traning Loss: tensor(101.4497)\n",
      "1674 Traning Loss: tensor(101.3936)\n",
      "1675 Traning Loss: tensor(101.3378)\n",
      "1676 Traning Loss: tensor(101.2820)\n",
      "1677 Traning Loss: tensor(101.2264)\n",
      "1678 Traning Loss: tensor(101.1710)\n",
      "1679 Traning Loss: tensor(101.1156)\n",
      "1680 Traning Loss: tensor(101.0604)\n",
      "1681 Traning Loss: tensor(101.0053)\n",
      "1682 Traning Loss: tensor(100.9504)\n",
      "1683 Traning Loss: tensor(100.8955)\n",
      "1684 Traning Loss: tensor(100.8409)\n",
      "1685 Traning Loss: tensor(100.7863)\n",
      "1686 Traning Loss: tensor(100.7318)\n",
      "1687 Traning Loss: tensor(100.6776)\n",
      "1688 Traning Loss: tensor(100.6234)\n",
      "1689 Traning Loss: tensor(100.5694)\n",
      "1690 Traning Loss: tensor(100.5154)\n",
      "1691 Traning Loss: tensor(100.4616)\n",
      "1692 Traning Loss: tensor(100.4080)\n",
      "1693 Traning Loss: tensor(100.3544)\n",
      "1694 Traning Loss: tensor(100.3010)\n",
      "1695 Traning Loss: tensor(100.2478)\n",
      "1696 Traning Loss: tensor(100.1946)\n",
      "1697 Traning Loss: tensor(100.1416)\n",
      "1698 Traning Loss: tensor(100.0887)\n",
      "1699 Traning Loss: tensor(100.0359)\n",
      "1700 Traning Loss: tensor(99.9832)\n",
      "1701 Traning Loss: tensor(99.9307)\n",
      "1702 Traning Loss: tensor(99.8783)\n",
      "1703 Traning Loss: tensor(99.8260)\n",
      "1704 Traning Loss: tensor(99.7738)\n",
      "1705 Traning Loss: tensor(99.7218)\n",
      "1706 Traning Loss: tensor(99.6699)\n",
      "1707 Traning Loss: tensor(99.6181)\n",
      "1708 Traning Loss: tensor(99.5664)\n",
      "1709 Traning Loss: tensor(99.5148)\n",
      "1710 Traning Loss: tensor(99.4634)\n",
      "1711 Traning Loss: tensor(99.4121)\n",
      "1712 Traning Loss: tensor(99.3609)\n",
      "1713 Traning Loss: tensor(99.3098)\n",
      "1714 Traning Loss: tensor(99.2589)\n",
      "1715 Traning Loss: tensor(99.2080)\n",
      "1716 Traning Loss: tensor(99.1573)\n",
      "1717 Traning Loss: tensor(99.1068)\n",
      "1718 Traning Loss: tensor(99.0563)\n",
      "1719 Traning Loss: tensor(99.0059)\n",
      "1720 Traning Loss: tensor(98.9557)\n",
      "1721 Traning Loss: tensor(98.9055)\n",
      "1722 Traning Loss: tensor(98.8555)\n",
      "1723 Traning Loss: tensor(98.8057)\n",
      "1724 Traning Loss: tensor(98.7559)\n",
      "1725 Traning Loss: tensor(98.7062)\n",
      "1726 Traning Loss: tensor(98.6567)\n",
      "1727 Traning Loss: tensor(98.6073)\n",
      "1728 Traning Loss: tensor(98.5580)\n",
      "1729 Traning Loss: tensor(98.5088)\n",
      "1730 Traning Loss: tensor(98.4597)\n",
      "1731 Traning Loss: tensor(98.4107)\n",
      "1732 Traning Loss: tensor(98.3619)\n",
      "1733 Traning Loss: tensor(98.3131)\n",
      "1734 Traning Loss: tensor(98.2645)\n",
      "1735 Traning Loss: tensor(98.2160)\n",
      "1736 Traning Loss: tensor(98.1676)\n",
      "1737 Traning Loss: tensor(98.1193)\n",
      "1738 Traning Loss: tensor(98.0711)\n",
      "1739 Traning Loss: tensor(98.0230)\n",
      "1740 Traning Loss: tensor(97.9751)\n",
      "1741 Traning Loss: tensor(97.9273)\n",
      "1742 Traning Loss: tensor(97.8795)\n",
      "1743 Traning Loss: tensor(97.8319)\n",
      "1744 Traning Loss: tensor(97.7844)\n",
      "1745 Traning Loss: tensor(97.7370)\n",
      "1746 Traning Loss: tensor(97.6897)\n",
      "1747 Traning Loss: tensor(97.6425)\n",
      "1748 Traning Loss: tensor(97.5954)\n",
      "1749 Traning Loss: tensor(97.5485)\n",
      "1750 Traning Loss: tensor(97.5016)\n",
      "1751 Traning Loss: tensor(97.4549)\n",
      "1752 Traning Loss: tensor(97.4082)\n",
      "1753 Traning Loss: tensor(97.3617)\n",
      "1754 Traning Loss: tensor(97.3153)\n",
      "1755 Traning Loss: tensor(97.2690)\n",
      "1756 Traning Loss: tensor(97.2228)\n",
      "1757 Traning Loss: tensor(97.1767)\n",
      "1758 Traning Loss: tensor(97.1306)\n",
      "1759 Traning Loss: tensor(97.0848)\n",
      "1760 Traning Loss: tensor(97.0390)\n",
      "1761 Traning Loss: tensor(96.9933)\n",
      "1762 Traning Loss: tensor(96.9477)\n",
      "1763 Traning Loss: tensor(96.9023)\n",
      "1764 Traning Loss: tensor(96.8569)\n",
      "1765 Traning Loss: tensor(96.8116)\n",
      "1766 Traning Loss: tensor(96.7664)\n",
      "1767 Traning Loss: tensor(96.7214)\n",
      "1768 Traning Loss: tensor(96.6764)\n",
      "1769 Traning Loss: tensor(96.6316)\n",
      "1770 Traning Loss: tensor(96.5868)\n",
      "1771 Traning Loss: tensor(96.5422)\n",
      "1772 Traning Loss: tensor(96.4976)\n",
      "1773 Traning Loss: tensor(96.4532)\n",
      "1774 Traning Loss: tensor(96.4088)\n",
      "1775 Traning Loss: tensor(96.3646)\n",
      "1776 Traning Loss: tensor(96.3205)\n",
      "1777 Traning Loss: tensor(96.2765)\n",
      "1778 Traning Loss: tensor(96.2325)\n",
      "1779 Traning Loss: tensor(96.1887)\n",
      "1780 Traning Loss: tensor(96.1449)\n",
      "1781 Traning Loss: tensor(96.1013)\n",
      "1782 Traning Loss: tensor(96.0577)\n",
      "1783 Traning Loss: tensor(96.0143)\n",
      "1784 Traning Loss: tensor(95.9710)\n",
      "1785 Traning Loss: tensor(95.9278)\n",
      "1786 Traning Loss: tensor(95.8846)\n",
      "1787 Traning Loss: tensor(95.8416)\n",
      "1788 Traning Loss: tensor(95.7986)\n",
      "1789 Traning Loss: tensor(95.7558)\n",
      "1790 Traning Loss: tensor(95.7130)\n",
      "1791 Traning Loss: tensor(95.6704)\n",
      "1792 Traning Loss: tensor(95.6278)\n",
      "1793 Traning Loss: tensor(95.5853)\n",
      "1794 Traning Loss: tensor(95.5430)\n",
      "1795 Traning Loss: tensor(95.5007)\n",
      "1796 Traning Loss: tensor(95.4585)\n",
      "1797 Traning Loss: tensor(95.4165)\n",
      "1798 Traning Loss: tensor(95.3745)\n",
      "1799 Traning Loss: tensor(95.3326)\n",
      "1800 Traning Loss: tensor(95.2908)\n",
      "1801 Traning Loss: tensor(95.2491)\n",
      "1802 Traning Loss: tensor(95.2075)\n",
      "1803 Traning Loss: tensor(95.1660)\n",
      "1804 Traning Loss: tensor(95.1246)\n",
      "1805 Traning Loss: tensor(95.0833)\n",
      "1806 Traning Loss: tensor(95.0420)\n",
      "1807 Traning Loss: tensor(95.0009)\n",
      "1808 Traning Loss: tensor(94.9598)\n",
      "1809 Traning Loss: tensor(94.9189)\n",
      "1810 Traning Loss: tensor(94.8780)\n",
      "1811 Traning Loss: tensor(94.8373)\n",
      "1812 Traning Loss: tensor(94.7966)\n",
      "1813 Traning Loss: tensor(94.7560)\n",
      "1814 Traning Loss: tensor(94.7155)\n",
      "1815 Traning Loss: tensor(94.6751)\n",
      "1816 Traning Loss: tensor(94.6348)\n",
      "1817 Traning Loss: tensor(94.5946)\n",
      "1818 Traning Loss: tensor(94.5545)\n",
      "1819 Traning Loss: tensor(94.5144)\n",
      "1820 Traning Loss: tensor(94.4745)\n",
      "1821 Traning Loss: tensor(94.4346)\n",
      "1822 Traning Loss: tensor(94.3948)\n",
      "1823 Traning Loss: tensor(94.3552)\n",
      "1824 Traning Loss: tensor(94.3156)\n",
      "1825 Traning Loss: tensor(94.2761)\n",
      "1826 Traning Loss: tensor(94.2366)\n",
      "1827 Traning Loss: tensor(94.1973)\n",
      "1828 Traning Loss: tensor(94.1581)\n",
      "1829 Traning Loss: tensor(94.1189)\n",
      "1830 Traning Loss: tensor(94.0799)\n",
      "1831 Traning Loss: tensor(94.0409)\n",
      "1832 Traning Loss: tensor(94.0020)\n",
      "1833 Traning Loss: tensor(93.9632)\n",
      "1834 Traning Loss: tensor(93.9245)\n",
      "1835 Traning Loss: tensor(93.8858)\n",
      "1836 Traning Loss: tensor(93.8473)\n",
      "1837 Traning Loss: tensor(93.8088)\n",
      "1838 Traning Loss: tensor(93.7705)\n",
      "1839 Traning Loss: tensor(93.7322)\n",
      "1840 Traning Loss: tensor(93.6939)\n",
      "1841 Traning Loss: tensor(93.6559)\n",
      "1842 Traning Loss: tensor(93.6178)\n",
      "1843 Traning Loss: tensor(93.5798)\n",
      "1844 Traning Loss: tensor(93.5420)\n",
      "1845 Traning Loss: tensor(93.5042)\n",
      "1846 Traning Loss: tensor(93.4665)\n",
      "1847 Traning Loss: tensor(93.4289)\n",
      "1848 Traning Loss: tensor(93.3914)\n",
      "1849 Traning Loss: tensor(93.3539)\n",
      "1850 Traning Loss: tensor(93.3166)\n",
      "1851 Traning Loss: tensor(93.2793)\n",
      "1852 Traning Loss: tensor(93.2421)\n",
      "1853 Traning Loss: tensor(93.2050)\n",
      "1854 Traning Loss: tensor(93.1679)\n",
      "1855 Traning Loss: tensor(93.1310)\n",
      "1856 Traning Loss: tensor(93.0941)\n",
      "1857 Traning Loss: tensor(93.0573)\n",
      "1858 Traning Loss: tensor(93.0206)\n",
      "1859 Traning Loss: tensor(92.9840)\n",
      "1860 Traning Loss: tensor(92.9475)\n",
      "1861 Traning Loss: tensor(92.9110)\n",
      "1862 Traning Loss: tensor(92.8746)\n",
      "1863 Traning Loss: tensor(92.8383)\n",
      "1864 Traning Loss: tensor(92.8021)\n",
      "1865 Traning Loss: tensor(92.7659)\n",
      "1866 Traning Loss: tensor(92.7299)\n",
      "1867 Traning Loss: tensor(92.6939)\n",
      "1868 Traning Loss: tensor(92.6580)\n",
      "1869 Traning Loss: tensor(92.6222)\n",
      "1870 Traning Loss: tensor(92.5864)\n",
      "1871 Traning Loss: tensor(92.5507)\n",
      "1872 Traning Loss: tensor(92.5151)\n",
      "1873 Traning Loss: tensor(92.4796)\n",
      "1874 Traning Loss: tensor(92.4442)\n",
      "1875 Traning Loss: tensor(92.4088)\n",
      "1876 Traning Loss: tensor(92.3736)\n",
      "1877 Traning Loss: tensor(92.3383)\n",
      "1878 Traning Loss: tensor(92.3032)\n",
      "1879 Traning Loss: tensor(92.2682)\n",
      "1880 Traning Loss: tensor(92.2332)\n",
      "1881 Traning Loss: tensor(92.1983)\n",
      "1882 Traning Loss: tensor(92.1635)\n",
      "1883 Traning Loss: tensor(92.1287)\n",
      "1884 Traning Loss: tensor(92.0941)\n",
      "1885 Traning Loss: tensor(92.0595)\n",
      "1886 Traning Loss: tensor(92.0250)\n",
      "1887 Traning Loss: tensor(91.9905)\n",
      "1888 Traning Loss: tensor(91.9561)\n",
      "1889 Traning Loss: tensor(91.9218)\n",
      "1890 Traning Loss: tensor(91.8876)\n",
      "1891 Traning Loss: tensor(91.8535)\n",
      "1892 Traning Loss: tensor(91.8194)\n",
      "1893 Traning Loss: tensor(91.7854)\n",
      "1894 Traning Loss: tensor(91.7515)\n",
      "1895 Traning Loss: tensor(91.7177)\n",
      "1896 Traning Loss: tensor(91.6839)\n",
      "1897 Traning Loss: tensor(91.6502)\n",
      "1898 Traning Loss: tensor(91.6165)\n",
      "1899 Traning Loss: tensor(91.5830)\n",
      "1900 Traning Loss: tensor(91.5495)\n",
      "1901 Traning Loss: tensor(91.5161)\n",
      "1902 Traning Loss: tensor(91.4828)\n",
      "1903 Traning Loss: tensor(91.4495)\n",
      "1904 Traning Loss: tensor(91.4164)\n",
      "1905 Traning Loss: tensor(91.3832)\n",
      "1906 Traning Loss: tensor(91.3502)\n",
      "1907 Traning Loss: tensor(91.3172)\n",
      "1908 Traning Loss: tensor(91.2843)\n",
      "1909 Traning Loss: tensor(91.2515)\n",
      "1910 Traning Loss: tensor(91.2187)\n",
      "1911 Traning Loss: tensor(91.1860)\n",
      "1912 Traning Loss: tensor(91.1534)\n",
      "1913 Traning Loss: tensor(91.1208)\n",
      "1914 Traning Loss: tensor(91.0884)\n",
      "1915 Traning Loss: tensor(91.0559)\n",
      "1916 Traning Loss: tensor(91.0236)\n",
      "1917 Traning Loss: tensor(90.9913)\n",
      "1918 Traning Loss: tensor(90.9591)\n",
      "1919 Traning Loss: tensor(90.9270)\n",
      "1920 Traning Loss: tensor(90.8949)\n",
      "1921 Traning Loss: tensor(90.8629)\n",
      "1922 Traning Loss: tensor(90.8310)\n",
      "1923 Traning Loss: tensor(90.7992)\n",
      "1924 Traning Loss: tensor(90.7674)\n",
      "1925 Traning Loss: tensor(90.7356)\n",
      "1926 Traning Loss: tensor(90.7040)\n",
      "1927 Traning Loss: tensor(90.6724)\n",
      "1928 Traning Loss: tensor(90.6409)\n",
      "1929 Traning Loss: tensor(90.6095)\n",
      "1930 Traning Loss: tensor(90.5781)\n",
      "1931 Traning Loss: tensor(90.5468)\n",
      "1932 Traning Loss: tensor(90.5155)\n",
      "1933 Traning Loss: tensor(90.4843)\n",
      "1934 Traning Loss: tensor(90.4532)\n",
      "1935 Traning Loss: tensor(90.4222)\n",
      "1936 Traning Loss: tensor(90.3912)\n",
      "1937 Traning Loss: tensor(90.3603)\n",
      "1938 Traning Loss: tensor(90.3294)\n",
      "1939 Traning Loss: tensor(90.2986)\n",
      "1940 Traning Loss: tensor(90.2679)\n",
      "1941 Traning Loss: tensor(90.2373)\n",
      "1942 Traning Loss: tensor(90.2067)\n",
      "1943 Traning Loss: tensor(90.1762)\n",
      "1944 Traning Loss: tensor(90.1457)\n",
      "1945 Traning Loss: tensor(90.1153)\n",
      "1946 Traning Loss: tensor(90.0850)\n",
      "1947 Traning Loss: tensor(90.0548)\n",
      "1948 Traning Loss: tensor(90.0246)\n",
      "1949 Traning Loss: tensor(89.9944)\n",
      "1950 Traning Loss: tensor(89.9644)\n",
      "1951 Traning Loss: tensor(89.9344)\n",
      "1952 Traning Loss: tensor(89.9044)\n",
      "1953 Traning Loss: tensor(89.8746)\n",
      "1954 Traning Loss: tensor(89.8447)\n",
      "1955 Traning Loss: tensor(89.8150)\n",
      "1956 Traning Loss: tensor(89.7853)\n",
      "1957 Traning Loss: tensor(89.7557)\n",
      "1958 Traning Loss: tensor(89.7261)\n",
      "1959 Traning Loss: tensor(89.6966)\n",
      "1960 Traning Loss: tensor(89.6672)\n",
      "1961 Traning Loss: tensor(89.6378)\n",
      "1962 Traning Loss: tensor(89.6085)\n",
      "1963 Traning Loss: tensor(89.5792)\n",
      "1964 Traning Loss: tensor(89.5500)\n",
      "1965 Traning Loss: tensor(89.5209)\n",
      "1966 Traning Loss: tensor(89.4918)\n",
      "1967 Traning Loss: tensor(89.4628)\n",
      "1968 Traning Loss: tensor(89.4339)\n",
      "1969 Traning Loss: tensor(89.4050)\n",
      "1970 Traning Loss: tensor(89.3762)\n",
      "1971 Traning Loss: tensor(89.3474)\n",
      "1972 Traning Loss: tensor(89.3187)\n",
      "1973 Traning Loss: tensor(89.2901)\n",
      "1974 Traning Loss: tensor(89.2615)\n",
      "1975 Traning Loss: tensor(89.2330)\n",
      "1976 Traning Loss: tensor(89.2045)\n",
      "1977 Traning Loss: tensor(89.1761)\n",
      "1978 Traning Loss: tensor(89.1478)\n",
      "1979 Traning Loss: tensor(89.1195)\n",
      "1980 Traning Loss: tensor(89.0913)\n",
      "1981 Traning Loss: tensor(89.0631)\n",
      "1982 Traning Loss: tensor(89.0350)\n",
      "1983 Traning Loss: tensor(89.0070)\n",
      "1984 Traning Loss: tensor(88.9790)\n",
      "1985 Traning Loss: tensor(88.9511)\n",
      "1986 Traning Loss: tensor(88.9232)\n",
      "1987 Traning Loss: tensor(88.8954)\n",
      "1988 Traning Loss: tensor(88.8677)\n",
      "1989 Traning Loss: tensor(88.8399)\n",
      "1990 Traning Loss: tensor(88.8123)\n",
      "1991 Traning Loss: tensor(88.7847)\n",
      "1992 Traning Loss: tensor(88.7572)\n",
      "1993 Traning Loss: tensor(88.7298)\n",
      "1994 Traning Loss: tensor(88.7023)\n",
      "1995 Traning Loss: tensor(88.6750)\n",
      "1996 Traning Loss: tensor(88.6477)\n",
      "1997 Traning Loss: tensor(88.6205)\n",
      "1998 Traning Loss: tensor(88.5933)\n",
      "1999 Traning Loss: tensor(88.5662)\n",
      "2000 Traning Loss: tensor(88.5391)\n",
      "2001 Traning Loss: tensor(88.5121)\n",
      "2002 Traning Loss: tensor(88.4851)\n",
      "2003 Traning Loss: tensor(88.4582)\n",
      "2004 Traning Loss: tensor(88.4314)\n",
      "2005 Traning Loss: tensor(88.4046)\n",
      "2006 Traning Loss: tensor(88.3779)\n",
      "2007 Traning Loss: tensor(88.3512)\n",
      "2008 Traning Loss: tensor(88.3246)\n",
      "2009 Traning Loss: tensor(88.2980)\n",
      "2010 Traning Loss: tensor(88.2715)\n",
      "2011 Traning Loss: tensor(88.2450)\n",
      "2012 Traning Loss: tensor(88.2187)\n",
      "2013 Traning Loss: tensor(88.1923)\n",
      "2014 Traning Loss: tensor(88.1660)\n",
      "2015 Traning Loss: tensor(88.1398)\n",
      "2016 Traning Loss: tensor(88.1136)\n",
      "2017 Traning Loss: tensor(88.0875)\n",
      "2018 Traning Loss: tensor(88.0614)\n",
      "2019 Traning Loss: tensor(88.0354)\n",
      "2020 Traning Loss: tensor(88.0094)\n",
      "2021 Traning Loss: tensor(87.9835)\n",
      "2022 Traning Loss: tensor(87.9576)\n",
      "2023 Traning Loss: tensor(87.9318)\n",
      "2024 Traning Loss: tensor(87.9061)\n",
      "2025 Traning Loss: tensor(87.8804)\n",
      "2026 Traning Loss: tensor(87.8547)\n",
      "2027 Traning Loss: tensor(87.8291)\n",
      "2028 Traning Loss: tensor(87.8036)\n",
      "2029 Traning Loss: tensor(87.7781)\n",
      "2030 Traning Loss: tensor(87.7527)\n",
      "2031 Traning Loss: tensor(87.7273)\n",
      "2032 Traning Loss: tensor(87.7020)\n",
      "2033 Traning Loss: tensor(87.6767)\n",
      "2034 Traning Loss: tensor(87.6514)\n",
      "2035 Traning Loss: tensor(87.6263)\n",
      "2036 Traning Loss: tensor(87.6012)\n",
      "2037 Traning Loss: tensor(87.5761)\n",
      "2038 Traning Loss: tensor(87.5511)\n",
      "2039 Traning Loss: tensor(87.5261)\n",
      "2040 Traning Loss: tensor(87.5012)\n",
      "2041 Traning Loss: tensor(87.4763)\n",
      "2042 Traning Loss: tensor(87.4515)\n",
      "2043 Traning Loss: tensor(87.4267)\n",
      "2044 Traning Loss: tensor(87.4020)\n",
      "2045 Traning Loss: tensor(87.3773)\n",
      "2046 Traning Loss: tensor(87.3527)\n",
      "2047 Traning Loss: tensor(87.3281)\n",
      "2048 Traning Loss: tensor(87.3036)\n",
      "2049 Traning Loss: tensor(87.2792)\n",
      "2050 Traning Loss: tensor(87.2547)\n",
      "2051 Traning Loss: tensor(87.2304)\n",
      "2052 Traning Loss: tensor(87.2060)\n",
      "2053 Traning Loss: tensor(87.1818)\n",
      "2054 Traning Loss: tensor(87.1576)\n",
      "2055 Traning Loss: tensor(87.1334)\n",
      "2056 Traning Loss: tensor(87.1093)\n",
      "2057 Traning Loss: tensor(87.0852)\n",
      "2058 Traning Loss: tensor(87.0612)\n",
      "2059 Traning Loss: tensor(87.0372)\n",
      "2060 Traning Loss: tensor(87.0133)\n",
      "2061 Traning Loss: tensor(86.9894)\n",
      "2062 Traning Loss: tensor(86.9656)\n",
      "2063 Traning Loss: tensor(86.9418)\n",
      "2064 Traning Loss: tensor(86.9180)\n",
      "2065 Traning Loss: tensor(86.8944)\n",
      "2066 Traning Loss: tensor(86.8707)\n",
      "2067 Traning Loss: tensor(86.8472)\n",
      "2068 Traning Loss: tensor(86.8236)\n",
      "2069 Traning Loss: tensor(86.8001)\n",
      "2070 Traning Loss: tensor(86.7767)\n",
      "2071 Traning Loss: tensor(86.7533)\n",
      "2072 Traning Loss: tensor(86.7299)\n",
      "2073 Traning Loss: tensor(86.7066)\n",
      "2074 Traning Loss: tensor(86.6833)\n",
      "2075 Traning Loss: tensor(86.6601)\n",
      "2076 Traning Loss: tensor(86.6370)\n",
      "2077 Traning Loss: tensor(86.6139)\n",
      "2078 Traning Loss: tensor(86.5908)\n",
      "2079 Traning Loss: tensor(86.5678)\n",
      "2080 Traning Loss: tensor(86.5448)\n",
      "2081 Traning Loss: tensor(86.5219)\n",
      "2082 Traning Loss: tensor(86.4990)\n",
      "2083 Traning Loss: tensor(86.4761)\n",
      "2084 Traning Loss: tensor(86.4533)\n",
      "2085 Traning Loss: tensor(86.4306)\n",
      "2086 Traning Loss: tensor(86.4079)\n",
      "2087 Traning Loss: tensor(86.3852)\n",
      "2088 Traning Loss: tensor(86.3626)\n",
      "2089 Traning Loss: tensor(86.3400)\n",
      "2090 Traning Loss: tensor(86.3175)\n",
      "2091 Traning Loss: tensor(86.2951)\n",
      "2092 Traning Loss: tensor(86.2726)\n",
      "2093 Traning Loss: tensor(86.2502)\n",
      "2094 Traning Loss: tensor(86.2279)\n",
      "2095 Traning Loss: tensor(86.2056)\n",
      "2096 Traning Loss: tensor(86.1833)\n",
      "2097 Traning Loss: tensor(86.1611)\n",
      "2098 Traning Loss: tensor(86.1390)\n",
      "2099 Traning Loss: tensor(86.1169)\n",
      "2100 Traning Loss: tensor(86.0947)\n",
      "2101 Traning Loss: tensor(86.0727)\n",
      "2102 Traning Loss: tensor(86.0507)\n",
      "2103 Traning Loss: tensor(86.0288)\n",
      "2104 Traning Loss: tensor(86.0069)\n",
      "2105 Traning Loss: tensor(85.9850)\n",
      "2106 Traning Loss: tensor(85.9632)\n",
      "2107 Traning Loss: tensor(85.9415)\n",
      "2108 Traning Loss: tensor(85.9197)\n",
      "2109 Traning Loss: tensor(85.8980)\n",
      "2110 Traning Loss: tensor(85.8764)\n",
      "2111 Traning Loss: tensor(85.8548)\n",
      "2112 Traning Loss: tensor(85.8332)\n",
      "2113 Traning Loss: tensor(85.8117)\n",
      "2114 Traning Loss: tensor(85.7903)\n",
      "2115 Traning Loss: tensor(85.7688)\n",
      "2116 Traning Loss: tensor(85.7474)\n",
      "2117 Traning Loss: tensor(85.7261)\n",
      "2118 Traning Loss: tensor(85.7048)\n",
      "2119 Traning Loss: tensor(85.6835)\n",
      "2120 Traning Loss: tensor(85.6623)\n",
      "2121 Traning Loss: tensor(85.6411)\n",
      "2122 Traning Loss: tensor(85.6200)\n",
      "2123 Traning Loss: tensor(85.5989)\n",
      "2124 Traning Loss: tensor(85.5778)\n",
      "2125 Traning Loss: tensor(85.5568)\n",
      "2126 Traning Loss: tensor(85.5359)\n",
      "2127 Traning Loss: tensor(85.5150)\n",
      "2128 Traning Loss: tensor(85.4941)\n",
      "2129 Traning Loss: tensor(85.4732)\n",
      "2130 Traning Loss: tensor(85.4524)\n",
      "2131 Traning Loss: tensor(85.4316)\n",
      "2132 Traning Loss: tensor(85.4109)\n",
      "2133 Traning Loss: tensor(85.3902)\n",
      "2134 Traning Loss: tensor(85.3696)\n",
      "2135 Traning Loss: tensor(85.3490)\n",
      "2136 Traning Loss: tensor(85.3285)\n",
      "2137 Traning Loss: tensor(85.3079)\n",
      "2138 Traning Loss: tensor(85.2874)\n",
      "2139 Traning Loss: tensor(85.2670)\n",
      "2140 Traning Loss: tensor(85.2466)\n",
      "2141 Traning Loss: tensor(85.2262)\n",
      "2142 Traning Loss: tensor(85.2059)\n",
      "2143 Traning Loss: tensor(85.1856)\n",
      "2144 Traning Loss: tensor(85.1654)\n",
      "2145 Traning Loss: tensor(85.1452)\n",
      "2146 Traning Loss: tensor(85.1250)\n",
      "2147 Traning Loss: tensor(85.1049)\n",
      "2148 Traning Loss: tensor(85.0848)\n",
      "2149 Traning Loss: tensor(85.0648)\n",
      "2150 Traning Loss: tensor(85.0448)\n",
      "2151 Traning Loss: tensor(85.0248)\n",
      "2152 Traning Loss: tensor(85.0049)\n",
      "2153 Traning Loss: tensor(84.9850)\n",
      "2154 Traning Loss: tensor(84.9651)\n",
      "2155 Traning Loss: tensor(84.9453)\n",
      "2156 Traning Loss: tensor(84.9256)\n",
      "2157 Traning Loss: tensor(84.9058)\n",
      "2158 Traning Loss: tensor(84.8861)\n",
      "2159 Traning Loss: tensor(84.8664)\n",
      "2160 Traning Loss: tensor(84.8468)\n",
      "2161 Traning Loss: tensor(84.8272)\n",
      "2162 Traning Loss: tensor(84.8077)\n",
      "2163 Traning Loss: tensor(84.7882)\n",
      "2164 Traning Loss: tensor(84.7687)\n",
      "2165 Traning Loss: tensor(84.7493)\n",
      "2166 Traning Loss: tensor(84.7299)\n",
      "2167 Traning Loss: tensor(84.7105)\n",
      "2168 Traning Loss: tensor(84.6912)\n",
      "2169 Traning Loss: tensor(84.6719)\n",
      "2170 Traning Loss: tensor(84.6527)\n",
      "2171 Traning Loss: tensor(84.6335)\n",
      "2172 Traning Loss: tensor(84.6143)\n",
      "2173 Traning Loss: tensor(84.5952)\n",
      "2174 Traning Loss: tensor(84.5761)\n",
      "2175 Traning Loss: tensor(84.5570)\n",
      "2176 Traning Loss: tensor(84.5380)\n",
      "2177 Traning Loss: tensor(84.5190)\n",
      "2178 Traning Loss: tensor(84.5000)\n",
      "2179 Traning Loss: tensor(84.4811)\n",
      "2180 Traning Loss: tensor(84.4623)\n",
      "2181 Traning Loss: tensor(84.4434)\n",
      "2182 Traning Loss: tensor(84.4246)\n",
      "2183 Traning Loss: tensor(84.4058)\n",
      "2184 Traning Loss: tensor(84.3871)\n",
      "2185 Traning Loss: tensor(84.3684)\n",
      "2186 Traning Loss: tensor(84.3498)\n",
      "2187 Traning Loss: tensor(84.3311)\n",
      "2188 Traning Loss: tensor(84.3125)\n",
      "2189 Traning Loss: tensor(84.2940)\n",
      "2190 Traning Loss: tensor(84.2754)\n",
      "2191 Traning Loss: tensor(84.2570)\n",
      "2192 Traning Loss: tensor(84.2385)\n",
      "2193 Traning Loss: tensor(84.2201)\n",
      "2194 Traning Loss: tensor(84.2017)\n",
      "2195 Traning Loss: tensor(84.1834)\n",
      "2196 Traning Loss: tensor(84.1651)\n",
      "2197 Traning Loss: tensor(84.1468)\n",
      "2198 Traning Loss: tensor(84.1285)\n",
      "2199 Traning Loss: tensor(84.1104)\n",
      "2200 Traning Loss: tensor(84.0922)\n",
      "2201 Traning Loss: tensor(84.0741)\n",
      "2202 Traning Loss: tensor(84.0559)\n",
      "2203 Traning Loss: tensor(84.0378)\n",
      "2204 Traning Loss: tensor(84.0198)\n",
      "2205 Traning Loss: tensor(84.0018)\n",
      "2206 Traning Loss: tensor(83.9838)\n",
      "2207 Traning Loss: tensor(83.9659)\n",
      "2208 Traning Loss: tensor(83.9480)\n",
      "2209 Traning Loss: tensor(83.9302)\n",
      "2210 Traning Loss: tensor(83.9123)\n",
      "2211 Traning Loss: tensor(83.8945)\n",
      "2212 Traning Loss: tensor(83.8768)\n",
      "2213 Traning Loss: tensor(83.8590)\n",
      "2214 Traning Loss: tensor(83.8414)\n",
      "2215 Traning Loss: tensor(83.8237)\n",
      "2216 Traning Loss: tensor(83.8061)\n",
      "2217 Traning Loss: tensor(83.7885)\n",
      "2218 Traning Loss: tensor(83.7709)\n",
      "2219 Traning Loss: tensor(83.7534)\n",
      "2220 Traning Loss: tensor(83.7359)\n",
      "2221 Traning Loss: tensor(83.7184)\n",
      "2222 Traning Loss: tensor(83.7010)\n",
      "2223 Traning Loss: tensor(83.6836)\n",
      "2224 Traning Loss: tensor(83.6662)\n",
      "2225 Traning Loss: tensor(83.6489)\n",
      "2226 Traning Loss: tensor(83.6316)\n",
      "2227 Traning Loss: tensor(83.6143)\n",
      "2228 Traning Loss: tensor(83.5971)\n",
      "2229 Traning Loss: tensor(83.5799)\n",
      "2230 Traning Loss: tensor(83.5627)\n",
      "2231 Traning Loss: tensor(83.5456)\n",
      "2232 Traning Loss: tensor(83.5285)\n",
      "2233 Traning Loss: tensor(83.5114)\n",
      "2234 Traning Loss: tensor(83.4944)\n",
      "2235 Traning Loss: tensor(83.4774)\n",
      "2236 Traning Loss: tensor(83.4604)\n",
      "2237 Traning Loss: tensor(83.4435)\n",
      "2238 Traning Loss: tensor(83.4265)\n",
      "2239 Traning Loss: tensor(83.4096)\n",
      "2240 Traning Loss: tensor(83.3928)\n",
      "2241 Traning Loss: tensor(83.3759)\n",
      "2242 Traning Loss: tensor(83.3592)\n",
      "2243 Traning Loss: tensor(83.3424)\n",
      "2244 Traning Loss: tensor(83.3257)\n",
      "2245 Traning Loss: tensor(83.3090)\n",
      "2246 Traning Loss: tensor(83.2923)\n",
      "2247 Traning Loss: tensor(83.2757)\n",
      "2248 Traning Loss: tensor(83.2591)\n",
      "2249 Traning Loss: tensor(83.2425)\n",
      "2250 Traning Loss: tensor(83.2260)\n",
      "2251 Traning Loss: tensor(83.2095)\n",
      "2252 Traning Loss: tensor(83.1930)\n",
      "2253 Traning Loss: tensor(83.1765)\n",
      "2254 Traning Loss: tensor(83.1601)\n",
      "2255 Traning Loss: tensor(83.1437)\n",
      "2256 Traning Loss: tensor(83.1273)\n",
      "2257 Traning Loss: tensor(83.1110)\n",
      "2258 Traning Loss: tensor(83.0947)\n",
      "2259 Traning Loss: tensor(83.0785)\n",
      "2260 Traning Loss: tensor(83.0622)\n",
      "2261 Traning Loss: tensor(83.0460)\n",
      "2262 Traning Loss: tensor(83.0298)\n",
      "2263 Traning Loss: tensor(83.0137)\n",
      "2264 Traning Loss: tensor(82.9976)\n",
      "2265 Traning Loss: tensor(82.9815)\n",
      "2266 Traning Loss: tensor(82.9654)\n",
      "2267 Traning Loss: tensor(82.9494)\n",
      "2268 Traning Loss: tensor(82.9334)\n",
      "2269 Traning Loss: tensor(82.9174)\n",
      "2270 Traning Loss: tensor(82.9015)\n",
      "2271 Traning Loss: tensor(82.8856)\n",
      "2272 Traning Loss: tensor(82.8697)\n",
      "2273 Traning Loss: tensor(82.8538)\n",
      "2274 Traning Loss: tensor(82.8380)\n",
      "2275 Traning Loss: tensor(82.8222)\n",
      "2276 Traning Loss: tensor(82.8064)\n",
      "2277 Traning Loss: tensor(82.7907)\n",
      "2278 Traning Loss: tensor(82.7750)\n",
      "2279 Traning Loss: tensor(82.7593)\n",
      "2280 Traning Loss: tensor(82.7437)\n",
      "2281 Traning Loss: tensor(82.7280)\n",
      "2282 Traning Loss: tensor(82.7124)\n",
      "2283 Traning Loss: tensor(82.6969)\n",
      "2284 Traning Loss: tensor(82.6813)\n",
      "2285 Traning Loss: tensor(82.6658)\n",
      "2286 Traning Loss: tensor(82.6503)\n",
      "2287 Traning Loss: tensor(82.6349)\n",
      "2288 Traning Loss: tensor(82.6195)\n",
      "2289 Traning Loss: tensor(82.6040)\n",
      "2290 Traning Loss: tensor(82.5887)\n",
      "2291 Traning Loss: tensor(82.5733)\n",
      "2292 Traning Loss: tensor(82.5580)\n",
      "2293 Traning Loss: tensor(82.5427)\n",
      "2294 Traning Loss: tensor(82.5275)\n",
      "2295 Traning Loss: tensor(82.5122)\n",
      "2296 Traning Loss: tensor(82.4970)\n",
      "2297 Traning Loss: tensor(82.4818)\n",
      "2298 Traning Loss: tensor(82.4667)\n",
      "2299 Traning Loss: tensor(82.4516)\n",
      "2300 Traning Loss: tensor(82.4365)\n",
      "2301 Traning Loss: tensor(82.4214)\n",
      "2302 Traning Loss: tensor(82.4064)\n",
      "2303 Traning Loss: tensor(82.3914)\n",
      "2304 Traning Loss: tensor(82.3764)\n",
      "2305 Traning Loss: tensor(82.3614)\n",
      "2306 Traning Loss: tensor(82.3465)\n",
      "2307 Traning Loss: tensor(82.3316)\n",
      "2308 Traning Loss: tensor(82.3167)\n",
      "2309 Traning Loss: tensor(82.3018)\n",
      "2310 Traning Loss: tensor(82.2870)\n",
      "2311 Traning Loss: tensor(82.2722)\n",
      "2312 Traning Loss: tensor(82.2575)\n",
      "2313 Traning Loss: tensor(82.2427)\n",
      "2314 Traning Loss: tensor(82.2280)\n",
      "2315 Traning Loss: tensor(82.2133)\n",
      "2316 Traning Loss: tensor(82.1986)\n",
      "2317 Traning Loss: tensor(82.1840)\n",
      "2318 Traning Loss: tensor(82.1694)\n",
      "2319 Traning Loss: tensor(82.1548)\n",
      "2320 Traning Loss: tensor(82.1402)\n",
      "2321 Traning Loss: tensor(82.1257)\n",
      "2322 Traning Loss: tensor(82.1112)\n",
      "2323 Traning Loss: tensor(82.0967)\n",
      "2324 Traning Loss: tensor(82.0822)\n",
      "2325 Traning Loss: tensor(82.0678)\n",
      "2326 Traning Loss: tensor(82.0534)\n",
      "2327 Traning Loss: tensor(82.0390)\n",
      "2328 Traning Loss: tensor(82.0246)\n",
      "2329 Traning Loss: tensor(82.0103)\n",
      "2330 Traning Loss: tensor(81.9960)\n",
      "2331 Traning Loss: tensor(81.9817)\n",
      "2332 Traning Loss: tensor(81.9675)\n",
      "2333 Traning Loss: tensor(81.9532)\n",
      "2334 Traning Loss: tensor(81.9391)\n",
      "2335 Traning Loss: tensor(81.9249)\n",
      "2336 Traning Loss: tensor(81.9107)\n",
      "2337 Traning Loss: tensor(81.8966)\n",
      "2338 Traning Loss: tensor(81.8825)\n",
      "2339 Traning Loss: tensor(81.8684)\n",
      "2340 Traning Loss: tensor(81.8544)\n",
      "2341 Traning Loss: tensor(81.8403)\n",
      "2342 Traning Loss: tensor(81.8263)\n",
      "2343 Traning Loss: tensor(81.8124)\n",
      "2344 Traning Loss: tensor(81.7984)\n",
      "2345 Traning Loss: tensor(81.7845)\n",
      "2346 Traning Loss: tensor(81.7706)\n",
      "2347 Traning Loss: tensor(81.7567)\n",
      "2348 Traning Loss: tensor(81.7428)\n",
      "2349 Traning Loss: tensor(81.7290)\n",
      "2350 Traning Loss: tensor(81.7152)\n",
      "2351 Traning Loss: tensor(81.7014)\n",
      "2352 Traning Loss: tensor(81.6876)\n",
      "2353 Traning Loss: tensor(81.6739)\n",
      "2354 Traning Loss: tensor(81.6602)\n",
      "2355 Traning Loss: tensor(81.6465)\n",
      "2356 Traning Loss: tensor(81.6329)\n",
      "2357 Traning Loss: tensor(81.6192)\n",
      "2358 Traning Loss: tensor(81.6056)\n",
      "2359 Traning Loss: tensor(81.5920)\n",
      "2360 Traning Loss: tensor(81.5784)\n",
      "2361 Traning Loss: tensor(81.5649)\n",
      "2362 Traning Loss: tensor(81.5514)\n",
      "2363 Traning Loss: tensor(81.5379)\n",
      "2364 Traning Loss: tensor(81.5244)\n",
      "2365 Traning Loss: tensor(81.5109)\n",
      "2366 Traning Loss: tensor(81.4975)\n",
      "2367 Traning Loss: tensor(81.4841)\n",
      "2368 Traning Loss: tensor(81.4708)\n",
      "2369 Traning Loss: tensor(81.4574)\n",
      "2370 Traning Loss: tensor(81.4441)\n",
      "2371 Traning Loss: tensor(81.4307)\n",
      "2372 Traning Loss: tensor(81.4174)\n",
      "2373 Traning Loss: tensor(81.4042)\n",
      "2374 Traning Loss: tensor(81.3909)\n",
      "2375 Traning Loss: tensor(81.3777)\n",
      "2376 Traning Loss: tensor(81.3645)\n",
      "2377 Traning Loss: tensor(81.3514)\n",
      "2378 Traning Loss: tensor(81.3382)\n",
      "2379 Traning Loss: tensor(81.3251)\n",
      "2380 Traning Loss: tensor(81.3120)\n",
      "2381 Traning Loss: tensor(81.2989)\n",
      "2382 Traning Loss: tensor(81.2859)\n",
      "2383 Traning Loss: tensor(81.2728)\n",
      "2384 Traning Loss: tensor(81.2598)\n",
      "2385 Traning Loss: tensor(81.2468)\n",
      "2386 Traning Loss: tensor(81.2338)\n",
      "2387 Traning Loss: tensor(81.2209)\n",
      "2388 Traning Loss: tensor(81.2080)\n",
      "2389 Traning Loss: tensor(81.1951)\n",
      "2390 Traning Loss: tensor(81.1822)\n",
      "2391 Traning Loss: tensor(81.1693)\n",
      "2392 Traning Loss: tensor(81.1565)\n",
      "2393 Traning Loss: tensor(81.1437)\n",
      "2394 Traning Loss: tensor(81.1309)\n",
      "2395 Traning Loss: tensor(81.1181)\n",
      "2396 Traning Loss: tensor(81.1054)\n",
      "2397 Traning Loss: tensor(81.0926)\n",
      "2398 Traning Loss: tensor(81.0799)\n",
      "2399 Traning Loss: tensor(81.0673)\n",
      "2400 Traning Loss: tensor(81.0546)\n",
      "2401 Traning Loss: tensor(81.0419)\n",
      "2402 Traning Loss: tensor(81.0293)\n",
      "2403 Traning Loss: tensor(81.0167)\n",
      "2404 Traning Loss: tensor(81.0042)\n",
      "2405 Traning Loss: tensor(80.9916)\n",
      "2406 Traning Loss: tensor(80.9791)\n",
      "2407 Traning Loss: tensor(80.9666)\n",
      "2408 Traning Loss: tensor(80.9541)\n",
      "2409 Traning Loss: tensor(80.9416)\n",
      "2410 Traning Loss: tensor(80.9292)\n",
      "2411 Traning Loss: tensor(80.9167)\n",
      "2412 Traning Loss: tensor(80.9043)\n",
      "2413 Traning Loss: tensor(80.8920)\n",
      "2414 Traning Loss: tensor(80.8796)\n",
      "2415 Traning Loss: tensor(80.8672)\n",
      "2416 Traning Loss: tensor(80.8549)\n",
      "2417 Traning Loss: tensor(80.8426)\n",
      "2418 Traning Loss: tensor(80.8303)\n",
      "2419 Traning Loss: tensor(80.8181)\n",
      "2420 Traning Loss: tensor(80.8058)\n",
      "2421 Traning Loss: tensor(80.7936)\n",
      "2422 Traning Loss: tensor(80.7814)\n",
      "2423 Traning Loss: tensor(80.7693)\n",
      "2424 Traning Loss: tensor(80.7571)\n",
      "2425 Traning Loss: tensor(80.7450)\n",
      "2426 Traning Loss: tensor(80.7328)\n",
      "2427 Traning Loss: tensor(80.7208)\n",
      "2428 Traning Loss: tensor(80.7087)\n",
      "2429 Traning Loss: tensor(80.6966)\n",
      "2430 Traning Loss: tensor(80.6846)\n",
      "2431 Traning Loss: tensor(80.6726)\n",
      "2432 Traning Loss: tensor(80.6606)\n",
      "2433 Traning Loss: tensor(80.6486)\n",
      "2434 Traning Loss: tensor(80.6367)\n",
      "2435 Traning Loss: tensor(80.6247)\n",
      "2436 Traning Loss: tensor(80.6128)\n",
      "2437 Traning Loss: tensor(80.6009)\n",
      "2438 Traning Loss: tensor(80.5890)\n",
      "2439 Traning Loss: tensor(80.5772)\n",
      "2440 Traning Loss: tensor(80.5654)\n",
      "2441 Traning Loss: tensor(80.5536)\n",
      "2442 Traning Loss: tensor(80.5417)\n",
      "2443 Traning Loss: tensor(80.5300)\n",
      "2444 Traning Loss: tensor(80.5182)\n",
      "2445 Traning Loss: tensor(80.5065)\n",
      "2446 Traning Loss: tensor(80.4948)\n",
      "2447 Traning Loss: tensor(80.4831)\n",
      "2448 Traning Loss: tensor(80.4714)\n",
      "2449 Traning Loss: tensor(80.4597)\n",
      "2450 Traning Loss: tensor(80.4481)\n",
      "2451 Traning Loss: tensor(80.4365)\n",
      "2452 Traning Loss: tensor(80.4249)\n",
      "2453 Traning Loss: tensor(80.4133)\n",
      "2454 Traning Loss: tensor(80.4017)\n",
      "2455 Traning Loss: tensor(80.3902)\n",
      "2456 Traning Loss: tensor(80.3787)\n",
      "2457 Traning Loss: tensor(80.3672)\n",
      "2458 Traning Loss: tensor(80.3557)\n",
      "2459 Traning Loss: tensor(80.3442)\n",
      "2460 Traning Loss: tensor(80.3328)\n",
      "2461 Traning Loss: tensor(80.3213)\n",
      "2462 Traning Loss: tensor(80.3099)\n",
      "2463 Traning Loss: tensor(80.2985)\n",
      "2464 Traning Loss: tensor(80.2872)\n",
      "2465 Traning Loss: tensor(80.2758)\n",
      "2466 Traning Loss: tensor(80.2645)\n",
      "2467 Traning Loss: tensor(80.2531)\n",
      "2468 Traning Loss: tensor(80.2418)\n",
      "2469 Traning Loss: tensor(80.2306)\n",
      "2470 Traning Loss: tensor(80.2193)\n",
      "2471 Traning Loss: tensor(80.2081)\n",
      "2472 Traning Loss: tensor(80.1968)\n",
      "2473 Traning Loss: tensor(80.1856)\n",
      "2474 Traning Loss: tensor(80.1744)\n",
      "2475 Traning Loss: tensor(80.1633)\n",
      "2476 Traning Loss: tensor(80.1521)\n",
      "2477 Traning Loss: tensor(80.1410)\n",
      "2478 Traning Loss: tensor(80.1299)\n",
      "2479 Traning Loss: tensor(80.1188)\n",
      "2480 Traning Loss: tensor(80.1077)\n",
      "2481 Traning Loss: tensor(80.0966)\n",
      "2482 Traning Loss: tensor(80.0856)\n",
      "2483 Traning Loss: tensor(80.0746)\n",
      "2484 Traning Loss: tensor(80.0635)\n",
      "2485 Traning Loss: tensor(80.0526)\n",
      "2486 Traning Loss: tensor(80.0416)\n",
      "2487 Traning Loss: tensor(80.0306)\n",
      "2488 Traning Loss: tensor(80.0197)\n",
      "2489 Traning Loss: tensor(80.0088)\n",
      "2490 Traning Loss: tensor(79.9979)\n",
      "2491 Traning Loss: tensor(79.9870)\n",
      "2492 Traning Loss: tensor(79.9761)\n",
      "2493 Traning Loss: tensor(79.9653)\n",
      "2494 Traning Loss: tensor(79.9544)\n",
      "2495 Traning Loss: tensor(79.9436)\n",
      "2496 Traning Loss: tensor(79.9328)\n",
      "2497 Traning Loss: tensor(79.9221)\n",
      "2498 Traning Loss: tensor(79.9113)\n",
      "2499 Traning Loss: tensor(79.9006)\n",
      "2500 Traning Loss: tensor(79.8898)\n",
      "2501 Traning Loss: tensor(79.8791)\n",
      "2502 Traning Loss: tensor(79.8684)\n",
      "2503 Traning Loss: tensor(79.8577)\n",
      "2504 Traning Loss: tensor(79.8471)\n",
      "2505 Traning Loss: tensor(79.8364)\n",
      "2506 Traning Loss: tensor(79.8258)\n",
      "2507 Traning Loss: tensor(79.8152)\n",
      "2508 Traning Loss: tensor(79.8046)\n",
      "2509 Traning Loss: tensor(79.7940)\n",
      "2510 Traning Loss: tensor(79.7835)\n",
      "2511 Traning Loss: tensor(79.7729)\n",
      "2512 Traning Loss: tensor(79.7624)\n",
      "2513 Traning Loss: tensor(79.7519)\n",
      "2514 Traning Loss: tensor(79.7414)\n",
      "2515 Traning Loss: tensor(79.7309)\n",
      "2516 Traning Loss: tensor(79.7205)\n",
      "2517 Traning Loss: tensor(79.7100)\n",
      "2518 Traning Loss: tensor(79.6996)\n",
      "2519 Traning Loss: tensor(79.6892)\n",
      "2520 Traning Loss: tensor(79.6788)\n",
      "2521 Traning Loss: tensor(79.6685)\n",
      "2522 Traning Loss: tensor(79.6581)\n",
      "2523 Traning Loss: tensor(79.6478)\n",
      "2524 Traning Loss: tensor(79.6374)\n",
      "2525 Traning Loss: tensor(79.6271)\n",
      "2526 Traning Loss: tensor(79.6168)\n",
      "2527 Traning Loss: tensor(79.6065)\n",
      "2528 Traning Loss: tensor(79.5963)\n",
      "2529 Traning Loss: tensor(79.5861)\n",
      "2530 Traning Loss: tensor(79.5758)\n",
      "2531 Traning Loss: tensor(79.5656)\n",
      "2532 Traning Loss: tensor(79.5554)\n",
      "2533 Traning Loss: tensor(79.5452)\n",
      "2534 Traning Loss: tensor(79.5350)\n",
      "2535 Traning Loss: tensor(79.5249)\n",
      "2536 Traning Loss: tensor(79.5148)\n",
      "2537 Traning Loss: tensor(79.5046)\n",
      "2538 Traning Loss: tensor(79.4945)\n",
      "2539 Traning Loss: tensor(79.4845)\n",
      "2540 Traning Loss: tensor(79.4744)\n",
      "2541 Traning Loss: tensor(79.4643)\n",
      "2542 Traning Loss: tensor(79.4543)\n",
      "2543 Traning Loss: tensor(79.4443)\n",
      "2544 Traning Loss: tensor(79.4343)\n",
      "2545 Traning Loss: tensor(79.4243)\n",
      "2546 Traning Loss: tensor(79.4143)\n",
      "2547 Traning Loss: tensor(79.4044)\n",
      "2548 Traning Loss: tensor(79.3944)\n",
      "2549 Traning Loss: tensor(79.3845)\n",
      "2550 Traning Loss: tensor(79.3746)\n",
      "2551 Traning Loss: tensor(79.3647)\n",
      "2552 Traning Loss: tensor(79.3548)\n",
      "2553 Traning Loss: tensor(79.3449)\n",
      "2554 Traning Loss: tensor(79.3350)\n",
      "2555 Traning Loss: tensor(79.3252)\n",
      "2556 Traning Loss: tensor(79.3154)\n",
      "2557 Traning Loss: tensor(79.3056)\n",
      "2558 Traning Loss: tensor(79.2958)\n",
      "2559 Traning Loss: tensor(79.2860)\n",
      "2560 Traning Loss: tensor(79.2762)\n",
      "2561 Traning Loss: tensor(79.2665)\n",
      "2562 Traning Loss: tensor(79.2568)\n",
      "2563 Traning Loss: tensor(79.2471)\n",
      "2564 Traning Loss: tensor(79.2374)\n",
      "2565 Traning Loss: tensor(79.2277)\n",
      "2566 Traning Loss: tensor(79.2180)\n",
      "2567 Traning Loss: tensor(79.2083)\n",
      "2568 Traning Loss: tensor(79.1987)\n",
      "2569 Traning Loss: tensor(79.1891)\n",
      "2570 Traning Loss: tensor(79.1794)\n",
      "2571 Traning Loss: tensor(79.1699)\n",
      "2572 Traning Loss: tensor(79.1603)\n",
      "2573 Traning Loss: tensor(79.1507)\n",
      "2574 Traning Loss: tensor(79.1411)\n",
      "2575 Traning Loss: tensor(79.1316)\n",
      "2576 Traning Loss: tensor(79.1221)\n",
      "2577 Traning Loss: tensor(79.1125)\n",
      "2578 Traning Loss: tensor(79.1031)\n",
      "2579 Traning Loss: tensor(79.0936)\n",
      "2580 Traning Loss: tensor(79.0841)\n",
      "2581 Traning Loss: tensor(79.0747)\n",
      "2582 Traning Loss: tensor(79.0652)\n",
      "2583 Traning Loss: tensor(79.0558)\n",
      "2584 Traning Loss: tensor(79.0464)\n",
      "2585 Traning Loss: tensor(79.0370)\n",
      "2586 Traning Loss: tensor(79.0276)\n",
      "2587 Traning Loss: tensor(79.0182)\n",
      "2588 Traning Loss: tensor(79.0089)\n",
      "2589 Traning Loss: tensor(78.9995)\n",
      "2590 Traning Loss: tensor(78.9902)\n",
      "2591 Traning Loss: tensor(78.9809)\n",
      "2592 Traning Loss: tensor(78.9716)\n",
      "2593 Traning Loss: tensor(78.9623)\n",
      "2594 Traning Loss: tensor(78.9530)\n",
      "2595 Traning Loss: tensor(78.9438)\n",
      "2596 Traning Loss: tensor(78.9345)\n",
      "2597 Traning Loss: tensor(78.9253)\n",
      "2598 Traning Loss: tensor(78.9161)\n",
      "2599 Traning Loss: tensor(78.9069)\n",
      "2600 Traning Loss: tensor(78.8977)\n",
      "2601 Traning Loss: tensor(78.8885)\n",
      "2602 Traning Loss: tensor(78.8794)\n",
      "2603 Traning Loss: tensor(78.8702)\n",
      "2604 Traning Loss: tensor(78.8611)\n",
      "2605 Traning Loss: tensor(78.8520)\n",
      "2606 Traning Loss: tensor(78.8429)\n",
      "2607 Traning Loss: tensor(78.8338)\n",
      "2608 Traning Loss: tensor(78.8247)\n",
      "2609 Traning Loss: tensor(78.8156)\n",
      "2610 Traning Loss: tensor(78.8066)\n",
      "2611 Traning Loss: tensor(78.7975)\n",
      "2612 Traning Loss: tensor(78.7885)\n",
      "2613 Traning Loss: tensor(78.7795)\n",
      "2614 Traning Loss: tensor(78.7705)\n",
      "2615 Traning Loss: tensor(78.7615)\n",
      "2616 Traning Loss: tensor(78.7525)\n",
      "2617 Traning Loss: tensor(78.7436)\n",
      "2618 Traning Loss: tensor(78.7346)\n",
      "2619 Traning Loss: tensor(78.7257)\n",
      "2620 Traning Loss: tensor(78.7168)\n",
      "2621 Traning Loss: tensor(78.7079)\n",
      "2622 Traning Loss: tensor(78.6990)\n",
      "2623 Traning Loss: tensor(78.6901)\n",
      "2624 Traning Loss: tensor(78.6812)\n",
      "2625 Traning Loss: tensor(78.6724)\n",
      "2626 Traning Loss: tensor(78.6635)\n",
      "2627 Traning Loss: tensor(78.6547)\n",
      "2628 Traning Loss: tensor(78.6459)\n",
      "2629 Traning Loss: tensor(78.6371)\n",
      "2630 Traning Loss: tensor(78.6283)\n",
      "2631 Traning Loss: tensor(78.6195)\n",
      "2632 Traning Loss: tensor(78.6108)\n",
      "2633 Traning Loss: tensor(78.6020)\n",
      "2634 Traning Loss: tensor(78.5933)\n",
      "2635 Traning Loss: tensor(78.5845)\n",
      "2636 Traning Loss: tensor(78.5758)\n",
      "2637 Traning Loss: tensor(78.5671)\n",
      "2638 Traning Loss: tensor(78.5584)\n",
      "2639 Traning Loss: tensor(78.5498)\n",
      "2640 Traning Loss: tensor(78.5411)\n",
      "2641 Traning Loss: tensor(78.5325)\n",
      "2642 Traning Loss: tensor(78.5238)\n",
      "2643 Traning Loss: tensor(78.5152)\n",
      "2644 Traning Loss: tensor(78.5066)\n",
      "2645 Traning Loss: tensor(78.4980)\n",
      "2646 Traning Loss: tensor(78.4894)\n",
      "2647 Traning Loss: tensor(78.4808)\n",
      "2648 Traning Loss: tensor(78.4722)\n",
      "2649 Traning Loss: tensor(78.4637)\n",
      "2650 Traning Loss: tensor(78.4552)\n",
      "2651 Traning Loss: tensor(78.4466)\n",
      "2652 Traning Loss: tensor(78.4381)\n",
      "2653 Traning Loss: tensor(78.4296)\n",
      "2654 Traning Loss: tensor(78.4211)\n",
      "2655 Traning Loss: tensor(78.4127)\n",
      "2656 Traning Loss: tensor(78.4042)\n",
      "2657 Traning Loss: tensor(78.3957)\n",
      "2658 Traning Loss: tensor(78.3873)\n",
      "2659 Traning Loss: tensor(78.3789)\n",
      "2660 Traning Loss: tensor(78.3704)\n",
      "2661 Traning Loss: tensor(78.3620)\n",
      "2662 Traning Loss: tensor(78.3536)\n",
      "2663 Traning Loss: tensor(78.3452)\n",
      "2664 Traning Loss: tensor(78.3369)\n",
      "2665 Traning Loss: tensor(78.3285)\n",
      "2666 Traning Loss: tensor(78.3202)\n",
      "2667 Traning Loss: tensor(78.3118)\n",
      "2668 Traning Loss: tensor(78.3035)\n",
      "2669 Traning Loss: tensor(78.2952)\n",
      "2670 Traning Loss: tensor(78.2869)\n",
      "2671 Traning Loss: tensor(78.2786)\n",
      "2672 Traning Loss: tensor(78.2703)\n",
      "2673 Traning Loss: tensor(78.2621)\n",
      "2674 Traning Loss: tensor(78.2538)\n",
      "2675 Traning Loss: tensor(78.2456)\n",
      "2676 Traning Loss: tensor(78.2373)\n",
      "2677 Traning Loss: tensor(78.2291)\n",
      "2678 Traning Loss: tensor(78.2209)\n",
      "2679 Traning Loss: tensor(78.2127)\n",
      "2680 Traning Loss: tensor(78.2046)\n",
      "2681 Traning Loss: tensor(78.1964)\n",
      "2682 Traning Loss: tensor(78.1882)\n",
      "2683 Traning Loss: tensor(78.1801)\n",
      "2684 Traning Loss: tensor(78.1719)\n",
      "2685 Traning Loss: tensor(78.1638)\n",
      "2686 Traning Loss: tensor(78.1557)\n",
      "2687 Traning Loss: tensor(78.1476)\n",
      "2688 Traning Loss: tensor(78.1395)\n",
      "2689 Traning Loss: tensor(78.1314)\n",
      "2690 Traning Loss: tensor(78.1233)\n",
      "2691 Traning Loss: tensor(78.1153)\n",
      "2692 Traning Loss: tensor(78.1072)\n",
      "2693 Traning Loss: tensor(78.0992)\n",
      "2694 Traning Loss: tensor(78.0911)\n",
      "2695 Traning Loss: tensor(78.0831)\n",
      "2696 Traning Loss: tensor(78.0751)\n",
      "2697 Traning Loss: tensor(78.0672)\n",
      "2698 Traning Loss: tensor(78.0592)\n",
      "2699 Traning Loss: tensor(78.0512)\n",
      "2700 Traning Loss: tensor(78.0432)\n",
      "2701 Traning Loss: tensor(78.0353)\n",
      "2702 Traning Loss: tensor(78.0274)\n",
      "2703 Traning Loss: tensor(78.0194)\n",
      "2704 Traning Loss: tensor(78.0115)\n",
      "2705 Traning Loss: tensor(78.0036)\n",
      "2706 Traning Loss: tensor(77.9957)\n",
      "2707 Traning Loss: tensor(77.9878)\n",
      "2708 Traning Loss: tensor(77.9800)\n",
      "2709 Traning Loss: tensor(77.9721)\n",
      "2710 Traning Loss: tensor(77.9642)\n",
      "2711 Traning Loss: tensor(77.9564)\n",
      "2712 Traning Loss: tensor(77.9486)\n",
      "2713 Traning Loss: tensor(77.9407)\n",
      "2714 Traning Loss: tensor(77.9329)\n",
      "2715 Traning Loss: tensor(77.9251)\n",
      "2716 Traning Loss: tensor(77.9174)\n",
      "2717 Traning Loss: tensor(77.9096)\n",
      "2718 Traning Loss: tensor(77.9018)\n",
      "2719 Traning Loss: tensor(77.8940)\n",
      "2720 Traning Loss: tensor(77.8863)\n",
      "2721 Traning Loss: tensor(77.8786)\n",
      "2722 Traning Loss: tensor(77.8709)\n",
      "2723 Traning Loss: tensor(77.8631)\n",
      "2724 Traning Loss: tensor(77.8554)\n",
      "2725 Traning Loss: tensor(77.8477)\n",
      "2726 Traning Loss: tensor(77.8400)\n",
      "2727 Traning Loss: tensor(77.8324)\n",
      "2728 Traning Loss: tensor(77.8247)\n",
      "2729 Traning Loss: tensor(77.8171)\n",
      "2730 Traning Loss: tensor(77.8094)\n",
      "2731 Traning Loss: tensor(77.8018)\n",
      "2732 Traning Loss: tensor(77.7942)\n",
      "2733 Traning Loss: tensor(77.7865)\n",
      "2734 Traning Loss: tensor(77.7789)\n",
      "2735 Traning Loss: tensor(77.7713)\n",
      "2736 Traning Loss: tensor(77.7638)\n",
      "2737 Traning Loss: tensor(77.7562)\n",
      "2738 Traning Loss: tensor(77.7486)\n",
      "2739 Traning Loss: tensor(77.7411)\n",
      "2740 Traning Loss: tensor(77.7335)\n",
      "2741 Traning Loss: tensor(77.7260)\n",
      "2742 Traning Loss: tensor(77.7185)\n",
      "2743 Traning Loss: tensor(77.7110)\n",
      "2744 Traning Loss: tensor(77.7034)\n",
      "2745 Traning Loss: tensor(77.6960)\n",
      "2746 Traning Loss: tensor(77.6885)\n",
      "2747 Traning Loss: tensor(77.6810)\n",
      "2748 Traning Loss: tensor(77.6736)\n",
      "2749 Traning Loss: tensor(77.6661)\n",
      "2750 Traning Loss: tensor(77.6587)\n",
      "2751 Traning Loss: tensor(77.6512)\n",
      "2752 Traning Loss: tensor(77.6438)\n",
      "2753 Traning Loss: tensor(77.6364)\n",
      "2754 Traning Loss: tensor(77.6290)\n",
      "2755 Traning Loss: tensor(77.6216)\n",
      "2756 Traning Loss: tensor(77.6142)\n",
      "2757 Traning Loss: tensor(77.6068)\n",
      "2758 Traning Loss: tensor(77.5995)\n",
      "2759 Traning Loss: tensor(77.5921)\n",
      "2760 Traning Loss: tensor(77.5848)\n",
      "2761 Traning Loss: tensor(77.5774)\n",
      "2762 Traning Loss: tensor(77.5701)\n",
      "2763 Traning Loss: tensor(77.5628)\n",
      "2764 Traning Loss: tensor(77.5555)\n",
      "2765 Traning Loss: tensor(77.5482)\n",
      "2766 Traning Loss: tensor(77.5409)\n",
      "2767 Traning Loss: tensor(77.5336)\n",
      "2768 Traning Loss: tensor(77.5264)\n",
      "2769 Traning Loss: tensor(77.5191)\n",
      "2770 Traning Loss: tensor(77.5118)\n",
      "2771 Traning Loss: tensor(77.5046)\n",
      "2772 Traning Loss: tensor(77.4973)\n",
      "2773 Traning Loss: tensor(77.4901)\n",
      "2774 Traning Loss: tensor(77.4829)\n",
      "2775 Traning Loss: tensor(77.4757)\n",
      "2776 Traning Loss: tensor(77.4685)\n",
      "2777 Traning Loss: tensor(77.4613)\n",
      "2778 Traning Loss: tensor(77.4542)\n",
      "2779 Traning Loss: tensor(77.4470)\n",
      "2780 Traning Loss: tensor(77.4398)\n",
      "2781 Traning Loss: tensor(77.4327)\n",
      "2782 Traning Loss: tensor(77.4255)\n",
      "2783 Traning Loss: tensor(77.4184)\n",
      "2784 Traning Loss: tensor(77.4113)\n",
      "2785 Traning Loss: tensor(77.4042)\n",
      "2786 Traning Loss: tensor(77.3970)\n",
      "2787 Traning Loss: tensor(77.3900)\n",
      "2788 Traning Loss: tensor(77.3829)\n",
      "2789 Traning Loss: tensor(77.3758)\n",
      "2790 Traning Loss: tensor(77.3687)\n",
      "2791 Traning Loss: tensor(77.3616)\n",
      "2792 Traning Loss: tensor(77.3546)\n",
      "2793 Traning Loss: tensor(77.3475)\n",
      "2794 Traning Loss: tensor(77.3405)\n",
      "2795 Traning Loss: tensor(77.3335)\n",
      "2796 Traning Loss: tensor(77.3265)\n",
      "2797 Traning Loss: tensor(77.3195)\n",
      "2798 Traning Loss: tensor(77.3125)\n",
      "2799 Traning Loss: tensor(77.3055)\n",
      "2800 Traning Loss: tensor(77.2985)\n",
      "2801 Traning Loss: tensor(77.2915)\n",
      "2802 Traning Loss: tensor(77.2846)\n",
      "2803 Traning Loss: tensor(77.2776)\n",
      "2804 Traning Loss: tensor(77.2707)\n",
      "2805 Traning Loss: tensor(77.2637)\n",
      "2806 Traning Loss: tensor(77.2568)\n",
      "2807 Traning Loss: tensor(77.2499)\n",
      "2808 Traning Loss: tensor(77.2430)\n",
      "2809 Traning Loss: tensor(77.2361)\n",
      "2810 Traning Loss: tensor(77.2292)\n",
      "2811 Traning Loss: tensor(77.2223)\n",
      "2812 Traning Loss: tensor(77.2154)\n",
      "2813 Traning Loss: tensor(77.2085)\n",
      "2814 Traning Loss: tensor(77.2017)\n",
      "2815 Traning Loss: tensor(77.1948)\n",
      "2816 Traning Loss: tensor(77.1880)\n",
      "2817 Traning Loss: tensor(77.1811)\n",
      "2818 Traning Loss: tensor(77.1743)\n",
      "2819 Traning Loss: tensor(77.1675)\n",
      "2820 Traning Loss: tensor(77.1607)\n",
      "2821 Traning Loss: tensor(77.1539)\n",
      "2822 Traning Loss: tensor(77.1471)\n",
      "2823 Traning Loss: tensor(77.1403)\n",
      "2824 Traning Loss: tensor(77.1335)\n",
      "2825 Traning Loss: tensor(77.1268)\n",
      "2826 Traning Loss: tensor(77.1200)\n",
      "2827 Traning Loss: tensor(77.1132)\n",
      "2828 Traning Loss: tensor(77.1065)\n",
      "2829 Traning Loss: tensor(77.0998)\n",
      "2830 Traning Loss: tensor(77.0930)\n",
      "2831 Traning Loss: tensor(77.0863)\n",
      "2832 Traning Loss: tensor(77.0796)\n",
      "2833 Traning Loss: tensor(77.0729)\n",
      "2834 Traning Loss: tensor(77.0662)\n",
      "2835 Traning Loss: tensor(77.0595)\n",
      "2836 Traning Loss: tensor(77.0528)\n",
      "2837 Traning Loss: tensor(77.0462)\n",
      "2838 Traning Loss: tensor(77.0395)\n",
      "2839 Traning Loss: tensor(77.0329)\n",
      "2840 Traning Loss: tensor(77.0262)\n",
      "2841 Traning Loss: tensor(77.0196)\n",
      "2842 Traning Loss: tensor(77.0129)\n",
      "2843 Traning Loss: tensor(77.0063)\n",
      "2844 Traning Loss: tensor(76.9997)\n",
      "2845 Traning Loss: tensor(76.9931)\n",
      "2846 Traning Loss: tensor(76.9865)\n",
      "2847 Traning Loss: tensor(76.9799)\n",
      "2848 Traning Loss: tensor(76.9733)\n",
      "2849 Traning Loss: tensor(76.9667)\n",
      "2850 Traning Loss: tensor(76.9601)\n",
      "2851 Traning Loss: tensor(76.9536)\n",
      "2852 Traning Loss: tensor(76.9470)\n",
      "2853 Traning Loss: tensor(76.9405)\n",
      "2854 Traning Loss: tensor(76.9340)\n",
      "2855 Traning Loss: tensor(76.9274)\n",
      "2856 Traning Loss: tensor(76.9209)\n",
      "2857 Traning Loss: tensor(76.9144)\n",
      "2858 Traning Loss: tensor(76.9079)\n",
      "2859 Traning Loss: tensor(76.9014)\n",
      "2860 Traning Loss: tensor(76.8949)\n",
      "2861 Traning Loss: tensor(76.8884)\n",
      "2862 Traning Loss: tensor(76.8819)\n",
      "2863 Traning Loss: tensor(76.8755)\n",
      "2864 Traning Loss: tensor(76.8690)\n",
      "2865 Traning Loss: tensor(76.8625)\n",
      "2866 Traning Loss: tensor(76.8561)\n",
      "2867 Traning Loss: tensor(76.8496)\n",
      "2868 Traning Loss: tensor(76.8432)\n",
      "2869 Traning Loss: tensor(76.8368)\n",
      "2870 Traning Loss: tensor(76.8304)\n",
      "2871 Traning Loss: tensor(76.8240)\n",
      "2872 Traning Loss: tensor(76.8175)\n",
      "2873 Traning Loss: tensor(76.8112)\n",
      "2874 Traning Loss: tensor(76.8048)\n",
      "2875 Traning Loss: tensor(76.7984)\n",
      "2876 Traning Loss: tensor(76.7920)\n",
      "2877 Traning Loss: tensor(76.7856)\n",
      "2878 Traning Loss: tensor(76.7793)\n",
      "2879 Traning Loss: tensor(76.7730)\n",
      "2880 Traning Loss: tensor(76.7666)\n",
      "2881 Traning Loss: tensor(76.7603)\n",
      "2882 Traning Loss: tensor(76.7540)\n",
      "2883 Traning Loss: tensor(76.7476)\n",
      "2884 Traning Loss: tensor(76.7413)\n",
      "2885 Traning Loss: tensor(76.7350)\n",
      "2886 Traning Loss: tensor(76.7287)\n",
      "2887 Traning Loss: tensor(76.7224)\n",
      "2888 Traning Loss: tensor(76.7161)\n",
      "2889 Traning Loss: tensor(76.7098)\n",
      "2890 Traning Loss: tensor(76.7036)\n",
      "2891 Traning Loss: tensor(76.6973)\n",
      "2892 Traning Loss: tensor(76.6910)\n",
      "2893 Traning Loss: tensor(76.6848)\n",
      "2894 Traning Loss: tensor(76.6786)\n",
      "2895 Traning Loss: tensor(76.6723)\n",
      "2896 Traning Loss: tensor(76.6661)\n",
      "2897 Traning Loss: tensor(76.6599)\n",
      "2898 Traning Loss: tensor(76.6537)\n",
      "2899 Traning Loss: tensor(76.6474)\n",
      "2900 Traning Loss: tensor(76.6412)\n",
      "2901 Traning Loss: tensor(76.6350)\n",
      "2902 Traning Loss: tensor(76.6289)\n",
      "2903 Traning Loss: tensor(76.6227)\n",
      "2904 Traning Loss: tensor(76.6165)\n",
      "2905 Traning Loss: tensor(76.6103)\n",
      "2906 Traning Loss: tensor(76.6041)\n",
      "2907 Traning Loss: tensor(76.5980)\n",
      "2908 Traning Loss: tensor(76.5919)\n",
      "2909 Traning Loss: tensor(76.5857)\n",
      "2910 Traning Loss: tensor(76.5796)\n",
      "2911 Traning Loss: tensor(76.5734)\n",
      "2912 Traning Loss: tensor(76.5673)\n",
      "2913 Traning Loss: tensor(76.5612)\n",
      "2914 Traning Loss: tensor(76.5551)\n",
      "2915 Traning Loss: tensor(76.5490)\n",
      "2916 Traning Loss: tensor(76.5429)\n",
      "2917 Traning Loss: tensor(76.5368)\n",
      "2918 Traning Loss: tensor(76.5307)\n",
      "2919 Traning Loss: tensor(76.5247)\n",
      "2920 Traning Loss: tensor(76.5186)\n",
      "2921 Traning Loss: tensor(76.5126)\n",
      "2922 Traning Loss: tensor(76.5065)\n",
      "2923 Traning Loss: tensor(76.5005)\n",
      "2924 Traning Loss: tensor(76.4944)\n",
      "2925 Traning Loss: tensor(76.4884)\n",
      "2926 Traning Loss: tensor(76.4824)\n",
      "2927 Traning Loss: tensor(76.4763)\n",
      "2928 Traning Loss: tensor(76.4703)\n",
      "2929 Traning Loss: tensor(76.4643)\n",
      "2930 Traning Loss: tensor(76.4583)\n",
      "2931 Traning Loss: tensor(76.4523)\n",
      "2932 Traning Loss: tensor(76.4463)\n",
      "2933 Traning Loss: tensor(76.4403)\n",
      "2934 Traning Loss: tensor(76.4344)\n",
      "2935 Traning Loss: tensor(76.4284)\n",
      "2936 Traning Loss: tensor(76.4224)\n",
      "2937 Traning Loss: tensor(76.4165)\n",
      "2938 Traning Loss: tensor(76.4105)\n",
      "2939 Traning Loss: tensor(76.4046)\n",
      "2940 Traning Loss: tensor(76.3987)\n",
      "2941 Traning Loss: tensor(76.3927)\n",
      "2942 Traning Loss: tensor(76.3868)\n",
      "2943 Traning Loss: tensor(76.3809)\n",
      "2944 Traning Loss: tensor(76.3750)\n",
      "2945 Traning Loss: tensor(76.3691)\n",
      "2946 Traning Loss: tensor(76.3632)\n",
      "2947 Traning Loss: tensor(76.3573)\n",
      "2948 Traning Loss: tensor(76.3514)\n",
      "2949 Traning Loss: tensor(76.3455)\n",
      "2950 Traning Loss: tensor(76.3396)\n",
      "2951 Traning Loss: tensor(76.3337)\n",
      "2952 Traning Loss: tensor(76.3279)\n",
      "2953 Traning Loss: tensor(76.3220)\n",
      "2954 Traning Loss: tensor(76.3162)\n",
      "2955 Traning Loss: tensor(76.3104)\n",
      "2956 Traning Loss: tensor(76.3045)\n",
      "2957 Traning Loss: tensor(76.2987)\n",
      "2958 Traning Loss: tensor(76.2929)\n",
      "2959 Traning Loss: tensor(76.2870)\n",
      "2960 Traning Loss: tensor(76.2812)\n",
      "2961 Traning Loss: tensor(76.2754)\n",
      "2962 Traning Loss: tensor(76.2696)\n",
      "2963 Traning Loss: tensor(76.2638)\n",
      "2964 Traning Loss: tensor(76.2580)\n",
      "2965 Traning Loss: tensor(76.2522)\n",
      "2966 Traning Loss: tensor(76.2464)\n",
      "2967 Traning Loss: tensor(76.2407)\n",
      "2968 Traning Loss: tensor(76.2349)\n",
      "2969 Traning Loss: tensor(76.2292)\n",
      "2970 Traning Loss: tensor(76.2234)\n",
      "2971 Traning Loss: tensor(76.2177)\n",
      "2972 Traning Loss: tensor(76.2119)\n",
      "2973 Traning Loss: tensor(76.2062)\n",
      "2974 Traning Loss: tensor(76.2004)\n",
      "2975 Traning Loss: tensor(76.1947)\n",
      "2976 Traning Loss: tensor(76.1890)\n",
      "2977 Traning Loss: tensor(76.1833)\n",
      "2978 Traning Loss: tensor(76.1776)\n",
      "2979 Traning Loss: tensor(76.1719)\n",
      "2980 Traning Loss: tensor(76.1662)\n",
      "2981 Traning Loss: tensor(76.1605)\n",
      "2982 Traning Loss: tensor(76.1548)\n",
      "2983 Traning Loss: tensor(76.1491)\n",
      "2984 Traning Loss: tensor(76.1434)\n",
      "2985 Traning Loss: tensor(76.1378)\n",
      "2986 Traning Loss: tensor(76.1321)\n",
      "2987 Traning Loss: tensor(76.1265)\n",
      "2988 Traning Loss: tensor(76.1208)\n",
      "2989 Traning Loss: tensor(76.1152)\n",
      "2990 Traning Loss: tensor(76.1095)\n",
      "2991 Traning Loss: tensor(76.1039)\n",
      "2992 Traning Loss: tensor(76.0983)\n",
      "2993 Traning Loss: tensor(76.0926)\n",
      "2994 Traning Loss: tensor(76.0870)\n",
      "2995 Traning Loss: tensor(76.0814)\n",
      "2996 Traning Loss: tensor(76.0758)\n",
      "2997 Traning Loss: tensor(76.0702)\n",
      "2998 Traning Loss: tensor(76.0646)\n",
      "2999 Traning Loss: tensor(76.0590)\n",
      "3000 Traning Loss: tensor(76.0534)\n",
      "3001 Traning Loss: tensor(76.0478)\n",
      "3002 Traning Loss: tensor(76.0423)\n",
      "3003 Traning Loss: tensor(76.0367)\n",
      "3004 Traning Loss: tensor(76.0311)\n",
      "3005 Traning Loss: tensor(76.0256)\n",
      "3006 Traning Loss: tensor(76.0200)\n",
      "3007 Traning Loss: tensor(76.0145)\n",
      "3008 Traning Loss: tensor(76.0090)\n",
      "3009 Traning Loss: tensor(76.0034)\n",
      "3010 Traning Loss: tensor(75.9979)\n",
      "3011 Traning Loss: tensor(75.9923)\n",
      "3012 Traning Loss: tensor(75.9868)\n",
      "3013 Traning Loss: tensor(75.9813)\n",
      "3014 Traning Loss: tensor(75.9758)\n",
      "3015 Traning Loss: tensor(75.9703)\n",
      "3016 Traning Loss: tensor(75.9648)\n",
      "3017 Traning Loss: tensor(75.9593)\n",
      "3018 Traning Loss: tensor(75.9538)\n",
      "3019 Traning Loss: tensor(75.9483)\n",
      "3020 Traning Loss: tensor(75.9429)\n",
      "3021 Traning Loss: tensor(75.9374)\n",
      "3022 Traning Loss: tensor(75.9319)\n",
      "3023 Traning Loss: tensor(75.9265)\n",
      "3024 Traning Loss: tensor(75.9210)\n",
      "3025 Traning Loss: tensor(75.9156)\n",
      "3026 Traning Loss: tensor(75.9101)\n",
      "3027 Traning Loss: tensor(75.9047)\n",
      "3028 Traning Loss: tensor(75.8992)\n",
      "3029 Traning Loss: tensor(75.8938)\n",
      "3030 Traning Loss: tensor(75.8884)\n",
      "3031 Traning Loss: tensor(75.8829)\n",
      "3032 Traning Loss: tensor(75.8775)\n",
      "3033 Traning Loss: tensor(75.8721)\n",
      "3034 Traning Loss: tensor(75.8667)\n",
      "3035 Traning Loss: tensor(75.8613)\n",
      "3036 Traning Loss: tensor(75.8559)\n",
      "3037 Traning Loss: tensor(75.8505)\n",
      "3038 Traning Loss: tensor(75.8451)\n",
      "3039 Traning Loss: tensor(75.8398)\n",
      "3040 Traning Loss: tensor(75.8344)\n",
      "3041 Traning Loss: tensor(75.8290)\n",
      "3042 Traning Loss: tensor(75.8236)\n",
      "3043 Traning Loss: tensor(75.8183)\n",
      "3044 Traning Loss: tensor(75.8129)\n",
      "3045 Traning Loss: tensor(75.8076)\n",
      "3046 Traning Loss: tensor(75.8022)\n",
      "3047 Traning Loss: tensor(75.7969)\n",
      "3048 Traning Loss: tensor(75.7915)\n",
      "3049 Traning Loss: tensor(75.7862)\n",
      "3050 Traning Loss: tensor(75.7809)\n",
      "3051 Traning Loss: tensor(75.7756)\n",
      "3052 Traning Loss: tensor(75.7702)\n",
      "3053 Traning Loss: tensor(75.7649)\n",
      "3054 Traning Loss: tensor(75.7596)\n",
      "3055 Traning Loss: tensor(75.7543)\n",
      "3056 Traning Loss: tensor(75.7490)\n",
      "3057 Traning Loss: tensor(75.7437)\n",
      "3058 Traning Loss: tensor(75.7384)\n",
      "3059 Traning Loss: tensor(75.7332)\n",
      "3060 Traning Loss: tensor(75.7279)\n",
      "3061 Traning Loss: tensor(75.7226)\n",
      "3062 Traning Loss: tensor(75.7174)\n",
      "3063 Traning Loss: tensor(75.7120)\n",
      "3064 Traning Loss: tensor(75.7068)\n",
      "3065 Traning Loss: tensor(75.7016)\n",
      "3066 Traning Loss: tensor(75.6963)\n",
      "3067 Traning Loss: tensor(75.6911)\n",
      "3068 Traning Loss: tensor(75.6858)\n",
      "3069 Traning Loss: tensor(75.6806)\n",
      "3070 Traning Loss: tensor(75.6753)\n",
      "3071 Traning Loss: tensor(75.6701)\n",
      "3072 Traning Loss: tensor(75.6649)\n",
      "3073 Traning Loss: tensor(75.6597)\n",
      "3074 Traning Loss: tensor(75.6545)\n",
      "3075 Traning Loss: tensor(75.6492)\n",
      "3076 Traning Loss: tensor(75.6440)\n",
      "3077 Traning Loss: tensor(75.6388)\n",
      "3078 Traning Loss: tensor(75.6336)\n",
      "3079 Traning Loss: tensor(75.6284)\n",
      "3080 Traning Loss: tensor(75.6233)\n",
      "3081 Traning Loss: tensor(75.6181)\n",
      "3082 Traning Loss: tensor(75.6129)\n",
      "3083 Traning Loss: tensor(75.6077)\n",
      "3084 Traning Loss: tensor(75.6026)\n",
      "3085 Traning Loss: tensor(75.5974)\n",
      "3086 Traning Loss: tensor(75.5922)\n",
      "3087 Traning Loss: tensor(75.5871)\n",
      "3088 Traning Loss: tensor(75.5819)\n",
      "3089 Traning Loss: tensor(75.5768)\n",
      "3090 Traning Loss: tensor(75.5716)\n",
      "3091 Traning Loss: tensor(75.5665)\n",
      "3092 Traning Loss: tensor(75.5613)\n",
      "3093 Traning Loss: tensor(75.5562)\n",
      "3094 Traning Loss: tensor(75.5511)\n",
      "3095 Traning Loss: tensor(75.5460)\n",
      "3096 Traning Loss: tensor(75.5409)\n",
      "3097 Traning Loss: tensor(75.5358)\n",
      "3098 Traning Loss: tensor(75.5306)\n",
      "3099 Traning Loss: tensor(75.5255)\n",
      "3100 Traning Loss: tensor(75.5205)\n",
      "3101 Traning Loss: tensor(75.5154)\n",
      "3102 Traning Loss: tensor(75.5103)\n",
      "3103 Traning Loss: tensor(75.5052)\n",
      "3104 Traning Loss: tensor(75.5001)\n",
      "3105 Traning Loss: tensor(75.4950)\n",
      "3106 Traning Loss: tensor(75.4899)\n",
      "3107 Traning Loss: tensor(75.4849)\n",
      "3108 Traning Loss: tensor(75.4798)\n",
      "3109 Traning Loss: tensor(75.4747)\n",
      "3110 Traning Loss: tensor(75.4697)\n",
      "3111 Traning Loss: tensor(75.4646)\n",
      "3112 Traning Loss: tensor(75.4596)\n",
      "3113 Traning Loss: tensor(75.4545)\n",
      "3114 Traning Loss: tensor(75.4495)\n",
      "3115 Traning Loss: tensor(75.4445)\n",
      "3116 Traning Loss: tensor(75.4394)\n",
      "3117 Traning Loss: tensor(75.4344)\n",
      "3118 Traning Loss: tensor(75.4294)\n",
      "3119 Traning Loss: tensor(75.4244)\n",
      "3120 Traning Loss: tensor(75.4193)\n",
      "3121 Traning Loss: tensor(75.4143)\n",
      "3122 Traning Loss: tensor(75.4093)\n",
      "3123 Traning Loss: tensor(75.4043)\n",
      "3124 Traning Loss: tensor(75.3993)\n",
      "3125 Traning Loss: tensor(75.3943)\n",
      "3126 Traning Loss: tensor(75.3893)\n",
      "3127 Traning Loss: tensor(75.3843)\n",
      "3128 Traning Loss: tensor(75.3794)\n",
      "3129 Traning Loss: tensor(75.3744)\n",
      "3130 Traning Loss: tensor(75.3694)\n",
      "3131 Traning Loss: tensor(75.3644)\n",
      "3132 Traning Loss: tensor(75.3595)\n",
      "3133 Traning Loss: tensor(75.3545)\n",
      "3134 Traning Loss: tensor(75.3495)\n",
      "3135 Traning Loss: tensor(75.3446)\n",
      "3136 Traning Loss: tensor(75.3396)\n",
      "3137 Traning Loss: tensor(75.3347)\n",
      "3138 Traning Loss: tensor(75.3297)\n",
      "3139 Traning Loss: tensor(75.3248)\n",
      "3140 Traning Loss: tensor(75.3198)\n",
      "3141 Traning Loss: tensor(75.3149)\n",
      "3142 Traning Loss: tensor(75.3100)\n",
      "3143 Traning Loss: tensor(75.3051)\n",
      "3144 Traning Loss: tensor(75.3001)\n",
      "3145 Traning Loss: tensor(75.2952)\n",
      "3146 Traning Loss: tensor(75.2903)\n",
      "3147 Traning Loss: tensor(75.2854)\n",
      "3148 Traning Loss: tensor(75.2805)\n",
      "3149 Traning Loss: tensor(75.2756)\n",
      "3150 Traning Loss: tensor(75.2707)\n",
      "3151 Traning Loss: tensor(75.2658)\n",
      "3152 Traning Loss: tensor(75.2609)\n",
      "3153 Traning Loss: tensor(75.2560)\n",
      "3154 Traning Loss: tensor(75.2511)\n",
      "3155 Traning Loss: tensor(75.2462)\n",
      "3156 Traning Loss: tensor(75.2414)\n",
      "3157 Traning Loss: tensor(75.2365)\n",
      "3158 Traning Loss: tensor(75.2317)\n",
      "3159 Traning Loss: tensor(75.2268)\n",
      "3160 Traning Loss: tensor(75.2219)\n",
      "3161 Traning Loss: tensor(75.2171)\n",
      "3162 Traning Loss: tensor(75.2122)\n",
      "3163 Traning Loss: tensor(75.2073)\n",
      "3164 Traning Loss: tensor(75.2025)\n",
      "3165 Traning Loss: tensor(75.1977)\n",
      "3166 Traning Loss: tensor(75.1928)\n",
      "3167 Traning Loss: tensor(75.1880)\n",
      "3168 Traning Loss: tensor(75.1831)\n",
      "3169 Traning Loss: tensor(75.1783)\n",
      "3170 Traning Loss: tensor(75.1735)\n",
      "3171 Traning Loss: tensor(75.1687)\n",
      "3172 Traning Loss: tensor(75.1639)\n",
      "3173 Traning Loss: tensor(75.1590)\n",
      "3174 Traning Loss: tensor(75.1542)\n",
      "3175 Traning Loss: tensor(75.1494)\n",
      "3176 Traning Loss: tensor(75.1446)\n",
      "3177 Traning Loss: tensor(75.1398)\n",
      "3178 Traning Loss: tensor(75.1350)\n",
      "3179 Traning Loss: tensor(75.1302)\n",
      "3180 Traning Loss: tensor(75.1254)\n",
      "3181 Traning Loss: tensor(75.1207)\n",
      "3182 Traning Loss: tensor(75.1159)\n",
      "3183 Traning Loss: tensor(75.1111)\n",
      "3184 Traning Loss: tensor(75.1063)\n",
      "3185 Traning Loss: tensor(75.1015)\n",
      "3186 Traning Loss: tensor(75.0968)\n",
      "3187 Traning Loss: tensor(75.0920)\n",
      "3188 Traning Loss: tensor(75.0872)\n",
      "3189 Traning Loss: tensor(75.0825)\n",
      "3190 Traning Loss: tensor(75.0777)\n",
      "3191 Traning Loss: tensor(75.0729)\n",
      "3192 Traning Loss: tensor(75.0682)\n",
      "3193 Traning Loss: tensor(75.0635)\n",
      "3194 Traning Loss: tensor(75.0587)\n",
      "3195 Traning Loss: tensor(75.0540)\n",
      "3196 Traning Loss: tensor(75.0493)\n",
      "3197 Traning Loss: tensor(75.0445)\n",
      "3198 Traning Loss: tensor(75.0398)\n",
      "3199 Traning Loss: tensor(75.0350)\n",
      "3200 Traning Loss: tensor(75.0303)\n",
      "3201 Traning Loss: tensor(75.0256)\n",
      "3202 Traning Loss: tensor(75.0209)\n",
      "3203 Traning Loss: tensor(75.0162)\n",
      "3204 Traning Loss: tensor(75.0115)\n",
      "3205 Traning Loss: tensor(75.0068)\n",
      "3206 Traning Loss: tensor(75.0021)\n",
      "3207 Traning Loss: tensor(74.9974)\n",
      "3208 Traning Loss: tensor(74.9927)\n",
      "3209 Traning Loss: tensor(74.9880)\n",
      "3210 Traning Loss: tensor(74.9833)\n",
      "3211 Traning Loss: tensor(74.9786)\n",
      "3212 Traning Loss: tensor(74.9739)\n",
      "3213 Traning Loss: tensor(74.9692)\n",
      "3214 Traning Loss: tensor(74.9645)\n",
      "3215 Traning Loss: tensor(74.9599)\n",
      "3216 Traning Loss: tensor(74.9552)\n",
      "3217 Traning Loss: tensor(74.9505)\n",
      "3218 Traning Loss: tensor(74.9459)\n",
      "3219 Traning Loss: tensor(74.9412)\n",
      "3220 Traning Loss: tensor(74.9365)\n",
      "3221 Traning Loss: tensor(74.9319)\n",
      "3222 Traning Loss: tensor(74.9272)\n",
      "3223 Traning Loss: tensor(74.9226)\n",
      "3224 Traning Loss: tensor(74.9179)\n",
      "3225 Traning Loss: tensor(74.9133)\n",
      "3226 Traning Loss: tensor(74.9087)\n",
      "3227 Traning Loss: tensor(74.9040)\n",
      "3228 Traning Loss: tensor(74.8994)\n",
      "3229 Traning Loss: tensor(74.8948)\n",
      "3230 Traning Loss: tensor(74.8901)\n",
      "3231 Traning Loss: tensor(74.8855)\n",
      "3232 Traning Loss: tensor(74.8809)\n",
      "3233 Traning Loss: tensor(74.8763)\n",
      "3234 Traning Loss: tensor(74.8716)\n",
      "3235 Traning Loss: tensor(74.8670)\n",
      "3236 Traning Loss: tensor(74.8624)\n",
      "3237 Traning Loss: tensor(74.8578)\n",
      "3238 Traning Loss: tensor(74.8532)\n",
      "3239 Traning Loss: tensor(74.8486)\n",
      "3240 Traning Loss: tensor(74.8440)\n",
      "3241 Traning Loss: tensor(74.8394)\n",
      "3242 Traning Loss: tensor(74.8348)\n",
      "3243 Traning Loss: tensor(74.8302)\n",
      "3244 Traning Loss: tensor(74.8256)\n",
      "3245 Traning Loss: tensor(74.8210)\n",
      "3246 Traning Loss: tensor(74.8165)\n",
      "3247 Traning Loss: tensor(74.8119)\n",
      "3248 Traning Loss: tensor(74.8073)\n",
      "3249 Traning Loss: tensor(74.8028)\n",
      "3250 Traning Loss: tensor(74.7982)\n",
      "3251 Traning Loss: tensor(74.7936)\n",
      "3252 Traning Loss: tensor(74.7891)\n",
      "3253 Traning Loss: tensor(74.7845)\n",
      "3254 Traning Loss: tensor(74.7799)\n",
      "3255 Traning Loss: tensor(74.7754)\n",
      "3256 Traning Loss: tensor(74.7708)\n",
      "3257 Traning Loss: tensor(74.7663)\n",
      "3258 Traning Loss: tensor(74.7617)\n",
      "3259 Traning Loss: tensor(74.7572)\n",
      "3260 Traning Loss: tensor(74.7526)\n",
      "3261 Traning Loss: tensor(74.7481)\n",
      "3262 Traning Loss: tensor(74.7436)\n",
      "3263 Traning Loss: tensor(74.7390)\n",
      "3264 Traning Loss: tensor(74.7345)\n",
      "3265 Traning Loss: tensor(74.7300)\n",
      "3266 Traning Loss: tensor(74.7254)\n",
      "3267 Traning Loss: tensor(74.7209)\n",
      "3268 Traning Loss: tensor(74.7164)\n",
      "3269 Traning Loss: tensor(74.7119)\n",
      "3270 Traning Loss: tensor(74.7074)\n",
      "3271 Traning Loss: tensor(74.7029)\n",
      "3272 Traning Loss: tensor(74.6984)\n",
      "3273 Traning Loss: tensor(74.6939)\n",
      "3274 Traning Loss: tensor(74.6893)\n",
      "3275 Traning Loss: tensor(74.6848)\n",
      "3276 Traning Loss: tensor(74.6804)\n",
      "3277 Traning Loss: tensor(74.6759)\n",
      "3278 Traning Loss: tensor(74.6713)\n",
      "3279 Traning Loss: tensor(74.6669)\n",
      "3280 Traning Loss: tensor(74.6624)\n",
      "3281 Traning Loss: tensor(74.6579)\n",
      "3282 Traning Loss: tensor(74.6534)\n",
      "3283 Traning Loss: tensor(74.6489)\n",
      "3284 Traning Loss: tensor(74.6444)\n",
      "3285 Traning Loss: tensor(74.6400)\n",
      "3286 Traning Loss: tensor(74.6355)\n",
      "3287 Traning Loss: tensor(74.6310)\n",
      "3288 Traning Loss: tensor(74.6266)\n",
      "3289 Traning Loss: tensor(74.6221)\n",
      "3290 Traning Loss: tensor(74.6177)\n",
      "3291 Traning Loss: tensor(74.6132)\n",
      "3292 Traning Loss: tensor(74.6087)\n",
      "3293 Traning Loss: tensor(74.6043)\n",
      "3294 Traning Loss: tensor(74.5998)\n",
      "3295 Traning Loss: tensor(74.5954)\n",
      "3296 Traning Loss: tensor(74.5909)\n",
      "3297 Traning Loss: tensor(74.5865)\n",
      "3298 Traning Loss: tensor(74.5821)\n",
      "3299 Traning Loss: tensor(74.5776)\n",
      "3300 Traning Loss: tensor(74.5732)\n",
      "3301 Traning Loss: tensor(74.5687)\n",
      "3302 Traning Loss: tensor(74.5643)\n",
      "3303 Traning Loss: tensor(74.5599)\n",
      "3304 Traning Loss: tensor(74.5555)\n",
      "3305 Traning Loss: tensor(74.5510)\n",
      "3306 Traning Loss: tensor(74.5466)\n",
      "3307 Traning Loss: tensor(74.5422)\n",
      "3308 Traning Loss: tensor(74.5378)\n",
      "3309 Traning Loss: tensor(74.5334)\n",
      "3310 Traning Loss: tensor(74.5289)\n",
      "3311 Traning Loss: tensor(74.5245)\n",
      "3312 Traning Loss: tensor(74.5201)\n",
      "3313 Traning Loss: tensor(74.5157)\n",
      "3314 Traning Loss: tensor(74.5113)\n",
      "3315 Traning Loss: tensor(74.5069)\n",
      "3316 Traning Loss: tensor(74.5025)\n",
      "3317 Traning Loss: tensor(74.4981)\n",
      "3318 Traning Loss: tensor(74.4937)\n",
      "3319 Traning Loss: tensor(74.4893)\n",
      "3320 Traning Loss: tensor(74.4850)\n",
      "3321 Traning Loss: tensor(74.4806)\n",
      "3322 Traning Loss: tensor(74.4762)\n",
      "3323 Traning Loss: tensor(74.4718)\n",
      "3324 Traning Loss: tensor(74.4674)\n",
      "3325 Traning Loss: tensor(74.4630)\n",
      "3326 Traning Loss: tensor(74.4586)\n",
      "3327 Traning Loss: tensor(74.4543)\n",
      "3328 Traning Loss: tensor(74.4499)\n",
      "3329 Traning Loss: tensor(74.4455)\n",
      "3330 Traning Loss: tensor(74.4412)\n",
      "3331 Traning Loss: tensor(74.4368)\n",
      "3332 Traning Loss: tensor(74.4325)\n",
      "3333 Traning Loss: tensor(74.4281)\n",
      "3334 Traning Loss: tensor(74.4237)\n",
      "3335 Traning Loss: tensor(74.4194)\n",
      "3336 Traning Loss: tensor(74.4150)\n",
      "3337 Traning Loss: tensor(74.4107)\n",
      "3338 Traning Loss: tensor(74.4064)\n",
      "3339 Traning Loss: tensor(74.4020)\n",
      "3340 Traning Loss: tensor(74.3977)\n",
      "3341 Traning Loss: tensor(74.3933)\n",
      "3342 Traning Loss: tensor(74.3890)\n",
      "3343 Traning Loss: tensor(74.3846)\n",
      "3344 Traning Loss: tensor(74.3803)\n",
      "3345 Traning Loss: tensor(74.3760)\n",
      "3346 Traning Loss: tensor(74.3717)\n",
      "3347 Traning Loss: tensor(74.3673)\n",
      "3348 Traning Loss: tensor(74.3630)\n",
      "3349 Traning Loss: tensor(74.3587)\n",
      "3350 Traning Loss: tensor(74.3543)\n",
      "3351 Traning Loss: tensor(74.3500)\n",
      "3352 Traning Loss: tensor(74.3457)\n",
      "3353 Traning Loss: tensor(74.3414)\n",
      "3354 Traning Loss: tensor(74.3371)\n",
      "3355 Traning Loss: tensor(74.3327)\n",
      "3356 Traning Loss: tensor(74.3284)\n",
      "3357 Traning Loss: tensor(74.3241)\n",
      "3358 Traning Loss: tensor(74.3198)\n",
      "3359 Traning Loss: tensor(74.3155)\n",
      "3360 Traning Loss: tensor(74.3112)\n",
      "3361 Traning Loss: tensor(74.3069)\n",
      "3362 Traning Loss: tensor(74.3027)\n",
      "3363 Traning Loss: tensor(74.2983)\n",
      "3364 Traning Loss: tensor(74.2940)\n",
      "3365 Traning Loss: tensor(74.2897)\n",
      "3366 Traning Loss: tensor(74.2855)\n",
      "3367 Traning Loss: tensor(74.2812)\n",
      "3368 Traning Loss: tensor(74.2769)\n",
      "3369 Traning Loss: tensor(74.2726)\n",
      "3370 Traning Loss: tensor(74.2683)\n",
      "3371 Traning Loss: tensor(74.2640)\n",
      "3372 Traning Loss: tensor(74.2598)\n",
      "3373 Traning Loss: tensor(74.2555)\n",
      "3374 Traning Loss: tensor(74.2512)\n",
      "3375 Traning Loss: tensor(74.2469)\n",
      "3376 Traning Loss: tensor(74.2427)\n",
      "3377 Traning Loss: tensor(74.2384)\n",
      "3378 Traning Loss: tensor(74.2341)\n",
      "3379 Traning Loss: tensor(74.2299)\n",
      "3380 Traning Loss: tensor(74.2256)\n",
      "3381 Traning Loss: tensor(74.2213)\n",
      "3382 Traning Loss: tensor(74.2171)\n",
      "3383 Traning Loss: tensor(74.2128)\n",
      "3384 Traning Loss: tensor(74.2086)\n",
      "3385 Traning Loss: tensor(74.2043)\n",
      "3386 Traning Loss: tensor(74.2001)\n",
      "3387 Traning Loss: tensor(74.1958)\n",
      "3388 Traning Loss: tensor(74.1916)\n",
      "3389 Traning Loss: tensor(74.1873)\n",
      "3390 Traning Loss: tensor(74.1831)\n",
      "3391 Traning Loss: tensor(74.1788)\n",
      "3392 Traning Loss: tensor(74.1746)\n",
      "3393 Traning Loss: tensor(74.1704)\n",
      "3394 Traning Loss: tensor(74.1661)\n",
      "3395 Traning Loss: tensor(74.1619)\n",
      "3396 Traning Loss: tensor(74.1576)\n",
      "3397 Traning Loss: tensor(74.1534)\n",
      "3398 Traning Loss: tensor(74.1492)\n",
      "3399 Traning Loss: tensor(74.1450)\n",
      "3400 Traning Loss: tensor(74.1408)\n",
      "3401 Traning Loss: tensor(74.1365)\n",
      "3402 Traning Loss: tensor(74.1323)\n",
      "3403 Traning Loss: tensor(74.1281)\n",
      "3404 Traning Loss: tensor(74.1239)\n",
      "3405 Traning Loss: tensor(74.1197)\n",
      "3406 Traning Loss: tensor(74.1154)\n",
      "3407 Traning Loss: tensor(74.1112)\n",
      "3408 Traning Loss: tensor(74.1070)\n",
      "3409 Traning Loss: tensor(74.1028)\n",
      "3410 Traning Loss: tensor(74.0986)\n",
      "3411 Traning Loss: tensor(74.0944)\n",
      "3412 Traning Loss: tensor(74.0902)\n",
      "3413 Traning Loss: tensor(74.0860)\n",
      "3414 Traning Loss: tensor(74.0818)\n",
      "3415 Traning Loss: tensor(74.0775)\n",
      "3416 Traning Loss: tensor(74.0734)\n",
      "3417 Traning Loss: tensor(74.0692)\n",
      "3418 Traning Loss: tensor(74.0650)\n",
      "3419 Traning Loss: tensor(74.0608)\n",
      "3420 Traning Loss: tensor(74.0566)\n",
      "3421 Traning Loss: tensor(74.0524)\n",
      "3422 Traning Loss: tensor(74.0482)\n",
      "3423 Traning Loss: tensor(74.0440)\n",
      "3424 Traning Loss: tensor(74.0399)\n",
      "3425 Traning Loss: tensor(74.0357)\n",
      "3426 Traning Loss: tensor(74.0315)\n",
      "3427 Traning Loss: tensor(74.0273)\n",
      "3428 Traning Loss: tensor(74.0231)\n",
      "3429 Traning Loss: tensor(74.0189)\n",
      "3430 Traning Loss: tensor(74.0148)\n",
      "3431 Traning Loss: tensor(74.0106)\n",
      "3432 Traning Loss: tensor(74.0064)\n",
      "3433 Traning Loss: tensor(74.0023)\n",
      "3434 Traning Loss: tensor(73.9981)\n",
      "3435 Traning Loss: tensor(73.9939)\n",
      "3436 Traning Loss: tensor(73.9898)\n",
      "3437 Traning Loss: tensor(73.9856)\n",
      "3438 Traning Loss: tensor(73.9814)\n",
      "3439 Traning Loss: tensor(73.9773)\n",
      "3440 Traning Loss: tensor(73.9731)\n",
      "3441 Traning Loss: tensor(73.9689)\n",
      "3442 Traning Loss: tensor(73.9648)\n",
      "3443 Traning Loss: tensor(73.9606)\n",
      "3444 Traning Loss: tensor(73.9565)\n",
      "3445 Traning Loss: tensor(73.9523)\n",
      "3446 Traning Loss: tensor(73.9482)\n",
      "3447 Traning Loss: tensor(73.9440)\n",
      "3448 Traning Loss: tensor(73.9399)\n",
      "3449 Traning Loss: tensor(73.9357)\n",
      "3450 Traning Loss: tensor(73.9316)\n",
      "3451 Traning Loss: tensor(73.9275)\n",
      "3452 Traning Loss: tensor(73.9233)\n",
      "3453 Traning Loss: tensor(73.9192)\n",
      "3454 Traning Loss: tensor(73.9150)\n",
      "3455 Traning Loss: tensor(73.9109)\n",
      "3456 Traning Loss: tensor(73.9068)\n",
      "3457 Traning Loss: tensor(73.9026)\n",
      "3458 Traning Loss: tensor(73.8985)\n",
      "3459 Traning Loss: tensor(73.8944)\n",
      "3460 Traning Loss: tensor(73.8902)\n",
      "3461 Traning Loss: tensor(73.8861)\n",
      "3462 Traning Loss: tensor(73.8820)\n",
      "3463 Traning Loss: tensor(73.8778)\n",
      "3464 Traning Loss: tensor(73.8737)\n",
      "3465 Traning Loss: tensor(73.8696)\n",
      "3466 Traning Loss: tensor(73.8655)\n",
      "3467 Traning Loss: tensor(73.8614)\n",
      "3468 Traning Loss: tensor(73.8572)\n",
      "3469 Traning Loss: tensor(73.8531)\n",
      "3470 Traning Loss: tensor(73.8490)\n",
      "3471 Traning Loss: tensor(73.8449)\n",
      "3472 Traning Loss: tensor(73.8408)\n",
      "3473 Traning Loss: tensor(73.8367)\n",
      "3474 Traning Loss: tensor(73.8325)\n",
      "3475 Traning Loss: tensor(73.8284)\n",
      "3476 Traning Loss: tensor(73.8243)\n",
      "3477 Traning Loss: tensor(73.8202)\n",
      "3478 Traning Loss: tensor(73.8161)\n",
      "3479 Traning Loss: tensor(73.8120)\n",
      "3480 Traning Loss: tensor(73.8079)\n",
      "3481 Traning Loss: tensor(73.8038)\n",
      "3482 Traning Loss: tensor(73.7997)\n",
      "3483 Traning Loss: tensor(73.7956)\n",
      "3484 Traning Loss: tensor(73.7915)\n",
      "3485 Traning Loss: tensor(73.7874)\n",
      "3486 Traning Loss: tensor(73.7833)\n",
      "3487 Traning Loss: tensor(73.7792)\n",
      "3488 Traning Loss: tensor(73.7751)\n",
      "3489 Traning Loss: tensor(73.7710)\n",
      "3490 Traning Loss: tensor(73.7670)\n",
      "3491 Traning Loss: tensor(73.7629)\n",
      "3492 Traning Loss: tensor(73.7588)\n",
      "3493 Traning Loss: tensor(73.7547)\n",
      "3494 Traning Loss: tensor(73.7506)\n",
      "3495 Traning Loss: tensor(73.7465)\n",
      "3496 Traning Loss: tensor(73.7424)\n",
      "3497 Traning Loss: tensor(73.7384)\n",
      "3498 Traning Loss: tensor(73.7343)\n",
      "3499 Traning Loss: tensor(73.7302)\n",
      "3500 Traning Loss: tensor(73.7261)\n",
      "3501 Traning Loss: tensor(73.7220)\n",
      "3502 Traning Loss: tensor(73.7179)\n",
      "3503 Traning Loss: tensor(73.7139)\n",
      "3504 Traning Loss: tensor(73.7098)\n",
      "3505 Traning Loss: tensor(73.7057)\n",
      "3506 Traning Loss: tensor(73.7017)\n",
      "3507 Traning Loss: tensor(73.6976)\n",
      "3508 Traning Loss: tensor(73.6935)\n",
      "3509 Traning Loss: tensor(73.6894)\n",
      "3510 Traning Loss: tensor(73.6854)\n",
      "3511 Traning Loss: tensor(73.6813)\n",
      "3512 Traning Loss: tensor(73.6772)\n",
      "3513 Traning Loss: tensor(73.6732)\n",
      "3514 Traning Loss: tensor(73.6691)\n",
      "3515 Traning Loss: tensor(73.6651)\n",
      "3516 Traning Loss: tensor(73.6610)\n",
      "3517 Traning Loss: tensor(73.6569)\n",
      "3518 Traning Loss: tensor(73.6529)\n",
      "3519 Traning Loss: tensor(73.6488)\n",
      "3520 Traning Loss: tensor(73.6448)\n",
      "3521 Traning Loss: tensor(73.6407)\n",
      "3522 Traning Loss: tensor(73.6367)\n",
      "3523 Traning Loss: tensor(73.6326)\n",
      "3524 Traning Loss: tensor(73.6286)\n",
      "3525 Traning Loss: tensor(73.6245)\n",
      "3526 Traning Loss: tensor(73.6205)\n",
      "3527 Traning Loss: tensor(73.6164)\n",
      "3528 Traning Loss: tensor(73.6124)\n",
      "3529 Traning Loss: tensor(73.6083)\n",
      "3530 Traning Loss: tensor(73.6042)\n",
      "3531 Traning Loss: tensor(73.6002)\n",
      "3532 Traning Loss: tensor(73.5962)\n",
      "3533 Traning Loss: tensor(73.5921)\n",
      "3534 Traning Loss: tensor(73.5881)\n",
      "3535 Traning Loss: tensor(73.5840)\n",
      "3536 Traning Loss: tensor(73.5800)\n",
      "3537 Traning Loss: tensor(73.5760)\n",
      "3538 Traning Loss: tensor(73.5719)\n",
      "3539 Traning Loss: tensor(73.5679)\n",
      "3540 Traning Loss: tensor(73.5639)\n",
      "3541 Traning Loss: tensor(73.5598)\n",
      "3542 Traning Loss: tensor(73.5558)\n",
      "3543 Traning Loss: tensor(73.5518)\n",
      "3544 Traning Loss: tensor(73.5477)\n",
      "3545 Traning Loss: tensor(73.5437)\n",
      "3546 Traning Loss: tensor(73.5397)\n",
      "3547 Traning Loss: tensor(73.5357)\n",
      "3548 Traning Loss: tensor(73.5316)\n",
      "3549 Traning Loss: tensor(73.5276)\n",
      "3550 Traning Loss: tensor(73.5236)\n",
      "3551 Traning Loss: tensor(73.5195)\n",
      "3552 Traning Loss: tensor(73.5155)\n",
      "3553 Traning Loss: tensor(73.5115)\n",
      "3554 Traning Loss: tensor(73.5075)\n",
      "3555 Traning Loss: tensor(73.5034)\n",
      "3556 Traning Loss: tensor(73.4994)\n",
      "3557 Traning Loss: tensor(73.4954)\n",
      "3558 Traning Loss: tensor(73.4914)\n",
      "3559 Traning Loss: tensor(73.4874)\n",
      "3560 Traning Loss: tensor(73.4833)\n",
      "3561 Traning Loss: tensor(73.4793)\n",
      "3562 Traning Loss: tensor(73.4753)\n",
      "3563 Traning Loss: tensor(73.4713)\n",
      "3564 Traning Loss: tensor(73.4673)\n",
      "3565 Traning Loss: tensor(73.4633)\n",
      "3566 Traning Loss: tensor(73.4593)\n",
      "3567 Traning Loss: tensor(73.4553)\n",
      "3568 Traning Loss: tensor(73.4512)\n",
      "3569 Traning Loss: tensor(73.4472)\n",
      "3570 Traning Loss: tensor(73.4432)\n",
      "3571 Traning Loss: tensor(73.4392)\n",
      "3572 Traning Loss: tensor(73.4352)\n",
      "3573 Traning Loss: tensor(73.4312)\n",
      "3574 Traning Loss: tensor(73.4272)\n",
      "3575 Traning Loss: tensor(73.4232)\n",
      "3576 Traning Loss: tensor(73.4192)\n",
      "3577 Traning Loss: tensor(73.4152)\n",
      "3578 Traning Loss: tensor(73.4112)\n",
      "3579 Traning Loss: tensor(73.4072)\n",
      "3580 Traning Loss: tensor(73.4032)\n",
      "3581 Traning Loss: tensor(73.3992)\n",
      "3582 Traning Loss: tensor(73.3952)\n",
      "3583 Traning Loss: tensor(73.3912)\n",
      "3584 Traning Loss: tensor(73.3872)\n",
      "3585 Traning Loss: tensor(73.3832)\n",
      "3586 Traning Loss: tensor(73.3792)\n",
      "3587 Traning Loss: tensor(73.3752)\n",
      "3588 Traning Loss: tensor(73.3712)\n",
      "3589 Traning Loss: tensor(73.3672)\n",
      "3590 Traning Loss: tensor(73.3632)\n",
      "3591 Traning Loss: tensor(73.3592)\n",
      "3592 Traning Loss: tensor(73.3552)\n",
      "3593 Traning Loss: tensor(73.3512)\n",
      "3594 Traning Loss: tensor(73.3472)\n",
      "3595 Traning Loss: tensor(73.3432)\n",
      "3596 Traning Loss: tensor(73.3392)\n",
      "3597 Traning Loss: tensor(73.3353)\n",
      "3598 Traning Loss: tensor(73.3313)\n",
      "3599 Traning Loss: tensor(73.3273)\n",
      "3600 Traning Loss: tensor(73.3233)\n",
      "3601 Traning Loss: tensor(73.3193)\n",
      "3602 Traning Loss: tensor(73.3153)\n",
      "3603 Traning Loss: tensor(73.3113)\n",
      "3604 Traning Loss: tensor(73.3073)\n",
      "3605 Traning Loss: tensor(73.3034)\n",
      "3606 Traning Loss: tensor(73.2994)\n",
      "3607 Traning Loss: tensor(73.2954)\n",
      "3608 Traning Loss: tensor(73.2914)\n",
      "3609 Traning Loss: tensor(73.2874)\n",
      "3610 Traning Loss: tensor(73.2835)\n",
      "3611 Traning Loss: tensor(73.2795)\n",
      "3612 Traning Loss: tensor(73.2755)\n",
      "3613 Traning Loss: tensor(73.2715)\n",
      "3614 Traning Loss: tensor(73.2676)\n",
      "3615 Traning Loss: tensor(73.2636)\n",
      "3616 Traning Loss: tensor(73.2596)\n",
      "3617 Traning Loss: tensor(73.2556)\n",
      "3618 Traning Loss: tensor(73.2516)\n",
      "3619 Traning Loss: tensor(73.2477)\n",
      "3620 Traning Loss: tensor(73.2437)\n",
      "3621 Traning Loss: tensor(73.2397)\n",
      "3622 Traning Loss: tensor(73.2357)\n",
      "3623 Traning Loss: tensor(73.2318)\n",
      "3624 Traning Loss: tensor(73.2278)\n",
      "3625 Traning Loss: tensor(73.2238)\n",
      "3626 Traning Loss: tensor(73.2198)\n",
      "3627 Traning Loss: tensor(73.2159)\n",
      "3628 Traning Loss: tensor(73.2119)\n",
      "3629 Traning Loss: tensor(73.2080)\n",
      "3630 Traning Loss: tensor(73.2040)\n",
      "3631 Traning Loss: tensor(73.2000)\n",
      "3632 Traning Loss: tensor(73.1961)\n",
      "3633 Traning Loss: tensor(73.1921)\n",
      "3634 Traning Loss: tensor(73.1881)\n",
      "3635 Traning Loss: tensor(73.1841)\n",
      "3636 Traning Loss: tensor(73.1802)\n",
      "3637 Traning Loss: tensor(73.1762)\n",
      "3638 Traning Loss: tensor(73.1723)\n",
      "3639 Traning Loss: tensor(73.1683)\n",
      "3640 Traning Loss: tensor(73.1643)\n",
      "3641 Traning Loss: tensor(73.1603)\n",
      "3642 Traning Loss: tensor(73.1564)\n",
      "3643 Traning Loss: tensor(73.1524)\n",
      "3644 Traning Loss: tensor(73.1485)\n",
      "3645 Traning Loss: tensor(73.1445)\n",
      "3646 Traning Loss: tensor(73.1405)\n",
      "3647 Traning Loss: tensor(73.1366)\n",
      "3648 Traning Loss: tensor(73.1326)\n",
      "3649 Traning Loss: tensor(73.1287)\n",
      "3650 Traning Loss: tensor(73.1247)\n",
      "3651 Traning Loss: tensor(73.1208)\n",
      "3652 Traning Loss: tensor(73.1168)\n",
      "3653 Traning Loss: tensor(73.1128)\n",
      "3654 Traning Loss: tensor(73.1089)\n",
      "3655 Traning Loss: tensor(73.1049)\n",
      "3656 Traning Loss: tensor(73.1010)\n",
      "3657 Traning Loss: tensor(73.0970)\n",
      "3658 Traning Loss: tensor(73.0931)\n",
      "3659 Traning Loss: tensor(73.0891)\n",
      "3660 Traning Loss: tensor(73.0851)\n",
      "3661 Traning Loss: tensor(73.0812)\n",
      "3662 Traning Loss: tensor(73.0772)\n",
      "3663 Traning Loss: tensor(73.0733)\n",
      "3664 Traning Loss: tensor(73.0693)\n",
      "3665 Traning Loss: tensor(73.0654)\n",
      "3666 Traning Loss: tensor(73.0614)\n",
      "3667 Traning Loss: tensor(73.0575)\n",
      "3668 Traning Loss: tensor(73.0535)\n",
      "3669 Traning Loss: tensor(73.0495)\n",
      "3670 Traning Loss: tensor(73.0456)\n",
      "3671 Traning Loss: tensor(73.0417)\n",
      "3672 Traning Loss: tensor(73.0377)\n",
      "3673 Traning Loss: tensor(73.0338)\n",
      "3674 Traning Loss: tensor(73.0298)\n",
      "3675 Traning Loss: tensor(73.0259)\n",
      "3676 Traning Loss: tensor(73.0219)\n",
      "3677 Traning Loss: tensor(73.0180)\n",
      "3678 Traning Loss: tensor(73.0140)\n",
      "3679 Traning Loss: tensor(73.0101)\n",
      "3680 Traning Loss: tensor(73.0061)\n",
      "3681 Traning Loss: tensor(73.0022)\n",
      "3682 Traning Loss: tensor(72.9982)\n",
      "3683 Traning Loss: tensor(72.9943)\n",
      "3684 Traning Loss: tensor(72.9903)\n",
      "3685 Traning Loss: tensor(72.9864)\n",
      "3686 Traning Loss: tensor(72.9824)\n",
      "3687 Traning Loss: tensor(72.9785)\n",
      "3688 Traning Loss: tensor(72.9746)\n",
      "3689 Traning Loss: tensor(72.9706)\n",
      "3690 Traning Loss: tensor(72.9667)\n",
      "3691 Traning Loss: tensor(72.9627)\n",
      "3692 Traning Loss: tensor(72.9588)\n",
      "3693 Traning Loss: tensor(72.9548)\n",
      "3694 Traning Loss: tensor(72.9509)\n",
      "3695 Traning Loss: tensor(72.9469)\n",
      "3696 Traning Loss: tensor(72.9430)\n",
      "3697 Traning Loss: tensor(72.9390)\n",
      "3698 Traning Loss: tensor(72.9351)\n",
      "3699 Traning Loss: tensor(72.9312)\n",
      "3700 Traning Loss: tensor(72.9272)\n",
      "3701 Traning Loss: tensor(72.9233)\n",
      "3702 Traning Loss: tensor(72.9193)\n",
      "3703 Traning Loss: tensor(72.9154)\n",
      "3704 Traning Loss: tensor(72.9115)\n",
      "3705 Traning Loss: tensor(72.9075)\n",
      "3706 Traning Loss: tensor(72.9036)\n",
      "3707 Traning Loss: tensor(72.8996)\n",
      "3708 Traning Loss: tensor(72.8957)\n",
      "3709 Traning Loss: tensor(72.8917)\n",
      "3710 Traning Loss: tensor(72.8878)\n",
      "3711 Traning Loss: tensor(72.8839)\n",
      "3712 Traning Loss: tensor(72.8799)\n",
      "3713 Traning Loss: tensor(72.8760)\n",
      "3714 Traning Loss: tensor(72.8720)\n",
      "3715 Traning Loss: tensor(72.8681)\n",
      "3716 Traning Loss: tensor(72.8642)\n",
      "3717 Traning Loss: tensor(72.8602)\n",
      "3718 Traning Loss: tensor(72.8563)\n",
      "3719 Traning Loss: tensor(72.8523)\n",
      "3720 Traning Loss: tensor(72.8484)\n",
      "3721 Traning Loss: tensor(72.8445)\n",
      "3722 Traning Loss: tensor(72.8405)\n",
      "3723 Traning Loss: tensor(72.8366)\n",
      "3724 Traning Loss: tensor(72.8326)\n",
      "3725 Traning Loss: tensor(72.8287)\n",
      "3726 Traning Loss: tensor(72.8248)\n",
      "3727 Traning Loss: tensor(72.8208)\n",
      "3728 Traning Loss: tensor(72.8169)\n",
      "3729 Traning Loss: tensor(72.8130)\n",
      "3730 Traning Loss: tensor(72.8090)\n",
      "3731 Traning Loss: tensor(72.8051)\n",
      "3732 Traning Loss: tensor(72.8012)\n",
      "3733 Traning Loss: tensor(72.7972)\n",
      "3734 Traning Loss: tensor(72.7933)\n",
      "3735 Traning Loss: tensor(72.7893)\n",
      "3736 Traning Loss: tensor(72.7854)\n",
      "3737 Traning Loss: tensor(72.7814)\n",
      "3738 Traning Loss: tensor(72.7775)\n",
      "3739 Traning Loss: tensor(72.7736)\n",
      "3740 Traning Loss: tensor(72.7697)\n",
      "3741 Traning Loss: tensor(72.7657)\n",
      "3742 Traning Loss: tensor(72.7618)\n",
      "3743 Traning Loss: tensor(72.7579)\n",
      "3744 Traning Loss: tensor(72.7539)\n",
      "3745 Traning Loss: tensor(72.7500)\n",
      "3746 Traning Loss: tensor(72.7460)\n",
      "3747 Traning Loss: tensor(72.7421)\n",
      "3748 Traning Loss: tensor(72.7382)\n",
      "3749 Traning Loss: tensor(72.7342)\n",
      "3750 Traning Loss: tensor(72.7303)\n",
      "3751 Traning Loss: tensor(72.7264)\n",
      "3752 Traning Loss: tensor(72.7224)\n",
      "3753 Traning Loss: tensor(72.7185)\n",
      "3754 Traning Loss: tensor(72.7145)\n",
      "3755 Traning Loss: tensor(72.7106)\n",
      "3756 Traning Loss: tensor(72.7066)\n",
      "3757 Traning Loss: tensor(72.7027)\n",
      "3758 Traning Loss: tensor(72.6988)\n",
      "3759 Traning Loss: tensor(72.6948)\n",
      "3760 Traning Loss: tensor(72.6909)\n",
      "3761 Traning Loss: tensor(72.6870)\n",
      "3762 Traning Loss: tensor(72.6830)\n",
      "3763 Traning Loss: tensor(72.6791)\n",
      "3764 Traning Loss: tensor(72.6752)\n",
      "3765 Traning Loss: tensor(72.6712)\n",
      "3766 Traning Loss: tensor(72.6673)\n",
      "3767 Traning Loss: tensor(72.6634)\n",
      "3768 Traning Loss: tensor(72.6594)\n",
      "3769 Traning Loss: tensor(72.6555)\n",
      "3770 Traning Loss: tensor(72.6516)\n",
      "3771 Traning Loss: tensor(72.6476)\n",
      "3772 Traning Loss: tensor(72.6437)\n",
      "3773 Traning Loss: tensor(72.6397)\n",
      "3774 Traning Loss: tensor(72.6358)\n",
      "3775 Traning Loss: tensor(72.6318)\n",
      "3776 Traning Loss: tensor(72.6279)\n",
      "3777 Traning Loss: tensor(72.6240)\n",
      "3778 Traning Loss: tensor(72.6201)\n",
      "3779 Traning Loss: tensor(72.6161)\n",
      "3780 Traning Loss: tensor(72.6122)\n",
      "3781 Traning Loss: tensor(72.6082)\n",
      "3782 Traning Loss: tensor(72.6043)\n",
      "3783 Traning Loss: tensor(72.6006)\n",
      "3784 Traning Loss: tensor(72.5969)\n",
      "3785 Traning Loss: tensor(72.5932)\n",
      "3786 Traning Loss: tensor(72.5896)\n",
      "3787 Traning Loss: tensor(72.5859)\n",
      "3788 Traning Loss: tensor(72.5822)\n",
      "3789 Traning Loss: tensor(72.5785)\n",
      "3790 Traning Loss: tensor(72.5748)\n",
      "3791 Traning Loss: tensor(72.5711)\n",
      "3792 Traning Loss: tensor(72.5675)\n",
      "3793 Traning Loss: tensor(72.5638)\n",
      "3794 Traning Loss: tensor(72.5601)\n",
      "3795 Traning Loss: tensor(72.5564)\n",
      "3796 Traning Loss: tensor(72.5527)\n",
      "3797 Traning Loss: tensor(72.5490)\n",
      "3798 Traning Loss: tensor(72.5453)\n",
      "3799 Traning Loss: tensor(72.5416)\n",
      "3800 Traning Loss: tensor(72.5379)\n",
      "3801 Traning Loss: tensor(72.5343)\n",
      "3802 Traning Loss: tensor(72.5306)\n",
      "3803 Traning Loss: tensor(72.5269)\n",
      "3804 Traning Loss: tensor(72.5232)\n",
      "3805 Traning Loss: tensor(72.5195)\n",
      "3806 Traning Loss: tensor(72.5159)\n",
      "3807 Traning Loss: tensor(72.5122)\n",
      "3808 Traning Loss: tensor(72.5085)\n",
      "3809 Traning Loss: tensor(72.5048)\n",
      "3810 Traning Loss: tensor(72.5012)\n",
      "3811 Traning Loss: tensor(72.4975)\n",
      "3812 Traning Loss: tensor(72.4938)\n",
      "3813 Traning Loss: tensor(72.4901)\n",
      "3814 Traning Loss: tensor(72.4864)\n",
      "3815 Traning Loss: tensor(72.4827)\n",
      "3816 Traning Loss: tensor(72.4791)\n",
      "3817 Traning Loss: tensor(72.4754)\n",
      "3818 Traning Loss: tensor(72.4717)\n",
      "3819 Traning Loss: tensor(72.4680)\n",
      "3820 Traning Loss: tensor(72.4643)\n",
      "3821 Traning Loss: tensor(72.4606)\n",
      "3822 Traning Loss: tensor(72.4570)\n",
      "3823 Traning Loss: tensor(72.4533)\n",
      "3824 Traning Loss: tensor(72.4496)\n",
      "3825 Traning Loss: tensor(72.4459)\n",
      "3826 Traning Loss: tensor(72.4422)\n",
      "3827 Traning Loss: tensor(72.4386)\n",
      "3828 Traning Loss: tensor(72.4349)\n",
      "3829 Traning Loss: tensor(72.4312)\n",
      "3830 Traning Loss: tensor(72.4275)\n",
      "3831 Traning Loss: tensor(72.4238)\n",
      "3832 Traning Loss: tensor(72.4201)\n",
      "3833 Traning Loss: tensor(72.4165)\n",
      "3834 Traning Loss: tensor(72.4128)\n",
      "3835 Traning Loss: tensor(72.4091)\n",
      "3836 Traning Loss: tensor(72.4054)\n",
      "3837 Traning Loss: tensor(72.4017)\n",
      "3838 Traning Loss: tensor(72.3981)\n",
      "3839 Traning Loss: tensor(72.3944)\n",
      "3840 Traning Loss: tensor(72.3907)\n",
      "3841 Traning Loss: tensor(72.3870)\n",
      "3842 Traning Loss: tensor(72.3833)\n",
      "3843 Traning Loss: tensor(72.3797)\n",
      "3844 Traning Loss: tensor(72.3760)\n",
      "3845 Traning Loss: tensor(72.3723)\n",
      "3846 Traning Loss: tensor(72.3686)\n",
      "3847 Traning Loss: tensor(72.3649)\n",
      "3848 Traning Loss: tensor(72.3612)\n",
      "3849 Traning Loss: tensor(72.3575)\n",
      "3850 Traning Loss: tensor(72.3539)\n",
      "3851 Traning Loss: tensor(72.3502)\n",
      "3852 Traning Loss: tensor(72.3465)\n",
      "3853 Traning Loss: tensor(72.3428)\n",
      "3854 Traning Loss: tensor(72.3391)\n",
      "3855 Traning Loss: tensor(72.3354)\n",
      "3856 Traning Loss: tensor(72.3318)\n",
      "3857 Traning Loss: tensor(72.3281)\n",
      "3858 Traning Loss: tensor(72.3244)\n",
      "3859 Traning Loss: tensor(72.3207)\n",
      "3860 Traning Loss: tensor(72.3170)\n",
      "3861 Traning Loss: tensor(72.3133)\n",
      "3862 Traning Loss: tensor(72.3097)\n",
      "3863 Traning Loss: tensor(72.3060)\n",
      "3864 Traning Loss: tensor(72.3023)\n",
      "3865 Traning Loss: tensor(72.2986)\n",
      "3866 Traning Loss: tensor(72.2949)\n",
      "3867 Traning Loss: tensor(72.2912)\n",
      "3868 Traning Loss: tensor(72.2875)\n",
      "3869 Traning Loss: tensor(72.2839)\n",
      "3870 Traning Loss: tensor(72.2802)\n",
      "3871 Traning Loss: tensor(72.2765)\n",
      "3872 Traning Loss: tensor(72.2728)\n",
      "3873 Traning Loss: tensor(72.2691)\n",
      "3874 Traning Loss: tensor(72.2654)\n",
      "3875 Traning Loss: tensor(72.2618)\n",
      "3876 Traning Loss: tensor(72.2581)\n",
      "3877 Traning Loss: tensor(72.2544)\n",
      "3878 Traning Loss: tensor(72.2507)\n",
      "3879 Traning Loss: tensor(72.2470)\n",
      "3880 Traning Loss: tensor(72.2433)\n",
      "3881 Traning Loss: tensor(72.2396)\n",
      "3882 Traning Loss: tensor(72.2359)\n",
      "3883 Traning Loss: tensor(72.2322)\n",
      "3884 Traning Loss: tensor(72.2286)\n",
      "3885 Traning Loss: tensor(72.2249)\n",
      "3886 Traning Loss: tensor(72.2212)\n",
      "3887 Traning Loss: tensor(72.2175)\n",
      "3888 Traning Loss: tensor(72.2138)\n",
      "3889 Traning Loss: tensor(72.2101)\n",
      "3890 Traning Loss: tensor(72.2064)\n",
      "3891 Traning Loss: tensor(72.2027)\n",
      "3892 Traning Loss: tensor(72.1990)\n",
      "3893 Traning Loss: tensor(72.1954)\n",
      "3894 Traning Loss: tensor(72.1917)\n",
      "3895 Traning Loss: tensor(72.1880)\n",
      "3896 Traning Loss: tensor(72.1843)\n",
      "3897 Traning Loss: tensor(72.1806)\n",
      "3898 Traning Loss: tensor(72.1769)\n",
      "3899 Traning Loss: tensor(72.1732)\n",
      "3900 Traning Loss: tensor(72.1695)\n",
      "3901 Traning Loss: tensor(72.1658)\n",
      "3902 Traning Loss: tensor(72.1621)\n",
      "3903 Traning Loss: tensor(72.1584)\n",
      "3904 Traning Loss: tensor(72.1547)\n",
      "3905 Traning Loss: tensor(72.1510)\n",
      "3906 Traning Loss: tensor(72.1474)\n",
      "3907 Traning Loss: tensor(72.1437)\n",
      "3908 Traning Loss: tensor(72.1400)\n",
      "3909 Traning Loss: tensor(72.1363)\n",
      "3910 Traning Loss: tensor(72.1326)\n",
      "3911 Traning Loss: tensor(72.1289)\n",
      "3912 Traning Loss: tensor(72.1252)\n",
      "3913 Traning Loss: tensor(72.1215)\n",
      "3914 Traning Loss: tensor(72.1178)\n",
      "3915 Traning Loss: tensor(72.1141)\n",
      "3916 Traning Loss: tensor(72.1104)\n",
      "3917 Traning Loss: tensor(72.1067)\n",
      "3918 Traning Loss: tensor(72.1030)\n",
      "3919 Traning Loss: tensor(72.0993)\n",
      "3920 Traning Loss: tensor(72.0956)\n",
      "3921 Traning Loss: tensor(72.0919)\n",
      "3922 Traning Loss: tensor(72.0882)\n",
      "3923 Traning Loss: tensor(72.0845)\n",
      "3924 Traning Loss: tensor(72.0808)\n",
      "3925 Traning Loss: tensor(72.0771)\n",
      "3926 Traning Loss: tensor(72.0734)\n",
      "3927 Traning Loss: tensor(72.0697)\n",
      "3928 Traning Loss: tensor(72.0660)\n",
      "3929 Traning Loss: tensor(72.0623)\n",
      "3930 Traning Loss: tensor(72.0586)\n",
      "3931 Traning Loss: tensor(72.0549)\n",
      "3932 Traning Loss: tensor(72.0512)\n",
      "3933 Traning Loss: tensor(72.0475)\n",
      "3934 Traning Loss: tensor(72.0438)\n",
      "3935 Traning Loss: tensor(72.0401)\n",
      "3936 Traning Loss: tensor(72.0364)\n",
      "3937 Traning Loss: tensor(72.0327)\n",
      "3938 Traning Loss: tensor(72.0290)\n",
      "3939 Traning Loss: tensor(72.0253)\n",
      "3940 Traning Loss: tensor(72.0216)\n",
      "3941 Traning Loss: tensor(72.0179)\n",
      "3942 Traning Loss: tensor(72.0142)\n",
      "3943 Traning Loss: tensor(72.0105)\n",
      "3944 Traning Loss: tensor(72.0068)\n",
      "3945 Traning Loss: tensor(72.0031)\n",
      "3946 Traning Loss: tensor(71.9994)\n",
      "3947 Traning Loss: tensor(71.9957)\n",
      "3948 Traning Loss: tensor(71.9920)\n",
      "3949 Traning Loss: tensor(71.9882)\n",
      "3950 Traning Loss: tensor(71.9845)\n",
      "3951 Traning Loss: tensor(71.9809)\n",
      "3952 Traning Loss: tensor(71.9771)\n",
      "3953 Traning Loss: tensor(71.9734)\n",
      "3954 Traning Loss: tensor(71.9697)\n",
      "3955 Traning Loss: tensor(71.9660)\n",
      "3956 Traning Loss: tensor(71.9623)\n",
      "3957 Traning Loss: tensor(71.9586)\n",
      "3958 Traning Loss: tensor(71.9549)\n",
      "3959 Traning Loss: tensor(71.9512)\n",
      "3960 Traning Loss: tensor(71.9474)\n",
      "3961 Traning Loss: tensor(71.9437)\n",
      "3962 Traning Loss: tensor(71.9400)\n",
      "3963 Traning Loss: tensor(71.9363)\n",
      "3964 Traning Loss: tensor(71.9326)\n",
      "3965 Traning Loss: tensor(71.9289)\n",
      "3966 Traning Loss: tensor(71.9252)\n",
      "3967 Traning Loss: tensor(71.9214)\n",
      "3968 Traning Loss: tensor(71.9177)\n",
      "3969 Traning Loss: tensor(71.9140)\n",
      "3970 Traning Loss: tensor(71.9103)\n",
      "3971 Traning Loss: tensor(71.9066)\n",
      "3972 Traning Loss: tensor(71.9029)\n",
      "3973 Traning Loss: tensor(71.8991)\n",
      "3974 Traning Loss: tensor(71.8954)\n",
      "3975 Traning Loss: tensor(71.8917)\n",
      "3976 Traning Loss: tensor(71.8880)\n",
      "3977 Traning Loss: tensor(71.8843)\n",
      "3978 Traning Loss: tensor(71.8806)\n",
      "3979 Traning Loss: tensor(71.8768)\n",
      "3980 Traning Loss: tensor(71.8731)\n",
      "3981 Traning Loss: tensor(71.8694)\n",
      "3982 Traning Loss: tensor(71.8657)\n",
      "3983 Traning Loss: tensor(71.8619)\n",
      "3984 Traning Loss: tensor(71.8582)\n",
      "3985 Traning Loss: tensor(71.8545)\n",
      "3986 Traning Loss: tensor(71.8508)\n",
      "3987 Traning Loss: tensor(71.8471)\n",
      "3988 Traning Loss: tensor(71.8433)\n",
      "3989 Traning Loss: tensor(71.8396)\n",
      "3990 Traning Loss: tensor(71.8359)\n",
      "3991 Traning Loss: tensor(71.8322)\n",
      "3992 Traning Loss: tensor(71.8284)\n",
      "3993 Traning Loss: tensor(71.8247)\n",
      "3994 Traning Loss: tensor(71.8210)\n",
      "3995 Traning Loss: tensor(71.8173)\n",
      "3996 Traning Loss: tensor(71.8135)\n",
      "3997 Traning Loss: tensor(71.8098)\n",
      "3998 Traning Loss: tensor(71.8061)\n",
      "3999 Traning Loss: tensor(71.8023)\n",
      "4000 Traning Loss: tensor(71.7986)\n",
      "4001 Traning Loss: tensor(71.7949)\n",
      "4002 Traning Loss: tensor(71.7912)\n",
      "4003 Traning Loss: tensor(71.7874)\n",
      "4004 Traning Loss: tensor(71.7837)\n",
      "4005 Traning Loss: tensor(71.7800)\n",
      "4006 Traning Loss: tensor(71.7762)\n",
      "4007 Traning Loss: tensor(71.7725)\n",
      "4008 Traning Loss: tensor(71.7688)\n",
      "4009 Traning Loss: tensor(71.7650)\n",
      "4010 Traning Loss: tensor(71.7613)\n",
      "4011 Traning Loss: tensor(71.7576)\n",
      "4012 Traning Loss: tensor(71.7538)\n",
      "4013 Traning Loss: tensor(71.7501)\n",
      "4014 Traning Loss: tensor(71.7463)\n",
      "4015 Traning Loss: tensor(71.7426)\n",
      "4016 Traning Loss: tensor(71.7389)\n",
      "4017 Traning Loss: tensor(71.7352)\n",
      "4018 Traning Loss: tensor(71.7314)\n",
      "4019 Traning Loss: tensor(71.7277)\n",
      "4020 Traning Loss: tensor(71.7239)\n",
      "4021 Traning Loss: tensor(71.7202)\n",
      "4022 Traning Loss: tensor(71.7164)\n",
      "4023 Traning Loss: tensor(71.7127)\n",
      "4024 Traning Loss: tensor(71.7090)\n",
      "4025 Traning Loss: tensor(71.7052)\n",
      "4026 Traning Loss: tensor(71.7015)\n",
      "4027 Traning Loss: tensor(71.6977)\n",
      "4028 Traning Loss: tensor(71.6939)\n",
      "4029 Traning Loss: tensor(71.6902)\n",
      "4030 Traning Loss: tensor(71.6865)\n",
      "4031 Traning Loss: tensor(71.6827)\n",
      "4032 Traning Loss: tensor(71.6790)\n",
      "4033 Traning Loss: tensor(71.6752)\n",
      "4034 Traning Loss: tensor(71.6715)\n",
      "4035 Traning Loss: tensor(71.6677)\n",
      "4036 Traning Loss: tensor(71.6640)\n",
      "4037 Traning Loss: tensor(71.6602)\n",
      "4038 Traning Loss: tensor(71.6565)\n",
      "4039 Traning Loss: tensor(71.6527)\n",
      "4040 Traning Loss: tensor(71.6490)\n",
      "4041 Traning Loss: tensor(71.6452)\n",
      "4042 Traning Loss: tensor(71.6415)\n",
      "4043 Traning Loss: tensor(71.6377)\n",
      "4044 Traning Loss: tensor(71.6340)\n",
      "4045 Traning Loss: tensor(71.6302)\n",
      "4046 Traning Loss: tensor(71.6265)\n",
      "4047 Traning Loss: tensor(71.6227)\n",
      "4048 Traning Loss: tensor(71.6189)\n",
      "4049 Traning Loss: tensor(71.6152)\n",
      "4050 Traning Loss: tensor(71.6114)\n",
      "4051 Traning Loss: tensor(71.6077)\n",
      "4052 Traning Loss: tensor(71.6039)\n",
      "4053 Traning Loss: tensor(71.6001)\n",
      "4054 Traning Loss: tensor(71.5964)\n",
      "4055 Traning Loss: tensor(71.5926)\n",
      "4056 Traning Loss: tensor(71.5889)\n",
      "4057 Traning Loss: tensor(71.5851)\n",
      "4058 Traning Loss: tensor(71.5813)\n",
      "4059 Traning Loss: tensor(71.5776)\n",
      "4060 Traning Loss: tensor(71.5738)\n",
      "4061 Traning Loss: tensor(71.5700)\n",
      "4062 Traning Loss: tensor(71.5663)\n",
      "4063 Traning Loss: tensor(71.5625)\n",
      "4064 Traning Loss: tensor(71.5587)\n",
      "4065 Traning Loss: tensor(71.5550)\n",
      "4066 Traning Loss: tensor(71.5512)\n",
      "4067 Traning Loss: tensor(71.5474)\n",
      "4068 Traning Loss: tensor(71.5437)\n",
      "4069 Traning Loss: tensor(71.5399)\n",
      "4070 Traning Loss: tensor(71.5361)\n",
      "4071 Traning Loss: tensor(71.5323)\n",
      "4072 Traning Loss: tensor(71.5286)\n",
      "4073 Traning Loss: tensor(71.5248)\n",
      "4074 Traning Loss: tensor(71.5210)\n",
      "4075 Traning Loss: tensor(71.5173)\n",
      "4076 Traning Loss: tensor(71.5135)\n",
      "4077 Traning Loss: tensor(71.5097)\n",
      "4078 Traning Loss: tensor(71.5060)\n",
      "4079 Traning Loss: tensor(71.5022)\n",
      "4080 Traning Loss: tensor(71.4984)\n",
      "4081 Traning Loss: tensor(71.4946)\n",
      "4082 Traning Loss: tensor(71.4908)\n",
      "4083 Traning Loss: tensor(71.4870)\n",
      "4084 Traning Loss: tensor(71.4833)\n",
      "4085 Traning Loss: tensor(71.4795)\n",
      "4086 Traning Loss: tensor(71.4757)\n",
      "4087 Traning Loss: tensor(71.4719)\n",
      "4088 Traning Loss: tensor(71.4681)\n",
      "4089 Traning Loss: tensor(71.4644)\n",
      "4090 Traning Loss: tensor(71.4606)\n",
      "4091 Traning Loss: tensor(71.4568)\n",
      "4092 Traning Loss: tensor(71.4530)\n",
      "4093 Traning Loss: tensor(71.4492)\n",
      "4094 Traning Loss: tensor(71.4454)\n",
      "4095 Traning Loss: tensor(71.4416)\n",
      "4096 Traning Loss: tensor(71.4378)\n",
      "4097 Traning Loss: tensor(71.4340)\n",
      "4098 Traning Loss: tensor(71.4302)\n",
      "4099 Traning Loss: tensor(71.4265)\n",
      "4100 Traning Loss: tensor(71.4227)\n",
      "4101 Traning Loss: tensor(71.4189)\n",
      "4102 Traning Loss: tensor(71.4151)\n",
      "4103 Traning Loss: tensor(71.4113)\n",
      "4104 Traning Loss: tensor(71.4075)\n",
      "4105 Traning Loss: tensor(71.4037)\n",
      "4106 Traning Loss: tensor(71.3999)\n",
      "4107 Traning Loss: tensor(71.3961)\n",
      "4108 Traning Loss: tensor(71.3923)\n",
      "4109 Traning Loss: tensor(71.3885)\n",
      "4110 Traning Loss: tensor(71.3847)\n",
      "4111 Traning Loss: tensor(71.3809)\n",
      "4112 Traning Loss: tensor(71.3771)\n",
      "4113 Traning Loss: tensor(71.3733)\n",
      "4114 Traning Loss: tensor(71.3695)\n",
      "4115 Traning Loss: tensor(71.3657)\n",
      "4116 Traning Loss: tensor(71.3619)\n",
      "4117 Traning Loss: tensor(71.3581)\n",
      "4118 Traning Loss: tensor(71.3543)\n",
      "4119 Traning Loss: tensor(71.3505)\n",
      "4120 Traning Loss: tensor(71.3467)\n",
      "4121 Traning Loss: tensor(71.3429)\n",
      "4122 Traning Loss: tensor(71.3391)\n",
      "4123 Traning Loss: tensor(71.3353)\n",
      "4124 Traning Loss: tensor(71.3314)\n",
      "4125 Traning Loss: tensor(71.3276)\n",
      "4126 Traning Loss: tensor(71.3238)\n",
      "4127 Traning Loss: tensor(71.3200)\n",
      "4128 Traning Loss: tensor(71.3162)\n",
      "4129 Traning Loss: tensor(71.3124)\n",
      "4130 Traning Loss: tensor(71.3086)\n",
      "4131 Traning Loss: tensor(71.3048)\n",
      "4132 Traning Loss: tensor(71.3009)\n",
      "4133 Traning Loss: tensor(71.2971)\n",
      "4134 Traning Loss: tensor(71.2933)\n",
      "4135 Traning Loss: tensor(71.2895)\n",
      "4136 Traning Loss: tensor(71.2857)\n",
      "4137 Traning Loss: tensor(71.2818)\n",
      "4138 Traning Loss: tensor(71.2780)\n",
      "4139 Traning Loss: tensor(71.2742)\n",
      "4140 Traning Loss: tensor(71.2704)\n",
      "4141 Traning Loss: tensor(71.2665)\n",
      "4142 Traning Loss: tensor(71.2627)\n",
      "4143 Traning Loss: tensor(71.2589)\n",
      "4144 Traning Loss: tensor(71.2551)\n",
      "4145 Traning Loss: tensor(71.2513)\n",
      "4146 Traning Loss: tensor(71.2474)\n",
      "4147 Traning Loss: tensor(71.2436)\n",
      "4148 Traning Loss: tensor(71.2398)\n",
      "4149 Traning Loss: tensor(71.2359)\n",
      "4150 Traning Loss: tensor(71.2321)\n",
      "4151 Traning Loss: tensor(71.2283)\n",
      "4152 Traning Loss: tensor(71.2244)\n",
      "4153 Traning Loss: tensor(71.2206)\n",
      "4154 Traning Loss: tensor(71.2168)\n",
      "4155 Traning Loss: tensor(71.2129)\n",
      "4156 Traning Loss: tensor(71.2091)\n",
      "4157 Traning Loss: tensor(71.2053)\n",
      "4158 Traning Loss: tensor(71.2014)\n",
      "4159 Traning Loss: tensor(71.1976)\n",
      "4160 Traning Loss: tensor(71.1937)\n",
      "4161 Traning Loss: tensor(71.1899)\n",
      "4162 Traning Loss: tensor(71.1861)\n",
      "4163 Traning Loss: tensor(71.1822)\n",
      "4164 Traning Loss: tensor(71.1784)\n",
      "4165 Traning Loss: tensor(71.1746)\n",
      "4166 Traning Loss: tensor(71.1707)\n",
      "4167 Traning Loss: tensor(71.1669)\n",
      "4168 Traning Loss: tensor(71.1630)\n",
      "4169 Traning Loss: tensor(71.1591)\n",
      "4170 Traning Loss: tensor(71.1553)\n",
      "4171 Traning Loss: tensor(71.1515)\n",
      "4172 Traning Loss: tensor(71.1476)\n",
      "4173 Traning Loss: tensor(71.1438)\n",
      "4174 Traning Loss: tensor(71.1399)\n",
      "4175 Traning Loss: tensor(71.1361)\n",
      "4176 Traning Loss: tensor(71.1322)\n",
      "4177 Traning Loss: tensor(71.1284)\n",
      "4178 Traning Loss: tensor(71.1245)\n",
      "4179 Traning Loss: tensor(71.1206)\n",
      "4180 Traning Loss: tensor(71.1168)\n",
      "4181 Traning Loss: tensor(71.1129)\n",
      "4182 Traning Loss: tensor(71.1091)\n",
      "4183 Traning Loss: tensor(71.1052)\n",
      "4184 Traning Loss: tensor(71.1013)\n",
      "4185 Traning Loss: tensor(71.0975)\n",
      "4186 Traning Loss: tensor(71.0936)\n",
      "4187 Traning Loss: tensor(71.0897)\n",
      "4188 Traning Loss: tensor(71.0859)\n",
      "4189 Traning Loss: tensor(71.0820)\n",
      "4190 Traning Loss: tensor(71.0781)\n",
      "4191 Traning Loss: tensor(71.0743)\n",
      "4192 Traning Loss: tensor(71.0704)\n",
      "4193 Traning Loss: tensor(71.0665)\n",
      "4194 Traning Loss: tensor(71.0627)\n",
      "4195 Traning Loss: tensor(71.0588)\n",
      "4196 Traning Loss: tensor(71.0549)\n",
      "4197 Traning Loss: tensor(71.0511)\n",
      "4198 Traning Loss: tensor(71.0472)\n",
      "4199 Traning Loss: tensor(71.0433)\n",
      "4200 Traning Loss: tensor(71.0394)\n",
      "4201 Traning Loss: tensor(71.0356)\n",
      "4202 Traning Loss: tensor(71.0317)\n",
      "4203 Traning Loss: tensor(71.0278)\n",
      "4204 Traning Loss: tensor(71.0239)\n",
      "4205 Traning Loss: tensor(71.0201)\n",
      "4206 Traning Loss: tensor(71.0162)\n",
      "4207 Traning Loss: tensor(71.0123)\n",
      "4208 Traning Loss: tensor(71.0084)\n",
      "4209 Traning Loss: tensor(71.0045)\n",
      "4210 Traning Loss: tensor(71.0006)\n",
      "4211 Traning Loss: tensor(70.9967)\n",
      "4212 Traning Loss: tensor(70.9929)\n",
      "4213 Traning Loss: tensor(70.9890)\n",
      "4214 Traning Loss: tensor(70.9851)\n",
      "4215 Traning Loss: tensor(70.9812)\n",
      "4216 Traning Loss: tensor(70.9773)\n",
      "4217 Traning Loss: tensor(70.9734)\n",
      "4218 Traning Loss: tensor(70.9696)\n",
      "4219 Traning Loss: tensor(70.9656)\n",
      "4220 Traning Loss: tensor(70.9617)\n",
      "4221 Traning Loss: tensor(70.9578)\n",
      "4222 Traning Loss: tensor(70.9539)\n",
      "4223 Traning Loss: tensor(70.9501)\n",
      "4224 Traning Loss: tensor(70.9462)\n",
      "4225 Traning Loss: tensor(70.9423)\n",
      "4226 Traning Loss: tensor(70.9384)\n",
      "4227 Traning Loss: tensor(70.9345)\n",
      "4228 Traning Loss: tensor(70.9306)\n",
      "4229 Traning Loss: tensor(70.9267)\n",
      "4230 Traning Loss: tensor(70.9228)\n",
      "4231 Traning Loss: tensor(70.9189)\n",
      "4232 Traning Loss: tensor(70.9149)\n",
      "4233 Traning Loss: tensor(70.9110)\n",
      "4234 Traning Loss: tensor(70.9071)\n",
      "4235 Traning Loss: tensor(70.9032)\n",
      "4236 Traning Loss: tensor(70.8993)\n",
      "4237 Traning Loss: tensor(70.8954)\n",
      "4238 Traning Loss: tensor(70.8915)\n",
      "4239 Traning Loss: tensor(70.8876)\n",
      "4240 Traning Loss: tensor(70.8837)\n",
      "4241 Traning Loss: tensor(70.8797)\n",
      "4242 Traning Loss: tensor(70.8758)\n",
      "4243 Traning Loss: tensor(70.8719)\n",
      "4244 Traning Loss: tensor(70.8680)\n",
      "4245 Traning Loss: tensor(70.8641)\n",
      "4246 Traning Loss: tensor(70.8602)\n",
      "4247 Traning Loss: tensor(70.8562)\n",
      "4248 Traning Loss: tensor(70.8523)\n",
      "4249 Traning Loss: tensor(70.8484)\n",
      "4250 Traning Loss: tensor(70.8445)\n",
      "4251 Traning Loss: tensor(70.8405)\n",
      "4252 Traning Loss: tensor(70.8366)\n",
      "4253 Traning Loss: tensor(70.8327)\n",
      "4254 Traning Loss: tensor(70.8287)\n",
      "4255 Traning Loss: tensor(70.8248)\n",
      "4256 Traning Loss: tensor(70.8209)\n",
      "4257 Traning Loss: tensor(70.8169)\n",
      "4258 Traning Loss: tensor(70.8130)\n",
      "4259 Traning Loss: tensor(70.8091)\n",
      "4260 Traning Loss: tensor(70.8052)\n",
      "4261 Traning Loss: tensor(70.8012)\n",
      "4262 Traning Loss: tensor(70.7973)\n",
      "4263 Traning Loss: tensor(70.7934)\n",
      "4264 Traning Loss: tensor(70.7894)\n",
      "4265 Traning Loss: tensor(70.7855)\n",
      "4266 Traning Loss: tensor(70.7815)\n",
      "4267 Traning Loss: tensor(70.7776)\n",
      "4268 Traning Loss: tensor(70.7737)\n",
      "4269 Traning Loss: tensor(70.7697)\n",
      "4270 Traning Loss: tensor(70.7658)\n",
      "4271 Traning Loss: tensor(70.7618)\n",
      "4272 Traning Loss: tensor(70.7579)\n",
      "4273 Traning Loss: tensor(70.7539)\n",
      "4274 Traning Loss: tensor(70.7500)\n",
      "4275 Traning Loss: tensor(70.7460)\n",
      "4276 Traning Loss: tensor(70.7421)\n",
      "4277 Traning Loss: tensor(70.7381)\n",
      "4278 Traning Loss: tensor(70.7342)\n",
      "4279 Traning Loss: tensor(70.7302)\n",
      "4280 Traning Loss: tensor(70.7263)\n",
      "4281 Traning Loss: tensor(70.7223)\n",
      "4282 Traning Loss: tensor(70.7183)\n",
      "4283 Traning Loss: tensor(70.7144)\n",
      "4284 Traning Loss: tensor(70.7104)\n",
      "4285 Traning Loss: tensor(70.7065)\n",
      "4286 Traning Loss: tensor(70.7025)\n",
      "4287 Traning Loss: tensor(70.6985)\n",
      "4288 Traning Loss: tensor(70.6946)\n",
      "4289 Traning Loss: tensor(70.6906)\n",
      "4290 Traning Loss: tensor(70.6866)\n",
      "4291 Traning Loss: tensor(70.6827)\n",
      "4292 Traning Loss: tensor(70.6787)\n",
      "4293 Traning Loss: tensor(70.6748)\n",
      "4294 Traning Loss: tensor(70.6708)\n",
      "4295 Traning Loss: tensor(70.6668)\n",
      "4296 Traning Loss: tensor(70.6628)\n",
      "4297 Traning Loss: tensor(70.6589)\n",
      "4298 Traning Loss: tensor(70.6549)\n",
      "4299 Traning Loss: tensor(70.6509)\n",
      "4300 Traning Loss: tensor(70.6469)\n",
      "4301 Traning Loss: tensor(70.6430)\n",
      "4302 Traning Loss: tensor(70.6390)\n",
      "4303 Traning Loss: tensor(70.6350)\n",
      "4304 Traning Loss: tensor(70.6310)\n",
      "4305 Traning Loss: tensor(70.6270)\n",
      "4306 Traning Loss: tensor(70.6230)\n",
      "4307 Traning Loss: tensor(70.6191)\n",
      "4308 Traning Loss: tensor(70.6151)\n",
      "4309 Traning Loss: tensor(70.6111)\n",
      "4310 Traning Loss: tensor(70.6071)\n",
      "4311 Traning Loss: tensor(70.6031)\n",
      "4312 Traning Loss: tensor(70.5991)\n",
      "4313 Traning Loss: tensor(70.5951)\n",
      "4314 Traning Loss: tensor(70.5911)\n",
      "4315 Traning Loss: tensor(70.5871)\n",
      "4316 Traning Loss: tensor(70.5831)\n",
      "4317 Traning Loss: tensor(70.5792)\n",
      "4318 Traning Loss: tensor(70.5751)\n",
      "4319 Traning Loss: tensor(70.5711)\n",
      "4320 Traning Loss: tensor(70.5671)\n",
      "4321 Traning Loss: tensor(70.5631)\n",
      "4322 Traning Loss: tensor(70.5591)\n",
      "4323 Traning Loss: tensor(70.5551)\n",
      "4324 Traning Loss: tensor(70.5511)\n",
      "4325 Traning Loss: tensor(70.5471)\n",
      "4326 Traning Loss: tensor(70.5431)\n",
      "4327 Traning Loss: tensor(70.5391)\n",
      "4328 Traning Loss: tensor(70.5351)\n",
      "4329 Traning Loss: tensor(70.5311)\n",
      "4330 Traning Loss: tensor(70.5271)\n",
      "4331 Traning Loss: tensor(70.5231)\n",
      "4332 Traning Loss: tensor(70.5191)\n",
      "4333 Traning Loss: tensor(70.5150)\n",
      "4334 Traning Loss: tensor(70.5110)\n",
      "4335 Traning Loss: tensor(70.5070)\n",
      "4336 Traning Loss: tensor(70.5030)\n",
      "4337 Traning Loss: tensor(70.4990)\n",
      "4338 Traning Loss: tensor(70.4950)\n",
      "4339 Traning Loss: tensor(70.4909)\n",
      "4340 Traning Loss: tensor(70.4869)\n",
      "4341 Traning Loss: tensor(70.4829)\n",
      "4342 Traning Loss: tensor(70.4789)\n",
      "4343 Traning Loss: tensor(70.4748)\n",
      "4344 Traning Loss: tensor(70.4708)\n",
      "4345 Traning Loss: tensor(70.4668)\n",
      "4346 Traning Loss: tensor(70.4628)\n",
      "4347 Traning Loss: tensor(70.4587)\n",
      "4348 Traning Loss: tensor(70.4547)\n",
      "4349 Traning Loss: tensor(70.4507)\n",
      "4350 Traning Loss: tensor(70.4466)\n",
      "4351 Traning Loss: tensor(70.4426)\n",
      "4352 Traning Loss: tensor(70.4386)\n",
      "4353 Traning Loss: tensor(70.4345)\n",
      "4354 Traning Loss: tensor(70.4305)\n",
      "4355 Traning Loss: tensor(70.4264)\n",
      "4356 Traning Loss: tensor(70.4224)\n",
      "4357 Traning Loss: tensor(70.4184)\n",
      "4358 Traning Loss: tensor(70.4143)\n",
      "4359 Traning Loss: tensor(70.4103)\n",
      "4360 Traning Loss: tensor(70.4062)\n",
      "4361 Traning Loss: tensor(70.4022)\n",
      "4362 Traning Loss: tensor(70.3981)\n",
      "4363 Traning Loss: tensor(70.3941)\n",
      "4364 Traning Loss: tensor(70.3900)\n",
      "4365 Traning Loss: tensor(70.3860)\n",
      "4366 Traning Loss: tensor(70.3819)\n",
      "4367 Traning Loss: tensor(70.3779)\n",
      "4368 Traning Loss: tensor(70.3738)\n",
      "4369 Traning Loss: tensor(70.3698)\n",
      "4370 Traning Loss: tensor(70.3657)\n",
      "4371 Traning Loss: tensor(70.3617)\n",
      "4372 Traning Loss: tensor(70.3576)\n",
      "4373 Traning Loss: tensor(70.3535)\n",
      "4374 Traning Loss: tensor(70.3495)\n",
      "4375 Traning Loss: tensor(70.3454)\n",
      "4376 Traning Loss: tensor(70.3413)\n",
      "4377 Traning Loss: tensor(70.3373)\n",
      "4378 Traning Loss: tensor(70.3332)\n",
      "4379 Traning Loss: tensor(70.3291)\n",
      "4380 Traning Loss: tensor(70.3251)\n",
      "4381 Traning Loss: tensor(70.3210)\n",
      "4382 Traning Loss: tensor(70.3169)\n",
      "4383 Traning Loss: tensor(70.3129)\n",
      "4384 Traning Loss: tensor(70.3087)\n",
      "4385 Traning Loss: tensor(70.3047)\n",
      "4386 Traning Loss: tensor(70.3006)\n",
      "4387 Traning Loss: tensor(70.2965)\n",
      "4388 Traning Loss: tensor(70.2924)\n",
      "4389 Traning Loss: tensor(70.2884)\n",
      "4390 Traning Loss: tensor(70.2843)\n",
      "4391 Traning Loss: tensor(70.2802)\n",
      "4392 Traning Loss: tensor(70.2761)\n",
      "4393 Traning Loss: tensor(70.2720)\n",
      "4394 Traning Loss: tensor(70.2679)\n",
      "4395 Traning Loss: tensor(70.2638)\n",
      "4396 Traning Loss: tensor(70.2597)\n",
      "4397 Traning Loss: tensor(70.2556)\n",
      "4398 Traning Loss: tensor(70.2516)\n",
      "4399 Traning Loss: tensor(70.2475)\n",
      "4400 Traning Loss: tensor(70.2434)\n",
      "4401 Traning Loss: tensor(70.2393)\n",
      "4402 Traning Loss: tensor(70.2352)\n",
      "4403 Traning Loss: tensor(70.2311)\n",
      "4404 Traning Loss: tensor(70.2270)\n",
      "4405 Traning Loss: tensor(70.2229)\n",
      "4406 Traning Loss: tensor(70.2188)\n",
      "4407 Traning Loss: tensor(70.2147)\n",
      "4408 Traning Loss: tensor(70.2106)\n",
      "4409 Traning Loss: tensor(70.2065)\n",
      "4410 Traning Loss: tensor(70.2023)\n",
      "4411 Traning Loss: tensor(70.1983)\n",
      "4412 Traning Loss: tensor(70.1941)\n",
      "4413 Traning Loss: tensor(70.1900)\n",
      "4414 Traning Loss: tensor(70.1859)\n",
      "4415 Traning Loss: tensor(70.1818)\n",
      "4416 Traning Loss: tensor(70.1777)\n",
      "4417 Traning Loss: tensor(70.1736)\n",
      "4418 Traning Loss: tensor(70.1695)\n",
      "4419 Traning Loss: tensor(70.1653)\n",
      "4420 Traning Loss: tensor(70.1612)\n",
      "4421 Traning Loss: tensor(70.1571)\n",
      "4422 Traning Loss: tensor(70.1530)\n",
      "4423 Traning Loss: tensor(70.1488)\n",
      "4424 Traning Loss: tensor(70.1447)\n",
      "4425 Traning Loss: tensor(70.1406)\n",
      "4426 Traning Loss: tensor(70.1364)\n",
      "4427 Traning Loss: tensor(70.1323)\n",
      "4428 Traning Loss: tensor(70.1282)\n",
      "4429 Traning Loss: tensor(70.1241)\n",
      "4430 Traning Loss: tensor(70.1199)\n",
      "4431 Traning Loss: tensor(70.1158)\n",
      "4432 Traning Loss: tensor(70.1117)\n",
      "4433 Traning Loss: tensor(70.1075)\n",
      "4434 Traning Loss: tensor(70.1034)\n",
      "4435 Traning Loss: tensor(70.0992)\n",
      "4436 Traning Loss: tensor(70.0951)\n",
      "4437 Traning Loss: tensor(70.0909)\n",
      "4438 Traning Loss: tensor(70.0868)\n",
      "4439 Traning Loss: tensor(70.0827)\n",
      "4440 Traning Loss: tensor(70.0785)\n",
      "4441 Traning Loss: tensor(70.0744)\n",
      "4442 Traning Loss: tensor(70.0702)\n",
      "4443 Traning Loss: tensor(70.0661)\n",
      "4444 Traning Loss: tensor(70.0619)\n",
      "4445 Traning Loss: tensor(70.0578)\n",
      "4446 Traning Loss: tensor(70.0536)\n",
      "4447 Traning Loss: tensor(70.0495)\n",
      "4448 Traning Loss: tensor(70.0453)\n",
      "4449 Traning Loss: tensor(70.0411)\n",
      "4450 Traning Loss: tensor(70.0370)\n",
      "4451 Traning Loss: tensor(70.0328)\n",
      "4452 Traning Loss: tensor(70.0287)\n",
      "4453 Traning Loss: tensor(70.0245)\n",
      "4454 Traning Loss: tensor(70.0203)\n",
      "4455 Traning Loss: tensor(70.0162)\n",
      "4456 Traning Loss: tensor(70.0120)\n",
      "4457 Traning Loss: tensor(70.0078)\n",
      "4458 Traning Loss: tensor(70.0037)\n",
      "4459 Traning Loss: tensor(69.9995)\n",
      "4460 Traning Loss: tensor(69.9953)\n",
      "4461 Traning Loss: tensor(69.9911)\n",
      "4462 Traning Loss: tensor(69.9870)\n",
      "4463 Traning Loss: tensor(69.9828)\n",
      "4464 Traning Loss: tensor(69.9786)\n",
      "4465 Traning Loss: tensor(69.9744)\n",
      "4466 Traning Loss: tensor(69.9702)\n",
      "4467 Traning Loss: tensor(69.9661)\n",
      "4468 Traning Loss: tensor(69.9619)\n",
      "4469 Traning Loss: tensor(69.9577)\n",
      "4470 Traning Loss: tensor(69.9535)\n",
      "4471 Traning Loss: tensor(69.9493)\n",
      "4472 Traning Loss: tensor(69.9451)\n",
      "4473 Traning Loss: tensor(69.9409)\n",
      "4474 Traning Loss: tensor(69.9368)\n",
      "4475 Traning Loss: tensor(69.9326)\n",
      "4476 Traning Loss: tensor(69.9284)\n",
      "4477 Traning Loss: tensor(69.9242)\n",
      "4478 Traning Loss: tensor(69.9200)\n",
      "4479 Traning Loss: tensor(69.9157)\n",
      "4480 Traning Loss: tensor(69.9116)\n",
      "4481 Traning Loss: tensor(69.9074)\n",
      "4482 Traning Loss: tensor(69.9032)\n",
      "4483 Traning Loss: tensor(69.8990)\n",
      "4484 Traning Loss: tensor(69.8948)\n",
      "4485 Traning Loss: tensor(69.8906)\n",
      "4486 Traning Loss: tensor(69.8864)\n",
      "4487 Traning Loss: tensor(69.8821)\n",
      "4488 Traning Loss: tensor(69.8779)\n",
      "4489 Traning Loss: tensor(69.8737)\n",
      "4490 Traning Loss: tensor(69.8695)\n",
      "4491 Traning Loss: tensor(69.8653)\n",
      "4492 Traning Loss: tensor(69.8611)\n",
      "4493 Traning Loss: tensor(69.8569)\n",
      "4494 Traning Loss: tensor(69.8526)\n",
      "4495 Traning Loss: tensor(69.8484)\n",
      "4496 Traning Loss: tensor(69.8442)\n",
      "4497 Traning Loss: tensor(69.8400)\n",
      "4498 Traning Loss: tensor(69.8357)\n",
      "4499 Traning Loss: tensor(69.8315)\n",
      "4500 Traning Loss: tensor(69.8273)\n",
      "4501 Traning Loss: tensor(69.8230)\n",
      "4502 Traning Loss: tensor(69.8188)\n",
      "4503 Traning Loss: tensor(69.8146)\n",
      "4504 Traning Loss: tensor(69.8104)\n",
      "4505 Traning Loss: tensor(69.8061)\n",
      "4506 Traning Loss: tensor(69.8019)\n",
      "4507 Traning Loss: tensor(69.7976)\n",
      "4508 Traning Loss: tensor(69.7934)\n",
      "4509 Traning Loss: tensor(69.7892)\n",
      "4510 Traning Loss: tensor(69.7849)\n",
      "4511 Traning Loss: tensor(69.7807)\n",
      "4512 Traning Loss: tensor(69.7764)\n",
      "4513 Traning Loss: tensor(69.7722)\n",
      "4514 Traning Loss: tensor(69.7679)\n",
      "4515 Traning Loss: tensor(69.7637)\n",
      "4516 Traning Loss: tensor(69.7594)\n",
      "4517 Traning Loss: tensor(69.7552)\n",
      "4518 Traning Loss: tensor(69.7510)\n",
      "4519 Traning Loss: tensor(69.7467)\n",
      "4520 Traning Loss: tensor(69.7424)\n",
      "4521 Traning Loss: tensor(69.7382)\n",
      "4522 Traning Loss: tensor(69.7339)\n",
      "4523 Traning Loss: tensor(69.7296)\n",
      "4524 Traning Loss: tensor(69.7254)\n",
      "4525 Traning Loss: tensor(69.7211)\n",
      "4526 Traning Loss: tensor(69.7169)\n",
      "4527 Traning Loss: tensor(69.7126)\n",
      "4528 Traning Loss: tensor(69.7083)\n",
      "4529 Traning Loss: tensor(69.7041)\n",
      "4530 Traning Loss: tensor(69.6998)\n",
      "4531 Traning Loss: tensor(69.6955)\n",
      "4532 Traning Loss: tensor(69.6912)\n",
      "4533 Traning Loss: tensor(69.6870)\n",
      "4534 Traning Loss: tensor(69.6827)\n",
      "4535 Traning Loss: tensor(69.6784)\n",
      "4536 Traning Loss: tensor(69.6742)\n",
      "4537 Traning Loss: tensor(69.6699)\n",
      "4538 Traning Loss: tensor(69.6656)\n",
      "4539 Traning Loss: tensor(69.6613)\n",
      "4540 Traning Loss: tensor(69.6570)\n",
      "4541 Traning Loss: tensor(69.6528)\n",
      "4542 Traning Loss: tensor(69.6485)\n",
      "4543 Traning Loss: tensor(69.6442)\n",
      "4544 Traning Loss: tensor(69.6399)\n",
      "4545 Traning Loss: tensor(69.6356)\n",
      "4546 Traning Loss: tensor(69.6313)\n",
      "4547 Traning Loss: tensor(69.6270)\n",
      "4548 Traning Loss: tensor(69.6227)\n",
      "4549 Traning Loss: tensor(69.6184)\n",
      "4550 Traning Loss: tensor(69.6141)\n",
      "4551 Traning Loss: tensor(69.6098)\n",
      "4552 Traning Loss: tensor(69.6055)\n",
      "4553 Traning Loss: tensor(69.6012)\n",
      "4554 Traning Loss: tensor(69.5969)\n",
      "4555 Traning Loss: tensor(69.5926)\n",
      "4556 Traning Loss: tensor(69.5883)\n",
      "4557 Traning Loss: tensor(69.5840)\n",
      "4558 Traning Loss: tensor(69.5797)\n",
      "4559 Traning Loss: tensor(69.5754)\n",
      "4560 Traning Loss: tensor(69.5710)\n",
      "4561 Traning Loss: tensor(69.5667)\n",
      "4562 Traning Loss: tensor(69.5624)\n",
      "4563 Traning Loss: tensor(69.5581)\n",
      "4564 Traning Loss: tensor(69.5538)\n",
      "4565 Traning Loss: tensor(69.5495)\n",
      "4566 Traning Loss: tensor(69.5451)\n",
      "4567 Traning Loss: tensor(69.5408)\n",
      "4568 Traning Loss: tensor(69.5365)\n",
      "4569 Traning Loss: tensor(69.5322)\n",
      "4570 Traning Loss: tensor(69.5278)\n",
      "4571 Traning Loss: tensor(69.5235)\n",
      "4572 Traning Loss: tensor(69.5191)\n",
      "4573 Traning Loss: tensor(69.5148)\n",
      "4574 Traning Loss: tensor(69.5105)\n",
      "4575 Traning Loss: tensor(69.5062)\n",
      "4576 Traning Loss: tensor(69.5018)\n",
      "4577 Traning Loss: tensor(69.4975)\n",
      "4578 Traning Loss: tensor(69.4931)\n",
      "4579 Traning Loss: tensor(69.4888)\n",
      "4580 Traning Loss: tensor(69.4845)\n",
      "4581 Traning Loss: tensor(69.4801)\n",
      "4582 Traning Loss: tensor(69.4758)\n",
      "4583 Traning Loss: tensor(69.4714)\n",
      "4584 Traning Loss: tensor(69.4671)\n",
      "4585 Traning Loss: tensor(69.4627)\n",
      "4586 Traning Loss: tensor(69.4584)\n",
      "4587 Traning Loss: tensor(69.4540)\n",
      "4588 Traning Loss: tensor(69.4497)\n",
      "4589 Traning Loss: tensor(69.4453)\n",
      "4590 Traning Loss: tensor(69.4410)\n",
      "4591 Traning Loss: tensor(69.4366)\n",
      "4592 Traning Loss: tensor(69.4322)\n",
      "4593 Traning Loss: tensor(69.4279)\n",
      "4594 Traning Loss: tensor(69.4235)\n",
      "4595 Traning Loss: tensor(69.4192)\n",
      "4596 Traning Loss: tensor(69.4148)\n",
      "4597 Traning Loss: tensor(69.4104)\n",
      "4598 Traning Loss: tensor(69.4061)\n",
      "4599 Traning Loss: tensor(69.4017)\n",
      "4600 Traning Loss: tensor(69.3973)\n",
      "4601 Traning Loss: tensor(69.3929)\n",
      "4602 Traning Loss: tensor(69.3885)\n",
      "4603 Traning Loss: tensor(69.3842)\n",
      "4604 Traning Loss: tensor(69.3798)\n",
      "4605 Traning Loss: tensor(69.3754)\n",
      "4606 Traning Loss: tensor(69.3710)\n",
      "4607 Traning Loss: tensor(69.3667)\n",
      "4608 Traning Loss: tensor(69.3623)\n",
      "4609 Traning Loss: tensor(69.3579)\n",
      "4610 Traning Loss: tensor(69.3535)\n",
      "4611 Traning Loss: tensor(69.3491)\n",
      "4612 Traning Loss: tensor(69.3447)\n",
      "4613 Traning Loss: tensor(69.3403)\n",
      "4614 Traning Loss: tensor(69.3359)\n",
      "4615 Traning Loss: tensor(69.3315)\n",
      "4616 Traning Loss: tensor(69.3271)\n",
      "4617 Traning Loss: tensor(69.3227)\n",
      "4618 Traning Loss: tensor(69.3184)\n",
      "4619 Traning Loss: tensor(69.3139)\n",
      "4620 Traning Loss: tensor(69.3095)\n",
      "4621 Traning Loss: tensor(69.3051)\n",
      "4622 Traning Loss: tensor(69.3007)\n",
      "4623 Traning Loss: tensor(69.2963)\n",
      "4624 Traning Loss: tensor(69.2919)\n",
      "4625 Traning Loss: tensor(69.2875)\n",
      "4626 Traning Loss: tensor(69.2831)\n",
      "4627 Traning Loss: tensor(69.2787)\n",
      "4628 Traning Loss: tensor(69.2743)\n",
      "4629 Traning Loss: tensor(69.2699)\n",
      "4630 Traning Loss: tensor(69.2654)\n",
      "4631 Traning Loss: tensor(69.2610)\n",
      "4632 Traning Loss: tensor(69.2566)\n",
      "4633 Traning Loss: tensor(69.2522)\n",
      "4634 Traning Loss: tensor(69.2478)\n",
      "4635 Traning Loss: tensor(69.2433)\n",
      "4636 Traning Loss: tensor(69.2389)\n",
      "4637 Traning Loss: tensor(69.2345)\n",
      "4638 Traning Loss: tensor(69.2300)\n",
      "4639 Traning Loss: tensor(69.2256)\n",
      "4640 Traning Loss: tensor(69.2212)\n",
      "4641 Traning Loss: tensor(69.2168)\n",
      "4642 Traning Loss: tensor(69.2123)\n",
      "4643 Traning Loss: tensor(69.2079)\n",
      "4644 Traning Loss: tensor(69.2034)\n",
      "4645 Traning Loss: tensor(69.1990)\n",
      "4646 Traning Loss: tensor(69.1945)\n",
      "4647 Traning Loss: tensor(69.1901)\n",
      "4648 Traning Loss: tensor(69.1856)\n",
      "4649 Traning Loss: tensor(69.1812)\n",
      "4650 Traning Loss: tensor(69.1767)\n",
      "4651 Traning Loss: tensor(69.1723)\n",
      "4652 Traning Loss: tensor(69.1678)\n",
      "4653 Traning Loss: tensor(69.1634)\n",
      "4654 Traning Loss: tensor(69.1589)\n",
      "4655 Traning Loss: tensor(69.1545)\n",
      "4656 Traning Loss: tensor(69.1500)\n",
      "4657 Traning Loss: tensor(69.1456)\n",
      "4658 Traning Loss: tensor(69.1411)\n",
      "4659 Traning Loss: tensor(69.1366)\n",
      "4660 Traning Loss: tensor(69.1322)\n",
      "4661 Traning Loss: tensor(69.1277)\n",
      "4662 Traning Loss: tensor(69.1233)\n",
      "4663 Traning Loss: tensor(69.1188)\n",
      "4664 Traning Loss: tensor(69.1143)\n",
      "4665 Traning Loss: tensor(69.1098)\n",
      "4666 Traning Loss: tensor(69.1054)\n",
      "4667 Traning Loss: tensor(69.1009)\n",
      "4668 Traning Loss: tensor(69.0964)\n",
      "4669 Traning Loss: tensor(69.0919)\n",
      "4670 Traning Loss: tensor(69.0874)\n",
      "4671 Traning Loss: tensor(69.0830)\n",
      "4672 Traning Loss: tensor(69.0785)\n",
      "4673 Traning Loss: tensor(69.0740)\n",
      "4674 Traning Loss: tensor(69.0695)\n",
      "4675 Traning Loss: tensor(69.0650)\n",
      "4676 Traning Loss: tensor(69.0605)\n",
      "4677 Traning Loss: tensor(69.0561)\n",
      "4678 Traning Loss: tensor(69.0516)\n",
      "4679 Traning Loss: tensor(69.0470)\n",
      "4680 Traning Loss: tensor(69.0425)\n",
      "4681 Traning Loss: tensor(69.0381)\n",
      "4682 Traning Loss: tensor(69.0336)\n",
      "4683 Traning Loss: tensor(69.0291)\n",
      "4684 Traning Loss: tensor(69.0246)\n",
      "4685 Traning Loss: tensor(69.0201)\n",
      "4686 Traning Loss: tensor(69.0156)\n",
      "4687 Traning Loss: tensor(69.0111)\n",
      "4688 Traning Loss: tensor(69.0066)\n",
      "4689 Traning Loss: tensor(69.0020)\n",
      "4690 Traning Loss: tensor(68.9975)\n",
      "4691 Traning Loss: tensor(68.9930)\n",
      "4692 Traning Loss: tensor(68.9885)\n",
      "4693 Traning Loss: tensor(68.9840)\n",
      "4694 Traning Loss: tensor(68.9795)\n",
      "4695 Traning Loss: tensor(68.9750)\n",
      "4696 Traning Loss: tensor(68.9704)\n",
      "4697 Traning Loss: tensor(68.9659)\n",
      "4698 Traning Loss: tensor(68.9614)\n",
      "4699 Traning Loss: tensor(68.9568)\n",
      "4700 Traning Loss: tensor(68.9523)\n",
      "4701 Traning Loss: tensor(68.9478)\n",
      "4702 Traning Loss: tensor(68.9432)\n",
      "4703 Traning Loss: tensor(68.9387)\n",
      "4704 Traning Loss: tensor(68.9342)\n",
      "4705 Traning Loss: tensor(68.9297)\n",
      "4706 Traning Loss: tensor(68.9251)\n",
      "4707 Traning Loss: tensor(68.9206)\n",
      "4708 Traning Loss: tensor(68.9160)\n",
      "4709 Traning Loss: tensor(68.9115)\n",
      "4710 Traning Loss: tensor(68.9069)\n",
      "4711 Traning Loss: tensor(68.9024)\n",
      "4712 Traning Loss: tensor(68.8979)\n",
      "4713 Traning Loss: tensor(68.8933)\n",
      "4714 Traning Loss: tensor(68.8888)\n",
      "4715 Traning Loss: tensor(68.8842)\n",
      "4716 Traning Loss: tensor(68.8797)\n",
      "4717 Traning Loss: tensor(68.8751)\n",
      "4718 Traning Loss: tensor(68.8705)\n",
      "4719 Traning Loss: tensor(68.8660)\n",
      "4720 Traning Loss: tensor(68.8614)\n",
      "4721 Traning Loss: tensor(68.8568)\n",
      "4722 Traning Loss: tensor(68.8523)\n",
      "4723 Traning Loss: tensor(68.8477)\n",
      "4724 Traning Loss: tensor(68.8432)\n",
      "4725 Traning Loss: tensor(68.8386)\n",
      "4726 Traning Loss: tensor(68.8340)\n",
      "4727 Traning Loss: tensor(68.8294)\n",
      "4728 Traning Loss: tensor(68.8249)\n",
      "4729 Traning Loss: tensor(68.8203)\n",
      "4730 Traning Loss: tensor(68.8157)\n",
      "4731 Traning Loss: tensor(68.8112)\n",
      "4732 Traning Loss: tensor(68.8066)\n",
      "4733 Traning Loss: tensor(68.8020)\n",
      "4734 Traning Loss: tensor(68.7974)\n",
      "4735 Traning Loss: tensor(68.7928)\n",
      "4736 Traning Loss: tensor(68.7882)\n",
      "4737 Traning Loss: tensor(68.7837)\n",
      "4738 Traning Loss: tensor(68.7791)\n",
      "4739 Traning Loss: tensor(68.7745)\n",
      "4740 Traning Loss: tensor(68.7699)\n",
      "4741 Traning Loss: tensor(68.7653)\n",
      "4742 Traning Loss: tensor(68.7607)\n",
      "4743 Traning Loss: tensor(68.7561)\n",
      "4744 Traning Loss: tensor(68.7515)\n",
      "4745 Traning Loss: tensor(68.7469)\n",
      "4746 Traning Loss: tensor(68.7423)\n",
      "4747 Traning Loss: tensor(68.7377)\n",
      "4748 Traning Loss: tensor(68.7331)\n",
      "4749 Traning Loss: tensor(68.7285)\n",
      "4750 Traning Loss: tensor(68.7239)\n",
      "4751 Traning Loss: tensor(68.7193)\n",
      "4752 Traning Loss: tensor(68.7147)\n",
      "4753 Traning Loss: tensor(68.7100)\n",
      "4754 Traning Loss: tensor(68.7054)\n",
      "4755 Traning Loss: tensor(68.7008)\n",
      "4756 Traning Loss: tensor(68.6962)\n",
      "4757 Traning Loss: tensor(68.6916)\n",
      "4758 Traning Loss: tensor(68.6869)\n",
      "4759 Traning Loss: tensor(68.6823)\n",
      "4760 Traning Loss: tensor(68.6777)\n",
      "4761 Traning Loss: tensor(68.6731)\n",
      "4762 Traning Loss: tensor(68.6684)\n",
      "4763 Traning Loss: tensor(68.6638)\n",
      "4764 Traning Loss: tensor(68.6592)\n",
      "4765 Traning Loss: tensor(68.6545)\n",
      "4766 Traning Loss: tensor(68.6499)\n",
      "4767 Traning Loss: tensor(68.6452)\n",
      "4768 Traning Loss: tensor(68.6406)\n",
      "4769 Traning Loss: tensor(68.6360)\n",
      "4770 Traning Loss: tensor(68.6313)\n",
      "4771 Traning Loss: tensor(68.6267)\n",
      "4772 Traning Loss: tensor(68.6220)\n",
      "4773 Traning Loss: tensor(68.6174)\n",
      "4774 Traning Loss: tensor(68.6127)\n",
      "4775 Traning Loss: tensor(68.6081)\n",
      "4776 Traning Loss: tensor(68.6035)\n",
      "4777 Traning Loss: tensor(68.5988)\n",
      "4778 Traning Loss: tensor(68.5941)\n",
      "4779 Traning Loss: tensor(68.5895)\n",
      "4780 Traning Loss: tensor(68.5848)\n",
      "4781 Traning Loss: tensor(68.5802)\n",
      "4782 Traning Loss: tensor(68.5755)\n",
      "4783 Traning Loss: tensor(68.5708)\n",
      "4784 Traning Loss: tensor(68.5662)\n",
      "4785 Traning Loss: tensor(68.5615)\n",
      "4786 Traning Loss: tensor(68.5569)\n",
      "4787 Traning Loss: tensor(68.5521)\n",
      "4788 Traning Loss: tensor(68.5475)\n",
      "4789 Traning Loss: tensor(68.5428)\n",
      "4790 Traning Loss: tensor(68.5382)\n",
      "4791 Traning Loss: tensor(68.5334)\n",
      "4792 Traning Loss: tensor(68.5288)\n",
      "4793 Traning Loss: tensor(68.5241)\n",
      "4794 Traning Loss: tensor(68.5194)\n",
      "4795 Traning Loss: tensor(68.5147)\n",
      "4796 Traning Loss: tensor(68.5101)\n",
      "4797 Traning Loss: tensor(68.5054)\n",
      "4798 Traning Loss: tensor(68.5007)\n",
      "4799 Traning Loss: tensor(68.4960)\n",
      "4800 Traning Loss: tensor(68.4913)\n",
      "4801 Traning Loss: tensor(68.4866)\n",
      "4802 Traning Loss: tensor(68.4819)\n",
      "4803 Traning Loss: tensor(68.4772)\n",
      "4804 Traning Loss: tensor(68.4725)\n",
      "4805 Traning Loss: tensor(68.4678)\n",
      "4806 Traning Loss: tensor(68.4631)\n",
      "4807 Traning Loss: tensor(68.4584)\n",
      "4808 Traning Loss: tensor(68.4537)\n",
      "4809 Traning Loss: tensor(68.4490)\n",
      "4810 Traning Loss: tensor(68.4443)\n",
      "4811 Traning Loss: tensor(68.4396)\n",
      "4812 Traning Loss: tensor(68.4349)\n",
      "4813 Traning Loss: tensor(68.4301)\n",
      "4814 Traning Loss: tensor(68.4254)\n",
      "4815 Traning Loss: tensor(68.4207)\n",
      "4816 Traning Loss: tensor(68.4160)\n",
      "4817 Traning Loss: tensor(68.4112)\n",
      "4818 Traning Loss: tensor(68.4066)\n",
      "4819 Traning Loss: tensor(68.4018)\n",
      "4820 Traning Loss: tensor(68.3971)\n",
      "4821 Traning Loss: tensor(68.3924)\n",
      "4822 Traning Loss: tensor(68.3876)\n",
      "4823 Traning Loss: tensor(68.3829)\n",
      "4824 Traning Loss: tensor(68.3782)\n",
      "4825 Traning Loss: tensor(68.3734)\n",
      "4826 Traning Loss: tensor(68.3687)\n",
      "4827 Traning Loss: tensor(68.3640)\n",
      "4828 Traning Loss: tensor(68.3592)\n",
      "4829 Traning Loss: tensor(68.3545)\n",
      "4830 Traning Loss: tensor(68.3497)\n",
      "4831 Traning Loss: tensor(68.3450)\n",
      "4832 Traning Loss: tensor(68.3403)\n",
      "4833 Traning Loss: tensor(68.3355)\n",
      "4834 Traning Loss: tensor(68.3307)\n",
      "4835 Traning Loss: tensor(68.3260)\n",
      "4836 Traning Loss: tensor(68.3212)\n",
      "4837 Traning Loss: tensor(68.3165)\n",
      "4838 Traning Loss: tensor(68.3117)\n",
      "4839 Traning Loss: tensor(68.3069)\n",
      "4840 Traning Loss: tensor(68.3022)\n",
      "4841 Traning Loss: tensor(68.2974)\n",
      "4842 Traning Loss: tensor(68.2926)\n",
      "4843 Traning Loss: tensor(68.2879)\n",
      "4844 Traning Loss: tensor(68.2831)\n",
      "4845 Traning Loss: tensor(68.2783)\n",
      "4846 Traning Loss: tensor(68.2736)\n",
      "4847 Traning Loss: tensor(68.2688)\n",
      "4848 Traning Loss: tensor(68.2640)\n",
      "4849 Traning Loss: tensor(68.2593)\n",
      "4850 Traning Loss: tensor(68.2545)\n",
      "4851 Traning Loss: tensor(68.2497)\n",
      "4852 Traning Loss: tensor(68.2449)\n",
      "4853 Traning Loss: tensor(68.2402)\n",
      "4854 Traning Loss: tensor(68.2353)\n",
      "4855 Traning Loss: tensor(68.2306)\n",
      "4856 Traning Loss: tensor(68.2258)\n",
      "4857 Traning Loss: tensor(68.2210)\n",
      "4858 Traning Loss: tensor(68.2162)\n",
      "4859 Traning Loss: tensor(68.2114)\n",
      "4860 Traning Loss: tensor(68.2066)\n",
      "4861 Traning Loss: tensor(68.2018)\n",
      "4862 Traning Loss: tensor(68.1970)\n",
      "4863 Traning Loss: tensor(68.1922)\n",
      "4864 Traning Loss: tensor(68.1874)\n",
      "4865 Traning Loss: tensor(68.1826)\n",
      "4866 Traning Loss: tensor(68.1778)\n",
      "4867 Traning Loss: tensor(68.1730)\n",
      "4868 Traning Loss: tensor(68.1682)\n",
      "4869 Traning Loss: tensor(68.1634)\n",
      "4870 Traning Loss: tensor(68.1585)\n",
      "4871 Traning Loss: tensor(68.1538)\n",
      "4872 Traning Loss: tensor(68.1489)\n",
      "4873 Traning Loss: tensor(68.1441)\n",
      "4874 Traning Loss: tensor(68.1393)\n",
      "4875 Traning Loss: tensor(68.1345)\n",
      "4876 Traning Loss: tensor(68.1297)\n",
      "4877 Traning Loss: tensor(68.1248)\n",
      "4878 Traning Loss: tensor(68.1200)\n",
      "4879 Traning Loss: tensor(68.1152)\n",
      "4880 Traning Loss: tensor(68.1103)\n",
      "4881 Traning Loss: tensor(68.1055)\n",
      "4882 Traning Loss: tensor(68.1007)\n",
      "4883 Traning Loss: tensor(68.0958)\n",
      "4884 Traning Loss: tensor(68.0910)\n",
      "4885 Traning Loss: tensor(68.0862)\n",
      "4886 Traning Loss: tensor(68.0813)\n",
      "4887 Traning Loss: tensor(68.0765)\n",
      "4888 Traning Loss: tensor(68.0716)\n",
      "4889 Traning Loss: tensor(68.0668)\n",
      "4890 Traning Loss: tensor(68.0619)\n",
      "4891 Traning Loss: tensor(68.0571)\n",
      "4892 Traning Loss: tensor(68.0523)\n",
      "4893 Traning Loss: tensor(68.0474)\n",
      "4894 Traning Loss: tensor(68.0426)\n",
      "4895 Traning Loss: tensor(68.0377)\n",
      "4896 Traning Loss: tensor(68.0328)\n",
      "4897 Traning Loss: tensor(68.0280)\n",
      "4898 Traning Loss: tensor(68.0231)\n",
      "4899 Traning Loss: tensor(68.0183)\n",
      "4900 Traning Loss: tensor(68.0134)\n",
      "4901 Traning Loss: tensor(68.0085)\n",
      "4902 Traning Loss: tensor(68.0036)\n",
      "4903 Traning Loss: tensor(67.9988)\n",
      "4904 Traning Loss: tensor(67.9939)\n",
      "4905 Traning Loss: tensor(67.9890)\n",
      "4906 Traning Loss: tensor(67.9841)\n",
      "4907 Traning Loss: tensor(67.9793)\n",
      "4908 Traning Loss: tensor(67.9744)\n",
      "4909 Traning Loss: tensor(67.9695)\n",
      "4910 Traning Loss: tensor(67.9646)\n",
      "4911 Traning Loss: tensor(67.9597)\n",
      "4912 Traning Loss: tensor(67.9548)\n",
      "4913 Traning Loss: tensor(67.9500)\n",
      "4914 Traning Loss: tensor(67.9451)\n",
      "4915 Traning Loss: tensor(67.9402)\n",
      "4916 Traning Loss: tensor(67.9353)\n",
      "4917 Traning Loss: tensor(67.9304)\n",
      "4918 Traning Loss: tensor(67.9255)\n",
      "4919 Traning Loss: tensor(67.9206)\n",
      "4920 Traning Loss: tensor(67.9157)\n",
      "4921 Traning Loss: tensor(67.9108)\n",
      "4922 Traning Loss: tensor(67.9059)\n",
      "4923 Traning Loss: tensor(67.9010)\n",
      "4924 Traning Loss: tensor(67.8961)\n",
      "4925 Traning Loss: tensor(67.8911)\n",
      "4926 Traning Loss: tensor(67.8862)\n",
      "4927 Traning Loss: tensor(67.8813)\n",
      "4928 Traning Loss: tensor(67.8764)\n",
      "4929 Traning Loss: tensor(67.8715)\n",
      "4930 Traning Loss: tensor(67.8666)\n",
      "4931 Traning Loss: tensor(67.8617)\n",
      "4932 Traning Loss: tensor(67.8567)\n",
      "4933 Traning Loss: tensor(67.8518)\n",
      "4934 Traning Loss: tensor(67.8469)\n",
      "4935 Traning Loss: tensor(67.8420)\n",
      "4936 Traning Loss: tensor(67.8370)\n",
      "4937 Traning Loss: tensor(67.8321)\n",
      "4938 Traning Loss: tensor(67.8272)\n",
      "4939 Traning Loss: tensor(67.8223)\n",
      "4940 Traning Loss: tensor(67.8173)\n",
      "4941 Traning Loss: tensor(67.8124)\n",
      "4942 Traning Loss: tensor(67.8074)\n",
      "4943 Traning Loss: tensor(67.8025)\n",
      "4944 Traning Loss: tensor(67.7975)\n",
      "4945 Traning Loss: tensor(67.7926)\n",
      "4946 Traning Loss: tensor(67.7876)\n",
      "4947 Traning Loss: tensor(67.7827)\n",
      "4948 Traning Loss: tensor(67.7777)\n",
      "4949 Traning Loss: tensor(67.7728)\n",
      "4950 Traning Loss: tensor(67.7678)\n",
      "4951 Traning Loss: tensor(67.7629)\n",
      "4952 Traning Loss: tensor(67.7579)\n",
      "4953 Traning Loss: tensor(67.7530)\n",
      "4954 Traning Loss: tensor(67.7480)\n",
      "4955 Traning Loss: tensor(67.7430)\n",
      "4956 Traning Loss: tensor(67.7381)\n",
      "4957 Traning Loss: tensor(67.7331)\n",
      "4958 Traning Loss: tensor(67.7281)\n",
      "4959 Traning Loss: tensor(67.7232)\n",
      "4960 Traning Loss: tensor(67.7182)\n",
      "4961 Traning Loss: tensor(67.7132)\n",
      "4962 Traning Loss: tensor(67.7082)\n",
      "4963 Traning Loss: tensor(67.7033)\n",
      "4964 Traning Loss: tensor(67.6983)\n",
      "4965 Traning Loss: tensor(67.6933)\n",
      "4966 Traning Loss: tensor(67.6883)\n",
      "4967 Traning Loss: tensor(67.6833)\n",
      "4968 Traning Loss: tensor(67.6784)\n",
      "4969 Traning Loss: tensor(67.6734)\n",
      "4970 Traning Loss: tensor(67.6684)\n",
      "4971 Traning Loss: tensor(67.6634)\n",
      "4972 Traning Loss: tensor(67.6584)\n",
      "4973 Traning Loss: tensor(67.6534)\n",
      "4974 Traning Loss: tensor(67.6484)\n",
      "4975 Traning Loss: tensor(67.6434)\n",
      "4976 Traning Loss: tensor(67.6384)\n",
      "4977 Traning Loss: tensor(67.6334)\n",
      "4978 Traning Loss: tensor(67.6284)\n",
      "4979 Traning Loss: tensor(67.6234)\n",
      "4980 Traning Loss: tensor(67.6184)\n",
      "4981 Traning Loss: tensor(67.6134)\n",
      "4982 Traning Loss: tensor(67.6084)\n",
      "4983 Traning Loss: tensor(67.6034)\n",
      "4984 Traning Loss: tensor(67.5983)\n",
      "4985 Traning Loss: tensor(67.5933)\n",
      "4986 Traning Loss: tensor(67.5883)\n",
      "4987 Traning Loss: tensor(67.5833)\n",
      "4988 Traning Loss: tensor(67.5783)\n",
      "4989 Traning Loss: tensor(67.5732)\n",
      "4990 Traning Loss: tensor(67.5682)\n",
      "4991 Traning Loss: tensor(67.5632)\n",
      "4992 Traning Loss: tensor(67.5581)\n",
      "4993 Traning Loss: tensor(67.5531)\n",
      "4994 Traning Loss: tensor(67.5481)\n",
      "4995 Traning Loss: tensor(67.5430)\n",
      "4996 Traning Loss: tensor(67.5380)\n",
      "4997 Traning Loss: tensor(67.5330)\n",
      "4998 Traning Loss: tensor(67.5279)\n",
      "4999 Traning Loss: tensor(67.5229)\n",
      "5000 Traning Loss: tensor(67.5178)\n",
      "5001 Traning Loss: tensor(67.5128)\n",
      "5002 Traning Loss: tensor(67.5077)\n",
      "5003 Traning Loss: tensor(67.5027)\n",
      "5004 Traning Loss: tensor(67.4977)\n",
      "5005 Traning Loss: tensor(67.4926)\n",
      "5006 Traning Loss: tensor(67.4875)\n",
      "5007 Traning Loss: tensor(67.4825)\n",
      "5008 Traning Loss: tensor(67.4774)\n",
      "5009 Traning Loss: tensor(67.4723)\n",
      "5010 Traning Loss: tensor(67.4673)\n",
      "5011 Traning Loss: tensor(67.4622)\n",
      "5012 Traning Loss: tensor(67.4572)\n",
      "5013 Traning Loss: tensor(67.4521)\n",
      "5014 Traning Loss: tensor(67.4470)\n",
      "5015 Traning Loss: tensor(67.4419)\n",
      "5016 Traning Loss: tensor(67.4369)\n",
      "5017 Traning Loss: tensor(67.4318)\n",
      "5018 Traning Loss: tensor(67.4267)\n",
      "5019 Traning Loss: tensor(67.4216)\n",
      "5020 Traning Loss: tensor(67.4166)\n",
      "5021 Traning Loss: tensor(67.4115)\n",
      "5022 Traning Loss: tensor(67.4064)\n",
      "5023 Traning Loss: tensor(67.4013)\n",
      "5024 Traning Loss: tensor(67.3962)\n",
      "5025 Traning Loss: tensor(67.3912)\n",
      "5026 Traning Loss: tensor(67.3860)\n",
      "5027 Traning Loss: tensor(67.3809)\n",
      "5028 Traning Loss: tensor(67.3758)\n",
      "5029 Traning Loss: tensor(67.3707)\n",
      "5030 Traning Loss: tensor(67.3656)\n",
      "5031 Traning Loss: tensor(67.3605)\n",
      "5032 Traning Loss: tensor(67.3554)\n",
      "5033 Traning Loss: tensor(67.3503)\n",
      "5034 Traning Loss: tensor(67.3452)\n",
      "5035 Traning Loss: tensor(67.3401)\n",
      "5036 Traning Loss: tensor(67.3350)\n",
      "5037 Traning Loss: tensor(67.3299)\n",
      "5038 Traning Loss: tensor(67.3248)\n",
      "5039 Traning Loss: tensor(67.3197)\n",
      "5040 Traning Loss: tensor(67.3145)\n",
      "5041 Traning Loss: tensor(67.3094)\n",
      "5042 Traning Loss: tensor(67.3043)\n",
      "5043 Traning Loss: tensor(67.2992)\n",
      "5044 Traning Loss: tensor(67.2940)\n",
      "5045 Traning Loss: tensor(67.2889)\n",
      "5046 Traning Loss: tensor(67.2838)\n",
      "5047 Traning Loss: tensor(67.2787)\n",
      "5048 Traning Loss: tensor(67.2735)\n",
      "5049 Traning Loss: tensor(67.2684)\n",
      "5050 Traning Loss: tensor(67.2633)\n",
      "5051 Traning Loss: tensor(67.2581)\n",
      "5052 Traning Loss: tensor(67.2530)\n",
      "5053 Traning Loss: tensor(67.2478)\n",
      "5054 Traning Loss: tensor(67.2427)\n",
      "5055 Traning Loss: tensor(67.2376)\n",
      "5056 Traning Loss: tensor(67.2324)\n",
      "5057 Traning Loss: tensor(67.2273)\n",
      "5058 Traning Loss: tensor(67.2221)\n",
      "5059 Traning Loss: tensor(67.2170)\n",
      "5060 Traning Loss: tensor(67.2118)\n",
      "5061 Traning Loss: tensor(67.2066)\n",
      "5062 Traning Loss: tensor(67.2015)\n",
      "5063 Traning Loss: tensor(67.1964)\n",
      "5064 Traning Loss: tensor(67.1912)\n",
      "5065 Traning Loss: tensor(67.1860)\n",
      "5066 Traning Loss: tensor(67.1808)\n",
      "5067 Traning Loss: tensor(67.1757)\n",
      "5068 Traning Loss: tensor(67.1705)\n",
      "5069 Traning Loss: tensor(67.1653)\n",
      "5070 Traning Loss: tensor(67.1601)\n",
      "5071 Traning Loss: tensor(67.1550)\n",
      "5072 Traning Loss: tensor(67.1498)\n",
      "5073 Traning Loss: tensor(67.1446)\n",
      "5074 Traning Loss: tensor(67.1394)\n",
      "5075 Traning Loss: tensor(67.1343)\n",
      "5076 Traning Loss: tensor(67.1291)\n",
      "5077 Traning Loss: tensor(67.1239)\n",
      "5078 Traning Loss: tensor(67.1187)\n",
      "5079 Traning Loss: tensor(67.1135)\n",
      "5080 Traning Loss: tensor(67.1083)\n",
      "5081 Traning Loss: tensor(67.1031)\n",
      "5082 Traning Loss: tensor(67.0979)\n",
      "5083 Traning Loss: tensor(67.0927)\n",
      "5084 Traning Loss: tensor(67.0875)\n",
      "5085 Traning Loss: tensor(67.0823)\n",
      "5086 Traning Loss: tensor(67.0771)\n",
      "5087 Traning Loss: tensor(67.0719)\n",
      "5088 Traning Loss: tensor(67.0667)\n",
      "5089 Traning Loss: tensor(67.0615)\n",
      "5090 Traning Loss: tensor(67.0563)\n",
      "5091 Traning Loss: tensor(67.0511)\n",
      "5092 Traning Loss: tensor(67.0458)\n",
      "5093 Traning Loss: tensor(67.0406)\n",
      "5094 Traning Loss: tensor(67.0354)\n",
      "5095 Traning Loss: tensor(67.0302)\n",
      "5096 Traning Loss: tensor(67.0250)\n",
      "5097 Traning Loss: tensor(67.0197)\n",
      "5098 Traning Loss: tensor(67.0145)\n",
      "5099 Traning Loss: tensor(67.0093)\n",
      "5100 Traning Loss: tensor(67.0041)\n",
      "5101 Traning Loss: tensor(66.9988)\n",
      "5102 Traning Loss: tensor(66.9936)\n",
      "5103 Traning Loss: tensor(66.9884)\n",
      "5104 Traning Loss: tensor(66.9831)\n",
      "5105 Traning Loss: tensor(66.9779)\n",
      "5106 Traning Loss: tensor(66.9727)\n",
      "5107 Traning Loss: tensor(66.9674)\n",
      "5108 Traning Loss: tensor(66.9622)\n",
      "5109 Traning Loss: tensor(66.9569)\n",
      "5110 Traning Loss: tensor(66.9517)\n",
      "5111 Traning Loss: tensor(66.9464)\n",
      "5112 Traning Loss: tensor(66.9412)\n",
      "5113 Traning Loss: tensor(66.9359)\n",
      "5114 Traning Loss: tensor(66.9307)\n",
      "5115 Traning Loss: tensor(66.9254)\n",
      "5116 Traning Loss: tensor(66.9202)\n",
      "5117 Traning Loss: tensor(66.9149)\n",
      "5118 Traning Loss: tensor(66.9096)\n",
      "5119 Traning Loss: tensor(66.9044)\n",
      "5120 Traning Loss: tensor(66.8991)\n",
      "5121 Traning Loss: tensor(66.8938)\n",
      "5122 Traning Loss: tensor(66.8885)\n",
      "5123 Traning Loss: tensor(66.8833)\n",
      "5124 Traning Loss: tensor(66.8780)\n",
      "5125 Traning Loss: tensor(66.8727)\n",
      "5126 Traning Loss: tensor(66.8674)\n",
      "5127 Traning Loss: tensor(66.8622)\n",
      "5128 Traning Loss: tensor(66.8569)\n",
      "5129 Traning Loss: tensor(66.8516)\n",
      "5130 Traning Loss: tensor(66.8463)\n",
      "5131 Traning Loss: tensor(66.8410)\n",
      "5132 Traning Loss: tensor(66.8357)\n",
      "5133 Traning Loss: tensor(66.8304)\n",
      "5134 Traning Loss: tensor(66.8252)\n",
      "5135 Traning Loss: tensor(66.8199)\n",
      "5136 Traning Loss: tensor(66.8145)\n",
      "5137 Traning Loss: tensor(66.8093)\n",
      "5138 Traning Loss: tensor(66.8040)\n",
      "5139 Traning Loss: tensor(66.7987)\n",
      "5140 Traning Loss: tensor(66.7934)\n",
      "5141 Traning Loss: tensor(66.7881)\n",
      "5142 Traning Loss: tensor(66.7828)\n",
      "5143 Traning Loss: tensor(66.7775)\n",
      "5144 Traning Loss: tensor(66.7721)\n",
      "5145 Traning Loss: tensor(66.7668)\n",
      "5146 Traning Loss: tensor(66.7615)\n",
      "5147 Traning Loss: tensor(66.7562)\n",
      "5148 Traning Loss: tensor(66.7509)\n",
      "5149 Traning Loss: tensor(66.7455)\n",
      "5150 Traning Loss: tensor(66.7402)\n",
      "5151 Traning Loss: tensor(66.7349)\n",
      "5152 Traning Loss: tensor(66.7295)\n",
      "5153 Traning Loss: tensor(66.7242)\n",
      "5154 Traning Loss: tensor(66.7189)\n",
      "5155 Traning Loss: tensor(66.7136)\n",
      "5156 Traning Loss: tensor(66.7082)\n",
      "5157 Traning Loss: tensor(66.7029)\n",
      "5158 Traning Loss: tensor(66.6975)\n",
      "5159 Traning Loss: tensor(66.6922)\n",
      "5160 Traning Loss: tensor(66.6869)\n",
      "5161 Traning Loss: tensor(66.6815)\n",
      "5162 Traning Loss: tensor(66.6762)\n",
      "5163 Traning Loss: tensor(66.6708)\n",
      "5164 Traning Loss: tensor(66.6655)\n",
      "5165 Traning Loss: tensor(66.6601)\n",
      "5166 Traning Loss: tensor(66.6548)\n",
      "5167 Traning Loss: tensor(66.6494)\n",
      "5168 Traning Loss: tensor(66.6441)\n",
      "5169 Traning Loss: tensor(66.6387)\n",
      "5170 Traning Loss: tensor(66.6333)\n",
      "5171 Traning Loss: tensor(66.6280)\n",
      "5172 Traning Loss: tensor(66.6226)\n",
      "5173 Traning Loss: tensor(66.6172)\n",
      "5174 Traning Loss: tensor(66.6119)\n",
      "5175 Traning Loss: tensor(66.6065)\n",
      "5176 Traning Loss: tensor(66.6011)\n",
      "5177 Traning Loss: tensor(66.5957)\n",
      "5178 Traning Loss: tensor(66.5904)\n",
      "5179 Traning Loss: tensor(66.5850)\n",
      "5180 Traning Loss: tensor(66.5796)\n",
      "5181 Traning Loss: tensor(66.5742)\n",
      "5182 Traning Loss: tensor(66.5688)\n",
      "5183 Traning Loss: tensor(66.5635)\n",
      "5184 Traning Loss: tensor(66.5581)\n",
      "5185 Traning Loss: tensor(66.5527)\n",
      "5186 Traning Loss: tensor(66.5473)\n",
      "5187 Traning Loss: tensor(66.5419)\n",
      "5188 Traning Loss: tensor(66.5365)\n",
      "5189 Traning Loss: tensor(66.5311)\n",
      "5190 Traning Loss: tensor(66.5257)\n",
      "5191 Traning Loss: tensor(66.5203)\n",
      "5192 Traning Loss: tensor(66.5149)\n",
      "5193 Traning Loss: tensor(66.5095)\n",
      "5194 Traning Loss: tensor(66.5040)\n",
      "5195 Traning Loss: tensor(66.4987)\n",
      "5196 Traning Loss: tensor(66.4933)\n",
      "5197 Traning Loss: tensor(66.4878)\n",
      "5198 Traning Loss: tensor(66.4824)\n",
      "5199 Traning Loss: tensor(66.4770)\n",
      "5200 Traning Loss: tensor(66.4716)\n",
      "5201 Traning Loss: tensor(66.4662)\n",
      "5202 Traning Loss: tensor(66.4607)\n",
      "5203 Traning Loss: tensor(66.4553)\n",
      "5204 Traning Loss: tensor(66.4499)\n",
      "5205 Traning Loss: tensor(66.4445)\n",
      "5206 Traning Loss: tensor(66.4391)\n",
      "5207 Traning Loss: tensor(66.4336)\n",
      "5208 Traning Loss: tensor(66.4282)\n",
      "5209 Traning Loss: tensor(66.4227)\n",
      "5210 Traning Loss: tensor(66.4173)\n",
      "5211 Traning Loss: tensor(66.4119)\n",
      "5212 Traning Loss: tensor(66.4064)\n",
      "5213 Traning Loss: tensor(66.4010)\n",
      "5214 Traning Loss: tensor(66.3955)\n",
      "5215 Traning Loss: tensor(66.3901)\n",
      "5216 Traning Loss: tensor(66.3846)\n",
      "5217 Traning Loss: tensor(66.3792)\n",
      "5218 Traning Loss: tensor(66.3737)\n",
      "5219 Traning Loss: tensor(66.3683)\n",
      "5220 Traning Loss: tensor(66.3628)\n",
      "5221 Traning Loss: tensor(66.3574)\n",
      "5222 Traning Loss: tensor(66.3519)\n",
      "5223 Traning Loss: tensor(66.3464)\n",
      "5224 Traning Loss: tensor(66.3410)\n",
      "5225 Traning Loss: tensor(66.3355)\n",
      "5226 Traning Loss: tensor(66.3300)\n",
      "5227 Traning Loss: tensor(66.3246)\n",
      "5228 Traning Loss: tensor(66.3191)\n",
      "5229 Traning Loss: tensor(66.3136)\n",
      "5230 Traning Loss: tensor(66.3082)\n",
      "5231 Traning Loss: tensor(66.3027)\n",
      "5232 Traning Loss: tensor(66.2972)\n",
      "5233 Traning Loss: tensor(66.2917)\n",
      "5234 Traning Loss: tensor(66.2862)\n",
      "5235 Traning Loss: tensor(66.2807)\n",
      "5236 Traning Loss: tensor(66.2752)\n",
      "5237 Traning Loss: tensor(66.2697)\n",
      "5238 Traning Loss: tensor(66.2643)\n",
      "5239 Traning Loss: tensor(66.2588)\n",
      "5240 Traning Loss: tensor(66.2533)\n",
      "5241 Traning Loss: tensor(66.2478)\n",
      "5242 Traning Loss: tensor(66.2423)\n",
      "5243 Traning Loss: tensor(66.2368)\n",
      "5244 Traning Loss: tensor(66.2313)\n",
      "5245 Traning Loss: tensor(66.2258)\n",
      "5246 Traning Loss: tensor(66.2203)\n",
      "5247 Traning Loss: tensor(66.2148)\n",
      "5248 Traning Loss: tensor(66.2093)\n",
      "5249 Traning Loss: tensor(66.2037)\n",
      "5250 Traning Loss: tensor(66.1982)\n",
      "5251 Traning Loss: tensor(66.1927)\n",
      "5252 Traning Loss: tensor(66.1872)\n",
      "5253 Traning Loss: tensor(66.1817)\n",
      "5254 Traning Loss: tensor(66.1761)\n",
      "5255 Traning Loss: tensor(66.1706)\n",
      "5256 Traning Loss: tensor(66.1651)\n",
      "5257 Traning Loss: tensor(66.1595)\n",
      "5258 Traning Loss: tensor(66.1540)\n",
      "5259 Traning Loss: tensor(66.1485)\n",
      "5260 Traning Loss: tensor(66.1430)\n",
      "5261 Traning Loss: tensor(66.1374)\n",
      "5262 Traning Loss: tensor(66.1319)\n",
      "5263 Traning Loss: tensor(66.1263)\n",
      "5264 Traning Loss: tensor(66.1208)\n",
      "5265 Traning Loss: tensor(66.1153)\n",
      "5266 Traning Loss: tensor(66.1097)\n",
      "5267 Traning Loss: tensor(66.1042)\n",
      "5268 Traning Loss: tensor(66.0986)\n",
      "5269 Traning Loss: tensor(66.0931)\n",
      "5270 Traning Loss: tensor(66.0875)\n",
      "5271 Traning Loss: tensor(66.0820)\n",
      "5272 Traning Loss: tensor(66.0764)\n",
      "5273 Traning Loss: tensor(66.0708)\n",
      "5274 Traning Loss: tensor(66.0653)\n",
      "5275 Traning Loss: tensor(66.0597)\n",
      "5276 Traning Loss: tensor(66.0542)\n",
      "5277 Traning Loss: tensor(66.0486)\n",
      "5278 Traning Loss: tensor(66.0430)\n",
      "5279 Traning Loss: tensor(66.0374)\n",
      "5280 Traning Loss: tensor(66.0319)\n",
      "5281 Traning Loss: tensor(66.0263)\n",
      "5282 Traning Loss: tensor(66.0207)\n",
      "5283 Traning Loss: tensor(66.0152)\n",
      "5284 Traning Loss: tensor(66.0096)\n",
      "5285 Traning Loss: tensor(66.0040)\n",
      "5286 Traning Loss: tensor(65.9984)\n",
      "5287 Traning Loss: tensor(65.9928)\n",
      "5288 Traning Loss: tensor(65.9872)\n",
      "5289 Traning Loss: tensor(65.9816)\n",
      "5290 Traning Loss: tensor(65.9760)\n",
      "5291 Traning Loss: tensor(65.9705)\n",
      "5292 Traning Loss: tensor(65.9649)\n",
      "5293 Traning Loss: tensor(65.9593)\n",
      "5294 Traning Loss: tensor(65.9536)\n",
      "5295 Traning Loss: tensor(65.9480)\n",
      "5296 Traning Loss: tensor(65.9424)\n",
      "5297 Traning Loss: tensor(65.9368)\n",
      "5298 Traning Loss: tensor(65.9312)\n",
      "5299 Traning Loss: tensor(65.9256)\n",
      "5300 Traning Loss: tensor(65.9200)\n",
      "5301 Traning Loss: tensor(65.9144)\n",
      "5302 Traning Loss: tensor(65.9088)\n",
      "5303 Traning Loss: tensor(65.9031)\n",
      "5304 Traning Loss: tensor(65.8975)\n",
      "5305 Traning Loss: tensor(65.8919)\n",
      "5306 Traning Loss: tensor(65.8863)\n",
      "5307 Traning Loss: tensor(65.8807)\n",
      "5308 Traning Loss: tensor(65.8751)\n",
      "5309 Traning Loss: tensor(65.8694)\n",
      "5310 Traning Loss: tensor(65.8638)\n",
      "5311 Traning Loss: tensor(65.8582)\n",
      "5312 Traning Loss: tensor(65.8525)\n",
      "5313 Traning Loss: tensor(65.8469)\n",
      "5314 Traning Loss: tensor(65.8412)\n",
      "5315 Traning Loss: tensor(65.8356)\n",
      "5316 Traning Loss: tensor(65.8299)\n",
      "5317 Traning Loss: tensor(65.8243)\n",
      "5318 Traning Loss: tensor(65.8187)\n",
      "5319 Traning Loss: tensor(65.8130)\n",
      "5320 Traning Loss: tensor(65.8074)\n",
      "5321 Traning Loss: tensor(65.8017)\n",
      "5322 Traning Loss: tensor(65.7961)\n",
      "5323 Traning Loss: tensor(65.7904)\n",
      "5324 Traning Loss: tensor(65.7847)\n",
      "5325 Traning Loss: tensor(65.7791)\n",
      "5326 Traning Loss: tensor(65.7734)\n",
      "5327 Traning Loss: tensor(65.7678)\n",
      "5328 Traning Loss: tensor(65.7621)\n",
      "5329 Traning Loss: tensor(65.7564)\n",
      "5330 Traning Loss: tensor(65.7508)\n",
      "5331 Traning Loss: tensor(65.7451)\n",
      "5332 Traning Loss: tensor(65.7394)\n",
      "5333 Traning Loss: tensor(65.7337)\n",
      "5334 Traning Loss: tensor(65.7281)\n",
      "5335 Traning Loss: tensor(65.7224)\n",
      "5336 Traning Loss: tensor(65.7167)\n",
      "5337 Traning Loss: tensor(65.7110)\n",
      "5338 Traning Loss: tensor(65.7053)\n",
      "5339 Traning Loss: tensor(65.6996)\n",
      "5340 Traning Loss: tensor(65.6939)\n",
      "5341 Traning Loss: tensor(65.6882)\n",
      "5342 Traning Loss: tensor(65.6826)\n",
      "5343 Traning Loss: tensor(65.6769)\n",
      "5344 Traning Loss: tensor(65.6712)\n",
      "5345 Traning Loss: tensor(65.6655)\n",
      "5346 Traning Loss: tensor(65.6598)\n",
      "5347 Traning Loss: tensor(65.6541)\n",
      "5348 Traning Loss: tensor(65.6484)\n",
      "5349 Traning Loss: tensor(65.6426)\n",
      "5350 Traning Loss: tensor(65.6369)\n",
      "5351 Traning Loss: tensor(65.6312)\n",
      "5352 Traning Loss: tensor(65.6255)\n",
      "5353 Traning Loss: tensor(65.6198)\n",
      "5354 Traning Loss: tensor(65.6141)\n",
      "5355 Traning Loss: tensor(65.6084)\n",
      "5356 Traning Loss: tensor(65.6026)\n",
      "5357 Traning Loss: tensor(65.5969)\n",
      "5358 Traning Loss: tensor(65.5912)\n",
      "5359 Traning Loss: tensor(65.5855)\n",
      "5360 Traning Loss: tensor(65.5797)\n",
      "5361 Traning Loss: tensor(65.5740)\n",
      "5362 Traning Loss: tensor(65.5683)\n",
      "5363 Traning Loss: tensor(65.5625)\n",
      "5364 Traning Loss: tensor(65.5568)\n",
      "5365 Traning Loss: tensor(65.5511)\n",
      "5366 Traning Loss: tensor(65.5453)\n",
      "5367 Traning Loss: tensor(65.5396)\n",
      "5368 Traning Loss: tensor(65.5338)\n",
      "5369 Traning Loss: tensor(65.5281)\n",
      "5370 Traning Loss: tensor(65.5224)\n",
      "5371 Traning Loss: tensor(65.5166)\n",
      "5372 Traning Loss: tensor(65.5109)\n",
      "5373 Traning Loss: tensor(65.5051)\n",
      "5374 Traning Loss: tensor(65.4993)\n",
      "5375 Traning Loss: tensor(65.4936)\n",
      "5376 Traning Loss: tensor(65.4878)\n",
      "5377 Traning Loss: tensor(65.4821)\n",
      "5378 Traning Loss: tensor(65.4763)\n",
      "5379 Traning Loss: tensor(65.4705)\n",
      "5380 Traning Loss: tensor(65.4647)\n",
      "5381 Traning Loss: tensor(65.4590)\n",
      "5382 Traning Loss: tensor(65.4532)\n",
      "5383 Traning Loss: tensor(65.4474)\n",
      "5384 Traning Loss: tensor(65.4417)\n",
      "5385 Traning Loss: tensor(65.4359)\n",
      "5386 Traning Loss: tensor(65.4301)\n",
      "5387 Traning Loss: tensor(65.4243)\n",
      "5388 Traning Loss: tensor(65.4185)\n",
      "5389 Traning Loss: tensor(65.4128)\n",
      "5390 Traning Loss: tensor(65.4070)\n",
      "5391 Traning Loss: tensor(65.4012)\n",
      "5392 Traning Loss: tensor(65.3954)\n",
      "5393 Traning Loss: tensor(65.3896)\n",
      "5394 Traning Loss: tensor(65.3838)\n",
      "5395 Traning Loss: tensor(65.3780)\n",
      "5396 Traning Loss: tensor(65.3722)\n",
      "5397 Traning Loss: tensor(65.3664)\n",
      "5398 Traning Loss: tensor(65.3606)\n",
      "5399 Traning Loss: tensor(65.3548)\n",
      "5400 Traning Loss: tensor(65.3490)\n",
      "5401 Traning Loss: tensor(65.3432)\n",
      "5402 Traning Loss: tensor(65.3374)\n",
      "5403 Traning Loss: tensor(65.3315)\n",
      "5404 Traning Loss: tensor(65.3257)\n",
      "5405 Traning Loss: tensor(65.3199)\n",
      "5406 Traning Loss: tensor(65.3141)\n",
      "5407 Traning Loss: tensor(65.3083)\n",
      "5408 Traning Loss: tensor(65.3025)\n",
      "5409 Traning Loss: tensor(65.2966)\n",
      "5410 Traning Loss: tensor(65.2908)\n",
      "5411 Traning Loss: tensor(65.2850)\n",
      "5412 Traning Loss: tensor(65.2791)\n",
      "5413 Traning Loss: tensor(65.2733)\n",
      "5414 Traning Loss: tensor(65.2675)\n",
      "5415 Traning Loss: tensor(65.2616)\n",
      "5416 Traning Loss: tensor(65.2558)\n",
      "5417 Traning Loss: tensor(65.2500)\n",
      "5418 Traning Loss: tensor(65.2441)\n",
      "5419 Traning Loss: tensor(65.2383)\n",
      "5420 Traning Loss: tensor(65.2324)\n",
      "5421 Traning Loss: tensor(65.2266)\n",
      "5422 Traning Loss: tensor(65.2207)\n",
      "5423 Traning Loss: tensor(65.2149)\n",
      "5424 Traning Loss: tensor(65.2090)\n",
      "5425 Traning Loss: tensor(65.2031)\n",
      "5426 Traning Loss: tensor(65.1973)\n",
      "5427 Traning Loss: tensor(65.1914)\n",
      "5428 Traning Loss: tensor(65.1856)\n",
      "5429 Traning Loss: tensor(65.1797)\n",
      "5430 Traning Loss: tensor(65.1739)\n",
      "5431 Traning Loss: tensor(65.1680)\n",
      "5432 Traning Loss: tensor(65.1621)\n",
      "5433 Traning Loss: tensor(65.1562)\n",
      "5434 Traning Loss: tensor(65.1504)\n",
      "5435 Traning Loss: tensor(65.1445)\n",
      "5436 Traning Loss: tensor(65.1386)\n",
      "5437 Traning Loss: tensor(65.1327)\n",
      "5438 Traning Loss: tensor(65.1269)\n",
      "5439 Traning Loss: tensor(65.1210)\n",
      "5440 Traning Loss: tensor(65.1151)\n",
      "5441 Traning Loss: tensor(65.1092)\n",
      "5442 Traning Loss: tensor(65.1033)\n",
      "5443 Traning Loss: tensor(65.0974)\n",
      "5444 Traning Loss: tensor(65.0915)\n",
      "5445 Traning Loss: tensor(65.0856)\n",
      "5446 Traning Loss: tensor(65.0797)\n",
      "5447 Traning Loss: tensor(65.0738)\n",
      "5448 Traning Loss: tensor(65.0679)\n",
      "5449 Traning Loss: tensor(65.0620)\n",
      "5450 Traning Loss: tensor(65.0561)\n",
      "5451 Traning Loss: tensor(65.0502)\n",
      "5452 Traning Loss: tensor(65.0443)\n",
      "5453 Traning Loss: tensor(65.0384)\n",
      "5454 Traning Loss: tensor(65.0325)\n",
      "5455 Traning Loss: tensor(65.0266)\n",
      "5456 Traning Loss: tensor(65.0206)\n",
      "5457 Traning Loss: tensor(65.0147)\n",
      "5458 Traning Loss: tensor(65.0088)\n",
      "5459 Traning Loss: tensor(65.0029)\n",
      "5460 Traning Loss: tensor(64.9969)\n",
      "5461 Traning Loss: tensor(64.9910)\n",
      "5462 Traning Loss: tensor(64.9851)\n",
      "5463 Traning Loss: tensor(64.9791)\n",
      "5464 Traning Loss: tensor(64.9732)\n",
      "5465 Traning Loss: tensor(64.9673)\n",
      "5466 Traning Loss: tensor(64.9613)\n",
      "5467 Traning Loss: tensor(64.9554)\n",
      "5468 Traning Loss: tensor(64.9495)\n",
      "5469 Traning Loss: tensor(64.9435)\n",
      "5470 Traning Loss: tensor(64.9376)\n",
      "5471 Traning Loss: tensor(64.9316)\n",
      "5472 Traning Loss: tensor(64.9257)\n",
      "5473 Traning Loss: tensor(64.9197)\n",
      "5474 Traning Loss: tensor(64.9138)\n",
      "5475 Traning Loss: tensor(64.9078)\n",
      "5476 Traning Loss: tensor(64.9019)\n",
      "5477 Traning Loss: tensor(64.8959)\n",
      "5478 Traning Loss: tensor(64.8899)\n",
      "5479 Traning Loss: tensor(64.8840)\n",
      "5480 Traning Loss: tensor(64.8780)\n",
      "5481 Traning Loss: tensor(64.8721)\n",
      "5482 Traning Loss: tensor(64.8661)\n",
      "5483 Traning Loss: tensor(64.8601)\n",
      "5484 Traning Loss: tensor(64.8541)\n",
      "5485 Traning Loss: tensor(64.8481)\n",
      "5486 Traning Loss: tensor(64.8422)\n",
      "5487 Traning Loss: tensor(64.8362)\n",
      "5488 Traning Loss: tensor(64.8302)\n",
      "5489 Traning Loss: tensor(64.8242)\n",
      "5490 Traning Loss: tensor(64.8182)\n",
      "5491 Traning Loss: tensor(64.8123)\n",
      "5492 Traning Loss: tensor(64.8063)\n",
      "5493 Traning Loss: tensor(64.8003)\n",
      "5494 Traning Loss: tensor(64.7943)\n",
      "5495 Traning Loss: tensor(64.7883)\n",
      "5496 Traning Loss: tensor(64.7823)\n",
      "5497 Traning Loss: tensor(64.7763)\n",
      "5498 Traning Loss: tensor(64.7703)\n",
      "5499 Traning Loss: tensor(64.7643)\n",
      "5500 Traning Loss: tensor(64.7583)\n",
      "5501 Traning Loss: tensor(64.7523)\n",
      "5502 Traning Loss: tensor(64.7463)\n",
      "5503 Traning Loss: tensor(64.7403)\n",
      "5504 Traning Loss: tensor(64.7343)\n",
      "5505 Traning Loss: tensor(64.7282)\n",
      "5506 Traning Loss: tensor(64.7222)\n",
      "5507 Traning Loss: tensor(64.7162)\n",
      "5508 Traning Loss: tensor(64.7102)\n",
      "5509 Traning Loss: tensor(64.7042)\n",
      "5510 Traning Loss: tensor(64.6981)\n",
      "5511 Traning Loss: tensor(64.6921)\n",
      "5512 Traning Loss: tensor(64.6861)\n",
      "5513 Traning Loss: tensor(64.6800)\n",
      "5514 Traning Loss: tensor(64.6740)\n",
      "5515 Traning Loss: tensor(64.6680)\n",
      "5516 Traning Loss: tensor(64.6619)\n",
      "5517 Traning Loss: tensor(64.6559)\n",
      "5518 Traning Loss: tensor(64.6499)\n",
      "5519 Traning Loss: tensor(64.6438)\n",
      "5520 Traning Loss: tensor(64.6378)\n",
      "5521 Traning Loss: tensor(64.6317)\n",
      "5522 Traning Loss: tensor(64.6257)\n",
      "5523 Traning Loss: tensor(64.6197)\n",
      "5524 Traning Loss: tensor(64.6136)\n",
      "5525 Traning Loss: tensor(64.6075)\n",
      "5526 Traning Loss: tensor(64.6015)\n",
      "5527 Traning Loss: tensor(64.5954)\n",
      "5528 Traning Loss: tensor(64.5893)\n",
      "5529 Traning Loss: tensor(64.5833)\n",
      "5530 Traning Loss: tensor(64.5772)\n",
      "5531 Traning Loss: tensor(64.5711)\n",
      "5532 Traning Loss: tensor(64.5651)\n",
      "5533 Traning Loss: tensor(64.5590)\n",
      "5534 Traning Loss: tensor(64.5530)\n",
      "5535 Traning Loss: tensor(64.5469)\n",
      "5536 Traning Loss: tensor(64.5408)\n",
      "5537 Traning Loss: tensor(64.5347)\n",
      "5538 Traning Loss: tensor(64.5286)\n",
      "5539 Traning Loss: tensor(64.5226)\n",
      "5540 Traning Loss: tensor(64.5165)\n",
      "5541 Traning Loss: tensor(64.5104)\n",
      "5542 Traning Loss: tensor(64.5043)\n",
      "5543 Traning Loss: tensor(64.4982)\n",
      "5544 Traning Loss: tensor(64.4921)\n",
      "5545 Traning Loss: tensor(64.4860)\n",
      "5546 Traning Loss: tensor(64.4799)\n",
      "5547 Traning Loss: tensor(64.4738)\n",
      "5548 Traning Loss: tensor(64.4677)\n",
      "5549 Traning Loss: tensor(64.4616)\n",
      "5550 Traning Loss: tensor(64.4555)\n",
      "5551 Traning Loss: tensor(64.4494)\n",
      "5552 Traning Loss: tensor(64.4433)\n",
      "5553 Traning Loss: tensor(64.4372)\n",
      "5554 Traning Loss: tensor(64.4311)\n",
      "5555 Traning Loss: tensor(64.4250)\n",
      "5556 Traning Loss: tensor(64.4189)\n",
      "5557 Traning Loss: tensor(64.4127)\n",
      "5558 Traning Loss: tensor(64.4066)\n",
      "5559 Traning Loss: tensor(64.4005)\n",
      "5560 Traning Loss: tensor(64.3944)\n",
      "5561 Traning Loss: tensor(64.3883)\n",
      "5562 Traning Loss: tensor(64.3821)\n",
      "5563 Traning Loss: tensor(64.3760)\n",
      "5564 Traning Loss: tensor(64.3699)\n",
      "5565 Traning Loss: tensor(64.3637)\n",
      "5566 Traning Loss: tensor(64.3576)\n",
      "5567 Traning Loss: tensor(64.3515)\n",
      "5568 Traning Loss: tensor(64.3453)\n",
      "5569 Traning Loss: tensor(64.3392)\n",
      "5570 Traning Loss: tensor(64.3330)\n",
      "5571 Traning Loss: tensor(64.3269)\n",
      "5572 Traning Loss: tensor(64.3207)\n",
      "5573 Traning Loss: tensor(64.3146)\n",
      "5574 Traning Loss: tensor(64.3084)\n",
      "5575 Traning Loss: tensor(64.3023)\n",
      "5576 Traning Loss: tensor(64.2961)\n",
      "5577 Traning Loss: tensor(64.2900)\n",
      "5578 Traning Loss: tensor(64.2838)\n",
      "5579 Traning Loss: tensor(64.2776)\n",
      "5580 Traning Loss: tensor(64.2715)\n",
      "5581 Traning Loss: tensor(64.2653)\n",
      "5582 Traning Loss: tensor(64.2592)\n",
      "5583 Traning Loss: tensor(64.2530)\n",
      "5584 Traning Loss: tensor(64.2468)\n",
      "5585 Traning Loss: tensor(64.2406)\n",
      "5586 Traning Loss: tensor(64.2345)\n",
      "5587 Traning Loss: tensor(64.2283)\n",
      "5588 Traning Loss: tensor(64.2221)\n",
      "5589 Traning Loss: tensor(64.2159)\n",
      "5590 Traning Loss: tensor(64.2097)\n",
      "5591 Traning Loss: tensor(64.2035)\n",
      "5592 Traning Loss: tensor(64.1973)\n",
      "5593 Traning Loss: tensor(64.1912)\n",
      "5594 Traning Loss: tensor(64.1850)\n",
      "5595 Traning Loss: tensor(64.1788)\n",
      "5596 Traning Loss: tensor(64.1726)\n",
      "5597 Traning Loss: tensor(64.1664)\n",
      "5598 Traning Loss: tensor(64.1602)\n",
      "5599 Traning Loss: tensor(64.1540)\n",
      "5600 Traning Loss: tensor(64.1478)\n",
      "5601 Traning Loss: tensor(64.1416)\n",
      "5602 Traning Loss: tensor(64.1354)\n",
      "5603 Traning Loss: tensor(64.1292)\n",
      "5604 Traning Loss: tensor(64.1230)\n",
      "5605 Traning Loss: tensor(64.1168)\n",
      "5606 Traning Loss: tensor(64.1105)\n",
      "5607 Traning Loss: tensor(64.1043)\n",
      "5608 Traning Loss: tensor(64.0981)\n",
      "5609 Traning Loss: tensor(64.0919)\n",
      "5610 Traning Loss: tensor(64.0856)\n",
      "5611 Traning Loss: tensor(64.0795)\n",
      "5612 Traning Loss: tensor(64.0732)\n",
      "5613 Traning Loss: tensor(64.0669)\n",
      "5614 Traning Loss: tensor(64.0607)\n",
      "5615 Traning Loss: tensor(64.0545)\n",
      "5616 Traning Loss: tensor(64.0482)\n",
      "5617 Traning Loss: tensor(64.0420)\n",
      "5618 Traning Loss: tensor(64.0358)\n",
      "5619 Traning Loss: tensor(64.0295)\n",
      "5620 Traning Loss: tensor(64.0233)\n",
      "5621 Traning Loss: tensor(64.0170)\n",
      "5622 Traning Loss: tensor(64.0108)\n",
      "5623 Traning Loss: tensor(64.0046)\n",
      "5624 Traning Loss: tensor(63.9983)\n",
      "5625 Traning Loss: tensor(63.9921)\n",
      "5626 Traning Loss: tensor(63.9858)\n",
      "5627 Traning Loss: tensor(63.9796)\n",
      "5628 Traning Loss: tensor(63.9733)\n",
      "5629 Traning Loss: tensor(63.9670)\n",
      "5630 Traning Loss: tensor(63.9608)\n",
      "5631 Traning Loss: tensor(63.9545)\n",
      "5632 Traning Loss: tensor(63.9482)\n",
      "5633 Traning Loss: tensor(63.9420)\n",
      "5634 Traning Loss: tensor(63.9357)\n",
      "5635 Traning Loss: tensor(63.9294)\n",
      "5636 Traning Loss: tensor(63.9231)\n",
      "5637 Traning Loss: tensor(63.9168)\n",
      "5638 Traning Loss: tensor(63.9106)\n",
      "5639 Traning Loss: tensor(63.9043)\n",
      "5640 Traning Loss: tensor(63.8980)\n",
      "5641 Traning Loss: tensor(63.8917)\n",
      "5642 Traning Loss: tensor(63.8854)\n",
      "5643 Traning Loss: tensor(63.8791)\n",
      "5644 Traning Loss: tensor(63.8728)\n",
      "5645 Traning Loss: tensor(63.8665)\n",
      "5646 Traning Loss: tensor(63.8603)\n",
      "5647 Traning Loss: tensor(63.8540)\n",
      "5648 Traning Loss: tensor(63.8477)\n",
      "5649 Traning Loss: tensor(63.8414)\n",
      "5650 Traning Loss: tensor(63.8351)\n",
      "5651 Traning Loss: tensor(63.8288)\n",
      "5652 Traning Loss: tensor(63.8225)\n",
      "5653 Traning Loss: tensor(63.8162)\n",
      "5654 Traning Loss: tensor(63.8098)\n",
      "5655 Traning Loss: tensor(63.8035)\n",
      "5656 Traning Loss: tensor(63.7972)\n",
      "5657 Traning Loss: tensor(63.7909)\n",
      "5658 Traning Loss: tensor(63.7845)\n",
      "5659 Traning Loss: tensor(63.7782)\n",
      "5660 Traning Loss: tensor(63.7719)\n",
      "5661 Traning Loss: tensor(63.7656)\n",
      "5662 Traning Loss: tensor(63.7593)\n",
      "5663 Traning Loss: tensor(63.7529)\n",
      "5664 Traning Loss: tensor(63.7466)\n",
      "5665 Traning Loss: tensor(63.7403)\n",
      "5666 Traning Loss: tensor(63.7339)\n",
      "5667 Traning Loss: tensor(63.7276)\n",
      "5668 Traning Loss: tensor(63.7213)\n",
      "5669 Traning Loss: tensor(63.7149)\n",
      "5670 Traning Loss: tensor(63.7086)\n",
      "5671 Traning Loss: tensor(63.7022)\n",
      "5672 Traning Loss: tensor(63.6959)\n",
      "5673 Traning Loss: tensor(63.6895)\n",
      "5674 Traning Loss: tensor(63.6832)\n",
      "5675 Traning Loss: tensor(63.6768)\n",
      "5676 Traning Loss: tensor(63.6705)\n",
      "5677 Traning Loss: tensor(63.6641)\n",
      "5678 Traning Loss: tensor(63.6577)\n",
      "5679 Traning Loss: tensor(63.6514)\n",
      "5680 Traning Loss: tensor(63.6450)\n",
      "5681 Traning Loss: tensor(63.6386)\n",
      "5682 Traning Loss: tensor(63.6323)\n",
      "5683 Traning Loss: tensor(63.6259)\n",
      "5684 Traning Loss: tensor(63.6196)\n",
      "5685 Traning Loss: tensor(63.6132)\n",
      "5686 Traning Loss: tensor(63.6068)\n",
      "5687 Traning Loss: tensor(63.6004)\n",
      "5688 Traning Loss: tensor(63.5940)\n",
      "5689 Traning Loss: tensor(63.5877)\n",
      "5690 Traning Loss: tensor(63.5813)\n",
      "5691 Traning Loss: tensor(63.5749)\n",
      "5692 Traning Loss: tensor(63.5685)\n",
      "5693 Traning Loss: tensor(63.5621)\n",
      "5694 Traning Loss: tensor(63.5557)\n",
      "5695 Traning Loss: tensor(63.5493)\n",
      "5696 Traning Loss: tensor(63.5429)\n",
      "5697 Traning Loss: tensor(63.5365)\n",
      "5698 Traning Loss: tensor(63.5301)\n",
      "5699 Traning Loss: tensor(63.5237)\n",
      "5700 Traning Loss: tensor(63.5173)\n",
      "5701 Traning Loss: tensor(63.5109)\n",
      "5702 Traning Loss: tensor(63.5045)\n",
      "5703 Traning Loss: tensor(63.4981)\n",
      "5704 Traning Loss: tensor(63.4917)\n",
      "5705 Traning Loss: tensor(63.4853)\n",
      "5706 Traning Loss: tensor(63.4789)\n",
      "5707 Traning Loss: tensor(63.4724)\n",
      "5708 Traning Loss: tensor(63.4660)\n",
      "5709 Traning Loss: tensor(63.4596)\n",
      "5710 Traning Loss: tensor(63.4532)\n",
      "5711 Traning Loss: tensor(63.4467)\n",
      "5712 Traning Loss: tensor(63.4403)\n",
      "5713 Traning Loss: tensor(63.4339)\n",
      "5714 Traning Loss: tensor(63.4275)\n",
      "5715 Traning Loss: tensor(63.4210)\n",
      "5716 Traning Loss: tensor(63.4146)\n",
      "5717 Traning Loss: tensor(63.4082)\n",
      "5718 Traning Loss: tensor(63.4017)\n",
      "5719 Traning Loss: tensor(63.3953)\n",
      "5720 Traning Loss: tensor(63.3888)\n",
      "5721 Traning Loss: tensor(63.3824)\n",
      "5722 Traning Loss: tensor(63.3759)\n",
      "5723 Traning Loss: tensor(63.3695)\n",
      "5724 Traning Loss: tensor(63.3630)\n",
      "5725 Traning Loss: tensor(63.3566)\n",
      "5726 Traning Loss: tensor(63.3501)\n",
      "5727 Traning Loss: tensor(63.3437)\n",
      "5728 Traning Loss: tensor(63.3372)\n",
      "5729 Traning Loss: tensor(63.3307)\n",
      "5730 Traning Loss: tensor(63.3243)\n",
      "5731 Traning Loss: tensor(63.3178)\n",
      "5732 Traning Loss: tensor(63.3113)\n",
      "5733 Traning Loss: tensor(63.3049)\n",
      "5734 Traning Loss: tensor(63.2984)\n",
      "5735 Traning Loss: tensor(63.2919)\n",
      "5736 Traning Loss: tensor(63.2855)\n",
      "5737 Traning Loss: tensor(63.2790)\n",
      "5738 Traning Loss: tensor(63.2725)\n",
      "5739 Traning Loss: tensor(63.2660)\n",
      "5740 Traning Loss: tensor(63.2595)\n",
      "5741 Traning Loss: tensor(63.2530)\n",
      "5742 Traning Loss: tensor(63.2466)\n",
      "5743 Traning Loss: tensor(63.2401)\n",
      "5744 Traning Loss: tensor(63.2336)\n",
      "5745 Traning Loss: tensor(63.2270)\n",
      "5746 Traning Loss: tensor(63.2206)\n",
      "5747 Traning Loss: tensor(63.2140)\n",
      "5748 Traning Loss: tensor(63.2076)\n",
      "5749 Traning Loss: tensor(63.2011)\n",
      "5750 Traning Loss: tensor(63.1945)\n",
      "5751 Traning Loss: tensor(63.1881)\n",
      "5752 Traning Loss: tensor(63.1816)\n",
      "5753 Traning Loss: tensor(63.1751)\n",
      "5754 Traning Loss: tensor(63.1685)\n",
      "5755 Traning Loss: tensor(63.1620)\n",
      "5756 Traning Loss: tensor(63.1555)\n",
      "5757 Traning Loss: tensor(63.1490)\n",
      "5758 Traning Loss: tensor(63.1425)\n",
      "5759 Traning Loss: tensor(63.1360)\n",
      "5760 Traning Loss: tensor(63.1294)\n",
      "5761 Traning Loss: tensor(63.1229)\n",
      "5762 Traning Loss: tensor(63.1164)\n",
      "5763 Traning Loss: tensor(63.1098)\n",
      "5764 Traning Loss: tensor(63.1033)\n",
      "5765 Traning Loss: tensor(63.0968)\n",
      "5766 Traning Loss: tensor(63.0902)\n",
      "5767 Traning Loss: tensor(63.0837)\n",
      "5768 Traning Loss: tensor(63.0771)\n",
      "5769 Traning Loss: tensor(63.0706)\n",
      "5770 Traning Loss: tensor(63.0641)\n",
      "5771 Traning Loss: tensor(63.0575)\n",
      "5772 Traning Loss: tensor(63.0509)\n",
      "5773 Traning Loss: tensor(63.0444)\n",
      "5774 Traning Loss: tensor(63.0379)\n",
      "5775 Traning Loss: tensor(63.0313)\n",
      "5776 Traning Loss: tensor(63.0248)\n",
      "5777 Traning Loss: tensor(63.0182)\n",
      "5778 Traning Loss: tensor(63.0116)\n",
      "5779 Traning Loss: tensor(63.0051)\n",
      "5780 Traning Loss: tensor(62.9985)\n",
      "5781 Traning Loss: tensor(62.9920)\n",
      "5782 Traning Loss: tensor(62.9854)\n",
      "5783 Traning Loss: tensor(62.9788)\n",
      "5784 Traning Loss: tensor(62.9722)\n",
      "5785 Traning Loss: tensor(62.9657)\n",
      "5786 Traning Loss: tensor(62.9591)\n",
      "5787 Traning Loss: tensor(62.9525)\n",
      "5788 Traning Loss: tensor(62.9460)\n",
      "5789 Traning Loss: tensor(62.9393)\n",
      "5790 Traning Loss: tensor(62.9327)\n",
      "5791 Traning Loss: tensor(62.9261)\n",
      "5792 Traning Loss: tensor(62.9196)\n",
      "5793 Traning Loss: tensor(62.9130)\n",
      "5794 Traning Loss: tensor(62.9064)\n",
      "5795 Traning Loss: tensor(62.8998)\n",
      "5796 Traning Loss: tensor(62.8932)\n",
      "5797 Traning Loss: tensor(62.8866)\n",
      "5798 Traning Loss: tensor(62.8800)\n",
      "5799 Traning Loss: tensor(62.8734)\n",
      "5800 Traning Loss: tensor(62.8668)\n",
      "5801 Traning Loss: tensor(62.8602)\n",
      "5802 Traning Loss: tensor(62.8536)\n",
      "5803 Traning Loss: tensor(62.8470)\n",
      "5804 Traning Loss: tensor(62.8404)\n",
      "5805 Traning Loss: tensor(62.8338)\n",
      "5806 Traning Loss: tensor(62.8272)\n",
      "5807 Traning Loss: tensor(62.8205)\n",
      "5808 Traning Loss: tensor(62.8139)\n",
      "5809 Traning Loss: tensor(62.8073)\n",
      "5810 Traning Loss: tensor(62.8007)\n",
      "5811 Traning Loss: tensor(62.7940)\n",
      "5812 Traning Loss: tensor(62.7874)\n",
      "5813 Traning Loss: tensor(62.7808)\n",
      "5814 Traning Loss: tensor(62.7741)\n",
      "5815 Traning Loss: tensor(62.7675)\n",
      "5816 Traning Loss: tensor(62.7609)\n",
      "5817 Traning Loss: tensor(62.7542)\n",
      "5818 Traning Loss: tensor(62.7476)\n",
      "5819 Traning Loss: tensor(62.7409)\n",
      "5820 Traning Loss: tensor(62.7343)\n",
      "5821 Traning Loss: tensor(62.7276)\n",
      "5822 Traning Loss: tensor(62.7210)\n",
      "5823 Traning Loss: tensor(62.7143)\n",
      "5824 Traning Loss: tensor(62.7077)\n",
      "5825 Traning Loss: tensor(62.7011)\n",
      "5826 Traning Loss: tensor(62.6944)\n",
      "5827 Traning Loss: tensor(62.6877)\n",
      "5828 Traning Loss: tensor(62.6811)\n",
      "5829 Traning Loss: tensor(62.6744)\n",
      "5830 Traning Loss: tensor(62.6678)\n",
      "5831 Traning Loss: tensor(62.6611)\n",
      "5832 Traning Loss: tensor(62.6544)\n",
      "5833 Traning Loss: tensor(62.6478)\n",
      "5834 Traning Loss: tensor(62.6411)\n",
      "5835 Traning Loss: tensor(62.6344)\n",
      "5836 Traning Loss: tensor(62.6277)\n",
      "5837 Traning Loss: tensor(62.6210)\n",
      "5838 Traning Loss: tensor(62.6144)\n",
      "5839 Traning Loss: tensor(62.6077)\n",
      "5840 Traning Loss: tensor(62.6010)\n",
      "5841 Traning Loss: tensor(62.5943)\n",
      "5842 Traning Loss: tensor(62.5876)\n",
      "5843 Traning Loss: tensor(62.5809)\n",
      "5844 Traning Loss: tensor(62.5742)\n",
      "5845 Traning Loss: tensor(62.5676)\n",
      "5846 Traning Loss: tensor(62.5609)\n",
      "5847 Traning Loss: tensor(62.5541)\n",
      "5848 Traning Loss: tensor(62.5475)\n",
      "5849 Traning Loss: tensor(62.5408)\n",
      "5850 Traning Loss: tensor(62.5341)\n",
      "5851 Traning Loss: tensor(62.5273)\n",
      "5852 Traning Loss: tensor(62.5206)\n",
      "5853 Traning Loss: tensor(62.5139)\n",
      "5854 Traning Loss: tensor(62.5072)\n",
      "5855 Traning Loss: tensor(62.5005)\n",
      "5856 Traning Loss: tensor(62.4938)\n",
      "5857 Traning Loss: tensor(62.4871)\n",
      "5858 Traning Loss: tensor(62.4803)\n",
      "5859 Traning Loss: tensor(62.4736)\n",
      "5860 Traning Loss: tensor(62.4669)\n",
      "5861 Traning Loss: tensor(62.4602)\n",
      "5862 Traning Loss: tensor(62.4534)\n",
      "5863 Traning Loss: tensor(62.4467)\n",
      "5864 Traning Loss: tensor(62.4400)\n",
      "5865 Traning Loss: tensor(62.4332)\n",
      "5866 Traning Loss: tensor(62.4265)\n",
      "5867 Traning Loss: tensor(62.4198)\n",
      "5868 Traning Loss: tensor(62.4130)\n",
      "5869 Traning Loss: tensor(62.4063)\n",
      "5870 Traning Loss: tensor(62.3996)\n",
      "5871 Traning Loss: tensor(62.3928)\n",
      "5872 Traning Loss: tensor(62.3861)\n",
      "5873 Traning Loss: tensor(62.3793)\n",
      "5874 Traning Loss: tensor(62.3725)\n",
      "5875 Traning Loss: tensor(62.3658)\n",
      "5876 Traning Loss: tensor(62.3590)\n",
      "5877 Traning Loss: tensor(62.3523)\n",
      "5878 Traning Loss: tensor(62.3455)\n",
      "5879 Traning Loss: tensor(62.3388)\n",
      "5880 Traning Loss: tensor(62.3320)\n",
      "5881 Traning Loss: tensor(62.3252)\n",
      "5882 Traning Loss: tensor(62.3184)\n",
      "5883 Traning Loss: tensor(62.3117)\n",
      "5884 Traning Loss: tensor(62.3049)\n",
      "5885 Traning Loss: tensor(62.2981)\n",
      "5886 Traning Loss: tensor(62.2914)\n",
      "5887 Traning Loss: tensor(62.2846)\n",
      "5888 Traning Loss: tensor(62.2778)\n",
      "5889 Traning Loss: tensor(62.2710)\n",
      "5890 Traning Loss: tensor(62.2643)\n",
      "5891 Traning Loss: tensor(62.2575)\n",
      "5892 Traning Loss: tensor(62.2507)\n",
      "5893 Traning Loss: tensor(62.2439)\n",
      "5894 Traning Loss: tensor(62.2371)\n",
      "5895 Traning Loss: tensor(62.2303)\n",
      "5896 Traning Loss: tensor(62.2235)\n",
      "5897 Traning Loss: tensor(62.2167)\n",
      "5898 Traning Loss: tensor(62.2099)\n",
      "5899 Traning Loss: tensor(62.2031)\n",
      "5900 Traning Loss: tensor(62.1963)\n",
      "5901 Traning Loss: tensor(62.1895)\n",
      "5902 Traning Loss: tensor(62.1827)\n",
      "5903 Traning Loss: tensor(62.1759)\n",
      "5904 Traning Loss: tensor(62.1690)\n",
      "5905 Traning Loss: tensor(62.1622)\n",
      "5906 Traning Loss: tensor(62.1554)\n",
      "5907 Traning Loss: tensor(62.1486)\n",
      "5908 Traning Loss: tensor(62.1418)\n",
      "5909 Traning Loss: tensor(62.1349)\n",
      "5910 Traning Loss: tensor(62.1281)\n",
      "5911 Traning Loss: tensor(62.1213)\n",
      "5912 Traning Loss: tensor(62.1145)\n",
      "5913 Traning Loss: tensor(62.1077)\n",
      "5914 Traning Loss: tensor(62.1008)\n",
      "5915 Traning Loss: tensor(62.0940)\n",
      "5916 Traning Loss: tensor(62.0872)\n",
      "5917 Traning Loss: tensor(62.0803)\n",
      "5918 Traning Loss: tensor(62.0735)\n",
      "5919 Traning Loss: tensor(62.0666)\n",
      "5920 Traning Loss: tensor(62.0598)\n",
      "5921 Traning Loss: tensor(62.0529)\n",
      "5922 Traning Loss: tensor(62.0461)\n",
      "5923 Traning Loss: tensor(62.0393)\n",
      "5924 Traning Loss: tensor(62.0324)\n",
      "5925 Traning Loss: tensor(62.0255)\n",
      "5926 Traning Loss: tensor(62.0187)\n",
      "5927 Traning Loss: tensor(62.0118)\n",
      "5928 Traning Loss: tensor(62.0049)\n",
      "5929 Traning Loss: tensor(61.9981)\n",
      "5930 Traning Loss: tensor(61.9912)\n",
      "5931 Traning Loss: tensor(61.9843)\n",
      "5932 Traning Loss: tensor(61.9775)\n",
      "5933 Traning Loss: tensor(61.9706)\n",
      "5934 Traning Loss: tensor(61.9638)\n",
      "5935 Traning Loss: tensor(61.9569)\n",
      "5936 Traning Loss: tensor(61.9500)\n",
      "5937 Traning Loss: tensor(61.9431)\n",
      "5938 Traning Loss: tensor(61.9363)\n",
      "5939 Traning Loss: tensor(61.9294)\n",
      "5940 Traning Loss: tensor(61.9225)\n",
      "5941 Traning Loss: tensor(61.9156)\n",
      "5942 Traning Loss: tensor(61.9087)\n",
      "5943 Traning Loss: tensor(61.9018)\n",
      "5944 Traning Loss: tensor(61.8950)\n",
      "5945 Traning Loss: tensor(61.8881)\n",
      "5946 Traning Loss: tensor(61.8812)\n",
      "5947 Traning Loss: tensor(61.8743)\n",
      "5948 Traning Loss: tensor(61.8674)\n",
      "5949 Traning Loss: tensor(61.8605)\n",
      "5950 Traning Loss: tensor(61.8535)\n",
      "5951 Traning Loss: tensor(61.8466)\n",
      "5952 Traning Loss: tensor(61.8397)\n",
      "5953 Traning Loss: tensor(61.8328)\n",
      "5954 Traning Loss: tensor(61.8259)\n",
      "5955 Traning Loss: tensor(61.8190)\n",
      "5956 Traning Loss: tensor(61.8121)\n",
      "5957 Traning Loss: tensor(61.8052)\n",
      "5958 Traning Loss: tensor(61.7983)\n",
      "5959 Traning Loss: tensor(61.7913)\n",
      "5960 Traning Loss: tensor(61.7844)\n",
      "5961 Traning Loss: tensor(61.7775)\n",
      "5962 Traning Loss: tensor(61.7706)\n",
      "5963 Traning Loss: tensor(61.7636)\n",
      "5964 Traning Loss: tensor(61.7567)\n",
      "5965 Traning Loss: tensor(61.7498)\n",
      "5966 Traning Loss: tensor(61.7428)\n",
      "5967 Traning Loss: tensor(61.7359)\n",
      "5968 Traning Loss: tensor(61.7290)\n",
      "5969 Traning Loss: tensor(61.7220)\n",
      "5970 Traning Loss: tensor(61.7151)\n",
      "5971 Traning Loss: tensor(61.7081)\n",
      "5972 Traning Loss: tensor(61.7012)\n",
      "5973 Traning Loss: tensor(61.6942)\n",
      "5974 Traning Loss: tensor(61.6873)\n",
      "5975 Traning Loss: tensor(61.6803)\n",
      "5976 Traning Loss: tensor(61.6734)\n",
      "5977 Traning Loss: tensor(61.6664)\n",
      "5978 Traning Loss: tensor(61.6595)\n",
      "5979 Traning Loss: tensor(61.6525)\n",
      "5980 Traning Loss: tensor(61.6455)\n",
      "5981 Traning Loss: tensor(61.6385)\n",
      "5982 Traning Loss: tensor(61.6316)\n",
      "5983 Traning Loss: tensor(61.6246)\n",
      "5984 Traning Loss: tensor(61.6177)\n",
      "5985 Traning Loss: tensor(61.6107)\n",
      "5986 Traning Loss: tensor(61.6037)\n",
      "5987 Traning Loss: tensor(61.5968)\n",
      "5988 Traning Loss: tensor(61.5898)\n",
      "5989 Traning Loss: tensor(61.5828)\n",
      "5990 Traning Loss: tensor(61.5758)\n",
      "5991 Traning Loss: tensor(61.5688)\n",
      "5992 Traning Loss: tensor(61.5618)\n",
      "5993 Traning Loss: tensor(61.5549)\n",
      "5994 Traning Loss: tensor(61.5479)\n",
      "5995 Traning Loss: tensor(61.5409)\n",
      "5996 Traning Loss: tensor(61.5338)\n",
      "5997 Traning Loss: tensor(61.5268)\n",
      "5998 Traning Loss: tensor(61.5198)\n",
      "5999 Traning Loss: tensor(61.5129)\n",
      "6000 Traning Loss: tensor(61.5059)\n",
      "6001 Traning Loss: tensor(61.4988)\n",
      "6002 Traning Loss: tensor(61.4918)\n",
      "6003 Traning Loss: tensor(61.4848)\n",
      "6004 Traning Loss: tensor(61.4778)\n",
      "6005 Traning Loss: tensor(61.4708)\n",
      "6006 Traning Loss: tensor(61.4638)\n",
      "6007 Traning Loss: tensor(61.4568)\n",
      "6008 Traning Loss: tensor(61.4498)\n",
      "6009 Traning Loss: tensor(61.4428)\n",
      "6010 Traning Loss: tensor(61.4357)\n",
      "6011 Traning Loss: tensor(61.4287)\n",
      "6012 Traning Loss: tensor(61.4217)\n",
      "6013 Traning Loss: tensor(61.4147)\n",
      "6014 Traning Loss: tensor(61.4076)\n",
      "6015 Traning Loss: tensor(61.4006)\n",
      "6016 Traning Loss: tensor(61.3936)\n",
      "6017 Traning Loss: tensor(61.3865)\n",
      "6018 Traning Loss: tensor(61.3795)\n",
      "6019 Traning Loss: tensor(61.3724)\n",
      "6020 Traning Loss: tensor(61.3654)\n",
      "6021 Traning Loss: tensor(61.3583)\n",
      "6022 Traning Loss: tensor(61.3513)\n",
      "6023 Traning Loss: tensor(61.3443)\n",
      "6024 Traning Loss: tensor(61.3372)\n",
      "6025 Traning Loss: tensor(61.3302)\n",
      "6026 Traning Loss: tensor(61.3231)\n",
      "6027 Traning Loss: tensor(61.3161)\n",
      "6028 Traning Loss: tensor(61.3090)\n",
      "6029 Traning Loss: tensor(61.3019)\n",
      "6030 Traning Loss: tensor(61.2949)\n",
      "6031 Traning Loss: tensor(61.2878)\n",
      "6032 Traning Loss: tensor(61.2808)\n",
      "6033 Traning Loss: tensor(61.2737)\n",
      "6034 Traning Loss: tensor(61.2666)\n",
      "6035 Traning Loss: tensor(61.2596)\n",
      "6036 Traning Loss: tensor(61.2525)\n",
      "6037 Traning Loss: tensor(61.2454)\n",
      "6038 Traning Loss: tensor(61.2383)\n",
      "6039 Traning Loss: tensor(61.2313)\n",
      "6040 Traning Loss: tensor(61.2242)\n",
      "6041 Traning Loss: tensor(61.2171)\n",
      "6042 Traning Loss: tensor(61.2100)\n",
      "6043 Traning Loss: tensor(61.2029)\n",
      "6044 Traning Loss: tensor(61.1958)\n",
      "6045 Traning Loss: tensor(61.1887)\n",
      "6046 Traning Loss: tensor(61.1816)\n",
      "6047 Traning Loss: tensor(61.1745)\n",
      "6048 Traning Loss: tensor(61.1674)\n",
      "6049 Traning Loss: tensor(61.1604)\n",
      "6050 Traning Loss: tensor(61.1533)\n",
      "6051 Traning Loss: tensor(61.1462)\n",
      "6052 Traning Loss: tensor(61.1390)\n",
      "6053 Traning Loss: tensor(61.1320)\n",
      "6054 Traning Loss: tensor(61.1248)\n",
      "6055 Traning Loss: tensor(61.1177)\n",
      "6056 Traning Loss: tensor(61.1106)\n",
      "6057 Traning Loss: tensor(61.1035)\n",
      "6058 Traning Loss: tensor(61.0964)\n",
      "6059 Traning Loss: tensor(61.0893)\n",
      "6060 Traning Loss: tensor(61.0821)\n",
      "6061 Traning Loss: tensor(61.0750)\n",
      "6062 Traning Loss: tensor(61.0679)\n",
      "6063 Traning Loss: tensor(61.0608)\n",
      "6064 Traning Loss: tensor(61.0537)\n",
      "6065 Traning Loss: tensor(61.0465)\n",
      "6066 Traning Loss: tensor(61.0394)\n",
      "6067 Traning Loss: tensor(61.0322)\n",
      "6068 Traning Loss: tensor(61.0251)\n",
      "6069 Traning Loss: tensor(61.0180)\n",
      "6070 Traning Loss: tensor(61.0108)\n",
      "6071 Traning Loss: tensor(61.0037)\n",
      "6072 Traning Loss: tensor(60.9966)\n",
      "6073 Traning Loss: tensor(60.9894)\n",
      "6074 Traning Loss: tensor(60.9823)\n",
      "6075 Traning Loss: tensor(60.9751)\n",
      "6076 Traning Loss: tensor(60.9680)\n",
      "6077 Traning Loss: tensor(60.9608)\n",
      "6078 Traning Loss: tensor(60.9537)\n",
      "6079 Traning Loss: tensor(60.9465)\n",
      "6080 Traning Loss: tensor(60.9393)\n",
      "6081 Traning Loss: tensor(60.9322)\n",
      "6082 Traning Loss: tensor(60.9250)\n",
      "6083 Traning Loss: tensor(60.9179)\n",
      "6084 Traning Loss: tensor(60.9107)\n",
      "6085 Traning Loss: tensor(60.9035)\n",
      "6086 Traning Loss: tensor(60.8964)\n",
      "6087 Traning Loss: tensor(60.8892)\n",
      "6088 Traning Loss: tensor(60.8820)\n",
      "6089 Traning Loss: tensor(60.8748)\n",
      "6090 Traning Loss: tensor(60.8677)\n",
      "6091 Traning Loss: tensor(60.8605)\n",
      "6092 Traning Loss: tensor(60.8533)\n",
      "6093 Traning Loss: tensor(60.8461)\n",
      "6094 Traning Loss: tensor(60.8389)\n",
      "6095 Traning Loss: tensor(60.8317)\n",
      "6096 Traning Loss: tensor(60.8245)\n",
      "6097 Traning Loss: tensor(60.8174)\n",
      "6098 Traning Loss: tensor(60.8102)\n",
      "6099 Traning Loss: tensor(60.8030)\n",
      "6100 Traning Loss: tensor(60.7958)\n",
      "6101 Traning Loss: tensor(60.7886)\n",
      "6102 Traning Loss: tensor(60.7814)\n",
      "6103 Traning Loss: tensor(60.7742)\n",
      "6104 Traning Loss: tensor(60.7670)\n",
      "6105 Traning Loss: tensor(60.7598)\n",
      "6106 Traning Loss: tensor(60.7526)\n",
      "6107 Traning Loss: tensor(60.7453)\n",
      "6108 Traning Loss: tensor(60.7381)\n",
      "6109 Traning Loss: tensor(60.7309)\n",
      "6110 Traning Loss: tensor(60.7237)\n",
      "6111 Traning Loss: tensor(60.7165)\n",
      "6112 Traning Loss: tensor(60.7093)\n",
      "6113 Traning Loss: tensor(60.7020)\n",
      "6114 Traning Loss: tensor(60.6948)\n",
      "6115 Traning Loss: tensor(60.6876)\n",
      "6116 Traning Loss: tensor(60.6803)\n",
      "6117 Traning Loss: tensor(60.6731)\n",
      "6118 Traning Loss: tensor(60.6659)\n",
      "6119 Traning Loss: tensor(60.6586)\n",
      "6120 Traning Loss: tensor(60.6514)\n",
      "6121 Traning Loss: tensor(60.6442)\n",
      "6122 Traning Loss: tensor(60.6369)\n",
      "6123 Traning Loss: tensor(60.6297)\n",
      "6124 Traning Loss: tensor(60.6225)\n",
      "6125 Traning Loss: tensor(60.6152)\n",
      "6126 Traning Loss: tensor(60.6080)\n",
      "6127 Traning Loss: tensor(60.6007)\n",
      "6128 Traning Loss: tensor(60.5935)\n",
      "6129 Traning Loss: tensor(60.5862)\n",
      "6130 Traning Loss: tensor(60.5789)\n",
      "6131 Traning Loss: tensor(60.5717)\n",
      "6132 Traning Loss: tensor(60.5644)\n",
      "6133 Traning Loss: tensor(60.5572)\n",
      "6134 Traning Loss: tensor(60.5499)\n",
      "6135 Traning Loss: tensor(60.5426)\n",
      "6136 Traning Loss: tensor(60.5354)\n",
      "6137 Traning Loss: tensor(60.5281)\n",
      "6138 Traning Loss: tensor(60.5209)\n",
      "6139 Traning Loss: tensor(60.5135)\n",
      "6140 Traning Loss: tensor(60.5062)\n",
      "6141 Traning Loss: tensor(60.4990)\n",
      "6142 Traning Loss: tensor(60.4917)\n",
      "6143 Traning Loss: tensor(60.4844)\n",
      "6144 Traning Loss: tensor(60.4772)\n",
      "6145 Traning Loss: tensor(60.4699)\n",
      "6146 Traning Loss: tensor(60.4626)\n",
      "6147 Traning Loss: tensor(60.4553)\n",
      "6148 Traning Loss: tensor(60.4480)\n",
      "6149 Traning Loss: tensor(60.4407)\n",
      "6150 Traning Loss: tensor(60.4334)\n",
      "6151 Traning Loss: tensor(60.4261)\n",
      "6152 Traning Loss: tensor(60.4188)\n",
      "6153 Traning Loss: tensor(60.4115)\n",
      "6154 Traning Loss: tensor(60.4042)\n",
      "6155 Traning Loss: tensor(60.3969)\n",
      "6156 Traning Loss: tensor(60.3896)\n",
      "6157 Traning Loss: tensor(60.3823)\n",
      "6158 Traning Loss: tensor(60.3750)\n",
      "6159 Traning Loss: tensor(60.3677)\n",
      "6160 Traning Loss: tensor(60.3604)\n",
      "6161 Traning Loss: tensor(60.3531)\n",
      "6162 Traning Loss: tensor(60.3458)\n",
      "6163 Traning Loss: tensor(60.3384)\n",
      "6164 Traning Loss: tensor(60.3311)\n",
      "6165 Traning Loss: tensor(60.3238)\n",
      "6166 Traning Loss: tensor(60.3165)\n",
      "6167 Traning Loss: tensor(60.3091)\n",
      "6168 Traning Loss: tensor(60.3018)\n",
      "6169 Traning Loss: tensor(60.2945)\n",
      "6170 Traning Loss: tensor(60.2872)\n",
      "6171 Traning Loss: tensor(60.2798)\n",
      "6172 Traning Loss: tensor(60.2725)\n",
      "6173 Traning Loss: tensor(60.2651)\n",
      "6174 Traning Loss: tensor(60.2578)\n",
      "6175 Traning Loss: tensor(60.2505)\n",
      "6176 Traning Loss: tensor(60.2431)\n",
      "6177 Traning Loss: tensor(60.2358)\n",
      "6178 Traning Loss: tensor(60.2284)\n",
      "6179 Traning Loss: tensor(60.2211)\n",
      "6180 Traning Loss: tensor(60.2137)\n",
      "6181 Traning Loss: tensor(60.2064)\n",
      "6182 Traning Loss: tensor(60.1990)\n",
      "6183 Traning Loss: tensor(60.1917)\n",
      "6184 Traning Loss: tensor(60.1843)\n",
      "6185 Traning Loss: tensor(60.1770)\n",
      "6186 Traning Loss: tensor(60.1696)\n",
      "6187 Traning Loss: tensor(60.1622)\n",
      "6188 Traning Loss: tensor(60.1548)\n",
      "6189 Traning Loss: tensor(60.1474)\n",
      "6190 Traning Loss: tensor(60.1401)\n",
      "6191 Traning Loss: tensor(60.1327)\n",
      "6192 Traning Loss: tensor(60.1253)\n",
      "6193 Traning Loss: tensor(60.1180)\n",
      "6194 Traning Loss: tensor(60.1106)\n",
      "6195 Traning Loss: tensor(60.1032)\n",
      "6196 Traning Loss: tensor(60.0958)\n",
      "6197 Traning Loss: tensor(60.0884)\n",
      "6198 Traning Loss: tensor(60.0811)\n",
      "6199 Traning Loss: tensor(60.0737)\n",
      "6200 Traning Loss: tensor(60.0663)\n",
      "6201 Traning Loss: tensor(60.0589)\n",
      "6202 Traning Loss: tensor(60.0515)\n",
      "6203 Traning Loss: tensor(60.0441)\n",
      "6204 Traning Loss: tensor(60.0367)\n",
      "6205 Traning Loss: tensor(60.0293)\n",
      "6206 Traning Loss: tensor(60.0219)\n",
      "6207 Traning Loss: tensor(60.0145)\n",
      "6208 Traning Loss: tensor(60.0071)\n",
      "6209 Traning Loss: tensor(59.9997)\n",
      "6210 Traning Loss: tensor(59.9923)\n",
      "6211 Traning Loss: tensor(59.9849)\n",
      "6212 Traning Loss: tensor(59.9774)\n",
      "6213 Traning Loss: tensor(59.9701)\n",
      "6214 Traning Loss: tensor(59.9626)\n",
      "6215 Traning Loss: tensor(59.9552)\n",
      "6216 Traning Loss: tensor(59.9478)\n",
      "6217 Traning Loss: tensor(59.9404)\n",
      "6218 Traning Loss: tensor(59.9329)\n",
      "6219 Traning Loss: tensor(59.9255)\n",
      "6220 Traning Loss: tensor(59.9181)\n",
      "6221 Traning Loss: tensor(59.9107)\n",
      "6222 Traning Loss: tensor(59.9033)\n",
      "6223 Traning Loss: tensor(59.8958)\n",
      "6224 Traning Loss: tensor(59.8884)\n",
      "6225 Traning Loss: tensor(59.8810)\n",
      "6226 Traning Loss: tensor(59.8735)\n",
      "6227 Traning Loss: tensor(59.8661)\n",
      "6228 Traning Loss: tensor(59.8586)\n",
      "6229 Traning Loss: tensor(59.8512)\n",
      "6230 Traning Loss: tensor(59.8437)\n",
      "6231 Traning Loss: tensor(59.8363)\n",
      "6232 Traning Loss: tensor(59.8288)\n",
      "6233 Traning Loss: tensor(59.8214)\n",
      "6234 Traning Loss: tensor(59.8139)\n",
      "6235 Traning Loss: tensor(59.8065)\n",
      "6236 Traning Loss: tensor(59.7990)\n",
      "6237 Traning Loss: tensor(59.7915)\n",
      "6238 Traning Loss: tensor(59.7841)\n",
      "6239 Traning Loss: tensor(59.7766)\n",
      "6240 Traning Loss: tensor(59.7691)\n",
      "6241 Traning Loss: tensor(59.7617)\n",
      "6242 Traning Loss: tensor(59.7542)\n",
      "6243 Traning Loss: tensor(59.7467)\n",
      "6244 Traning Loss: tensor(59.7393)\n",
      "6245 Traning Loss: tensor(59.7318)\n",
      "6246 Traning Loss: tensor(59.7243)\n",
      "6247 Traning Loss: tensor(59.7169)\n",
      "6248 Traning Loss: tensor(59.7094)\n",
      "6249 Traning Loss: tensor(59.7019)\n",
      "6250 Traning Loss: tensor(59.6944)\n",
      "6251 Traning Loss: tensor(59.6869)\n",
      "6252 Traning Loss: tensor(59.6794)\n",
      "6253 Traning Loss: tensor(59.6719)\n",
      "6254 Traning Loss: tensor(59.6645)\n",
      "6255 Traning Loss: tensor(59.6570)\n",
      "6256 Traning Loss: tensor(59.6495)\n",
      "6257 Traning Loss: tensor(59.6420)\n",
      "6258 Traning Loss: tensor(59.6345)\n",
      "6259 Traning Loss: tensor(59.6270)\n",
      "6260 Traning Loss: tensor(59.6195)\n",
      "6261 Traning Loss: tensor(59.6119)\n",
      "6262 Traning Loss: tensor(59.6044)\n",
      "6263 Traning Loss: tensor(59.5969)\n",
      "6264 Traning Loss: tensor(59.5894)\n",
      "6265 Traning Loss: tensor(59.5819)\n",
      "6266 Traning Loss: tensor(59.5744)\n",
      "6267 Traning Loss: tensor(59.5669)\n",
      "6268 Traning Loss: tensor(59.5594)\n",
      "6269 Traning Loss: tensor(59.5519)\n",
      "6270 Traning Loss: tensor(59.5443)\n",
      "6271 Traning Loss: tensor(59.5368)\n",
      "6272 Traning Loss: tensor(59.5293)\n",
      "6273 Traning Loss: tensor(59.5218)\n",
      "6274 Traning Loss: tensor(59.5143)\n",
      "6275 Traning Loss: tensor(59.5067)\n",
      "6276 Traning Loss: tensor(59.4992)\n",
      "6277 Traning Loss: tensor(59.4916)\n",
      "6278 Traning Loss: tensor(59.4841)\n",
      "6279 Traning Loss: tensor(59.4766)\n",
      "6280 Traning Loss: tensor(59.4691)\n",
      "6281 Traning Loss: tensor(59.4615)\n",
      "6282 Traning Loss: tensor(59.4539)\n",
      "6283 Traning Loss: tensor(59.4464)\n",
      "6284 Traning Loss: tensor(59.4389)\n",
      "6285 Traning Loss: tensor(59.4313)\n",
      "6286 Traning Loss: tensor(59.4237)\n",
      "6287 Traning Loss: tensor(59.4162)\n",
      "6288 Traning Loss: tensor(59.4086)\n",
      "6289 Traning Loss: tensor(59.4011)\n",
      "6290 Traning Loss: tensor(59.3935)\n",
      "6291 Traning Loss: tensor(59.3860)\n",
      "6292 Traning Loss: tensor(59.3784)\n",
      "6293 Traning Loss: tensor(59.3708)\n",
      "6294 Traning Loss: tensor(59.3633)\n",
      "6295 Traning Loss: tensor(59.3557)\n",
      "6296 Traning Loss: tensor(59.3481)\n",
      "6297 Traning Loss: tensor(59.3406)\n",
      "6298 Traning Loss: tensor(59.3330)\n",
      "6299 Traning Loss: tensor(59.3254)\n",
      "6300 Traning Loss: tensor(59.3179)\n",
      "6301 Traning Loss: tensor(59.3103)\n",
      "6302 Traning Loss: tensor(59.3027)\n",
      "6303 Traning Loss: tensor(59.2951)\n",
      "6304 Traning Loss: tensor(59.2875)\n",
      "6305 Traning Loss: tensor(59.2799)\n",
      "6306 Traning Loss: tensor(59.2724)\n",
      "6307 Traning Loss: tensor(59.2648)\n",
      "6308 Traning Loss: tensor(59.2572)\n",
      "6309 Traning Loss: tensor(59.2496)\n",
      "6310 Traning Loss: tensor(59.2419)\n",
      "6311 Traning Loss: tensor(59.2343)\n",
      "6312 Traning Loss: tensor(59.2268)\n",
      "6313 Traning Loss: tensor(59.2192)\n",
      "6314 Traning Loss: tensor(59.2116)\n",
      "6315 Traning Loss: tensor(59.2040)\n",
      "6316 Traning Loss: tensor(59.1964)\n",
      "6317 Traning Loss: tensor(59.1888)\n",
      "6318 Traning Loss: tensor(59.1811)\n",
      "6319 Traning Loss: tensor(59.1735)\n",
      "6320 Traning Loss: tensor(59.1659)\n",
      "6321 Traning Loss: tensor(59.1583)\n",
      "6322 Traning Loss: tensor(59.1507)\n",
      "6323 Traning Loss: tensor(59.1431)\n",
      "6324 Traning Loss: tensor(59.1354)\n",
      "6325 Traning Loss: tensor(59.1278)\n",
      "6326 Traning Loss: tensor(59.1202)\n",
      "6327 Traning Loss: tensor(59.1126)\n",
      "6328 Traning Loss: tensor(59.1049)\n",
      "6329 Traning Loss: tensor(59.0973)\n",
      "6330 Traning Loss: tensor(59.0897)\n",
      "6331 Traning Loss: tensor(59.0821)\n",
      "6332 Traning Loss: tensor(59.0744)\n",
      "6333 Traning Loss: tensor(59.0668)\n",
      "6334 Traning Loss: tensor(59.0592)\n",
      "6335 Traning Loss: tensor(59.0515)\n",
      "6336 Traning Loss: tensor(59.0438)\n",
      "6337 Traning Loss: tensor(59.0362)\n",
      "6338 Traning Loss: tensor(59.0285)\n",
      "6339 Traning Loss: tensor(59.0209)\n",
      "6340 Traning Loss: tensor(59.0132)\n",
      "6341 Traning Loss: tensor(59.0056)\n",
      "6342 Traning Loss: tensor(58.9979)\n",
      "6343 Traning Loss: tensor(58.9903)\n",
      "6344 Traning Loss: tensor(58.9826)\n",
      "6345 Traning Loss: tensor(58.9750)\n",
      "6346 Traning Loss: tensor(58.9673)\n",
      "6347 Traning Loss: tensor(58.9596)\n",
      "6348 Traning Loss: tensor(58.9520)\n",
      "6349 Traning Loss: tensor(58.9443)\n",
      "6350 Traning Loss: tensor(58.9367)\n",
      "6351 Traning Loss: tensor(58.9290)\n",
      "6352 Traning Loss: tensor(58.9213)\n",
      "6353 Traning Loss: tensor(58.9137)\n",
      "6354 Traning Loss: tensor(58.9060)\n",
      "6355 Traning Loss: tensor(58.8983)\n",
      "6356 Traning Loss: tensor(58.8906)\n",
      "6357 Traning Loss: tensor(58.8829)\n",
      "6358 Traning Loss: tensor(58.8752)\n",
      "6359 Traning Loss: tensor(58.8676)\n",
      "6360 Traning Loss: tensor(58.8598)\n",
      "6361 Traning Loss: tensor(58.8521)\n",
      "6362 Traning Loss: tensor(58.8444)\n",
      "6363 Traning Loss: tensor(58.8368)\n",
      "6364 Traning Loss: tensor(58.8291)\n",
      "6365 Traning Loss: tensor(58.8214)\n",
      "6366 Traning Loss: tensor(58.8137)\n",
      "6367 Traning Loss: tensor(58.8060)\n",
      "6368 Traning Loss: tensor(58.7983)\n",
      "6369 Traning Loss: tensor(58.7906)\n",
      "6370 Traning Loss: tensor(58.7829)\n",
      "6371 Traning Loss: tensor(58.7752)\n",
      "6372 Traning Loss: tensor(58.7675)\n",
      "6373 Traning Loss: tensor(58.7598)\n",
      "6374 Traning Loss: tensor(58.7521)\n",
      "6375 Traning Loss: tensor(58.7444)\n",
      "6376 Traning Loss: tensor(58.7366)\n",
      "6377 Traning Loss: tensor(58.7289)\n",
      "6378 Traning Loss: tensor(58.7212)\n",
      "6379 Traning Loss: tensor(58.7135)\n",
      "6380 Traning Loss: tensor(58.7058)\n",
      "6381 Traning Loss: tensor(58.6980)\n",
      "6382 Traning Loss: tensor(58.6903)\n",
      "6383 Traning Loss: tensor(58.6826)\n",
      "6384 Traning Loss: tensor(58.6748)\n",
      "6385 Traning Loss: tensor(58.6671)\n",
      "6386 Traning Loss: tensor(58.6593)\n",
      "6387 Traning Loss: tensor(58.6516)\n",
      "6388 Traning Loss: tensor(58.6439)\n",
      "6389 Traning Loss: tensor(58.6361)\n",
      "6390 Traning Loss: tensor(58.6284)\n",
      "6391 Traning Loss: tensor(58.6206)\n",
      "6392 Traning Loss: tensor(58.6129)\n",
      "6393 Traning Loss: tensor(58.6052)\n",
      "6394 Traning Loss: tensor(58.5974)\n",
      "6395 Traning Loss: tensor(58.5897)\n",
      "6396 Traning Loss: tensor(58.5819)\n",
      "6397 Traning Loss: tensor(58.5742)\n",
      "6398 Traning Loss: tensor(58.5664)\n",
      "6399 Traning Loss: tensor(58.5587)\n",
      "6400 Traning Loss: tensor(58.5509)\n",
      "6401 Traning Loss: tensor(58.5431)\n",
      "6402 Traning Loss: tensor(58.5354)\n",
      "6403 Traning Loss: tensor(58.5276)\n",
      "6404 Traning Loss: tensor(58.5199)\n",
      "6405 Traning Loss: tensor(58.5121)\n",
      "6406 Traning Loss: tensor(58.5043)\n",
      "6407 Traning Loss: tensor(58.4965)\n",
      "6408 Traning Loss: tensor(58.4888)\n",
      "6409 Traning Loss: tensor(58.4810)\n",
      "6410 Traning Loss: tensor(58.4732)\n",
      "6411 Traning Loss: tensor(58.4654)\n",
      "6412 Traning Loss: tensor(58.4576)\n",
      "6413 Traning Loss: tensor(58.4498)\n",
      "6414 Traning Loss: tensor(58.4420)\n",
      "6415 Traning Loss: tensor(58.4343)\n",
      "6416 Traning Loss: tensor(58.4265)\n",
      "6417 Traning Loss: tensor(58.4187)\n",
      "6418 Traning Loss: tensor(58.4109)\n",
      "6419 Traning Loss: tensor(58.4031)\n",
      "6420 Traning Loss: tensor(58.3953)\n",
      "6421 Traning Loss: tensor(58.3875)\n",
      "6422 Traning Loss: tensor(58.3797)\n",
      "6423 Traning Loss: tensor(58.3719)\n",
      "6424 Traning Loss: tensor(58.3641)\n",
      "6425 Traning Loss: tensor(58.3563)\n",
      "6426 Traning Loss: tensor(58.3485)\n",
      "6427 Traning Loss: tensor(58.3407)\n",
      "6428 Traning Loss: tensor(58.3329)\n",
      "6429 Traning Loss: tensor(58.3251)\n",
      "6430 Traning Loss: tensor(58.3173)\n",
      "6431 Traning Loss: tensor(58.3095)\n",
      "6432 Traning Loss: tensor(58.3017)\n",
      "6433 Traning Loss: tensor(58.2939)\n",
      "6434 Traning Loss: tensor(58.2860)\n",
      "6435 Traning Loss: tensor(58.2782)\n",
      "6436 Traning Loss: tensor(58.2704)\n",
      "6437 Traning Loss: tensor(58.2625)\n",
      "6438 Traning Loss: tensor(58.2547)\n",
      "6439 Traning Loss: tensor(58.2469)\n",
      "6440 Traning Loss: tensor(58.2391)\n",
      "6441 Traning Loss: tensor(58.2312)\n",
      "6442 Traning Loss: tensor(58.2234)\n",
      "6443 Traning Loss: tensor(58.2156)\n",
      "6444 Traning Loss: tensor(58.2077)\n",
      "6445 Traning Loss: tensor(58.1999)\n",
      "6446 Traning Loss: tensor(58.1920)\n",
      "6447 Traning Loss: tensor(58.1842)\n",
      "6448 Traning Loss: tensor(58.1763)\n",
      "6449 Traning Loss: tensor(58.1685)\n",
      "6450 Traning Loss: tensor(58.1607)\n",
      "6451 Traning Loss: tensor(58.1528)\n",
      "6452 Traning Loss: tensor(58.1450)\n",
      "6453 Traning Loss: tensor(58.1371)\n",
      "6454 Traning Loss: tensor(58.1293)\n",
      "6455 Traning Loss: tensor(58.1214)\n",
      "6456 Traning Loss: tensor(58.1136)\n",
      "6457 Traning Loss: tensor(58.1057)\n",
      "6458 Traning Loss: tensor(58.0978)\n",
      "6459 Traning Loss: tensor(58.0900)\n",
      "6460 Traning Loss: tensor(58.0821)\n",
      "6461 Traning Loss: tensor(58.0742)\n",
      "6462 Traning Loss: tensor(58.0663)\n",
      "6463 Traning Loss: tensor(58.0585)\n",
      "6464 Traning Loss: tensor(58.0506)\n",
      "6465 Traning Loss: tensor(58.0427)\n",
      "6466 Traning Loss: tensor(58.0348)\n",
      "6467 Traning Loss: tensor(58.0270)\n",
      "6468 Traning Loss: tensor(58.0191)\n",
      "6469 Traning Loss: tensor(58.0112)\n",
      "6470 Traning Loss: tensor(58.0033)\n",
      "6471 Traning Loss: tensor(57.9954)\n",
      "6472 Traning Loss: tensor(57.9876)\n",
      "6473 Traning Loss: tensor(57.9797)\n",
      "6474 Traning Loss: tensor(57.9718)\n",
      "6475 Traning Loss: tensor(57.9639)\n",
      "6476 Traning Loss: tensor(57.9560)\n",
      "6477 Traning Loss: tensor(57.9481)\n",
      "6478 Traning Loss: tensor(57.9402)\n",
      "6479 Traning Loss: tensor(57.9323)\n",
      "6480 Traning Loss: tensor(57.9244)\n",
      "6481 Traning Loss: tensor(57.9165)\n",
      "6482 Traning Loss: tensor(57.9086)\n",
      "6483 Traning Loss: tensor(57.9007)\n",
      "6484 Traning Loss: tensor(57.8928)\n",
      "6485 Traning Loss: tensor(57.8849)\n",
      "6486 Traning Loss: tensor(57.8769)\n",
      "6487 Traning Loss: tensor(57.8690)\n",
      "6488 Traning Loss: tensor(57.8611)\n",
      "6489 Traning Loss: tensor(57.8532)\n",
      "6490 Traning Loss: tensor(57.8453)\n",
      "6491 Traning Loss: tensor(57.8374)\n",
      "6492 Traning Loss: tensor(57.8294)\n",
      "6493 Traning Loss: tensor(57.8215)\n",
      "6494 Traning Loss: tensor(57.8136)\n",
      "6495 Traning Loss: tensor(57.8057)\n",
      "6496 Traning Loss: tensor(57.7978)\n",
      "6497 Traning Loss: tensor(57.7898)\n",
      "6498 Traning Loss: tensor(57.7819)\n",
      "6499 Traning Loss: tensor(57.7740)\n",
      "6500 Traning Loss: tensor(57.7660)\n",
      "6501 Traning Loss: tensor(57.7581)\n",
      "6502 Traning Loss: tensor(57.7502)\n",
      "6503 Traning Loss: tensor(57.7422)\n",
      "6504 Traning Loss: tensor(57.7343)\n",
      "6505 Traning Loss: tensor(57.7263)\n",
      "6506 Traning Loss: tensor(57.7184)\n",
      "6507 Traning Loss: tensor(57.7104)\n",
      "6508 Traning Loss: tensor(57.7025)\n",
      "6509 Traning Loss: tensor(57.6946)\n",
      "6510 Traning Loss: tensor(57.6866)\n",
      "6511 Traning Loss: tensor(57.6786)\n",
      "6512 Traning Loss: tensor(57.6706)\n",
      "6513 Traning Loss: tensor(57.6627)\n",
      "6514 Traning Loss: tensor(57.6547)\n",
      "6515 Traning Loss: tensor(57.6468)\n",
      "6516 Traning Loss: tensor(57.6388)\n",
      "6517 Traning Loss: tensor(57.6308)\n",
      "6518 Traning Loss: tensor(57.6229)\n",
      "6519 Traning Loss: tensor(57.6149)\n",
      "6520 Traning Loss: tensor(57.6069)\n",
      "6521 Traning Loss: tensor(57.5990)\n",
      "6522 Traning Loss: tensor(57.5910)\n",
      "6523 Traning Loss: tensor(57.5830)\n",
      "6524 Traning Loss: tensor(57.5751)\n",
      "6525 Traning Loss: tensor(57.5671)\n",
      "6526 Traning Loss: tensor(57.5591)\n",
      "6527 Traning Loss: tensor(57.5511)\n",
      "6528 Traning Loss: tensor(57.5432)\n",
      "6529 Traning Loss: tensor(57.5352)\n",
      "6530 Traning Loss: tensor(57.5272)\n",
      "6531 Traning Loss: tensor(57.5192)\n",
      "6532 Traning Loss: tensor(57.5112)\n",
      "6533 Traning Loss: tensor(57.5032)\n",
      "6534 Traning Loss: tensor(57.4952)\n",
      "6535 Traning Loss: tensor(57.4872)\n",
      "6536 Traning Loss: tensor(57.4792)\n",
      "6537 Traning Loss: tensor(57.4712)\n",
      "6538 Traning Loss: tensor(57.4632)\n",
      "6539 Traning Loss: tensor(57.4552)\n",
      "6540 Traning Loss: tensor(57.4472)\n",
      "6541 Traning Loss: tensor(57.4392)\n",
      "6542 Traning Loss: tensor(57.4312)\n",
      "6543 Traning Loss: tensor(57.4232)\n",
      "6544 Traning Loss: tensor(57.4151)\n",
      "6545 Traning Loss: tensor(57.4072)\n",
      "6546 Traning Loss: tensor(57.3991)\n",
      "6547 Traning Loss: tensor(57.3911)\n",
      "6548 Traning Loss: tensor(57.3831)\n",
      "6549 Traning Loss: tensor(57.3751)\n",
      "6550 Traning Loss: tensor(57.3671)\n",
      "6551 Traning Loss: tensor(57.3590)\n",
      "6552 Traning Loss: tensor(57.3510)\n",
      "6553 Traning Loss: tensor(57.3430)\n",
      "6554 Traning Loss: tensor(57.3350)\n",
      "6555 Traning Loss: tensor(57.3270)\n",
      "6556 Traning Loss: tensor(57.3189)\n",
      "6557 Traning Loss: tensor(57.3109)\n",
      "6558 Traning Loss: tensor(57.3029)\n",
      "6559 Traning Loss: tensor(57.2948)\n",
      "6560 Traning Loss: tensor(57.2868)\n",
      "6561 Traning Loss: tensor(57.2788)\n",
      "6562 Traning Loss: tensor(57.2707)\n",
      "6563 Traning Loss: tensor(57.2627)\n",
      "6564 Traning Loss: tensor(57.2546)\n",
      "6565 Traning Loss: tensor(57.2465)\n",
      "6566 Traning Loss: tensor(57.2385)\n",
      "6567 Traning Loss: tensor(57.2304)\n",
      "6568 Traning Loss: tensor(57.2224)\n",
      "6569 Traning Loss: tensor(57.2144)\n",
      "6570 Traning Loss: tensor(57.2063)\n",
      "6571 Traning Loss: tensor(57.1982)\n",
      "6572 Traning Loss: tensor(57.1902)\n",
      "6573 Traning Loss: tensor(57.1821)\n",
      "6574 Traning Loss: tensor(57.1741)\n",
      "6575 Traning Loss: tensor(57.1660)\n",
      "6576 Traning Loss: tensor(57.1580)\n",
      "6577 Traning Loss: tensor(57.1499)\n",
      "6578 Traning Loss: tensor(57.1418)\n",
      "6579 Traning Loss: tensor(57.1337)\n",
      "6580 Traning Loss: tensor(57.1257)\n",
      "6581 Traning Loss: tensor(57.1176)\n",
      "6582 Traning Loss: tensor(57.1096)\n",
      "6583 Traning Loss: tensor(57.1014)\n",
      "6584 Traning Loss: tensor(57.0934)\n",
      "6585 Traning Loss: tensor(57.0853)\n",
      "6586 Traning Loss: tensor(57.0772)\n",
      "6587 Traning Loss: tensor(57.0691)\n",
      "6588 Traning Loss: tensor(57.0611)\n",
      "6589 Traning Loss: tensor(57.0530)\n",
      "6590 Traning Loss: tensor(57.0448)\n",
      "6591 Traning Loss: tensor(57.0367)\n",
      "6592 Traning Loss: tensor(57.0287)\n",
      "6593 Traning Loss: tensor(57.0205)\n",
      "6594 Traning Loss: tensor(57.0125)\n",
      "6595 Traning Loss: tensor(57.0044)\n",
      "6596 Traning Loss: tensor(56.9963)\n",
      "6597 Traning Loss: tensor(56.9882)\n",
      "6598 Traning Loss: tensor(56.9801)\n",
      "6599 Traning Loss: tensor(56.9720)\n",
      "6600 Traning Loss: tensor(56.9639)\n",
      "6601 Traning Loss: tensor(56.9558)\n",
      "6602 Traning Loss: tensor(56.9477)\n",
      "6603 Traning Loss: tensor(56.9396)\n",
      "6604 Traning Loss: tensor(56.9315)\n",
      "6605 Traning Loss: tensor(56.9234)\n",
      "6606 Traning Loss: tensor(56.9152)\n",
      "6607 Traning Loss: tensor(56.9071)\n",
      "6608 Traning Loss: tensor(56.8990)\n",
      "6609 Traning Loss: tensor(56.8909)\n",
      "6610 Traning Loss: tensor(56.8828)\n",
      "6611 Traning Loss: tensor(56.8747)\n",
      "6612 Traning Loss: tensor(56.8665)\n",
      "6613 Traning Loss: tensor(56.8584)\n",
      "6614 Traning Loss: tensor(56.8503)\n",
      "6615 Traning Loss: tensor(56.8421)\n",
      "6616 Traning Loss: tensor(56.8340)\n",
      "6617 Traning Loss: tensor(56.8258)\n",
      "6618 Traning Loss: tensor(56.8177)\n",
      "6619 Traning Loss: tensor(56.8096)\n",
      "6620 Traning Loss: tensor(56.8014)\n",
      "6621 Traning Loss: tensor(56.7933)\n",
      "6622 Traning Loss: tensor(56.7851)\n",
      "6623 Traning Loss: tensor(56.7770)\n",
      "6624 Traning Loss: tensor(56.7689)\n",
      "6625 Traning Loss: tensor(56.7607)\n",
      "6626 Traning Loss: tensor(56.7526)\n",
      "6627 Traning Loss: tensor(56.7445)\n",
      "6628 Traning Loss: tensor(56.7363)\n",
      "6629 Traning Loss: tensor(56.7281)\n",
      "6630 Traning Loss: tensor(56.7200)\n",
      "6631 Traning Loss: tensor(56.7118)\n",
      "6632 Traning Loss: tensor(56.7037)\n",
      "6633 Traning Loss: tensor(56.6955)\n",
      "6634 Traning Loss: tensor(56.6874)\n",
      "6635 Traning Loss: tensor(56.6792)\n",
      "6636 Traning Loss: tensor(56.6711)\n",
      "6637 Traning Loss: tensor(56.6629)\n",
      "6638 Traning Loss: tensor(56.6547)\n",
      "6639 Traning Loss: tensor(56.6466)\n",
      "6640 Traning Loss: tensor(56.6384)\n",
      "6641 Traning Loss: tensor(56.6302)\n",
      "6642 Traning Loss: tensor(56.6220)\n",
      "6643 Traning Loss: tensor(56.6138)\n",
      "6644 Traning Loss: tensor(56.6056)\n",
      "6645 Traning Loss: tensor(56.5975)\n",
      "6646 Traning Loss: tensor(56.5893)\n",
      "6647 Traning Loss: tensor(56.5811)\n",
      "6648 Traning Loss: tensor(56.5729)\n",
      "6649 Traning Loss: tensor(56.5648)\n",
      "6650 Traning Loss: tensor(56.5566)\n",
      "6651 Traning Loss: tensor(56.5484)\n",
      "6652 Traning Loss: tensor(56.5402)\n",
      "6653 Traning Loss: tensor(56.5320)\n",
      "6654 Traning Loss: tensor(56.5238)\n",
      "6655 Traning Loss: tensor(56.5156)\n",
      "6656 Traning Loss: tensor(56.5074)\n",
      "6657 Traning Loss: tensor(56.4992)\n",
      "6658 Traning Loss: tensor(56.4910)\n",
      "6659 Traning Loss: tensor(56.4828)\n",
      "6660 Traning Loss: tensor(56.4746)\n",
      "6661 Traning Loss: tensor(56.4665)\n",
      "6662 Traning Loss: tensor(56.4582)\n",
      "6663 Traning Loss: tensor(56.4500)\n",
      "6664 Traning Loss: tensor(56.4418)\n",
      "6665 Traning Loss: tensor(56.4336)\n",
      "6666 Traning Loss: tensor(56.4254)\n",
      "6667 Traning Loss: tensor(56.4172)\n",
      "6668 Traning Loss: tensor(56.4090)\n",
      "6669 Traning Loss: tensor(56.4007)\n",
      "6670 Traning Loss: tensor(56.3925)\n",
      "6671 Traning Loss: tensor(56.3843)\n",
      "6672 Traning Loss: tensor(56.3760)\n",
      "6673 Traning Loss: tensor(56.3678)\n",
      "6674 Traning Loss: tensor(56.3596)\n",
      "6675 Traning Loss: tensor(56.3514)\n",
      "6676 Traning Loss: tensor(56.3432)\n",
      "6677 Traning Loss: tensor(56.3349)\n",
      "6678 Traning Loss: tensor(56.3267)\n",
      "6679 Traning Loss: tensor(56.3185)\n",
      "6680 Traning Loss: tensor(56.3103)\n",
      "6681 Traning Loss: tensor(56.3020)\n",
      "6682 Traning Loss: tensor(56.2938)\n",
      "6683 Traning Loss: tensor(56.2856)\n",
      "6684 Traning Loss: tensor(56.2773)\n",
      "6685 Traning Loss: tensor(56.2691)\n",
      "6686 Traning Loss: tensor(56.2608)\n",
      "6687 Traning Loss: tensor(56.2526)\n",
      "6688 Traning Loss: tensor(56.2443)\n",
      "6689 Traning Loss: tensor(56.2361)\n",
      "6690 Traning Loss: tensor(56.2278)\n",
      "6691 Traning Loss: tensor(56.2196)\n",
      "6692 Traning Loss: tensor(56.2113)\n",
      "6693 Traning Loss: tensor(56.2031)\n",
      "6694 Traning Loss: tensor(56.1948)\n",
      "6695 Traning Loss: tensor(56.1865)\n",
      "6696 Traning Loss: tensor(56.1783)\n",
      "6697 Traning Loss: tensor(56.1700)\n",
      "6698 Traning Loss: tensor(56.1617)\n",
      "6699 Traning Loss: tensor(56.1535)\n",
      "6700 Traning Loss: tensor(56.1452)\n",
      "6701 Traning Loss: tensor(56.1369)\n",
      "6702 Traning Loss: tensor(56.1287)\n",
      "6703 Traning Loss: tensor(56.1204)\n",
      "6704 Traning Loss: tensor(56.1121)\n",
      "6705 Traning Loss: tensor(56.1039)\n",
      "6706 Traning Loss: tensor(56.0956)\n",
      "6707 Traning Loss: tensor(56.0873)\n",
      "6708 Traning Loss: tensor(56.0791)\n",
      "6709 Traning Loss: tensor(56.0708)\n",
      "6710 Traning Loss: tensor(56.0625)\n",
      "6711 Traning Loss: tensor(56.0542)\n",
      "6712 Traning Loss: tensor(56.0459)\n",
      "6713 Traning Loss: tensor(56.0377)\n",
      "6714 Traning Loss: tensor(56.0294)\n",
      "6715 Traning Loss: tensor(56.0211)\n",
      "6716 Traning Loss: tensor(56.0128)\n",
      "6717 Traning Loss: tensor(56.0045)\n",
      "6718 Traning Loss: tensor(55.9962)\n",
      "6719 Traning Loss: tensor(55.9879)\n",
      "6720 Traning Loss: tensor(55.9796)\n",
      "6721 Traning Loss: tensor(55.9713)\n",
      "6722 Traning Loss: tensor(55.9630)\n",
      "6723 Traning Loss: tensor(55.9547)\n",
      "6724 Traning Loss: tensor(55.9463)\n",
      "6725 Traning Loss: tensor(55.9380)\n",
      "6726 Traning Loss: tensor(55.9298)\n",
      "6727 Traning Loss: tensor(55.9215)\n",
      "6728 Traning Loss: tensor(55.9131)\n",
      "6729 Traning Loss: tensor(55.9049)\n",
      "6730 Traning Loss: tensor(55.8965)\n",
      "6731 Traning Loss: tensor(55.8882)\n",
      "6732 Traning Loss: tensor(55.8799)\n",
      "6733 Traning Loss: tensor(55.8716)\n",
      "6734 Traning Loss: tensor(55.8633)\n",
      "6735 Traning Loss: tensor(55.8549)\n",
      "6736 Traning Loss: tensor(55.8466)\n",
      "6737 Traning Loss: tensor(55.8383)\n",
      "6738 Traning Loss: tensor(55.8300)\n",
      "6739 Traning Loss: tensor(55.8217)\n",
      "6740 Traning Loss: tensor(55.8134)\n",
      "6741 Traning Loss: tensor(55.8050)\n",
      "6742 Traning Loss: tensor(55.7967)\n",
      "6743 Traning Loss: tensor(55.7884)\n",
      "6744 Traning Loss: tensor(55.7800)\n",
      "6745 Traning Loss: tensor(55.7717)\n",
      "6746 Traning Loss: tensor(55.7633)\n",
      "6747 Traning Loss: tensor(55.7550)\n",
      "6748 Traning Loss: tensor(55.7467)\n",
      "6749 Traning Loss: tensor(55.7383)\n",
      "6750 Traning Loss: tensor(55.7299)\n",
      "6751 Traning Loss: tensor(55.7216)\n",
      "6752 Traning Loss: tensor(55.7132)\n",
      "6753 Traning Loss: tensor(55.7049)\n",
      "6754 Traning Loss: tensor(55.6965)\n",
      "6755 Traning Loss: tensor(55.6882)\n",
      "6756 Traning Loss: tensor(55.6798)\n",
      "6757 Traning Loss: tensor(55.6715)\n",
      "6758 Traning Loss: tensor(55.6632)\n",
      "6759 Traning Loss: tensor(55.6548)\n",
      "6760 Traning Loss: tensor(55.6464)\n",
      "6761 Traning Loss: tensor(55.6381)\n",
      "6762 Traning Loss: tensor(55.6297)\n",
      "6763 Traning Loss: tensor(55.6214)\n",
      "6764 Traning Loss: tensor(55.6130)\n",
      "6765 Traning Loss: tensor(55.6046)\n",
      "6766 Traning Loss: tensor(55.5963)\n",
      "6767 Traning Loss: tensor(55.5879)\n",
      "6768 Traning Loss: tensor(55.5795)\n",
      "6769 Traning Loss: tensor(55.5712)\n",
      "6770 Traning Loss: tensor(55.5628)\n",
      "6771 Traning Loss: tensor(55.5544)\n",
      "6772 Traning Loss: tensor(55.5461)\n",
      "6773 Traning Loss: tensor(55.5377)\n",
      "6774 Traning Loss: tensor(55.5293)\n",
      "6775 Traning Loss: tensor(55.5209)\n",
      "6776 Traning Loss: tensor(55.5125)\n",
      "6777 Traning Loss: tensor(55.5041)\n",
      "6778 Traning Loss: tensor(55.4957)\n",
      "6779 Traning Loss: tensor(55.4873)\n",
      "6780 Traning Loss: tensor(55.4789)\n",
      "6781 Traning Loss: tensor(55.4705)\n",
      "6782 Traning Loss: tensor(55.4621)\n",
      "6783 Traning Loss: tensor(55.4538)\n",
      "6784 Traning Loss: tensor(55.4454)\n",
      "6785 Traning Loss: tensor(55.4370)\n",
      "6786 Traning Loss: tensor(55.4286)\n",
      "6787 Traning Loss: tensor(55.4202)\n",
      "6788 Traning Loss: tensor(55.4118)\n",
      "6789 Traning Loss: tensor(55.4034)\n",
      "6790 Traning Loss: tensor(55.3950)\n",
      "6791 Traning Loss: tensor(55.3866)\n",
      "6792 Traning Loss: tensor(55.3782)\n",
      "6793 Traning Loss: tensor(55.3698)\n",
      "6794 Traning Loss: tensor(55.3614)\n",
      "6795 Traning Loss: tensor(55.3530)\n",
      "6796 Traning Loss: tensor(55.3446)\n",
      "6797 Traning Loss: tensor(55.3361)\n",
      "6798 Traning Loss: tensor(55.3277)\n",
      "6799 Traning Loss: tensor(55.3193)\n",
      "6800 Traning Loss: tensor(55.3109)\n",
      "6801 Traning Loss: tensor(55.3025)\n",
      "6802 Traning Loss: tensor(55.2941)\n",
      "6803 Traning Loss: tensor(55.2856)\n",
      "6804 Traning Loss: tensor(55.2771)\n",
      "6805 Traning Loss: tensor(55.2687)\n",
      "6806 Traning Loss: tensor(55.2603)\n",
      "6807 Traning Loss: tensor(55.2519)\n",
      "6808 Traning Loss: tensor(55.2434)\n",
      "6809 Traning Loss: tensor(55.2350)\n",
      "6810 Traning Loss: tensor(55.2266)\n",
      "6811 Traning Loss: tensor(55.2182)\n",
      "6812 Traning Loss: tensor(55.2097)\n",
      "6813 Traning Loss: tensor(55.2013)\n",
      "6814 Traning Loss: tensor(55.1929)\n",
      "6815 Traning Loss: tensor(55.1844)\n",
      "6816 Traning Loss: tensor(55.1760)\n",
      "6817 Traning Loss: tensor(55.1675)\n",
      "6818 Traning Loss: tensor(55.1591)\n",
      "6819 Traning Loss: tensor(55.1506)\n",
      "6820 Traning Loss: tensor(55.1422)\n",
      "6821 Traning Loss: tensor(55.1337)\n",
      "6822 Traning Loss: tensor(55.1253)\n",
      "6823 Traning Loss: tensor(55.1169)\n",
      "6824 Traning Loss: tensor(55.1084)\n",
      "6825 Traning Loss: tensor(55.0999)\n",
      "6826 Traning Loss: tensor(55.0915)\n",
      "6827 Traning Loss: tensor(55.0830)\n",
      "6828 Traning Loss: tensor(55.0746)\n",
      "6829 Traning Loss: tensor(55.0661)\n",
      "6830 Traning Loss: tensor(55.0577)\n",
      "6831 Traning Loss: tensor(55.0491)\n",
      "6832 Traning Loss: tensor(55.0407)\n",
      "6833 Traning Loss: tensor(55.0322)\n",
      "6834 Traning Loss: tensor(55.0237)\n",
      "6835 Traning Loss: tensor(55.0153)\n",
      "6836 Traning Loss: tensor(55.0068)\n",
      "6837 Traning Loss: tensor(54.9983)\n",
      "6838 Traning Loss: tensor(54.9898)\n",
      "6839 Traning Loss: tensor(54.9814)\n",
      "6840 Traning Loss: tensor(54.9729)\n",
      "6841 Traning Loss: tensor(54.9644)\n",
      "6842 Traning Loss: tensor(54.9560)\n",
      "6843 Traning Loss: tensor(54.9475)\n",
      "6844 Traning Loss: tensor(54.9390)\n",
      "6845 Traning Loss: tensor(54.9305)\n",
      "6846 Traning Loss: tensor(54.9220)\n",
      "6847 Traning Loss: tensor(54.9136)\n",
      "6848 Traning Loss: tensor(54.9051)\n",
      "6849 Traning Loss: tensor(54.8966)\n",
      "6850 Traning Loss: tensor(54.8881)\n",
      "6851 Traning Loss: tensor(54.8796)\n",
      "6852 Traning Loss: tensor(54.8711)\n",
      "6853 Traning Loss: tensor(54.8626)\n",
      "6854 Traning Loss: tensor(54.8541)\n",
      "6855 Traning Loss: tensor(54.8456)\n",
      "6856 Traning Loss: tensor(54.8371)\n",
      "6857 Traning Loss: tensor(54.8286)\n",
      "6858 Traning Loss: tensor(54.8201)\n",
      "6859 Traning Loss: tensor(54.8116)\n",
      "6860 Traning Loss: tensor(54.8030)\n",
      "6861 Traning Loss: tensor(54.7945)\n",
      "6862 Traning Loss: tensor(54.7861)\n",
      "6863 Traning Loss: tensor(54.7775)\n",
      "6864 Traning Loss: tensor(54.7690)\n",
      "6865 Traning Loss: tensor(54.7605)\n",
      "6866 Traning Loss: tensor(54.7520)\n",
      "6867 Traning Loss: tensor(54.7435)\n",
      "6868 Traning Loss: tensor(54.7350)\n",
      "6869 Traning Loss: tensor(54.7264)\n",
      "6870 Traning Loss: tensor(54.7180)\n",
      "6871 Traning Loss: tensor(54.7094)\n",
      "6872 Traning Loss: tensor(54.7009)\n",
      "6873 Traning Loss: tensor(54.6924)\n",
      "6874 Traning Loss: tensor(54.6838)\n",
      "6875 Traning Loss: tensor(54.6753)\n",
      "6876 Traning Loss: tensor(54.6668)\n",
      "6877 Traning Loss: tensor(54.6583)\n",
      "6878 Traning Loss: tensor(54.6497)\n",
      "6879 Traning Loss: tensor(54.6412)\n",
      "6880 Traning Loss: tensor(54.6327)\n",
      "6881 Traning Loss: tensor(54.6241)\n",
      "6882 Traning Loss: tensor(54.6156)\n",
      "6883 Traning Loss: tensor(54.6071)\n",
      "6884 Traning Loss: tensor(54.5985)\n",
      "6885 Traning Loss: tensor(54.5900)\n",
      "6886 Traning Loss: tensor(54.5814)\n",
      "6887 Traning Loss: tensor(54.5728)\n",
      "6888 Traning Loss: tensor(54.5643)\n",
      "6889 Traning Loss: tensor(54.5558)\n",
      "6890 Traning Loss: tensor(54.5472)\n",
      "6891 Traning Loss: tensor(54.5387)\n",
      "6892 Traning Loss: tensor(54.5301)\n",
      "6893 Traning Loss: tensor(54.5216)\n",
      "6894 Traning Loss: tensor(54.5130)\n",
      "6895 Traning Loss: tensor(54.5045)\n",
      "6896 Traning Loss: tensor(54.4959)\n",
      "6897 Traning Loss: tensor(54.4874)\n",
      "6898 Traning Loss: tensor(54.4788)\n",
      "6899 Traning Loss: tensor(54.4702)\n",
      "6900 Traning Loss: tensor(54.4617)\n",
      "6901 Traning Loss: tensor(54.4531)\n",
      "6902 Traning Loss: tensor(54.4446)\n",
      "6903 Traning Loss: tensor(54.4360)\n",
      "6904 Traning Loss: tensor(54.4274)\n",
      "6905 Traning Loss: tensor(54.4189)\n",
      "6906 Traning Loss: tensor(54.4103)\n",
      "6907 Traning Loss: tensor(54.4017)\n",
      "6908 Traning Loss: tensor(54.3932)\n",
      "6909 Traning Loss: tensor(54.3846)\n",
      "6910 Traning Loss: tensor(54.3760)\n",
      "6911 Traning Loss: tensor(54.3674)\n",
      "6912 Traning Loss: tensor(54.3589)\n",
      "6913 Traning Loss: tensor(54.3503)\n",
      "6914 Traning Loss: tensor(54.3416)\n",
      "6915 Traning Loss: tensor(54.3330)\n",
      "6916 Traning Loss: tensor(54.3245)\n",
      "6917 Traning Loss: tensor(54.3159)\n",
      "6918 Traning Loss: tensor(54.3073)\n",
      "6919 Traning Loss: tensor(54.2987)\n",
      "6920 Traning Loss: tensor(54.2901)\n",
      "6921 Traning Loss: tensor(54.2816)\n",
      "6922 Traning Loss: tensor(54.2729)\n",
      "6923 Traning Loss: tensor(54.2644)\n",
      "6924 Traning Loss: tensor(54.2558)\n",
      "6925 Traning Loss: tensor(54.2472)\n",
      "6926 Traning Loss: tensor(54.2386)\n",
      "6927 Traning Loss: tensor(54.2300)\n",
      "6928 Traning Loss: tensor(54.2214)\n",
      "6929 Traning Loss: tensor(54.2128)\n",
      "6930 Traning Loss: tensor(54.2042)\n",
      "6931 Traning Loss: tensor(54.1956)\n",
      "6932 Traning Loss: tensor(54.1870)\n",
      "6933 Traning Loss: tensor(54.1784)\n",
      "6934 Traning Loss: tensor(54.1698)\n",
      "6935 Traning Loss: tensor(54.1612)\n",
      "6936 Traning Loss: tensor(54.1525)\n",
      "6937 Traning Loss: tensor(54.1439)\n",
      "6938 Traning Loss: tensor(54.1353)\n",
      "6939 Traning Loss: tensor(54.1267)\n",
      "6940 Traning Loss: tensor(54.1181)\n",
      "6941 Traning Loss: tensor(54.1095)\n",
      "6942 Traning Loss: tensor(54.1008)\n",
      "6943 Traning Loss: tensor(54.0922)\n",
      "6944 Traning Loss: tensor(54.0835)\n",
      "6945 Traning Loss: tensor(54.0749)\n",
      "6946 Traning Loss: tensor(54.0663)\n",
      "6947 Traning Loss: tensor(54.0577)\n",
      "6948 Traning Loss: tensor(54.0491)\n",
      "6949 Traning Loss: tensor(54.0404)\n",
      "6950 Traning Loss: tensor(54.0318)\n",
      "6951 Traning Loss: tensor(54.0232)\n",
      "6952 Traning Loss: tensor(54.0145)\n",
      "6953 Traning Loss: tensor(54.0059)\n",
      "6954 Traning Loss: tensor(53.9973)\n",
      "6955 Traning Loss: tensor(53.9886)\n",
      "6956 Traning Loss: tensor(53.9800)\n",
      "6957 Traning Loss: tensor(53.9714)\n",
      "6958 Traning Loss: tensor(53.9627)\n",
      "6959 Traning Loss: tensor(53.9541)\n",
      "6960 Traning Loss: tensor(53.9455)\n",
      "6961 Traning Loss: tensor(53.9368)\n",
      "6962 Traning Loss: tensor(53.9282)\n",
      "6963 Traning Loss: tensor(53.9195)\n",
      "6964 Traning Loss: tensor(53.9109)\n",
      "6965 Traning Loss: tensor(53.9022)\n",
      "6966 Traning Loss: tensor(53.8936)\n",
      "6967 Traning Loss: tensor(53.8849)\n",
      "6968 Traning Loss: tensor(53.8763)\n",
      "6969 Traning Loss: tensor(53.8676)\n",
      "6970 Traning Loss: tensor(53.8589)\n",
      "6971 Traning Loss: tensor(53.8502)\n",
      "6972 Traning Loss: tensor(53.8416)\n",
      "6973 Traning Loss: tensor(53.8329)\n",
      "6974 Traning Loss: tensor(53.8243)\n",
      "6975 Traning Loss: tensor(53.8156)\n",
      "6976 Traning Loss: tensor(53.8069)\n",
      "6977 Traning Loss: tensor(53.7983)\n",
      "6978 Traning Loss: tensor(53.7896)\n",
      "6979 Traning Loss: tensor(53.7809)\n",
      "6980 Traning Loss: tensor(53.7723)\n",
      "6981 Traning Loss: tensor(53.7636)\n",
      "6982 Traning Loss: tensor(53.7549)\n",
      "6983 Traning Loss: tensor(53.7463)\n",
      "6984 Traning Loss: tensor(53.7376)\n",
      "6985 Traning Loss: tensor(53.7289)\n",
      "6986 Traning Loss: tensor(53.7202)\n",
      "6987 Traning Loss: tensor(53.7116)\n",
      "6988 Traning Loss: tensor(53.7029)\n",
      "6989 Traning Loss: tensor(53.6942)\n",
      "6990 Traning Loss: tensor(53.6855)\n",
      "6991 Traning Loss: tensor(53.6769)\n",
      "6992 Traning Loss: tensor(53.6682)\n",
      "6993 Traning Loss: tensor(53.6595)\n",
      "6994 Traning Loss: tensor(53.6508)\n",
      "6995 Traning Loss: tensor(53.6421)\n",
      "6996 Traning Loss: tensor(53.6334)\n",
      "6997 Traning Loss: tensor(53.6247)\n",
      "6998 Traning Loss: tensor(53.6160)\n",
      "6999 Traning Loss: tensor(53.6073)\n",
      "7000 Traning Loss: tensor(53.5986)\n",
      "7001 Traning Loss: tensor(53.5899)\n",
      "7002 Traning Loss: tensor(53.5812)\n",
      "7003 Traning Loss: tensor(53.5725)\n",
      "7004 Traning Loss: tensor(53.5638)\n",
      "7005 Traning Loss: tensor(53.5551)\n",
      "7006 Traning Loss: tensor(53.5464)\n",
      "7007 Traning Loss: tensor(53.5377)\n",
      "7008 Traning Loss: tensor(53.5290)\n",
      "7009 Traning Loss: tensor(53.5203)\n",
      "7010 Traning Loss: tensor(53.5116)\n",
      "7011 Traning Loss: tensor(53.5029)\n",
      "7012 Traning Loss: tensor(53.4942)\n",
      "7013 Traning Loss: tensor(53.4854)\n",
      "7014 Traning Loss: tensor(53.4767)\n",
      "7015 Traning Loss: tensor(53.4680)\n",
      "7016 Traning Loss: tensor(53.4593)\n",
      "7017 Traning Loss: tensor(53.4506)\n",
      "7018 Traning Loss: tensor(53.4419)\n",
      "7019 Traning Loss: tensor(53.4332)\n",
      "7020 Traning Loss: tensor(53.4244)\n",
      "7021 Traning Loss: tensor(53.4157)\n",
      "7022 Traning Loss: tensor(53.4070)\n",
      "7023 Traning Loss: tensor(53.3983)\n",
      "7024 Traning Loss: tensor(53.3895)\n",
      "7025 Traning Loss: tensor(53.3808)\n",
      "7026 Traning Loss: tensor(53.3721)\n",
      "7027 Traning Loss: tensor(53.3633)\n",
      "7028 Traning Loss: tensor(53.3546)\n",
      "7029 Traning Loss: tensor(53.3458)\n",
      "7030 Traning Loss: tensor(53.3371)\n",
      "7031 Traning Loss: tensor(53.3284)\n",
      "7032 Traning Loss: tensor(53.3196)\n",
      "7033 Traning Loss: tensor(53.3109)\n",
      "7034 Traning Loss: tensor(53.3022)\n",
      "7035 Traning Loss: tensor(53.2934)\n",
      "7036 Traning Loss: tensor(53.2847)\n",
      "7037 Traning Loss: tensor(53.2759)\n",
      "7038 Traning Loss: tensor(53.2672)\n",
      "7039 Traning Loss: tensor(53.2585)\n",
      "7040 Traning Loss: tensor(53.2497)\n",
      "7041 Traning Loss: tensor(53.2410)\n",
      "7042 Traning Loss: tensor(53.2322)\n",
      "7043 Traning Loss: tensor(53.2235)\n",
      "7044 Traning Loss: tensor(53.2147)\n",
      "7045 Traning Loss: tensor(53.2060)\n",
      "7046 Traning Loss: tensor(53.1972)\n",
      "7047 Traning Loss: tensor(53.1885)\n",
      "7048 Traning Loss: tensor(53.1797)\n",
      "7049 Traning Loss: tensor(53.1710)\n",
      "7050 Traning Loss: tensor(53.1622)\n",
      "7051 Traning Loss: tensor(53.1534)\n",
      "7052 Traning Loss: tensor(53.1447)\n",
      "7053 Traning Loss: tensor(53.1359)\n",
      "7054 Traning Loss: tensor(53.1272)\n",
      "7055 Traning Loss: tensor(53.1184)\n",
      "7056 Traning Loss: tensor(53.1095)\n",
      "7057 Traning Loss: tensor(53.1008)\n",
      "7058 Traning Loss: tensor(53.0920)\n",
      "7059 Traning Loss: tensor(53.0833)\n",
      "7060 Traning Loss: tensor(53.0745)\n",
      "7061 Traning Loss: tensor(53.0657)\n",
      "7062 Traning Loss: tensor(53.0569)\n",
      "7063 Traning Loss: tensor(53.0482)\n",
      "7064 Traning Loss: tensor(53.0394)\n",
      "7065 Traning Loss: tensor(53.0306)\n",
      "7066 Traning Loss: tensor(53.0219)\n",
      "7067 Traning Loss: tensor(53.0131)\n",
      "7068 Traning Loss: tensor(53.0043)\n",
      "7069 Traning Loss: tensor(52.9955)\n",
      "7070 Traning Loss: tensor(52.9867)\n",
      "7071 Traning Loss: tensor(52.9779)\n",
      "7072 Traning Loss: tensor(52.9692)\n",
      "7073 Traning Loss: tensor(52.9604)\n",
      "7074 Traning Loss: tensor(52.9516)\n",
      "7075 Traning Loss: tensor(52.9428)\n",
      "7076 Traning Loss: tensor(52.9340)\n",
      "7077 Traning Loss: tensor(52.9252)\n",
      "7078 Traning Loss: tensor(52.9164)\n",
      "7079 Traning Loss: tensor(52.9076)\n",
      "7080 Traning Loss: tensor(52.8989)\n",
      "7081 Traning Loss: tensor(52.8900)\n",
      "7082 Traning Loss: tensor(52.8813)\n",
      "7083 Traning Loss: tensor(52.8725)\n",
      "7084 Traning Loss: tensor(52.8637)\n",
      "7085 Traning Loss: tensor(52.8548)\n",
      "7086 Traning Loss: tensor(52.8460)\n",
      "7087 Traning Loss: tensor(52.8372)\n",
      "7088 Traning Loss: tensor(52.8284)\n",
      "7089 Traning Loss: tensor(52.8196)\n",
      "7090 Traning Loss: tensor(52.8108)\n",
      "7091 Traning Loss: tensor(52.8020)\n",
      "7092 Traning Loss: tensor(52.7932)\n",
      "7093 Traning Loss: tensor(52.7844)\n",
      "7094 Traning Loss: tensor(52.7755)\n",
      "7095 Traning Loss: tensor(52.7668)\n",
      "7096 Traning Loss: tensor(52.7579)\n",
      "7097 Traning Loss: tensor(52.7491)\n",
      "7098 Traning Loss: tensor(52.7403)\n",
      "7099 Traning Loss: tensor(52.7315)\n",
      "7100 Traning Loss: tensor(52.7226)\n",
      "7101 Traning Loss: tensor(52.7138)\n",
      "7102 Traning Loss: tensor(52.7050)\n",
      "7103 Traning Loss: tensor(52.6962)\n",
      "7104 Traning Loss: tensor(52.6874)\n",
      "7105 Traning Loss: tensor(52.6786)\n",
      "7106 Traning Loss: tensor(52.6697)\n",
      "7107 Traning Loss: tensor(52.6609)\n",
      "7108 Traning Loss: tensor(52.6521)\n",
      "7109 Traning Loss: tensor(52.6432)\n",
      "7110 Traning Loss: tensor(52.6344)\n",
      "7111 Traning Loss: tensor(52.6256)\n",
      "7112 Traning Loss: tensor(52.6168)\n",
      "7113 Traning Loss: tensor(52.6079)\n",
      "7114 Traning Loss: tensor(52.5990)\n",
      "7115 Traning Loss: tensor(52.5902)\n",
      "7116 Traning Loss: tensor(52.5813)\n",
      "7117 Traning Loss: tensor(52.5725)\n",
      "7118 Traning Loss: tensor(52.5637)\n",
      "7119 Traning Loss: tensor(52.5548)\n",
      "7120 Traning Loss: tensor(52.5460)\n",
      "7121 Traning Loss: tensor(52.5371)\n",
      "7122 Traning Loss: tensor(52.5283)\n",
      "7123 Traning Loss: tensor(52.5195)\n",
      "7124 Traning Loss: tensor(52.5106)\n",
      "7125 Traning Loss: tensor(52.5018)\n",
      "7126 Traning Loss: tensor(52.4929)\n",
      "7127 Traning Loss: tensor(52.4841)\n",
      "7128 Traning Loss: tensor(52.4752)\n",
      "7129 Traning Loss: tensor(52.4664)\n",
      "7130 Traning Loss: tensor(52.4575)\n",
      "7131 Traning Loss: tensor(52.4487)\n",
      "7132 Traning Loss: tensor(52.4398)\n",
      "7133 Traning Loss: tensor(52.4310)\n",
      "7134 Traning Loss: tensor(52.4221)\n",
      "7135 Traning Loss: tensor(52.4132)\n",
      "7136 Traning Loss: tensor(52.4044)\n",
      "7137 Traning Loss: tensor(52.3955)\n",
      "7138 Traning Loss: tensor(52.3866)\n",
      "7139 Traning Loss: tensor(52.3778)\n",
      "7140 Traning Loss: tensor(52.3689)\n",
      "7141 Traning Loss: tensor(52.3601)\n",
      "7142 Traning Loss: tensor(52.3512)\n",
      "7143 Traning Loss: tensor(52.3422)\n",
      "7144 Traning Loss: tensor(52.3334)\n",
      "7145 Traning Loss: tensor(52.3245)\n",
      "7146 Traning Loss: tensor(52.3156)\n",
      "7147 Traning Loss: tensor(52.3068)\n",
      "7148 Traning Loss: tensor(52.2979)\n",
      "7149 Traning Loss: tensor(52.2890)\n",
      "7150 Traning Loss: tensor(52.2801)\n",
      "7151 Traning Loss: tensor(52.2713)\n",
      "7152 Traning Loss: tensor(52.2624)\n",
      "7153 Traning Loss: tensor(52.2535)\n",
      "7154 Traning Loss: tensor(52.2446)\n",
      "7155 Traning Loss: tensor(52.2358)\n",
      "7156 Traning Loss: tensor(52.2269)\n",
      "7157 Traning Loss: tensor(52.2180)\n",
      "7158 Traning Loss: tensor(52.2091)\n",
      "7159 Traning Loss: tensor(52.2002)\n",
      "7160 Traning Loss: tensor(52.1913)\n",
      "7161 Traning Loss: tensor(52.1825)\n",
      "7162 Traning Loss: tensor(52.1736)\n",
      "7163 Traning Loss: tensor(52.1647)\n",
      "7164 Traning Loss: tensor(52.1558)\n",
      "7165 Traning Loss: tensor(52.1469)\n",
      "7166 Traning Loss: tensor(52.1380)\n",
      "7167 Traning Loss: tensor(52.1291)\n",
      "7168 Traning Loss: tensor(52.1202)\n",
      "7169 Traning Loss: tensor(52.1113)\n",
      "7170 Traning Loss: tensor(52.1024)\n",
      "7171 Traning Loss: tensor(52.0935)\n",
      "7172 Traning Loss: tensor(52.0846)\n",
      "7173 Traning Loss: tensor(52.0756)\n",
      "7174 Traning Loss: tensor(52.0667)\n",
      "7175 Traning Loss: tensor(52.0578)\n",
      "7176 Traning Loss: tensor(52.0489)\n",
      "7177 Traning Loss: tensor(52.0400)\n",
      "7178 Traning Loss: tensor(52.0311)\n",
      "7179 Traning Loss: tensor(52.0222)\n",
      "7180 Traning Loss: tensor(52.0133)\n",
      "7181 Traning Loss: tensor(52.0044)\n",
      "7182 Traning Loss: tensor(51.9955)\n",
      "7183 Traning Loss: tensor(51.9866)\n",
      "7184 Traning Loss: tensor(51.9777)\n",
      "7185 Traning Loss: tensor(51.9688)\n",
      "7186 Traning Loss: tensor(51.9598)\n",
      "7187 Traning Loss: tensor(51.9509)\n",
      "7188 Traning Loss: tensor(51.9420)\n",
      "7189 Traning Loss: tensor(51.9331)\n",
      "7190 Traning Loss: tensor(51.9242)\n",
      "7191 Traning Loss: tensor(51.9152)\n",
      "7192 Traning Loss: tensor(51.9063)\n",
      "7193 Traning Loss: tensor(51.8974)\n",
      "7194 Traning Loss: tensor(51.8885)\n",
      "7195 Traning Loss: tensor(51.8795)\n",
      "7196 Traning Loss: tensor(51.8706)\n",
      "7197 Traning Loss: tensor(51.8617)\n",
      "7198 Traning Loss: tensor(51.8528)\n",
      "7199 Traning Loss: tensor(51.8438)\n",
      "7200 Traning Loss: tensor(51.8349)\n",
      "7201 Traning Loss: tensor(51.8260)\n",
      "7202 Traning Loss: tensor(51.8170)\n",
      "7203 Traning Loss: tensor(51.8080)\n",
      "7204 Traning Loss: tensor(51.7991)\n",
      "7205 Traning Loss: tensor(51.7901)\n",
      "7206 Traning Loss: tensor(51.7812)\n",
      "7207 Traning Loss: tensor(51.7723)\n",
      "7208 Traning Loss: tensor(51.7633)\n",
      "7209 Traning Loss: tensor(51.7544)\n",
      "7210 Traning Loss: tensor(51.7455)\n",
      "7211 Traning Loss: tensor(51.7365)\n",
      "7212 Traning Loss: tensor(51.7276)\n",
      "7213 Traning Loss: tensor(51.7186)\n",
      "7214 Traning Loss: tensor(51.7097)\n",
      "7215 Traning Loss: tensor(51.7007)\n",
      "7216 Traning Loss: tensor(51.6918)\n",
      "7217 Traning Loss: tensor(51.6828)\n",
      "7218 Traning Loss: tensor(51.6739)\n",
      "7219 Traning Loss: tensor(51.6650)\n",
      "7220 Traning Loss: tensor(51.6560)\n",
      "7221 Traning Loss: tensor(51.6471)\n",
      "7222 Traning Loss: tensor(51.6381)\n",
      "7223 Traning Loss: tensor(51.6291)\n",
      "7224 Traning Loss: tensor(51.6202)\n",
      "7225 Traning Loss: tensor(51.6112)\n",
      "7226 Traning Loss: tensor(51.6023)\n",
      "7227 Traning Loss: tensor(51.5933)\n",
      "7228 Traning Loss: tensor(51.5843)\n",
      "7229 Traning Loss: tensor(51.5754)\n",
      "7230 Traning Loss: tensor(51.5664)\n",
      "7231 Traning Loss: tensor(51.5575)\n",
      "7232 Traning Loss: tensor(51.5484)\n",
      "7233 Traning Loss: tensor(51.5394)\n",
      "7234 Traning Loss: tensor(51.5305)\n",
      "7235 Traning Loss: tensor(51.5215)\n",
      "7236 Traning Loss: tensor(51.5126)\n",
      "7237 Traning Loss: tensor(51.5036)\n",
      "7238 Traning Loss: tensor(51.4946)\n",
      "7239 Traning Loss: tensor(51.4857)\n",
      "7240 Traning Loss: tensor(51.4767)\n",
      "7241 Traning Loss: tensor(51.4677)\n",
      "7242 Traning Loss: tensor(51.4587)\n",
      "7243 Traning Loss: tensor(51.4498)\n",
      "7244 Traning Loss: tensor(51.4408)\n",
      "7245 Traning Loss: tensor(51.4318)\n",
      "7246 Traning Loss: tensor(51.4228)\n",
      "7247 Traning Loss: tensor(51.4138)\n",
      "7248 Traning Loss: tensor(51.4049)\n",
      "7249 Traning Loss: tensor(51.3959)\n",
      "7250 Traning Loss: tensor(51.3869)\n",
      "7251 Traning Loss: tensor(51.3779)\n",
      "7252 Traning Loss: tensor(51.3689)\n",
      "7253 Traning Loss: tensor(51.3599)\n",
      "7254 Traning Loss: tensor(51.3510)\n",
      "7255 Traning Loss: tensor(51.3420)\n",
      "7256 Traning Loss: tensor(51.3330)\n",
      "7257 Traning Loss: tensor(51.3240)\n",
      "7258 Traning Loss: tensor(51.3150)\n",
      "7259 Traning Loss: tensor(51.3060)\n",
      "7260 Traning Loss: tensor(51.2970)\n",
      "7261 Traning Loss: tensor(51.2880)\n",
      "7262 Traning Loss: tensor(51.2789)\n",
      "7263 Traning Loss: tensor(51.2699)\n",
      "7264 Traning Loss: tensor(51.2609)\n",
      "7265 Traning Loss: tensor(51.2519)\n",
      "7266 Traning Loss: tensor(51.2430)\n",
      "7267 Traning Loss: tensor(51.2340)\n",
      "7268 Traning Loss: tensor(51.2249)\n",
      "7269 Traning Loss: tensor(51.2160)\n",
      "7270 Traning Loss: tensor(51.2070)\n",
      "7271 Traning Loss: tensor(51.1979)\n",
      "7272 Traning Loss: tensor(51.1889)\n",
      "7273 Traning Loss: tensor(51.1799)\n",
      "7274 Traning Loss: tensor(51.1709)\n",
      "7275 Traning Loss: tensor(51.1619)\n",
      "7276 Traning Loss: tensor(51.1529)\n",
      "7277 Traning Loss: tensor(51.1439)\n",
      "7278 Traning Loss: tensor(51.1349)\n",
      "7279 Traning Loss: tensor(51.1259)\n",
      "7280 Traning Loss: tensor(51.1169)\n",
      "7281 Traning Loss: tensor(51.1079)\n",
      "7282 Traning Loss: tensor(51.0989)\n",
      "7283 Traning Loss: tensor(51.0898)\n",
      "7284 Traning Loss: tensor(51.0808)\n",
      "7285 Traning Loss: tensor(51.0718)\n",
      "7286 Traning Loss: tensor(51.0628)\n",
      "7287 Traning Loss: tensor(51.0538)\n",
      "7288 Traning Loss: tensor(51.0447)\n",
      "7289 Traning Loss: tensor(51.0357)\n",
      "7290 Traning Loss: tensor(51.0267)\n",
      "7291 Traning Loss: tensor(51.0177)\n",
      "7292 Traning Loss: tensor(51.0086)\n",
      "7293 Traning Loss: tensor(50.9995)\n",
      "7294 Traning Loss: tensor(50.9905)\n",
      "7295 Traning Loss: tensor(50.9815)\n",
      "7296 Traning Loss: tensor(50.9724)\n",
      "7297 Traning Loss: tensor(50.9634)\n",
      "7298 Traning Loss: tensor(50.9544)\n",
      "7299 Traning Loss: tensor(50.9454)\n",
      "7300 Traning Loss: tensor(50.9363)\n",
      "7301 Traning Loss: tensor(50.9273)\n",
      "7302 Traning Loss: tensor(50.9183)\n",
      "7303 Traning Loss: tensor(50.9092)\n",
      "7304 Traning Loss: tensor(50.9002)\n",
      "7305 Traning Loss: tensor(50.8912)\n",
      "7306 Traning Loss: tensor(50.8821)\n",
      "7307 Traning Loss: tensor(50.8731)\n",
      "7308 Traning Loss: tensor(50.8640)\n",
      "7309 Traning Loss: tensor(50.8550)\n",
      "7310 Traning Loss: tensor(50.8460)\n",
      "7311 Traning Loss: tensor(50.8369)\n",
      "7312 Traning Loss: tensor(50.8279)\n",
      "7313 Traning Loss: tensor(50.8188)\n",
      "7314 Traning Loss: tensor(50.8098)\n",
      "7315 Traning Loss: tensor(50.8007)\n",
      "7316 Traning Loss: tensor(50.7917)\n",
      "7317 Traning Loss: tensor(50.7826)\n",
      "7318 Traning Loss: tensor(50.7736)\n",
      "7319 Traning Loss: tensor(50.7645)\n",
      "7320 Traning Loss: tensor(50.7555)\n",
      "7321 Traning Loss: tensor(50.7464)\n",
      "7322 Traning Loss: tensor(50.7374)\n",
      "7323 Traning Loss: tensor(50.7282)\n",
      "7324 Traning Loss: tensor(50.7192)\n",
      "7325 Traning Loss: tensor(50.7101)\n",
      "7326 Traning Loss: tensor(50.7011)\n",
      "7327 Traning Loss: tensor(50.6920)\n",
      "7328 Traning Loss: tensor(50.6830)\n",
      "7329 Traning Loss: tensor(50.6739)\n",
      "7330 Traning Loss: tensor(50.6648)\n",
      "7331 Traning Loss: tensor(50.6558)\n",
      "7332 Traning Loss: tensor(50.6467)\n",
      "7333 Traning Loss: tensor(50.6377)\n",
      "7334 Traning Loss: tensor(50.6286)\n",
      "7335 Traning Loss: tensor(50.6195)\n",
      "7336 Traning Loss: tensor(50.6105)\n",
      "7337 Traning Loss: tensor(50.6014)\n",
      "7338 Traning Loss: tensor(50.5923)\n",
      "7339 Traning Loss: tensor(50.5833)\n",
      "7340 Traning Loss: tensor(50.5742)\n",
      "7341 Traning Loss: tensor(50.5651)\n",
      "7342 Traning Loss: tensor(50.5561)\n",
      "7343 Traning Loss: tensor(50.5470)\n",
      "7344 Traning Loss: tensor(50.5379)\n",
      "7345 Traning Loss: tensor(50.5288)\n",
      "7346 Traning Loss: tensor(50.5198)\n",
      "7347 Traning Loss: tensor(50.5107)\n",
      "7348 Traning Loss: tensor(50.5016)\n",
      "7349 Traning Loss: tensor(50.4925)\n",
      "7350 Traning Loss: tensor(50.4834)\n",
      "7351 Traning Loss: tensor(50.4743)\n",
      "7352 Traning Loss: tensor(50.4653)\n",
      "7353 Traning Loss: tensor(50.4562)\n",
      "7354 Traning Loss: tensor(50.4470)\n",
      "7355 Traning Loss: tensor(50.4377)\n",
      "7356 Traning Loss: tensor(50.4286)\n",
      "7357 Traning Loss: tensor(50.4195)\n",
      "7358 Traning Loss: tensor(50.4104)\n",
      "7359 Traning Loss: tensor(50.4013)\n",
      "7360 Traning Loss: tensor(50.3923)\n",
      "7361 Traning Loss: tensor(50.3832)\n",
      "7362 Traning Loss: tensor(50.3741)\n",
      "7363 Traning Loss: tensor(50.3650)\n",
      "7364 Traning Loss: tensor(50.3559)\n",
      "7365 Traning Loss: tensor(50.3468)\n",
      "7366 Traning Loss: tensor(50.3377)\n",
      "7367 Traning Loss: tensor(50.3286)\n",
      "7368 Traning Loss: tensor(50.3195)\n",
      "7369 Traning Loss: tensor(50.3104)\n",
      "7370 Traning Loss: tensor(50.3013)\n",
      "7371 Traning Loss: tensor(50.2922)\n",
      "7372 Traning Loss: tensor(50.2831)\n",
      "7373 Traning Loss: tensor(50.2740)\n",
      "7374 Traning Loss: tensor(50.2649)\n",
      "7375 Traning Loss: tensor(50.2558)\n",
      "7376 Traning Loss: tensor(50.2467)\n",
      "7377 Traning Loss: tensor(50.2376)\n",
      "7378 Traning Loss: tensor(50.2285)\n",
      "7379 Traning Loss: tensor(50.2194)\n",
      "7380 Traning Loss: tensor(50.2103)\n",
      "7381 Traning Loss: tensor(50.2012)\n",
      "7382 Traning Loss: tensor(50.1921)\n",
      "7383 Traning Loss: tensor(50.1830)\n",
      "7384 Traning Loss: tensor(50.1739)\n",
      "7385 Traning Loss: tensor(50.1646)\n",
      "7386 Traning Loss: tensor(50.1556)\n",
      "7387 Traning Loss: tensor(50.1464)\n",
      "7388 Traning Loss: tensor(50.1373)\n",
      "7389 Traning Loss: tensor(50.1282)\n",
      "7390 Traning Loss: tensor(50.1191)\n",
      "7391 Traning Loss: tensor(50.1100)\n",
      "7392 Traning Loss: tensor(50.1009)\n",
      "7393 Traning Loss: tensor(50.0918)\n",
      "7394 Traning Loss: tensor(50.0826)\n",
      "7395 Traning Loss: tensor(50.0735)\n",
      "7396 Traning Loss: tensor(50.0644)\n",
      "7397 Traning Loss: tensor(50.0553)\n",
      "7398 Traning Loss: tensor(50.0462)\n",
      "7399 Traning Loss: tensor(50.0370)\n",
      "7400 Traning Loss: tensor(50.0279)\n",
      "7401 Traning Loss: tensor(50.0188)\n",
      "7402 Traning Loss: tensor(50.0097)\n",
      "7403 Traning Loss: tensor(50.0005)\n",
      "7404 Traning Loss: tensor(49.9914)\n",
      "7405 Traning Loss: tensor(49.9823)\n",
      "7406 Traning Loss: tensor(49.9731)\n",
      "7407 Traning Loss: tensor(49.9640)\n",
      "7408 Traning Loss: tensor(49.9549)\n",
      "7409 Traning Loss: tensor(49.9458)\n",
      "7410 Traning Loss: tensor(49.9366)\n",
      "7411 Traning Loss: tensor(49.9275)\n",
      "7412 Traning Loss: tensor(49.9184)\n",
      "7413 Traning Loss: tensor(49.9092)\n",
      "7414 Traning Loss: tensor(49.9001)\n",
      "7415 Traning Loss: tensor(49.8909)\n",
      "7416 Traning Loss: tensor(49.8817)\n",
      "7417 Traning Loss: tensor(49.8726)\n",
      "7418 Traning Loss: tensor(49.8634)\n",
      "7419 Traning Loss: tensor(49.8543)\n",
      "7420 Traning Loss: tensor(49.8452)\n",
      "7421 Traning Loss: tensor(49.8360)\n",
      "7422 Traning Loss: tensor(49.8269)\n",
      "7423 Traning Loss: tensor(49.8177)\n",
      "7424 Traning Loss: tensor(49.8086)\n",
      "7425 Traning Loss: tensor(49.7995)\n",
      "7426 Traning Loss: tensor(49.7903)\n",
      "7427 Traning Loss: tensor(49.7812)\n",
      "7428 Traning Loss: tensor(49.7720)\n",
      "7429 Traning Loss: tensor(49.7629)\n",
      "7430 Traning Loss: tensor(49.7537)\n",
      "7431 Traning Loss: tensor(49.7446)\n",
      "7432 Traning Loss: tensor(49.7354)\n",
      "7433 Traning Loss: tensor(49.7263)\n",
      "7434 Traning Loss: tensor(49.7171)\n",
      "7435 Traning Loss: tensor(49.7080)\n",
      "7436 Traning Loss: tensor(49.6988)\n",
      "7437 Traning Loss: tensor(49.6897)\n",
      "7438 Traning Loss: tensor(49.6805)\n",
      "7439 Traning Loss: tensor(49.6713)\n",
      "7440 Traning Loss: tensor(49.6622)\n",
      "7441 Traning Loss: tensor(49.6530)\n",
      "7442 Traning Loss: tensor(49.6439)\n",
      "7443 Traning Loss: tensor(49.6347)\n",
      "7444 Traning Loss: tensor(49.6256)\n",
      "7445 Traning Loss: tensor(49.6164)\n",
      "7446 Traning Loss: tensor(49.6072)\n",
      "7447 Traning Loss: tensor(49.5981)\n",
      "7448 Traning Loss: tensor(49.5888)\n",
      "7449 Traning Loss: tensor(49.5797)\n",
      "7450 Traning Loss: tensor(49.5705)\n",
      "7451 Traning Loss: tensor(49.5613)\n",
      "7452 Traning Loss: tensor(49.5522)\n",
      "7453 Traning Loss: tensor(49.5430)\n",
      "7454 Traning Loss: tensor(49.5338)\n",
      "7455 Traning Loss: tensor(49.5247)\n",
      "7456 Traning Loss: tensor(49.5155)\n",
      "7457 Traning Loss: tensor(49.5063)\n",
      "7458 Traning Loss: tensor(49.4972)\n",
      "7459 Traning Loss: tensor(49.4880)\n",
      "7460 Traning Loss: tensor(49.4788)\n",
      "7461 Traning Loss: tensor(49.4696)\n",
      "7462 Traning Loss: tensor(49.4605)\n",
      "7463 Traning Loss: tensor(49.4513)\n",
      "7464 Traning Loss: tensor(49.4421)\n",
      "7465 Traning Loss: tensor(49.4329)\n",
      "7466 Traning Loss: tensor(49.4238)\n",
      "7467 Traning Loss: tensor(49.4146)\n",
      "7468 Traning Loss: tensor(49.4054)\n",
      "7469 Traning Loss: tensor(49.3962)\n",
      "7470 Traning Loss: tensor(49.3870)\n",
      "7471 Traning Loss: tensor(49.3779)\n",
      "7472 Traning Loss: tensor(49.3687)\n",
      "7473 Traning Loss: tensor(49.3595)\n",
      "7474 Traning Loss: tensor(49.3503)\n",
      "7475 Traning Loss: tensor(49.3411)\n",
      "7476 Traning Loss: tensor(49.3319)\n",
      "7477 Traning Loss: tensor(49.3228)\n",
      "7478 Traning Loss: tensor(49.3136)\n",
      "7479 Traning Loss: tensor(49.3043)\n",
      "7480 Traning Loss: tensor(49.2951)\n",
      "7481 Traning Loss: tensor(49.2859)\n",
      "7482 Traning Loss: tensor(49.2767)\n",
      "7483 Traning Loss: tensor(49.2675)\n",
      "7484 Traning Loss: tensor(49.2583)\n",
      "7485 Traning Loss: tensor(49.2492)\n",
      "7486 Traning Loss: tensor(49.2400)\n",
      "7487 Traning Loss: tensor(49.2308)\n",
      "7488 Traning Loss: tensor(49.2216)\n",
      "7489 Traning Loss: tensor(49.2124)\n",
      "7490 Traning Loss: tensor(49.2032)\n",
      "7491 Traning Loss: tensor(49.1940)\n",
      "7492 Traning Loss: tensor(49.1848)\n",
      "7493 Traning Loss: tensor(49.1756)\n",
      "7494 Traning Loss: tensor(49.1664)\n",
      "7495 Traning Loss: tensor(49.1572)\n",
      "7496 Traning Loss: tensor(49.1480)\n",
      "7497 Traning Loss: tensor(49.1388)\n",
      "7498 Traning Loss: tensor(49.1296)\n",
      "7499 Traning Loss: tensor(49.1204)\n",
      "7500 Traning Loss: tensor(49.1112)\n",
      "7501 Traning Loss: tensor(49.1020)\n",
      "7502 Traning Loss: tensor(49.0928)\n",
      "7503 Traning Loss: tensor(49.0836)\n",
      "7504 Traning Loss: tensor(49.0744)\n",
      "7505 Traning Loss: tensor(49.0652)\n",
      "7506 Traning Loss: tensor(49.0560)\n",
      "7507 Traning Loss: tensor(49.0468)\n",
      "7508 Traning Loss: tensor(49.0375)\n",
      "7509 Traning Loss: tensor(49.0283)\n",
      "7510 Traning Loss: tensor(49.0191)\n",
      "7511 Traning Loss: tensor(49.0098)\n",
      "7512 Traning Loss: tensor(49.0006)\n",
      "7513 Traning Loss: tensor(48.9914)\n",
      "7514 Traning Loss: tensor(48.9822)\n",
      "7515 Traning Loss: tensor(48.9730)\n",
      "7516 Traning Loss: tensor(48.9638)\n",
      "7517 Traning Loss: tensor(48.9545)\n",
      "7518 Traning Loss: tensor(48.9453)\n",
      "7519 Traning Loss: tensor(48.9361)\n",
      "7520 Traning Loss: tensor(48.9269)\n",
      "7521 Traning Loss: tensor(48.9177)\n",
      "7522 Traning Loss: tensor(48.9085)\n",
      "7523 Traning Loss: tensor(48.8993)\n",
      "7524 Traning Loss: tensor(48.8900)\n",
      "7525 Traning Loss: tensor(48.8808)\n",
      "7526 Traning Loss: tensor(48.8716)\n",
      "7527 Traning Loss: tensor(48.8624)\n",
      "7528 Traning Loss: tensor(48.8531)\n",
      "7529 Traning Loss: tensor(48.8439)\n",
      "7530 Traning Loss: tensor(48.8347)\n",
      "7531 Traning Loss: tensor(48.8255)\n",
      "7532 Traning Loss: tensor(48.8163)\n",
      "7533 Traning Loss: tensor(48.8070)\n",
      "7534 Traning Loss: tensor(48.7978)\n",
      "7535 Traning Loss: tensor(48.7886)\n",
      "7536 Traning Loss: tensor(48.7793)\n",
      "7537 Traning Loss: tensor(48.7701)\n",
      "7538 Traning Loss: tensor(48.7609)\n",
      "7539 Traning Loss: tensor(48.7516)\n",
      "7540 Traning Loss: tensor(48.7424)\n",
      "7541 Traning Loss: tensor(48.7332)\n",
      "7542 Traning Loss: tensor(48.7239)\n",
      "7543 Traning Loss: tensor(48.7147)\n",
      "7544 Traning Loss: tensor(48.7054)\n",
      "7545 Traning Loss: tensor(48.6961)\n",
      "7546 Traning Loss: tensor(48.6869)\n",
      "7547 Traning Loss: tensor(48.6777)\n",
      "7548 Traning Loss: tensor(48.6684)\n",
      "7549 Traning Loss: tensor(48.6592)\n",
      "7550 Traning Loss: tensor(48.6500)\n",
      "7551 Traning Loss: tensor(48.6407)\n",
      "7552 Traning Loss: tensor(48.6315)\n",
      "7553 Traning Loss: tensor(48.6223)\n",
      "7554 Traning Loss: tensor(48.6130)\n",
      "7555 Traning Loss: tensor(48.6038)\n",
      "7556 Traning Loss: tensor(48.5945)\n",
      "7557 Traning Loss: tensor(48.5853)\n",
      "7558 Traning Loss: tensor(48.5761)\n",
      "7559 Traning Loss: tensor(48.5668)\n",
      "7560 Traning Loss: tensor(48.5576)\n",
      "7561 Traning Loss: tensor(48.5483)\n",
      "7562 Traning Loss: tensor(48.5391)\n",
      "7563 Traning Loss: tensor(48.5298)\n",
      "7564 Traning Loss: tensor(48.5206)\n",
      "7565 Traning Loss: tensor(48.5113)\n",
      "7566 Traning Loss: tensor(48.5021)\n",
      "7567 Traning Loss: tensor(48.4928)\n",
      "7568 Traning Loss: tensor(48.4836)\n",
      "7569 Traning Loss: tensor(48.4743)\n",
      "7570 Traning Loss: tensor(48.4651)\n",
      "7571 Traning Loss: tensor(48.4558)\n",
      "7572 Traning Loss: tensor(48.4466)\n",
      "7573 Traning Loss: tensor(48.4373)\n",
      "7574 Traning Loss: tensor(48.4281)\n",
      "7575 Traning Loss: tensor(48.4188)\n",
      "7576 Traning Loss: tensor(48.4094)\n",
      "7577 Traning Loss: tensor(48.4002)\n",
      "7578 Traning Loss: tensor(48.3909)\n",
      "7579 Traning Loss: tensor(48.3817)\n",
      "7580 Traning Loss: tensor(48.3724)\n",
      "7581 Traning Loss: tensor(48.3632)\n",
      "7582 Traning Loss: tensor(48.3539)\n",
      "7583 Traning Loss: tensor(48.3447)\n",
      "7584 Traning Loss: tensor(48.3354)\n",
      "7585 Traning Loss: tensor(48.3261)\n",
      "7586 Traning Loss: tensor(48.3169)\n",
      "7587 Traning Loss: tensor(48.3076)\n",
      "7588 Traning Loss: tensor(48.2984)\n",
      "7589 Traning Loss: tensor(48.2891)\n",
      "7590 Traning Loss: tensor(48.2798)\n",
      "7591 Traning Loss: tensor(48.2706)\n",
      "7592 Traning Loss: tensor(48.2613)\n",
      "7593 Traning Loss: tensor(48.2521)\n",
      "7594 Traning Loss: tensor(48.2428)\n",
      "7595 Traning Loss: tensor(48.2335)\n",
      "7596 Traning Loss: tensor(48.2242)\n",
      "7597 Traning Loss: tensor(48.2150)\n",
      "7598 Traning Loss: tensor(48.2057)\n",
      "7599 Traning Loss: tensor(48.1964)\n",
      "7600 Traning Loss: tensor(48.1872)\n",
      "7601 Traning Loss: tensor(48.1779)\n",
      "7602 Traning Loss: tensor(48.1686)\n",
      "7603 Traning Loss: tensor(48.1594)\n",
      "7604 Traning Loss: tensor(48.1501)\n",
      "7605 Traning Loss: tensor(48.1408)\n",
      "7606 Traning Loss: tensor(48.1315)\n",
      "7607 Traning Loss: tensor(48.1223)\n",
      "7608 Traning Loss: tensor(48.1130)\n",
      "7609 Traning Loss: tensor(48.1036)\n",
      "7610 Traning Loss: tensor(48.0943)\n",
      "7611 Traning Loss: tensor(48.0850)\n",
      "7612 Traning Loss: tensor(48.0758)\n",
      "7613 Traning Loss: tensor(48.0665)\n",
      "7614 Traning Loss: tensor(48.0572)\n",
      "7615 Traning Loss: tensor(48.0479)\n",
      "7616 Traning Loss: tensor(48.0387)\n",
      "7617 Traning Loss: tensor(48.0294)\n",
      "7618 Traning Loss: tensor(48.0201)\n",
      "7619 Traning Loss: tensor(48.0108)\n",
      "7620 Traning Loss: tensor(48.0015)\n",
      "7621 Traning Loss: tensor(47.9923)\n",
      "7622 Traning Loss: tensor(47.9830)\n",
      "7623 Traning Loss: tensor(47.9737)\n",
      "7624 Traning Loss: tensor(47.9644)\n",
      "7625 Traning Loss: tensor(47.9551)\n",
      "7626 Traning Loss: tensor(47.9458)\n",
      "7627 Traning Loss: tensor(47.9366)\n",
      "7628 Traning Loss: tensor(47.9273)\n",
      "7629 Traning Loss: tensor(47.9180)\n",
      "7630 Traning Loss: tensor(47.9087)\n",
      "7631 Traning Loss: tensor(47.8994)\n",
      "7632 Traning Loss: tensor(47.8901)\n",
      "7633 Traning Loss: tensor(47.8808)\n",
      "7634 Traning Loss: tensor(47.8715)\n",
      "7635 Traning Loss: tensor(47.8622)\n",
      "7636 Traning Loss: tensor(47.8529)\n",
      "7637 Traning Loss: tensor(47.8437)\n",
      "7638 Traning Loss: tensor(47.8344)\n",
      "7639 Traning Loss: tensor(47.8251)\n",
      "7640 Traning Loss: tensor(47.8158)\n",
      "7641 Traning Loss: tensor(47.8065)\n",
      "7642 Traning Loss: tensor(47.7971)\n",
      "7643 Traning Loss: tensor(47.7878)\n",
      "7644 Traning Loss: tensor(47.7785)\n",
      "7645 Traning Loss: tensor(47.7692)\n",
      "7646 Traning Loss: tensor(47.7599)\n",
      "7647 Traning Loss: tensor(47.7506)\n",
      "7648 Traning Loss: tensor(47.7413)\n",
      "7649 Traning Loss: tensor(47.7320)\n",
      "7650 Traning Loss: tensor(47.7227)\n",
      "7651 Traning Loss: tensor(47.7134)\n",
      "7652 Traning Loss: tensor(47.7041)\n",
      "7653 Traning Loss: tensor(47.6948)\n",
      "7654 Traning Loss: tensor(47.6855)\n",
      "7655 Traning Loss: tensor(47.6762)\n",
      "7656 Traning Loss: tensor(47.6669)\n",
      "7657 Traning Loss: tensor(47.6576)\n",
      "7658 Traning Loss: tensor(47.6483)\n",
      "7659 Traning Loss: tensor(47.6390)\n",
      "7660 Traning Loss: tensor(47.6297)\n",
      "7661 Traning Loss: tensor(47.6204)\n",
      "7662 Traning Loss: tensor(47.6111)\n",
      "7663 Traning Loss: tensor(47.6018)\n",
      "7664 Traning Loss: tensor(47.5925)\n",
      "7665 Traning Loss: tensor(47.5832)\n",
      "7666 Traning Loss: tensor(47.5738)\n",
      "7667 Traning Loss: tensor(47.5645)\n",
      "7668 Traning Loss: tensor(47.5552)\n",
      "7669 Traning Loss: tensor(47.5459)\n",
      "7670 Traning Loss: tensor(47.5366)\n",
      "7671 Traning Loss: tensor(47.5273)\n",
      "7672 Traning Loss: tensor(47.5180)\n",
      "7673 Traning Loss: tensor(47.5087)\n",
      "7674 Traning Loss: tensor(47.4993)\n",
      "7675 Traning Loss: tensor(47.4899)\n",
      "7676 Traning Loss: tensor(47.4806)\n",
      "7677 Traning Loss: tensor(47.4713)\n",
      "7678 Traning Loss: tensor(47.4620)\n",
      "7679 Traning Loss: tensor(47.4527)\n",
      "7680 Traning Loss: tensor(47.4434)\n",
      "7681 Traning Loss: tensor(47.4340)\n",
      "7682 Traning Loss: tensor(47.4247)\n",
      "7683 Traning Loss: tensor(47.4154)\n",
      "7684 Traning Loss: tensor(47.4061)\n",
      "7685 Traning Loss: tensor(47.3968)\n",
      "7686 Traning Loss: tensor(47.3875)\n",
      "7687 Traning Loss: tensor(47.3781)\n",
      "7688 Traning Loss: tensor(47.3688)\n",
      "7689 Traning Loss: tensor(47.3595)\n",
      "7690 Traning Loss: tensor(47.3502)\n",
      "7691 Traning Loss: tensor(47.3409)\n",
      "7692 Traning Loss: tensor(47.3315)\n",
      "7693 Traning Loss: tensor(47.3222)\n",
      "7694 Traning Loss: tensor(47.3129)\n",
      "7695 Traning Loss: tensor(47.3036)\n",
      "7696 Traning Loss: tensor(47.2943)\n",
      "7697 Traning Loss: tensor(47.2849)\n",
      "7698 Traning Loss: tensor(47.2756)\n",
      "7699 Traning Loss: tensor(47.2663)\n",
      "7700 Traning Loss: tensor(47.2570)\n",
      "7701 Traning Loss: tensor(47.2476)\n",
      "7702 Traning Loss: tensor(47.2383)\n",
      "7703 Traning Loss: tensor(47.2290)\n",
      "7704 Traning Loss: tensor(47.2196)\n",
      "7705 Traning Loss: tensor(47.2103)\n",
      "7706 Traning Loss: tensor(47.2010)\n",
      "7707 Traning Loss: tensor(47.1917)\n",
      "7708 Traning Loss: tensor(47.1823)\n",
      "7709 Traning Loss: tensor(47.1729)\n",
      "7710 Traning Loss: tensor(47.1635)\n",
      "7711 Traning Loss: tensor(47.1542)\n",
      "7712 Traning Loss: tensor(47.1449)\n",
      "7713 Traning Loss: tensor(47.1355)\n",
      "7714 Traning Loss: tensor(47.1262)\n",
      "7715 Traning Loss: tensor(47.1169)\n",
      "7716 Traning Loss: tensor(47.1076)\n",
      "7717 Traning Loss: tensor(47.0982)\n",
      "7718 Traning Loss: tensor(47.0889)\n",
      "7719 Traning Loss: tensor(47.0796)\n",
      "7720 Traning Loss: tensor(47.0702)\n",
      "7721 Traning Loss: tensor(47.0609)\n",
      "7722 Traning Loss: tensor(47.0515)\n",
      "7723 Traning Loss: tensor(47.0422)\n",
      "7724 Traning Loss: tensor(47.0329)\n",
      "7725 Traning Loss: tensor(47.0235)\n",
      "7726 Traning Loss: tensor(47.0142)\n",
      "7727 Traning Loss: tensor(47.0049)\n",
      "7728 Traning Loss: tensor(46.9955)\n",
      "7729 Traning Loss: tensor(46.9862)\n",
      "7730 Traning Loss: tensor(46.9768)\n",
      "7731 Traning Loss: tensor(46.9675)\n",
      "7732 Traning Loss: tensor(46.9582)\n",
      "7733 Traning Loss: tensor(46.9488)\n",
      "7734 Traning Loss: tensor(46.9395)\n",
      "7735 Traning Loss: tensor(46.9301)\n",
      "7736 Traning Loss: tensor(46.9208)\n",
      "7737 Traning Loss: tensor(46.9114)\n",
      "7738 Traning Loss: tensor(46.9021)\n",
      "7739 Traning Loss: tensor(46.8928)\n",
      "7740 Traning Loss: tensor(46.8834)\n",
      "7741 Traning Loss: tensor(46.8741)\n",
      "7742 Traning Loss: tensor(46.8647)\n",
      "7743 Traning Loss: tensor(46.8552)\n",
      "7744 Traning Loss: tensor(46.8459)\n",
      "7745 Traning Loss: tensor(46.8365)\n",
      "7746 Traning Loss: tensor(46.8272)\n",
      "7747 Traning Loss: tensor(46.8179)\n",
      "7748 Traning Loss: tensor(46.8085)\n",
      "7749 Traning Loss: tensor(46.7992)\n",
      "7750 Traning Loss: tensor(46.7898)\n",
      "7751 Traning Loss: tensor(46.7805)\n",
      "7752 Traning Loss: tensor(46.7711)\n",
      "7753 Traning Loss: tensor(46.7618)\n",
      "7754 Traning Loss: tensor(46.7524)\n",
      "7755 Traning Loss: tensor(46.7431)\n",
      "7756 Traning Loss: tensor(46.7337)\n",
      "7757 Traning Loss: tensor(46.7244)\n",
      "7758 Traning Loss: tensor(46.7150)\n",
      "7759 Traning Loss: tensor(46.7057)\n",
      "7760 Traning Loss: tensor(46.6963)\n",
      "7761 Traning Loss: tensor(46.6870)\n",
      "7762 Traning Loss: tensor(46.6776)\n",
      "7763 Traning Loss: tensor(46.6683)\n",
      "7764 Traning Loss: tensor(46.6589)\n",
      "7765 Traning Loss: tensor(46.6495)\n",
      "7766 Traning Loss: tensor(46.6402)\n",
      "7767 Traning Loss: tensor(46.6308)\n",
      "7768 Traning Loss: tensor(46.6215)\n",
      "7769 Traning Loss: tensor(46.6121)\n",
      "7770 Traning Loss: tensor(46.6028)\n",
      "7771 Traning Loss: tensor(46.5934)\n",
      "7772 Traning Loss: tensor(46.5840)\n",
      "7773 Traning Loss: tensor(46.5747)\n",
      "7774 Traning Loss: tensor(46.5653)\n",
      "7775 Traning Loss: tensor(46.5560)\n",
      "7776 Traning Loss: tensor(46.5466)\n",
      "7777 Traning Loss: tensor(46.5371)\n",
      "7778 Traning Loss: tensor(46.5277)\n",
      "7779 Traning Loss: tensor(46.5184)\n",
      "7780 Traning Loss: tensor(46.5090)\n",
      "7781 Traning Loss: tensor(46.4997)\n",
      "7782 Traning Loss: tensor(46.4903)\n",
      "7783 Traning Loss: tensor(46.4809)\n",
      "7784 Traning Loss: tensor(46.4716)\n",
      "7785 Traning Loss: tensor(46.4622)\n",
      "7786 Traning Loss: tensor(46.4529)\n",
      "7787 Traning Loss: tensor(46.4435)\n",
      "7788 Traning Loss: tensor(46.4341)\n",
      "7789 Traning Loss: tensor(46.4247)\n",
      "7790 Traning Loss: tensor(46.4154)\n",
      "7791 Traning Loss: tensor(46.4060)\n",
      "7792 Traning Loss: tensor(46.3967)\n",
      "7793 Traning Loss: tensor(46.3873)\n",
      "7794 Traning Loss: tensor(46.3779)\n",
      "7795 Traning Loss: tensor(46.3686)\n",
      "7796 Traning Loss: tensor(46.3592)\n",
      "7797 Traning Loss: tensor(46.3498)\n",
      "7798 Traning Loss: tensor(46.3405)\n",
      "7799 Traning Loss: tensor(46.3311)\n",
      "7800 Traning Loss: tensor(46.3217)\n",
      "7801 Traning Loss: tensor(46.3123)\n",
      "7802 Traning Loss: tensor(46.3030)\n",
      "7803 Traning Loss: tensor(46.2936)\n",
      "7804 Traning Loss: tensor(46.2842)\n",
      "7805 Traning Loss: tensor(46.2748)\n",
      "7806 Traning Loss: tensor(46.2655)\n",
      "7807 Traning Loss: tensor(46.2561)\n",
      "7808 Traning Loss: tensor(46.2467)\n",
      "7809 Traning Loss: tensor(46.2373)\n",
      "7810 Traning Loss: tensor(46.2280)\n",
      "7811 Traning Loss: tensor(46.2186)\n",
      "7812 Traning Loss: tensor(46.2091)\n",
      "7813 Traning Loss: tensor(46.1997)\n",
      "7814 Traning Loss: tensor(46.1903)\n",
      "7815 Traning Loss: tensor(46.1810)\n",
      "7816 Traning Loss: tensor(46.1716)\n",
      "7817 Traning Loss: tensor(46.1622)\n",
      "7818 Traning Loss: tensor(46.1529)\n",
      "7819 Traning Loss: tensor(46.1435)\n",
      "7820 Traning Loss: tensor(46.1341)\n",
      "7821 Traning Loss: tensor(46.1247)\n",
      "7822 Traning Loss: tensor(46.1153)\n",
      "7823 Traning Loss: tensor(46.1060)\n",
      "7824 Traning Loss: tensor(46.0966)\n",
      "7825 Traning Loss: tensor(46.0872)\n",
      "7826 Traning Loss: tensor(46.0778)\n",
      "7827 Traning Loss: tensor(46.0685)\n",
      "7828 Traning Loss: tensor(46.0591)\n",
      "7829 Traning Loss: tensor(46.0497)\n",
      "7830 Traning Loss: tensor(46.0403)\n",
      "7831 Traning Loss: tensor(46.0309)\n",
      "7832 Traning Loss: tensor(46.0215)\n",
      "7833 Traning Loss: tensor(46.0122)\n",
      "7834 Traning Loss: tensor(46.0028)\n",
      "7835 Traning Loss: tensor(45.9934)\n",
      "7836 Traning Loss: tensor(45.9840)\n",
      "7837 Traning Loss: tensor(45.9746)\n",
      "7838 Traning Loss: tensor(45.9652)\n",
      "7839 Traning Loss: tensor(45.9559)\n",
      "7840 Traning Loss: tensor(45.9465)\n",
      "7841 Traning Loss: tensor(45.9371)\n",
      "7842 Traning Loss: tensor(45.9277)\n",
      "7843 Traning Loss: tensor(45.9183)\n",
      "7844 Traning Loss: tensor(45.9089)\n",
      "7845 Traning Loss: tensor(45.8995)\n",
      "7846 Traning Loss: tensor(45.8901)\n",
      "7847 Traning Loss: tensor(45.8806)\n",
      "7848 Traning Loss: tensor(45.8712)\n",
      "7849 Traning Loss: tensor(45.8619)\n",
      "7850 Traning Loss: tensor(45.8525)\n",
      "7851 Traning Loss: tensor(45.8431)\n",
      "7852 Traning Loss: tensor(45.8337)\n",
      "7853 Traning Loss: tensor(45.8243)\n",
      "7854 Traning Loss: tensor(45.8149)\n",
      "7855 Traning Loss: tensor(45.8055)\n",
      "7856 Traning Loss: tensor(45.7962)\n",
      "7857 Traning Loss: tensor(45.7868)\n",
      "7858 Traning Loss: tensor(45.7774)\n",
      "7859 Traning Loss: tensor(45.7680)\n",
      "7860 Traning Loss: tensor(45.7586)\n",
      "7861 Traning Loss: tensor(45.7492)\n",
      "7862 Traning Loss: tensor(45.7398)\n",
      "7863 Traning Loss: tensor(45.7304)\n",
      "7864 Traning Loss: tensor(45.7210)\n",
      "7865 Traning Loss: tensor(45.7116)\n",
      "7866 Traning Loss: tensor(45.7022)\n",
      "7867 Traning Loss: tensor(45.6928)\n",
      "7868 Traning Loss: tensor(45.6835)\n",
      "7869 Traning Loss: tensor(45.6740)\n",
      "7870 Traning Loss: tensor(45.6647)\n",
      "7871 Traning Loss: tensor(45.6553)\n",
      "7872 Traning Loss: tensor(45.6459)\n",
      "7873 Traning Loss: tensor(45.6365)\n",
      "7874 Traning Loss: tensor(45.6271)\n",
      "7875 Traning Loss: tensor(45.6177)\n",
      "7876 Traning Loss: tensor(45.6083)\n",
      "7877 Traning Loss: tensor(45.5989)\n",
      "7878 Traning Loss: tensor(45.5895)\n",
      "7879 Traning Loss: tensor(45.5801)\n",
      "7880 Traning Loss: tensor(45.5707)\n",
      "7881 Traning Loss: tensor(45.5613)\n",
      "7882 Traning Loss: tensor(45.5518)\n",
      "7883 Traning Loss: tensor(45.5424)\n",
      "7884 Traning Loss: tensor(45.5330)\n",
      "7885 Traning Loss: tensor(45.5236)\n",
      "7886 Traning Loss: tensor(45.5142)\n",
      "7887 Traning Loss: tensor(45.5048)\n",
      "7888 Traning Loss: tensor(45.4954)\n",
      "7889 Traning Loss: tensor(45.4860)\n",
      "7890 Traning Loss: tensor(45.4766)\n",
      "7891 Traning Loss: tensor(45.4672)\n",
      "7892 Traning Loss: tensor(45.4578)\n",
      "7893 Traning Loss: tensor(45.4484)\n",
      "7894 Traning Loss: tensor(45.4390)\n",
      "7895 Traning Loss: tensor(45.4296)\n",
      "7896 Traning Loss: tensor(45.4202)\n",
      "7897 Traning Loss: tensor(45.4108)\n",
      "7898 Traning Loss: tensor(45.4014)\n",
      "7899 Traning Loss: tensor(45.3920)\n",
      "7900 Traning Loss: tensor(45.3826)\n",
      "7901 Traning Loss: tensor(45.3732)\n",
      "7902 Traning Loss: tensor(45.3638)\n",
      "7903 Traning Loss: tensor(45.3544)\n",
      "7904 Traning Loss: tensor(45.3450)\n",
      "7905 Traning Loss: tensor(45.3356)\n",
      "7906 Traning Loss: tensor(45.3261)\n",
      "7907 Traning Loss: tensor(45.3167)\n",
      "7908 Traning Loss: tensor(45.3073)\n",
      "7909 Traning Loss: tensor(45.2979)\n",
      "7910 Traning Loss: tensor(45.2885)\n",
      "7911 Traning Loss: tensor(45.2791)\n",
      "7912 Traning Loss: tensor(45.2697)\n",
      "7913 Traning Loss: tensor(45.2603)\n",
      "7914 Traning Loss: tensor(45.2509)\n",
      "7915 Traning Loss: tensor(45.2415)\n",
      "7916 Traning Loss: tensor(45.2321)\n",
      "7917 Traning Loss: tensor(45.2227)\n",
      "7918 Traning Loss: tensor(45.2131)\n",
      "7919 Traning Loss: tensor(45.2037)\n",
      "7920 Traning Loss: tensor(45.1943)\n",
      "7921 Traning Loss: tensor(45.1849)\n",
      "7922 Traning Loss: tensor(45.1755)\n",
      "7923 Traning Loss: tensor(45.1661)\n",
      "7924 Traning Loss: tensor(45.1567)\n",
      "7925 Traning Loss: tensor(45.1473)\n",
      "7926 Traning Loss: tensor(45.1379)\n",
      "7927 Traning Loss: tensor(45.1285)\n",
      "7928 Traning Loss: tensor(45.1190)\n",
      "7929 Traning Loss: tensor(45.1096)\n",
      "7930 Traning Loss: tensor(45.1002)\n",
      "7931 Traning Loss: tensor(45.0908)\n",
      "7932 Traning Loss: tensor(45.0814)\n",
      "7933 Traning Loss: tensor(45.0720)\n",
      "7934 Traning Loss: tensor(45.0626)\n",
      "7935 Traning Loss: tensor(45.0532)\n",
      "7936 Traning Loss: tensor(45.0438)\n",
      "7937 Traning Loss: tensor(45.0343)\n",
      "7938 Traning Loss: tensor(45.0249)\n",
      "7939 Traning Loss: tensor(45.0155)\n",
      "7940 Traning Loss: tensor(45.0061)\n",
      "7941 Traning Loss: tensor(44.9967)\n",
      "7942 Traning Loss: tensor(44.9873)\n",
      "7943 Traning Loss: tensor(44.9779)\n",
      "7944 Traning Loss: tensor(44.9685)\n",
      "7945 Traning Loss: tensor(44.9590)\n",
      "7946 Traning Loss: tensor(44.9496)\n",
      "7947 Traning Loss: tensor(44.9402)\n",
      "7948 Traning Loss: tensor(44.9308)\n",
      "7949 Traning Loss: tensor(44.9214)\n",
      "7950 Traning Loss: tensor(44.9119)\n",
      "7951 Traning Loss: tensor(44.9025)\n",
      "7952 Traning Loss: tensor(44.8931)\n",
      "7953 Traning Loss: tensor(44.8837)\n",
      "7954 Traning Loss: tensor(44.8741)\n",
      "7955 Traning Loss: tensor(44.8647)\n",
      "7956 Traning Loss: tensor(44.8553)\n",
      "7957 Traning Loss: tensor(44.8459)\n",
      "7958 Traning Loss: tensor(44.8365)\n",
      "7959 Traning Loss: tensor(44.8271)\n",
      "7960 Traning Loss: tensor(44.8176)\n",
      "7961 Traning Loss: tensor(44.8082)\n",
      "7962 Traning Loss: tensor(44.7988)\n",
      "7963 Traning Loss: tensor(44.7894)\n",
      "7964 Traning Loss: tensor(44.7800)\n",
      "7965 Traning Loss: tensor(44.7706)\n",
      "7966 Traning Loss: tensor(44.7612)\n",
      "7967 Traning Loss: tensor(44.7517)\n",
      "7968 Traning Loss: tensor(44.7423)\n",
      "7969 Traning Loss: tensor(44.7329)\n",
      "7970 Traning Loss: tensor(44.7235)\n",
      "7971 Traning Loss: tensor(44.7141)\n",
      "7972 Traning Loss: tensor(44.7046)\n",
      "7973 Traning Loss: tensor(44.6952)\n",
      "7974 Traning Loss: tensor(44.6858)\n",
      "7975 Traning Loss: tensor(44.6764)\n",
      "7976 Traning Loss: tensor(44.6670)\n",
      "7977 Traning Loss: tensor(44.6575)\n",
      "7978 Traning Loss: tensor(44.6481)\n",
      "7979 Traning Loss: tensor(44.6387)\n",
      "7980 Traning Loss: tensor(44.6293)\n",
      "7981 Traning Loss: tensor(44.6198)\n",
      "7982 Traning Loss: tensor(44.6104)\n",
      "7983 Traning Loss: tensor(44.6010)\n",
      "7984 Traning Loss: tensor(44.5916)\n",
      "7985 Traning Loss: tensor(44.5822)\n",
      "7986 Traning Loss: tensor(44.5727)\n",
      "7987 Traning Loss: tensor(44.5633)\n",
      "7988 Traning Loss: tensor(44.5539)\n",
      "7989 Traning Loss: tensor(44.5444)\n",
      "7990 Traning Loss: tensor(44.5349)\n",
      "7991 Traning Loss: tensor(44.5255)\n",
      "7992 Traning Loss: tensor(44.5160)\n",
      "7993 Traning Loss: tensor(44.5066)\n",
      "7994 Traning Loss: tensor(44.4972)\n",
      "7995 Traning Loss: tensor(44.4878)\n",
      "7996 Traning Loss: tensor(44.4783)\n",
      "7997 Traning Loss: tensor(44.4689)\n",
      "7998 Traning Loss: tensor(44.4595)\n",
      "7999 Traning Loss: tensor(44.4501)\n",
      "8000 Traning Loss: tensor(44.4407)\n",
      "8001 Traning Loss: tensor(44.4312)\n",
      "8002 Traning Loss: tensor(44.4218)\n",
      "8003 Traning Loss: tensor(44.4124)\n",
      "8004 Traning Loss: tensor(44.4030)\n",
      "8005 Traning Loss: tensor(44.3935)\n",
      "8006 Traning Loss: tensor(44.3841)\n",
      "8007 Traning Loss: tensor(44.3747)\n",
      "8008 Traning Loss: tensor(44.3653)\n",
      "8009 Traning Loss: tensor(44.3558)\n",
      "8010 Traning Loss: tensor(44.3464)\n",
      "8011 Traning Loss: tensor(44.3370)\n",
      "8012 Traning Loss: tensor(44.3276)\n",
      "8013 Traning Loss: tensor(44.3181)\n",
      "8014 Traning Loss: tensor(44.3087)\n",
      "8015 Traning Loss: tensor(44.2993)\n",
      "8016 Traning Loss: tensor(44.2898)\n",
      "8017 Traning Loss: tensor(44.2804)\n",
      "8018 Traning Loss: tensor(44.2710)\n",
      "8019 Traning Loss: tensor(44.2616)\n",
      "8020 Traning Loss: tensor(44.2521)\n",
      "8021 Traning Loss: tensor(44.2427)\n",
      "8022 Traning Loss: tensor(44.2333)\n",
      "8023 Traning Loss: tensor(44.2239)\n",
      "8024 Traning Loss: tensor(44.2144)\n",
      "8025 Traning Loss: tensor(44.2050)\n",
      "8026 Traning Loss: tensor(44.1956)\n",
      "8027 Traning Loss: tensor(44.1860)\n",
      "8028 Traning Loss: tensor(44.1765)\n",
      "8029 Traning Loss: tensor(44.1671)\n",
      "8030 Traning Loss: tensor(44.1577)\n",
      "8031 Traning Loss: tensor(44.1483)\n",
      "8032 Traning Loss: tensor(44.1388)\n",
      "8033 Traning Loss: tensor(44.1294)\n",
      "8034 Traning Loss: tensor(44.1200)\n",
      "8035 Traning Loss: tensor(44.1105)\n",
      "8036 Traning Loss: tensor(44.1011)\n",
      "8037 Traning Loss: tensor(44.0917)\n",
      "8038 Traning Loss: tensor(44.0823)\n",
      "8039 Traning Loss: tensor(44.0728)\n",
      "8040 Traning Loss: tensor(44.0634)\n",
      "8041 Traning Loss: tensor(44.0540)\n",
      "8042 Traning Loss: tensor(44.0446)\n",
      "8043 Traning Loss: tensor(44.0351)\n",
      "8044 Traning Loss: tensor(44.0257)\n",
      "8045 Traning Loss: tensor(44.0163)\n",
      "8046 Traning Loss: tensor(44.0068)\n",
      "8047 Traning Loss: tensor(43.9974)\n",
      "8048 Traning Loss: tensor(43.9880)\n",
      "8049 Traning Loss: tensor(43.9785)\n",
      "8050 Traning Loss: tensor(43.9691)\n",
      "8051 Traning Loss: tensor(43.9597)\n",
      "8052 Traning Loss: tensor(43.9502)\n",
      "8053 Traning Loss: tensor(43.9408)\n",
      "8054 Traning Loss: tensor(43.9314)\n",
      "8055 Traning Loss: tensor(43.9219)\n",
      "8056 Traning Loss: tensor(43.9125)\n",
      "8057 Traning Loss: tensor(43.9031)\n",
      "8058 Traning Loss: tensor(43.8936)\n",
      "8059 Traning Loss: tensor(43.8842)\n",
      "8060 Traning Loss: tensor(43.8748)\n",
      "8061 Traning Loss: tensor(43.8653)\n",
      "8062 Traning Loss: tensor(43.8559)\n",
      "8063 Traning Loss: tensor(43.8465)\n",
      "8064 Traning Loss: tensor(43.8369)\n",
      "8065 Traning Loss: tensor(43.8274)\n",
      "8066 Traning Loss: tensor(43.8180)\n",
      "8067 Traning Loss: tensor(43.8086)\n",
      "8068 Traning Loss: tensor(43.7992)\n",
      "8069 Traning Loss: tensor(43.7897)\n",
      "8070 Traning Loss: tensor(43.7803)\n",
      "8071 Traning Loss: tensor(43.7709)\n",
      "8072 Traning Loss: tensor(43.7614)\n",
      "8073 Traning Loss: tensor(43.7520)\n",
      "8074 Traning Loss: tensor(43.7426)\n",
      "8075 Traning Loss: tensor(43.7331)\n",
      "8076 Traning Loss: tensor(43.7237)\n",
      "8077 Traning Loss: tensor(43.7143)\n",
      "8078 Traning Loss: tensor(43.7048)\n",
      "8079 Traning Loss: tensor(43.6954)\n",
      "8080 Traning Loss: tensor(43.6860)\n",
      "8081 Traning Loss: tensor(43.6765)\n",
      "8082 Traning Loss: tensor(43.6671)\n",
      "8083 Traning Loss: tensor(43.6577)\n",
      "8084 Traning Loss: tensor(43.6482)\n",
      "8085 Traning Loss: tensor(43.6388)\n",
      "8086 Traning Loss: tensor(43.6294)\n",
      "8087 Traning Loss: tensor(43.6199)\n",
      "8088 Traning Loss: tensor(43.6105)\n",
      "8089 Traning Loss: tensor(43.6010)\n",
      "8090 Traning Loss: tensor(43.5916)\n",
      "8091 Traning Loss: tensor(43.5822)\n",
      "8092 Traning Loss: tensor(43.5727)\n",
      "8093 Traning Loss: tensor(43.5633)\n",
      "8094 Traning Loss: tensor(43.5539)\n",
      "8095 Traning Loss: tensor(43.5444)\n",
      "8096 Traning Loss: tensor(43.5350)\n",
      "8097 Traning Loss: tensor(43.5256)\n",
      "8098 Traning Loss: tensor(43.5161)\n",
      "8099 Traning Loss: tensor(43.5067)\n",
      "8100 Traning Loss: tensor(43.4972)\n",
      "8101 Traning Loss: tensor(43.4878)\n",
      "8102 Traning Loss: tensor(43.4782)\n",
      "8103 Traning Loss: tensor(43.4688)\n",
      "8104 Traning Loss: tensor(43.4593)\n",
      "8105 Traning Loss: tensor(43.4499)\n",
      "8106 Traning Loss: tensor(43.4405)\n",
      "8107 Traning Loss: tensor(43.4310)\n",
      "8108 Traning Loss: tensor(43.4216)\n",
      "8109 Traning Loss: tensor(43.4122)\n",
      "8110 Traning Loss: tensor(43.4027)\n",
      "8111 Traning Loss: tensor(43.3933)\n",
      "8112 Traning Loss: tensor(43.3839)\n",
      "8113 Traning Loss: tensor(43.3744)\n",
      "8114 Traning Loss: tensor(43.3650)\n",
      "8115 Traning Loss: tensor(43.3556)\n",
      "8116 Traning Loss: tensor(43.3461)\n",
      "8117 Traning Loss: tensor(43.3367)\n",
      "8118 Traning Loss: tensor(43.3273)\n",
      "8119 Traning Loss: tensor(43.3178)\n",
      "8120 Traning Loss: tensor(43.3084)\n",
      "8121 Traning Loss: tensor(43.2989)\n",
      "8122 Traning Loss: tensor(43.2895)\n",
      "8123 Traning Loss: tensor(43.2801)\n",
      "8124 Traning Loss: tensor(43.2706)\n",
      "8125 Traning Loss: tensor(43.2612)\n",
      "8126 Traning Loss: tensor(43.2518)\n",
      "8127 Traning Loss: tensor(43.2423)\n",
      "8128 Traning Loss: tensor(43.2329)\n",
      "8129 Traning Loss: tensor(43.2234)\n",
      "8130 Traning Loss: tensor(43.2140)\n",
      "8131 Traning Loss: tensor(43.2046)\n",
      "8132 Traning Loss: tensor(43.1951)\n",
      "8133 Traning Loss: tensor(43.1857)\n",
      "8134 Traning Loss: tensor(43.1762)\n",
      "8135 Traning Loss: tensor(43.1668)\n",
      "8136 Traning Loss: tensor(43.1574)\n",
      "8137 Traning Loss: tensor(43.1479)\n",
      "8138 Traning Loss: tensor(43.1385)\n",
      "8139 Traning Loss: tensor(43.1290)\n",
      "8140 Traning Loss: tensor(43.1195)\n",
      "8141 Traning Loss: tensor(43.1100)\n",
      "8142 Traning Loss: tensor(43.1006)\n",
      "8143 Traning Loss: tensor(43.0912)\n",
      "8144 Traning Loss: tensor(43.0817)\n",
      "8145 Traning Loss: tensor(43.0723)\n",
      "8146 Traning Loss: tensor(43.0629)\n",
      "8147 Traning Loss: tensor(43.0534)\n",
      "8148 Traning Loss: tensor(43.0440)\n",
      "8149 Traning Loss: tensor(43.0345)\n",
      "8150 Traning Loss: tensor(43.0251)\n",
      "8151 Traning Loss: tensor(43.0157)\n",
      "8152 Traning Loss: tensor(43.0062)\n",
      "8153 Traning Loss: tensor(42.9968)\n",
      "8154 Traning Loss: tensor(42.9874)\n",
      "8155 Traning Loss: tensor(42.9779)\n",
      "8156 Traning Loss: tensor(42.9685)\n",
      "8157 Traning Loss: tensor(42.9591)\n",
      "8158 Traning Loss: tensor(42.9496)\n",
      "8159 Traning Loss: tensor(42.9402)\n",
      "8160 Traning Loss: tensor(42.9307)\n",
      "8161 Traning Loss: tensor(42.9213)\n",
      "8162 Traning Loss: tensor(42.9119)\n",
      "8163 Traning Loss: tensor(42.9024)\n",
      "8164 Traning Loss: tensor(42.8930)\n",
      "8165 Traning Loss: tensor(42.8836)\n",
      "8166 Traning Loss: tensor(42.8741)\n",
      "8167 Traning Loss: tensor(42.8647)\n",
      "8168 Traning Loss: tensor(42.8552)\n",
      "8169 Traning Loss: tensor(42.8458)\n",
      "8170 Traning Loss: tensor(42.8364)\n",
      "8171 Traning Loss: tensor(42.8269)\n",
      "8172 Traning Loss: tensor(42.8175)\n",
      "8173 Traning Loss: tensor(42.8080)\n",
      "8174 Traning Loss: tensor(42.7986)\n",
      "8175 Traning Loss: tensor(42.7892)\n",
      "8176 Traning Loss: tensor(42.7797)\n",
      "8177 Traning Loss: tensor(42.7703)\n",
      "8178 Traning Loss: tensor(42.7607)\n",
      "8179 Traning Loss: tensor(42.7512)\n",
      "8180 Traning Loss: tensor(42.7418)\n",
      "8181 Traning Loss: tensor(42.7324)\n",
      "8182 Traning Loss: tensor(42.7229)\n",
      "8183 Traning Loss: tensor(42.7135)\n",
      "8184 Traning Loss: tensor(42.7041)\n",
      "8185 Traning Loss: tensor(42.6946)\n",
      "8186 Traning Loss: tensor(42.6852)\n",
      "8187 Traning Loss: tensor(42.6758)\n",
      "8188 Traning Loss: tensor(42.6663)\n",
      "8189 Traning Loss: tensor(42.6569)\n",
      "8190 Traning Loss: tensor(42.6475)\n",
      "8191 Traning Loss: tensor(42.6380)\n",
      "8192 Traning Loss: tensor(42.6286)\n",
      "8193 Traning Loss: tensor(42.6192)\n",
      "8194 Traning Loss: tensor(42.6097)\n",
      "8195 Traning Loss: tensor(42.6003)\n",
      "8196 Traning Loss: tensor(42.5908)\n",
      "8197 Traning Loss: tensor(42.5814)\n",
      "8198 Traning Loss: tensor(42.5720)\n",
      "8199 Traning Loss: tensor(42.5625)\n",
      "8200 Traning Loss: tensor(42.5531)\n",
      "8201 Traning Loss: tensor(42.5437)\n",
      "8202 Traning Loss: tensor(42.5342)\n",
      "8203 Traning Loss: tensor(42.5248)\n",
      "8204 Traning Loss: tensor(42.5154)\n",
      "8205 Traning Loss: tensor(42.5059)\n",
      "8206 Traning Loss: tensor(42.4965)\n",
      "8207 Traning Loss: tensor(42.4870)\n",
      "8208 Traning Loss: tensor(42.4776)\n",
      "8209 Traning Loss: tensor(42.4682)\n",
      "8210 Traning Loss: tensor(42.4587)\n",
      "8211 Traning Loss: tensor(42.4493)\n",
      "8212 Traning Loss: tensor(42.4399)\n",
      "8213 Traning Loss: tensor(42.4304)\n",
      "8214 Traning Loss: tensor(42.4210)\n",
      "8215 Traning Loss: tensor(42.4115)\n",
      "8216 Traning Loss: tensor(42.4021)\n",
      "8217 Traning Loss: tensor(42.3925)\n",
      "8218 Traning Loss: tensor(42.3831)\n",
      "8219 Traning Loss: tensor(42.3736)\n",
      "8220 Traning Loss: tensor(42.3642)\n",
      "8221 Traning Loss: tensor(42.3548)\n",
      "8222 Traning Loss: tensor(42.3453)\n",
      "8223 Traning Loss: tensor(42.3359)\n",
      "8224 Traning Loss: tensor(42.3265)\n",
      "8225 Traning Loss: tensor(42.3170)\n",
      "8226 Traning Loss: tensor(42.3076)\n",
      "8227 Traning Loss: tensor(42.2982)\n",
      "8228 Traning Loss: tensor(42.2887)\n",
      "8229 Traning Loss: tensor(42.2793)\n",
      "8230 Traning Loss: tensor(42.2699)\n",
      "8231 Traning Loss: tensor(42.2604)\n",
      "8232 Traning Loss: tensor(42.2510)\n",
      "8233 Traning Loss: tensor(42.2416)\n",
      "8234 Traning Loss: tensor(42.2321)\n",
      "8235 Traning Loss: tensor(42.2227)\n",
      "8236 Traning Loss: tensor(42.2133)\n",
      "8237 Traning Loss: tensor(42.2038)\n",
      "8238 Traning Loss: tensor(42.1944)\n",
      "8239 Traning Loss: tensor(42.1850)\n",
      "8240 Traning Loss: tensor(42.1755)\n",
      "8241 Traning Loss: tensor(42.1661)\n",
      "8242 Traning Loss: tensor(42.1567)\n",
      "8243 Traning Loss: tensor(42.1472)\n",
      "8244 Traning Loss: tensor(42.1378)\n",
      "8245 Traning Loss: tensor(42.1284)\n",
      "8246 Traning Loss: tensor(42.1189)\n",
      "8247 Traning Loss: tensor(42.1095)\n",
      "8248 Traning Loss: tensor(42.1001)\n",
      "8249 Traning Loss: tensor(42.0906)\n",
      "8250 Traning Loss: tensor(42.0812)\n",
      "8251 Traning Loss: tensor(42.0718)\n",
      "8252 Traning Loss: tensor(42.0623)\n",
      "8253 Traning Loss: tensor(42.0529)\n",
      "8254 Traning Loss: tensor(42.0434)\n",
      "8255 Traning Loss: tensor(42.0340)\n",
      "8256 Traning Loss: tensor(42.0246)\n",
      "8257 Traning Loss: tensor(42.0150)\n",
      "8258 Traning Loss: tensor(42.0055)\n",
      "8259 Traning Loss: tensor(41.9961)\n",
      "8260 Traning Loss: tensor(41.9867)\n",
      "8261 Traning Loss: tensor(41.9773)\n",
      "8262 Traning Loss: tensor(41.9678)\n",
      "8263 Traning Loss: tensor(41.9584)\n",
      "8264 Traning Loss: tensor(41.9490)\n",
      "8265 Traning Loss: tensor(41.9395)\n",
      "8266 Traning Loss: tensor(41.9301)\n",
      "8267 Traning Loss: tensor(41.9207)\n",
      "8268 Traning Loss: tensor(41.9113)\n",
      "8269 Traning Loss: tensor(41.9018)\n",
      "8270 Traning Loss: tensor(41.8924)\n",
      "8271 Traning Loss: tensor(41.8830)\n",
      "8272 Traning Loss: tensor(41.8736)\n",
      "8273 Traning Loss: tensor(41.8641)\n",
      "8274 Traning Loss: tensor(41.8547)\n",
      "8275 Traning Loss: tensor(41.8453)\n",
      "8276 Traning Loss: tensor(41.8358)\n",
      "8277 Traning Loss: tensor(41.8264)\n",
      "8278 Traning Loss: tensor(41.8170)\n",
      "8279 Traning Loss: tensor(41.8075)\n",
      "8280 Traning Loss: tensor(41.7981)\n",
      "8281 Traning Loss: tensor(41.7887)\n",
      "8282 Traning Loss: tensor(41.7793)\n",
      "8283 Traning Loss: tensor(41.7698)\n",
      "8284 Traning Loss: tensor(41.7604)\n",
      "8285 Traning Loss: tensor(41.7510)\n",
      "8286 Traning Loss: tensor(41.7415)\n",
      "8287 Traning Loss: tensor(41.7321)\n",
      "8288 Traning Loss: tensor(41.7227)\n",
      "8289 Traning Loss: tensor(41.7132)\n",
      "8290 Traning Loss: tensor(41.7038)\n",
      "8291 Traning Loss: tensor(41.6944)\n",
      "8292 Traning Loss: tensor(41.6849)\n",
      "8293 Traning Loss: tensor(41.6755)\n",
      "8294 Traning Loss: tensor(41.6661)\n",
      "8295 Traning Loss: tensor(41.6567)\n",
      "8296 Traning Loss: tensor(41.6470)\n",
      "8297 Traning Loss: tensor(41.6376)\n",
      "8298 Traning Loss: tensor(41.6282)\n",
      "8299 Traning Loss: tensor(41.6188)\n",
      "8300 Traning Loss: tensor(41.6094)\n",
      "8301 Traning Loss: tensor(41.5999)\n",
      "8302 Traning Loss: tensor(41.5905)\n",
      "8303 Traning Loss: tensor(41.5811)\n",
      "8304 Traning Loss: tensor(41.5716)\n",
      "8305 Traning Loss: tensor(41.5622)\n",
      "8306 Traning Loss: tensor(41.5528)\n",
      "8307 Traning Loss: tensor(41.5434)\n",
      "8308 Traning Loss: tensor(41.5340)\n",
      "8309 Traning Loss: tensor(41.5245)\n",
      "8310 Traning Loss: tensor(41.5151)\n",
      "8311 Traning Loss: tensor(41.5057)\n",
      "8312 Traning Loss: tensor(41.4963)\n",
      "8313 Traning Loss: tensor(41.4868)\n",
      "8314 Traning Loss: tensor(41.4774)\n",
      "8315 Traning Loss: tensor(41.4680)\n",
      "8316 Traning Loss: tensor(41.4586)\n",
      "8317 Traning Loss: tensor(41.4491)\n",
      "8318 Traning Loss: tensor(41.4397)\n",
      "8319 Traning Loss: tensor(41.4303)\n",
      "8320 Traning Loss: tensor(41.4209)\n",
      "8321 Traning Loss: tensor(41.4114)\n",
      "8322 Traning Loss: tensor(41.4020)\n",
      "8323 Traning Loss: tensor(41.3926)\n",
      "8324 Traning Loss: tensor(41.3832)\n",
      "8325 Traning Loss: tensor(41.3738)\n",
      "8326 Traning Loss: tensor(41.3643)\n",
      "8327 Traning Loss: tensor(41.3549)\n",
      "8328 Traning Loss: tensor(41.3455)\n",
      "8329 Traning Loss: tensor(41.3361)\n",
      "8330 Traning Loss: tensor(41.3266)\n",
      "8331 Traning Loss: tensor(41.3172)\n",
      "8332 Traning Loss: tensor(41.3078)\n",
      "8333 Traning Loss: tensor(41.2984)\n",
      "8334 Traning Loss: tensor(41.2889)\n",
      "8335 Traning Loss: tensor(41.2795)\n",
      "8336 Traning Loss: tensor(41.2701)\n",
      "8337 Traning Loss: tensor(41.2605)\n",
      "8338 Traning Loss: tensor(41.2511)\n",
      "8339 Traning Loss: tensor(41.2416)\n",
      "8340 Traning Loss: tensor(41.2322)\n",
      "8341 Traning Loss: tensor(41.2228)\n",
      "8342 Traning Loss: tensor(41.2134)\n",
      "8343 Traning Loss: tensor(41.2040)\n",
      "8344 Traning Loss: tensor(41.1946)\n",
      "8345 Traning Loss: tensor(41.1851)\n",
      "8346 Traning Loss: tensor(41.1757)\n",
      "8347 Traning Loss: tensor(41.1663)\n",
      "8348 Traning Loss: tensor(41.1569)\n",
      "8349 Traning Loss: tensor(41.1475)\n",
      "8350 Traning Loss: tensor(41.1381)\n",
      "8351 Traning Loss: tensor(41.1286)\n",
      "8352 Traning Loss: tensor(41.1192)\n",
      "8353 Traning Loss: tensor(41.1098)\n",
      "8354 Traning Loss: tensor(41.1004)\n",
      "8355 Traning Loss: tensor(41.0910)\n",
      "8356 Traning Loss: tensor(41.0816)\n",
      "8357 Traning Loss: tensor(41.0721)\n",
      "8358 Traning Loss: tensor(41.0627)\n",
      "8359 Traning Loss: tensor(41.0533)\n",
      "8360 Traning Loss: tensor(41.0439)\n",
      "8361 Traning Loss: tensor(41.0345)\n",
      "8362 Traning Loss: tensor(41.0251)\n",
      "8363 Traning Loss: tensor(41.0157)\n",
      "8364 Traning Loss: tensor(41.0062)\n",
      "8365 Traning Loss: tensor(40.9968)\n",
      "8366 Traning Loss: tensor(40.9874)\n",
      "8367 Traning Loss: tensor(40.9780)\n",
      "8368 Traning Loss: tensor(40.9686)\n",
      "8369 Traning Loss: tensor(40.9592)\n",
      "8370 Traning Loss: tensor(40.9497)\n",
      "8371 Traning Loss: tensor(40.9403)\n",
      "8372 Traning Loss: tensor(40.9309)\n",
      "8373 Traning Loss: tensor(40.9215)\n",
      "8374 Traning Loss: tensor(40.9121)\n",
      "8375 Traning Loss: tensor(40.9027)\n",
      "8376 Traning Loss: tensor(40.8932)\n",
      "8377 Traning Loss: tensor(40.8838)\n",
      "8378 Traning Loss: tensor(40.8742)\n",
      "8379 Traning Loss: tensor(40.8648)\n",
      "8380 Traning Loss: tensor(40.8554)\n",
      "8381 Traning Loss: tensor(40.8460)\n",
      "8382 Traning Loss: tensor(40.8366)\n",
      "8383 Traning Loss: tensor(40.8272)\n",
      "8384 Traning Loss: tensor(40.8178)\n",
      "8385 Traning Loss: tensor(40.8084)\n",
      "8386 Traning Loss: tensor(40.7990)\n",
      "8387 Traning Loss: tensor(40.7895)\n",
      "8388 Traning Loss: tensor(40.7802)\n",
      "8389 Traning Loss: tensor(40.7707)\n",
      "8390 Traning Loss: tensor(40.7613)\n",
      "8391 Traning Loss: tensor(40.7519)\n",
      "8392 Traning Loss: tensor(40.7425)\n",
      "8393 Traning Loss: tensor(40.7331)\n",
      "8394 Traning Loss: tensor(40.7237)\n",
      "8395 Traning Loss: tensor(40.7143)\n",
      "8396 Traning Loss: tensor(40.7049)\n",
      "8397 Traning Loss: tensor(40.6955)\n",
      "8398 Traning Loss: tensor(40.6861)\n",
      "8399 Traning Loss: tensor(40.6766)\n",
      "8400 Traning Loss: tensor(40.6672)\n",
      "8401 Traning Loss: tensor(40.6578)\n",
      "8402 Traning Loss: tensor(40.6484)\n",
      "8403 Traning Loss: tensor(40.6390)\n",
      "8404 Traning Loss: tensor(40.6296)\n",
      "8405 Traning Loss: tensor(40.6202)\n",
      "8406 Traning Loss: tensor(40.6108)\n",
      "8407 Traning Loss: tensor(40.6014)\n",
      "8408 Traning Loss: tensor(40.5920)\n",
      "8409 Traning Loss: tensor(40.5826)\n",
      "8410 Traning Loss: tensor(40.5732)\n",
      "8411 Traning Loss: tensor(40.5638)\n",
      "8412 Traning Loss: tensor(40.5544)\n",
      "8413 Traning Loss: tensor(40.5450)\n",
      "8414 Traning Loss: tensor(40.5355)\n",
      "8415 Traning Loss: tensor(40.5261)\n",
      "8416 Traning Loss: tensor(40.5167)\n",
      "8417 Traning Loss: tensor(40.5073)\n",
      "8418 Traning Loss: tensor(40.4979)\n",
      "8419 Traning Loss: tensor(40.4883)\n",
      "8420 Traning Loss: tensor(40.4789)\n",
      "8421 Traning Loss: tensor(40.4695)\n",
      "8422 Traning Loss: tensor(40.4601)\n",
      "8423 Traning Loss: tensor(40.4507)\n",
      "8424 Traning Loss: tensor(40.4413)\n",
      "8425 Traning Loss: tensor(40.4319)\n",
      "8426 Traning Loss: tensor(40.4225)\n",
      "8427 Traning Loss: tensor(40.4131)\n",
      "8428 Traning Loss: tensor(40.4037)\n",
      "8429 Traning Loss: tensor(40.3943)\n",
      "8430 Traning Loss: tensor(40.3849)\n",
      "8431 Traning Loss: tensor(40.3755)\n",
      "8432 Traning Loss: tensor(40.3661)\n",
      "8433 Traning Loss: tensor(40.3567)\n",
      "8434 Traning Loss: tensor(40.3473)\n",
      "8435 Traning Loss: tensor(40.3379)\n",
      "8436 Traning Loss: tensor(40.3286)\n",
      "8437 Traning Loss: tensor(40.3192)\n",
      "8438 Traning Loss: tensor(40.3098)\n",
      "8439 Traning Loss: tensor(40.3004)\n",
      "8440 Traning Loss: tensor(40.2910)\n",
      "8441 Traning Loss: tensor(40.2816)\n",
      "8442 Traning Loss: tensor(40.2722)\n",
      "8443 Traning Loss: tensor(40.2628)\n",
      "8444 Traning Loss: tensor(40.2534)\n",
      "8445 Traning Loss: tensor(40.2440)\n",
      "8446 Traning Loss: tensor(40.2346)\n",
      "8447 Traning Loss: tensor(40.2252)\n",
      "8448 Traning Loss: tensor(40.2158)\n",
      "8449 Traning Loss: tensor(40.2064)\n",
      "8450 Traning Loss: tensor(40.1970)\n",
      "8451 Traning Loss: tensor(40.1876)\n",
      "8452 Traning Loss: tensor(40.1782)\n",
      "8453 Traning Loss: tensor(40.1688)\n",
      "8454 Traning Loss: tensor(40.1594)\n",
      "8455 Traning Loss: tensor(40.1500)\n",
      "8456 Traning Loss: tensor(40.1406)\n",
      "8457 Traning Loss: tensor(40.1312)\n",
      "8458 Traning Loss: tensor(40.1218)\n",
      "8459 Traning Loss: tensor(40.1124)\n",
      "8460 Traning Loss: tensor(40.1031)\n",
      "8461 Traning Loss: tensor(40.0935)\n",
      "8462 Traning Loss: tensor(40.0841)\n",
      "8463 Traning Loss: tensor(40.0747)\n",
      "8464 Traning Loss: tensor(40.0653)\n",
      "8465 Traning Loss: tensor(40.0559)\n",
      "8466 Traning Loss: tensor(40.0465)\n",
      "8467 Traning Loss: tensor(40.0371)\n",
      "8468 Traning Loss: tensor(40.0277)\n",
      "8469 Traning Loss: tensor(40.0184)\n",
      "8470 Traning Loss: tensor(40.0090)\n",
      "8471 Traning Loss: tensor(39.9996)\n",
      "8472 Traning Loss: tensor(39.9902)\n",
      "8473 Traning Loss: tensor(39.9808)\n",
      "8474 Traning Loss: tensor(39.9714)\n",
      "8475 Traning Loss: tensor(39.9621)\n",
      "8476 Traning Loss: tensor(39.9527)\n",
      "8477 Traning Loss: tensor(39.9433)\n",
      "8478 Traning Loss: tensor(39.9339)\n",
      "8479 Traning Loss: tensor(39.9245)\n",
      "8480 Traning Loss: tensor(39.9151)\n",
      "8481 Traning Loss: tensor(39.9057)\n",
      "8482 Traning Loss: tensor(39.8957)\n",
      "8483 Traning Loss: tensor(39.8863)\n",
      "8484 Traning Loss: tensor(39.8769)\n",
      "8485 Traning Loss: tensor(39.8675)\n",
      "8486 Traning Loss: tensor(39.8581)\n",
      "8487 Traning Loss: tensor(39.8488)\n",
      "8488 Traning Loss: tensor(39.8394)\n",
      "8489 Traning Loss: tensor(39.8300)\n",
      "8490 Traning Loss: tensor(39.8206)\n",
      "8491 Traning Loss: tensor(39.8112)\n",
      "8492 Traning Loss: tensor(39.8018)\n",
      "8493 Traning Loss: tensor(39.7924)\n",
      "8494 Traning Loss: tensor(39.7831)\n",
      "8495 Traning Loss: tensor(39.7737)\n",
      "8496 Traning Loss: tensor(39.7643)\n",
      "8497 Traning Loss: tensor(39.7549)\n",
      "8498 Traning Loss: tensor(39.7455)\n",
      "8499 Traning Loss: tensor(39.7361)\n",
      "8500 Traning Loss: tensor(39.7268)\n",
      "8501 Traning Loss: tensor(39.7174)\n",
      "8502 Traning Loss: tensor(39.7080)\n",
      "8503 Traning Loss: tensor(39.6984)\n",
      "8504 Traning Loss: tensor(39.6890)\n",
      "8505 Traning Loss: tensor(39.6796)\n",
      "8506 Traning Loss: tensor(39.6703)\n",
      "8507 Traning Loss: tensor(39.6609)\n",
      "8508 Traning Loss: tensor(39.6515)\n",
      "8509 Traning Loss: tensor(39.6421)\n",
      "8510 Traning Loss: tensor(39.6328)\n",
      "8511 Traning Loss: tensor(39.6234)\n",
      "8512 Traning Loss: tensor(39.6140)\n",
      "8513 Traning Loss: tensor(39.6046)\n",
      "8514 Traning Loss: tensor(39.5953)\n",
      "8515 Traning Loss: tensor(39.5859)\n",
      "8516 Traning Loss: tensor(39.5765)\n",
      "8517 Traning Loss: tensor(39.5671)\n",
      "8518 Traning Loss: tensor(39.5578)\n",
      "8519 Traning Loss: tensor(39.5484)\n",
      "8520 Traning Loss: tensor(39.5390)\n",
      "8521 Traning Loss: tensor(39.5296)\n",
      "8522 Traning Loss: tensor(39.5203)\n",
      "8523 Traning Loss: tensor(39.5109)\n",
      "8524 Traning Loss: tensor(39.5015)\n",
      "8525 Traning Loss: tensor(39.4921)\n",
      "8526 Traning Loss: tensor(39.4828)\n",
      "8527 Traning Loss: tensor(39.4734)\n",
      "8528 Traning Loss: tensor(39.4640)\n",
      "8529 Traning Loss: tensor(39.4547)\n",
      "8530 Traning Loss: tensor(39.4453)\n",
      "8531 Traning Loss: tensor(39.4359)\n",
      "8532 Traning Loss: tensor(39.4265)\n",
      "8533 Traning Loss: tensor(39.4172)\n",
      "8534 Traning Loss: tensor(39.4078)\n",
      "8535 Traning Loss: tensor(39.3984)\n",
      "8536 Traning Loss: tensor(39.3891)\n",
      "8537 Traning Loss: tensor(39.3797)\n",
      "8538 Traning Loss: tensor(39.3703)\n",
      "8539 Traning Loss: tensor(39.3609)\n",
      "8540 Traning Loss: tensor(39.3516)\n",
      "8541 Traning Loss: tensor(39.3422)\n",
      "8542 Traning Loss: tensor(39.3328)\n",
      "8543 Traning Loss: tensor(39.3235)\n",
      "8544 Traning Loss: tensor(39.3141)\n",
      "8545 Traning Loss: tensor(39.3047)\n",
      "8546 Traning Loss: tensor(39.2953)\n",
      "8547 Traning Loss: tensor(39.2858)\n",
      "8548 Traning Loss: tensor(39.2764)\n",
      "8549 Traning Loss: tensor(39.2671)\n",
      "8550 Traning Loss: tensor(39.2577)\n",
      "8551 Traning Loss: tensor(39.2483)\n",
      "8552 Traning Loss: tensor(39.2390)\n",
      "8553 Traning Loss: tensor(39.2296)\n",
      "8554 Traning Loss: tensor(39.2202)\n",
      "8555 Traning Loss: tensor(39.2109)\n",
      "8556 Traning Loss: tensor(39.2015)\n",
      "8557 Traning Loss: tensor(39.1922)\n",
      "8558 Traning Loss: tensor(39.1828)\n",
      "8559 Traning Loss: tensor(39.1735)\n",
      "8560 Traning Loss: tensor(39.1641)\n",
      "8561 Traning Loss: tensor(39.1547)\n",
      "8562 Traning Loss: tensor(39.1454)\n",
      "8563 Traning Loss: tensor(39.1360)\n",
      "8564 Traning Loss: tensor(39.1267)\n",
      "8565 Traning Loss: tensor(39.1173)\n",
      "8566 Traning Loss: tensor(39.1080)\n",
      "8567 Traning Loss: tensor(39.0986)\n",
      "8568 Traning Loss: tensor(39.0892)\n",
      "8569 Traning Loss: tensor(39.0799)\n",
      "8570 Traning Loss: tensor(39.0705)\n",
      "8571 Traning Loss: tensor(39.0612)\n",
      "8572 Traning Loss: tensor(39.0518)\n",
      "8573 Traning Loss: tensor(39.0425)\n",
      "8574 Traning Loss: tensor(39.0331)\n",
      "8575 Traning Loss: tensor(39.0237)\n",
      "8576 Traning Loss: tensor(39.0144)\n",
      "8577 Traning Loss: tensor(39.0050)\n",
      "8578 Traning Loss: tensor(38.9957)\n",
      "8579 Traning Loss: tensor(38.9863)\n",
      "8580 Traning Loss: tensor(38.9770)\n",
      "8581 Traning Loss: tensor(38.9676)\n",
      "8582 Traning Loss: tensor(38.9583)\n",
      "8583 Traning Loss: tensor(38.9489)\n",
      "8584 Traning Loss: tensor(38.9395)\n",
      "8585 Traning Loss: tensor(38.9302)\n",
      "8586 Traning Loss: tensor(38.9208)\n",
      "8587 Traning Loss: tensor(38.9115)\n",
      "8588 Traning Loss: tensor(38.9021)\n",
      "8589 Traning Loss: tensor(38.8928)\n",
      "8590 Traning Loss: tensor(38.8832)\n",
      "8591 Traning Loss: tensor(38.8739)\n",
      "8592 Traning Loss: tensor(38.8645)\n",
      "8593 Traning Loss: tensor(38.8552)\n",
      "8594 Traning Loss: tensor(38.8458)\n",
      "8595 Traning Loss: tensor(38.8365)\n",
      "8596 Traning Loss: tensor(38.8271)\n",
      "8597 Traning Loss: tensor(38.8178)\n",
      "8598 Traning Loss: tensor(38.8085)\n",
      "8599 Traning Loss: tensor(38.7991)\n",
      "8600 Traning Loss: tensor(38.7898)\n",
      "8601 Traning Loss: tensor(38.7804)\n",
      "8602 Traning Loss: tensor(38.7711)\n",
      "8603 Traning Loss: tensor(38.7617)\n",
      "8604 Traning Loss: tensor(38.7524)\n",
      "8605 Traning Loss: tensor(38.7431)\n",
      "8606 Traning Loss: tensor(38.7337)\n",
      "8607 Traning Loss: tensor(38.7244)\n",
      "8608 Traning Loss: tensor(38.7151)\n",
      "8609 Traning Loss: tensor(38.7057)\n",
      "8610 Traning Loss: tensor(38.6964)\n",
      "8611 Traning Loss: tensor(38.6870)\n",
      "8612 Traning Loss: tensor(38.6777)\n",
      "8613 Traning Loss: tensor(38.6684)\n",
      "8614 Traning Loss: tensor(38.6590)\n",
      "8615 Traning Loss: tensor(38.6497)\n",
      "8616 Traning Loss: tensor(38.6403)\n",
      "8617 Traning Loss: tensor(38.6310)\n",
      "8618 Traning Loss: tensor(38.6217)\n",
      "8619 Traning Loss: tensor(38.6123)\n",
      "8620 Traning Loss: tensor(38.6030)\n",
      "8621 Traning Loss: tensor(38.5936)\n",
      "8622 Traning Loss: tensor(38.5843)\n",
      "8623 Traning Loss: tensor(38.5750)\n",
      "8624 Traning Loss: tensor(38.5656)\n",
      "8625 Traning Loss: tensor(38.5563)\n",
      "8626 Traning Loss: tensor(38.5470)\n",
      "8627 Traning Loss: tensor(38.5376)\n",
      "8628 Traning Loss: tensor(38.5283)\n",
      "8629 Traning Loss: tensor(38.5190)\n",
      "8630 Traning Loss: tensor(38.5096)\n",
      "8631 Traning Loss: tensor(38.5003)\n",
      "8632 Traning Loss: tensor(38.4909)\n",
      "8633 Traning Loss: tensor(38.4816)\n",
      "8634 Traning Loss: tensor(38.4723)\n",
      "8635 Traning Loss: tensor(38.4627)\n",
      "8636 Traning Loss: tensor(38.4534)\n",
      "8637 Traning Loss: tensor(38.4441)\n",
      "8638 Traning Loss: tensor(38.4348)\n",
      "8639 Traning Loss: tensor(38.4254)\n",
      "8640 Traning Loss: tensor(38.4161)\n",
      "8641 Traning Loss: tensor(38.4068)\n",
      "8642 Traning Loss: tensor(38.3974)\n",
      "8643 Traning Loss: tensor(38.3881)\n",
      "8644 Traning Loss: tensor(38.3788)\n",
      "8645 Traning Loss: tensor(38.3695)\n",
      "8646 Traning Loss: tensor(38.3602)\n",
      "8647 Traning Loss: tensor(38.3508)\n",
      "8648 Traning Loss: tensor(38.3415)\n",
      "8649 Traning Loss: tensor(38.3322)\n",
      "8650 Traning Loss: tensor(38.3229)\n",
      "8651 Traning Loss: tensor(38.3136)\n",
      "8652 Traning Loss: tensor(38.3042)\n",
      "8653 Traning Loss: tensor(38.2949)\n",
      "8654 Traning Loss: tensor(38.2856)\n",
      "8655 Traning Loss: tensor(38.2763)\n",
      "8656 Traning Loss: tensor(38.2669)\n",
      "8657 Traning Loss: tensor(38.2576)\n",
      "8658 Traning Loss: tensor(38.2483)\n",
      "8659 Traning Loss: tensor(38.2390)\n",
      "8660 Traning Loss: tensor(38.2297)\n",
      "8661 Traning Loss: tensor(38.2204)\n",
      "8662 Traning Loss: tensor(38.2110)\n",
      "8663 Traning Loss: tensor(38.2017)\n",
      "8664 Traning Loss: tensor(38.1924)\n",
      "8665 Traning Loss: tensor(38.1831)\n",
      "8666 Traning Loss: tensor(38.1738)\n",
      "8667 Traning Loss: tensor(38.1645)\n",
      "8668 Traning Loss: tensor(38.1551)\n",
      "8669 Traning Loss: tensor(38.1458)\n",
      "8670 Traning Loss: tensor(38.1365)\n",
      "8671 Traning Loss: tensor(38.1272)\n",
      "8672 Traning Loss: tensor(38.1179)\n",
      "8673 Traning Loss: tensor(38.1086)\n",
      "8674 Traning Loss: tensor(38.0992)\n",
      "8675 Traning Loss: tensor(38.0899)\n",
      "8676 Traning Loss: tensor(38.0806)\n",
      "8677 Traning Loss: tensor(38.0713)\n",
      "8678 Traning Loss: tensor(38.0620)\n",
      "8679 Traning Loss: tensor(38.0527)\n",
      "8680 Traning Loss: tensor(38.0431)\n",
      "8681 Traning Loss: tensor(38.0338)\n",
      "8682 Traning Loss: tensor(38.0245)\n",
      "8683 Traning Loss: tensor(38.0152)\n",
      "8684 Traning Loss: tensor(38.0059)\n",
      "8685 Traning Loss: tensor(37.9966)\n",
      "8686 Traning Loss: tensor(37.9873)\n",
      "8687 Traning Loss: tensor(37.9780)\n",
      "8688 Traning Loss: tensor(37.9687)\n",
      "8689 Traning Loss: tensor(37.9594)\n",
      "8690 Traning Loss: tensor(37.9501)\n",
      "8691 Traning Loss: tensor(37.9408)\n",
      "8692 Traning Loss: tensor(37.9315)\n",
      "8693 Traning Loss: tensor(37.9222)\n",
      "8694 Traning Loss: tensor(37.9129)\n",
      "8695 Traning Loss: tensor(37.9036)\n",
      "8696 Traning Loss: tensor(37.8943)\n",
      "8697 Traning Loss: tensor(37.8850)\n",
      "8698 Traning Loss: tensor(37.8757)\n",
      "8699 Traning Loss: tensor(37.8664)\n",
      "8700 Traning Loss: tensor(37.8571)\n",
      "8701 Traning Loss: tensor(37.8478)\n",
      "8702 Traning Loss: tensor(37.8385)\n",
      "8703 Traning Loss: tensor(37.8292)\n",
      "8704 Traning Loss: tensor(37.8199)\n",
      "8705 Traning Loss: tensor(37.8106)\n",
      "8706 Traning Loss: tensor(37.8013)\n",
      "8707 Traning Loss: tensor(37.7920)\n",
      "8708 Traning Loss: tensor(37.7827)\n",
      "8709 Traning Loss: tensor(37.7734)\n",
      "8710 Traning Loss: tensor(37.7641)\n",
      "8711 Traning Loss: tensor(37.7548)\n",
      "8712 Traning Loss: tensor(37.7455)\n",
      "8713 Traning Loss: tensor(37.7362)\n",
      "8714 Traning Loss: tensor(37.7269)\n",
      "8715 Traning Loss: tensor(37.7176)\n",
      "8716 Traning Loss: tensor(37.7084)\n",
      "8717 Traning Loss: tensor(37.6991)\n",
      "8718 Traning Loss: tensor(37.6898)\n",
      "8719 Traning Loss: tensor(37.6805)\n",
      "8720 Traning Loss: tensor(37.6712)\n",
      "8721 Traning Loss: tensor(37.6619)\n",
      "8722 Traning Loss: tensor(37.6526)\n",
      "8723 Traning Loss: tensor(37.6433)\n",
      "8724 Traning Loss: tensor(37.6340)\n",
      "8725 Traning Loss: tensor(37.6245)\n",
      "8726 Traning Loss: tensor(37.6152)\n",
      "8727 Traning Loss: tensor(37.6059)\n",
      "8728 Traning Loss: tensor(37.5966)\n",
      "8729 Traning Loss: tensor(37.5873)\n",
      "8730 Traning Loss: tensor(37.5781)\n",
      "8731 Traning Loss: tensor(37.5688)\n",
      "8732 Traning Loss: tensor(37.5595)\n",
      "8733 Traning Loss: tensor(37.5502)\n",
      "8734 Traning Loss: tensor(37.5410)\n",
      "8735 Traning Loss: tensor(37.5317)\n",
      "8736 Traning Loss: tensor(37.5224)\n",
      "8737 Traning Loss: tensor(37.5131)\n",
      "8738 Traning Loss: tensor(37.5038)\n",
      "8739 Traning Loss: tensor(37.4945)\n",
      "8740 Traning Loss: tensor(37.4853)\n",
      "8741 Traning Loss: tensor(37.4760)\n",
      "8742 Traning Loss: tensor(37.4667)\n",
      "8743 Traning Loss: tensor(37.4574)\n",
      "8744 Traning Loss: tensor(37.4482)\n",
      "8745 Traning Loss: tensor(37.4389)\n",
      "8746 Traning Loss: tensor(37.4296)\n",
      "8747 Traning Loss: tensor(37.4204)\n",
      "8748 Traning Loss: tensor(37.4111)\n",
      "8749 Traning Loss: tensor(37.4018)\n",
      "8750 Traning Loss: tensor(37.3925)\n",
      "8751 Traning Loss: tensor(37.3833)\n",
      "8752 Traning Loss: tensor(37.3740)\n",
      "8753 Traning Loss: tensor(37.3647)\n",
      "8754 Traning Loss: tensor(37.3554)\n",
      "8755 Traning Loss: tensor(37.3462)\n",
      "8756 Traning Loss: tensor(37.3369)\n",
      "8757 Traning Loss: tensor(37.3276)\n",
      "8758 Traning Loss: tensor(37.3183)\n",
      "8759 Traning Loss: tensor(37.3091)\n",
      "8760 Traning Loss: tensor(37.2998)\n",
      "8761 Traning Loss: tensor(37.2905)\n",
      "8762 Traning Loss: tensor(37.2813)\n",
      "8763 Traning Loss: tensor(37.2720)\n",
      "8764 Traning Loss: tensor(37.2627)\n",
      "8765 Traning Loss: tensor(37.2535)\n",
      "8766 Traning Loss: tensor(37.2442)\n",
      "8767 Traning Loss: tensor(37.2349)\n",
      "8768 Traning Loss: tensor(37.2257)\n",
      "8769 Traning Loss: tensor(37.2164)\n",
      "8770 Traning Loss: tensor(37.2071)\n",
      "8771 Traning Loss: tensor(37.1979)\n",
      "8772 Traning Loss: tensor(37.1883)\n",
      "8773 Traning Loss: tensor(37.1791)\n",
      "8774 Traning Loss: tensor(37.1698)\n",
      "8775 Traning Loss: tensor(37.1606)\n",
      "8776 Traning Loss: tensor(37.1513)\n",
      "8777 Traning Loss: tensor(37.1421)\n",
      "8778 Traning Loss: tensor(37.1328)\n",
      "8779 Traning Loss: tensor(37.1235)\n",
      "8780 Traning Loss: tensor(37.1143)\n",
      "8781 Traning Loss: tensor(37.1050)\n",
      "8782 Traning Loss: tensor(37.0958)\n",
      "8783 Traning Loss: tensor(37.0865)\n",
      "8784 Traning Loss: tensor(37.0773)\n",
      "8785 Traning Loss: tensor(37.0680)\n",
      "8786 Traning Loss: tensor(37.0588)\n",
      "8787 Traning Loss: tensor(37.0495)\n",
      "8788 Traning Loss: tensor(37.0402)\n",
      "8789 Traning Loss: tensor(37.0310)\n",
      "8790 Traning Loss: tensor(37.0218)\n",
      "8791 Traning Loss: tensor(37.0125)\n",
      "8792 Traning Loss: tensor(37.0033)\n",
      "8793 Traning Loss: tensor(36.9940)\n",
      "8794 Traning Loss: tensor(36.9848)\n",
      "8795 Traning Loss: tensor(36.9755)\n",
      "8796 Traning Loss: tensor(36.9663)\n",
      "8797 Traning Loss: tensor(36.9570)\n",
      "8798 Traning Loss: tensor(36.9478)\n",
      "8799 Traning Loss: tensor(36.9385)\n",
      "8800 Traning Loss: tensor(36.9293)\n",
      "8801 Traning Loss: tensor(36.9200)\n",
      "8802 Traning Loss: tensor(36.9108)\n",
      "8803 Traning Loss: tensor(36.9015)\n",
      "8804 Traning Loss: tensor(36.8923)\n",
      "8805 Traning Loss: tensor(36.8830)\n",
      "8806 Traning Loss: tensor(36.8738)\n",
      "8807 Traning Loss: tensor(36.8646)\n",
      "8808 Traning Loss: tensor(36.8553)\n",
      "8809 Traning Loss: tensor(36.8461)\n",
      "8810 Traning Loss: tensor(36.8368)\n",
      "8811 Traning Loss: tensor(36.8276)\n",
      "8812 Traning Loss: tensor(36.8183)\n",
      "8813 Traning Loss: tensor(36.8091)\n",
      "8814 Traning Loss: tensor(36.7998)\n",
      "8815 Traning Loss: tensor(36.7906)\n",
      "8816 Traning Loss: tensor(36.7814)\n",
      "8817 Traning Loss: tensor(36.7721)\n",
      "8818 Traning Loss: tensor(36.7629)\n",
      "8819 Traning Loss: tensor(36.7534)\n",
      "8820 Traning Loss: tensor(36.7442)\n",
      "8821 Traning Loss: tensor(36.7349)\n",
      "8822 Traning Loss: tensor(36.7257)\n",
      "8823 Traning Loss: tensor(36.7165)\n",
      "8824 Traning Loss: tensor(36.7072)\n",
      "8825 Traning Loss: tensor(36.6980)\n",
      "8826 Traning Loss: tensor(36.6888)\n",
      "8827 Traning Loss: tensor(36.6796)\n",
      "8828 Traning Loss: tensor(36.6703)\n",
      "8829 Traning Loss: tensor(36.6611)\n",
      "8830 Traning Loss: tensor(36.6519)\n",
      "8831 Traning Loss: tensor(36.6427)\n",
      "8832 Traning Loss: tensor(36.6334)\n",
      "8833 Traning Loss: tensor(36.6242)\n",
      "8834 Traning Loss: tensor(36.6150)\n",
      "8835 Traning Loss: tensor(36.6057)\n",
      "8836 Traning Loss: tensor(36.5965)\n",
      "8837 Traning Loss: tensor(36.5873)\n",
      "8838 Traning Loss: tensor(36.5781)\n",
      "8839 Traning Loss: tensor(36.5689)\n",
      "8840 Traning Loss: tensor(36.5596)\n",
      "8841 Traning Loss: tensor(36.5504)\n",
      "8842 Traning Loss: tensor(36.5412)\n",
      "8843 Traning Loss: tensor(36.5320)\n",
      "8844 Traning Loss: tensor(36.5227)\n",
      "8845 Traning Loss: tensor(36.5135)\n",
      "8846 Traning Loss: tensor(36.5043)\n",
      "8847 Traning Loss: tensor(36.4951)\n",
      "8848 Traning Loss: tensor(36.4859)\n",
      "8849 Traning Loss: tensor(36.4767)\n",
      "8850 Traning Loss: tensor(36.4674)\n",
      "8851 Traning Loss: tensor(36.4582)\n",
      "8852 Traning Loss: tensor(36.4490)\n",
      "8853 Traning Loss: tensor(36.4398)\n",
      "8854 Traning Loss: tensor(36.4306)\n",
      "8855 Traning Loss: tensor(36.4213)\n",
      "8856 Traning Loss: tensor(36.4121)\n",
      "8857 Traning Loss: tensor(36.4029)\n",
      "8858 Traning Loss: tensor(36.3937)\n",
      "8859 Traning Loss: tensor(36.3845)\n",
      "8860 Traning Loss: tensor(36.3753)\n",
      "8861 Traning Loss: tensor(36.3661)\n",
      "8862 Traning Loss: tensor(36.3568)\n",
      "8863 Traning Loss: tensor(36.3476)\n",
      "8864 Traning Loss: tensor(36.3384)\n",
      "8865 Traning Loss: tensor(36.3292)\n",
      "8866 Traning Loss: tensor(36.3200)\n",
      "8867 Traning Loss: tensor(36.3105)\n",
      "8868 Traning Loss: tensor(36.3013)\n",
      "8869 Traning Loss: tensor(36.2921)\n",
      "8870 Traning Loss: tensor(36.2829)\n",
      "8871 Traning Loss: tensor(36.2737)\n",
      "8872 Traning Loss: tensor(36.2645)\n",
      "8873 Traning Loss: tensor(36.2553)\n",
      "8874 Traning Loss: tensor(36.2461)\n",
      "8875 Traning Loss: tensor(36.2369)\n",
      "8876 Traning Loss: tensor(36.2277)\n",
      "8877 Traning Loss: tensor(36.2185)\n",
      "8878 Traning Loss: tensor(36.2093)\n",
      "8879 Traning Loss: tensor(36.2001)\n",
      "8880 Traning Loss: tensor(36.1909)\n",
      "8881 Traning Loss: tensor(36.1817)\n",
      "8882 Traning Loss: tensor(36.1725)\n",
      "8883 Traning Loss: tensor(36.1633)\n",
      "8884 Traning Loss: tensor(36.1541)\n",
      "8885 Traning Loss: tensor(36.1449)\n",
      "8886 Traning Loss: tensor(36.1357)\n",
      "8887 Traning Loss: tensor(36.1265)\n",
      "8888 Traning Loss: tensor(36.1174)\n",
      "8889 Traning Loss: tensor(36.1082)\n",
      "8890 Traning Loss: tensor(36.0990)\n",
      "8891 Traning Loss: tensor(36.0898)\n",
      "8892 Traning Loss: tensor(36.0806)\n",
      "8893 Traning Loss: tensor(36.0714)\n",
      "8894 Traning Loss: tensor(36.0622)\n",
      "8895 Traning Loss: tensor(36.0530)\n",
      "8896 Traning Loss: tensor(36.0438)\n",
      "8897 Traning Loss: tensor(36.0346)\n",
      "8898 Traning Loss: tensor(36.0255)\n",
      "8899 Traning Loss: tensor(36.0163)\n",
      "8900 Traning Loss: tensor(36.0071)\n",
      "8901 Traning Loss: tensor(35.9979)\n",
      "8902 Traning Loss: tensor(35.9887)\n",
      "8903 Traning Loss: tensor(35.9795)\n",
      "8904 Traning Loss: tensor(35.9703)\n",
      "8905 Traning Loss: tensor(35.9612)\n",
      "8906 Traning Loss: tensor(35.9520)\n",
      "8907 Traning Loss: tensor(35.9428)\n",
      "8908 Traning Loss: tensor(35.9336)\n",
      "8909 Traning Loss: tensor(35.9244)\n",
      "8910 Traning Loss: tensor(35.9152)\n",
      "8911 Traning Loss: tensor(35.9060)\n",
      "8912 Traning Loss: tensor(35.8969)\n",
      "8913 Traning Loss: tensor(35.8877)\n",
      "8914 Traning Loss: tensor(35.8785)\n",
      "8915 Traning Loss: tensor(35.8691)\n",
      "8916 Traning Loss: tensor(35.8599)\n",
      "8917 Traning Loss: tensor(35.8507)\n",
      "8918 Traning Loss: tensor(35.8415)\n",
      "8919 Traning Loss: tensor(35.8324)\n",
      "8920 Traning Loss: tensor(35.8232)\n",
      "8921 Traning Loss: tensor(35.8140)\n",
      "8922 Traning Loss: tensor(35.8049)\n",
      "8923 Traning Loss: tensor(35.7957)\n",
      "8924 Traning Loss: tensor(35.7865)\n",
      "8925 Traning Loss: tensor(35.7773)\n",
      "8926 Traning Loss: tensor(35.7682)\n",
      "8927 Traning Loss: tensor(35.7590)\n",
      "8928 Traning Loss: tensor(35.7498)\n",
      "8929 Traning Loss: tensor(35.7407)\n",
      "8930 Traning Loss: tensor(35.7315)\n",
      "8931 Traning Loss: tensor(35.7224)\n",
      "8932 Traning Loss: tensor(35.7132)\n",
      "8933 Traning Loss: tensor(35.7040)\n",
      "8934 Traning Loss: tensor(35.6949)\n",
      "8935 Traning Loss: tensor(35.6857)\n",
      "8936 Traning Loss: tensor(35.6765)\n",
      "8937 Traning Loss: tensor(35.6674)\n",
      "8938 Traning Loss: tensor(35.6582)\n",
      "8939 Traning Loss: tensor(35.6491)\n",
      "8940 Traning Loss: tensor(35.6399)\n",
      "8941 Traning Loss: tensor(35.6307)\n",
      "8942 Traning Loss: tensor(35.6216)\n",
      "8943 Traning Loss: tensor(35.6124)\n",
      "8944 Traning Loss: tensor(35.6033)\n",
      "8945 Traning Loss: tensor(35.5941)\n",
      "8946 Traning Loss: tensor(35.5850)\n",
      "8947 Traning Loss: tensor(35.5758)\n",
      "8948 Traning Loss: tensor(35.5666)\n",
      "8949 Traning Loss: tensor(35.5575)\n",
      "8950 Traning Loss: tensor(35.5483)\n",
      "8951 Traning Loss: tensor(35.5392)\n",
      "8952 Traning Loss: tensor(35.5300)\n",
      "8953 Traning Loss: tensor(35.5209)\n",
      "8954 Traning Loss: tensor(35.5117)\n",
      "8955 Traning Loss: tensor(35.5026)\n",
      "8956 Traning Loss: tensor(35.4934)\n",
      "8957 Traning Loss: tensor(35.4842)\n",
      "8958 Traning Loss: tensor(35.4751)\n",
      "8959 Traning Loss: tensor(35.4659)\n",
      "8960 Traning Loss: tensor(35.4568)\n",
      "8961 Traning Loss: tensor(35.4476)\n",
      "8962 Traning Loss: tensor(35.4385)\n",
      "8963 Traning Loss: tensor(35.4293)\n",
      "8964 Traning Loss: tensor(35.4202)\n",
      "8965 Traning Loss: tensor(35.4108)\n",
      "8966 Traning Loss: tensor(35.4016)\n",
      "8967 Traning Loss: tensor(35.3925)\n",
      "8968 Traning Loss: tensor(35.3834)\n",
      "8969 Traning Loss: tensor(35.3742)\n",
      "8970 Traning Loss: tensor(35.3651)\n",
      "8971 Traning Loss: tensor(35.3559)\n",
      "8972 Traning Loss: tensor(35.3468)\n",
      "8973 Traning Loss: tensor(35.3377)\n",
      "8974 Traning Loss: tensor(35.3285)\n",
      "8975 Traning Loss: tensor(35.3194)\n",
      "8976 Traning Loss: tensor(35.3103)\n",
      "8977 Traning Loss: tensor(35.3011)\n",
      "8978 Traning Loss: tensor(35.2920)\n",
      "8979 Traning Loss: tensor(35.2829)\n",
      "8980 Traning Loss: tensor(35.2738)\n",
      "8981 Traning Loss: tensor(35.2646)\n",
      "8982 Traning Loss: tensor(35.2555)\n",
      "8983 Traning Loss: tensor(35.2464)\n",
      "8984 Traning Loss: tensor(35.2372)\n",
      "8985 Traning Loss: tensor(35.2281)\n",
      "8986 Traning Loss: tensor(35.2190)\n",
      "8987 Traning Loss: tensor(35.2098)\n",
      "8988 Traning Loss: tensor(35.2007)\n",
      "8989 Traning Loss: tensor(35.1916)\n",
      "8990 Traning Loss: tensor(35.1825)\n",
      "8991 Traning Loss: tensor(35.1733)\n",
      "8992 Traning Loss: tensor(35.1642)\n",
      "8993 Traning Loss: tensor(35.1551)\n",
      "8994 Traning Loss: tensor(35.1460)\n",
      "8995 Traning Loss: tensor(35.1368)\n",
      "8996 Traning Loss: tensor(35.1277)\n",
      "8997 Traning Loss: tensor(35.1186)\n",
      "8998 Traning Loss: tensor(35.1095)\n",
      "8999 Traning Loss: tensor(35.1004)\n",
      "9000 Traning Loss: tensor(35.0912)\n",
      "9001 Traning Loss: tensor(35.0821)\n",
      "9002 Traning Loss: tensor(35.0730)\n",
      "9003 Traning Loss: tensor(35.0639)\n",
      "9004 Traning Loss: tensor(35.0548)\n",
      "9005 Traning Loss: tensor(35.0456)\n",
      "9006 Traning Loss: tensor(35.0365)\n",
      "9007 Traning Loss: tensor(35.0274)\n",
      "9008 Traning Loss: tensor(35.0183)\n",
      "9009 Traning Loss: tensor(35.0092)\n",
      "9010 Traning Loss: tensor(35.0000)\n",
      "9011 Traning Loss: tensor(34.9909)\n",
      "9012 Traning Loss: tensor(34.9818)\n",
      "9013 Traning Loss: tensor(34.9727)\n",
      "9014 Traning Loss: tensor(34.9636)\n",
      "9015 Traning Loss: tensor(34.9542)\n",
      "9016 Traning Loss: tensor(34.9451)\n",
      "9017 Traning Loss: tensor(34.9360)\n",
      "9018 Traning Loss: tensor(34.9269)\n",
      "9019 Traning Loss: tensor(34.9178)\n",
      "9020 Traning Loss: tensor(34.9087)\n",
      "9021 Traning Loss: tensor(34.8996)\n",
      "9022 Traning Loss: tensor(34.8905)\n",
      "9023 Traning Loss: tensor(34.8814)\n",
      "9024 Traning Loss: tensor(34.8723)\n",
      "9025 Traning Loss: tensor(34.8632)\n",
      "9026 Traning Loss: tensor(34.8541)\n",
      "9027 Traning Loss: tensor(34.8450)\n",
      "9028 Traning Loss: tensor(34.8359)\n",
      "9029 Traning Loss: tensor(34.8268)\n",
      "9030 Traning Loss: tensor(34.8177)\n",
      "9031 Traning Loss: tensor(34.8086)\n",
      "9032 Traning Loss: tensor(34.7995)\n",
      "9033 Traning Loss: tensor(34.7904)\n",
      "9034 Traning Loss: tensor(34.7813)\n",
      "9035 Traning Loss: tensor(34.7722)\n",
      "9036 Traning Loss: tensor(34.7631)\n",
      "9037 Traning Loss: tensor(34.7540)\n",
      "9038 Traning Loss: tensor(34.7449)\n",
      "9039 Traning Loss: tensor(34.7359)\n",
      "9040 Traning Loss: tensor(34.7268)\n",
      "9041 Traning Loss: tensor(34.7177)\n",
      "9042 Traning Loss: tensor(34.7086)\n",
      "9043 Traning Loss: tensor(34.6995)\n",
      "9044 Traning Loss: tensor(34.6904)\n",
      "9045 Traning Loss: tensor(34.6813)\n",
      "9046 Traning Loss: tensor(34.6722)\n",
      "9047 Traning Loss: tensor(34.6632)\n",
      "9048 Traning Loss: tensor(34.6541)\n",
      "9049 Traning Loss: tensor(34.6450)\n",
      "9050 Traning Loss: tensor(34.6359)\n",
      "9051 Traning Loss: tensor(34.6268)\n",
      "9052 Traning Loss: tensor(34.6177)\n",
      "9053 Traning Loss: tensor(34.6087)\n",
      "9054 Traning Loss: tensor(34.5996)\n",
      "9055 Traning Loss: tensor(34.5905)\n",
      "9056 Traning Loss: tensor(34.5814)\n",
      "9057 Traning Loss: tensor(34.5723)\n",
      "9058 Traning Loss: tensor(34.5632)\n",
      "9059 Traning Loss: tensor(34.5542)\n",
      "9060 Traning Loss: tensor(34.5451)\n",
      "9061 Traning Loss: tensor(34.5360)\n",
      "9062 Traning Loss: tensor(34.5269)\n",
      "9063 Traning Loss: tensor(34.5178)\n",
      "9064 Traning Loss: tensor(34.5088)\n",
      "9065 Traning Loss: tensor(34.4997)\n",
      "9066 Traning Loss: tensor(34.4903)\n",
      "9067 Traning Loss: tensor(34.4813)\n",
      "9068 Traning Loss: tensor(34.4722)\n",
      "9069 Traning Loss: tensor(34.4631)\n",
      "9070 Traning Loss: tensor(34.4541)\n",
      "9071 Traning Loss: tensor(34.4450)\n",
      "9072 Traning Loss: tensor(34.4359)\n",
      "9073 Traning Loss: tensor(34.4269)\n",
      "9074 Traning Loss: tensor(34.4178)\n",
      "9075 Traning Loss: tensor(34.4087)\n",
      "9076 Traning Loss: tensor(34.3997)\n",
      "9077 Traning Loss: tensor(34.3906)\n",
      "9078 Traning Loss: tensor(34.3815)\n",
      "9079 Traning Loss: tensor(34.3725)\n",
      "9080 Traning Loss: tensor(34.3634)\n",
      "9081 Traning Loss: tensor(34.3544)\n",
      "9082 Traning Loss: tensor(34.3453)\n",
      "9083 Traning Loss: tensor(34.3363)\n",
      "9084 Traning Loss: tensor(34.3272)\n",
      "9085 Traning Loss: tensor(34.3181)\n",
      "9086 Traning Loss: tensor(34.3091)\n",
      "9087 Traning Loss: tensor(34.3000)\n",
      "9088 Traning Loss: tensor(34.2910)\n",
      "9089 Traning Loss: tensor(34.2819)\n",
      "9090 Traning Loss: tensor(34.2729)\n",
      "9091 Traning Loss: tensor(34.2638)\n",
      "9092 Traning Loss: tensor(34.2548)\n",
      "9093 Traning Loss: tensor(34.2457)\n",
      "9094 Traning Loss: tensor(34.2367)\n",
      "9095 Traning Loss: tensor(34.2276)\n",
      "9096 Traning Loss: tensor(34.2186)\n",
      "9097 Traning Loss: tensor(34.2095)\n",
      "9098 Traning Loss: tensor(34.2005)\n",
      "9099 Traning Loss: tensor(34.1914)\n",
      "9100 Traning Loss: tensor(34.1824)\n",
      "9101 Traning Loss: tensor(34.1733)\n",
      "9102 Traning Loss: tensor(34.1643)\n",
      "9103 Traning Loss: tensor(34.1552)\n",
      "9104 Traning Loss: tensor(34.1462)\n",
      "9105 Traning Loss: tensor(34.1371)\n",
      "9106 Traning Loss: tensor(34.1281)\n",
      "9107 Traning Loss: tensor(34.1191)\n",
      "9108 Traning Loss: tensor(34.1100)\n",
      "9109 Traning Loss: tensor(34.1010)\n",
      "9110 Traning Loss: tensor(34.0919)\n",
      "9111 Traning Loss: tensor(34.0829)\n",
      "9112 Traning Loss: tensor(34.0739)\n",
      "9113 Traning Loss: tensor(34.0648)\n",
      "9114 Traning Loss: tensor(34.0558)\n",
      "9115 Traning Loss: tensor(34.0467)\n",
      "9116 Traning Loss: tensor(34.0377)\n",
      "9117 Traning Loss: tensor(34.0287)\n",
      "9118 Traning Loss: tensor(34.0193)\n",
      "9119 Traning Loss: tensor(34.0103)\n",
      "9120 Traning Loss: tensor(34.0013)\n",
      "9121 Traning Loss: tensor(33.9923)\n",
      "9122 Traning Loss: tensor(33.9832)\n",
      "9123 Traning Loss: tensor(33.9742)\n",
      "9124 Traning Loss: tensor(33.9652)\n",
      "9125 Traning Loss: tensor(33.9562)\n",
      "9126 Traning Loss: tensor(33.9471)\n",
      "9127 Traning Loss: tensor(33.9381)\n",
      "9128 Traning Loss: tensor(33.9291)\n",
      "9129 Traning Loss: tensor(33.9201)\n",
      "9130 Traning Loss: tensor(33.9110)\n",
      "9131 Traning Loss: tensor(33.9020)\n",
      "9132 Traning Loss: tensor(33.8930)\n",
      "9133 Traning Loss: tensor(33.8840)\n",
      "9134 Traning Loss: tensor(33.8750)\n",
      "9135 Traning Loss: tensor(33.8660)\n",
      "9136 Traning Loss: tensor(33.8569)\n",
      "9137 Traning Loss: tensor(33.8479)\n",
      "9138 Traning Loss: tensor(33.8389)\n",
      "9139 Traning Loss: tensor(33.8299)\n",
      "9140 Traning Loss: tensor(33.8209)\n",
      "9141 Traning Loss: tensor(33.8119)\n",
      "9142 Traning Loss: tensor(33.8029)\n",
      "9143 Traning Loss: tensor(33.7938)\n",
      "9144 Traning Loss: tensor(33.7848)\n",
      "9145 Traning Loss: tensor(33.7758)\n",
      "9146 Traning Loss: tensor(33.7668)\n",
      "9147 Traning Loss: tensor(33.7578)\n",
      "9148 Traning Loss: tensor(33.7488)\n",
      "9149 Traning Loss: tensor(33.7398)\n",
      "9150 Traning Loss: tensor(33.7308)\n",
      "9151 Traning Loss: tensor(33.7218)\n",
      "9152 Traning Loss: tensor(33.7128)\n",
      "9153 Traning Loss: tensor(33.7037)\n",
      "9154 Traning Loss: tensor(33.6947)\n",
      "9155 Traning Loss: tensor(33.6857)\n",
      "9156 Traning Loss: tensor(33.6767)\n",
      "9157 Traning Loss: tensor(33.6677)\n",
      "9158 Traning Loss: tensor(33.6587)\n",
      "9159 Traning Loss: tensor(33.6497)\n",
      "9160 Traning Loss: tensor(33.6407)\n",
      "9161 Traning Loss: tensor(33.6317)\n",
      "9162 Traning Loss: tensor(33.6227)\n",
      "9163 Traning Loss: tensor(33.6137)\n",
      "9164 Traning Loss: tensor(33.6047)\n",
      "9165 Traning Loss: tensor(33.5957)\n",
      "9166 Traning Loss: tensor(33.5867)\n",
      "9167 Traning Loss: tensor(33.5777)\n",
      "9168 Traning Loss: tensor(33.5687)\n",
      "9169 Traning Loss: tensor(33.5597)\n",
      "9170 Traning Loss: tensor(33.5507)\n",
      "9171 Traning Loss: tensor(33.5414)\n",
      "9172 Traning Loss: tensor(33.5324)\n",
      "9173 Traning Loss: tensor(33.5235)\n",
      "9174 Traning Loss: tensor(33.5145)\n",
      "9175 Traning Loss: tensor(33.5055)\n",
      "9176 Traning Loss: tensor(33.4965)\n",
      "9177 Traning Loss: tensor(33.4875)\n",
      "9178 Traning Loss: tensor(33.4786)\n",
      "9179 Traning Loss: tensor(33.4696)\n",
      "9180 Traning Loss: tensor(33.4606)\n",
      "9181 Traning Loss: tensor(33.4516)\n",
      "9182 Traning Loss: tensor(33.4426)\n",
      "9183 Traning Loss: tensor(33.4336)\n",
      "9184 Traning Loss: tensor(33.4247)\n",
      "9185 Traning Loss: tensor(33.4157)\n",
      "9186 Traning Loss: tensor(33.4067)\n",
      "9187 Traning Loss: tensor(33.3977)\n",
      "9188 Traning Loss: tensor(33.3888)\n",
      "9189 Traning Loss: tensor(33.3798)\n",
      "9190 Traning Loss: tensor(33.3708)\n",
      "9191 Traning Loss: tensor(33.3618)\n",
      "9192 Traning Loss: tensor(33.3529)\n",
      "9193 Traning Loss: tensor(33.3439)\n",
      "9194 Traning Loss: tensor(33.3349)\n",
      "9195 Traning Loss: tensor(33.3260)\n",
      "9196 Traning Loss: tensor(33.3170)\n",
      "9197 Traning Loss: tensor(33.3080)\n",
      "9198 Traning Loss: tensor(33.2991)\n",
      "9199 Traning Loss: tensor(33.2901)\n",
      "9200 Traning Loss: tensor(33.2811)\n",
      "9201 Traning Loss: tensor(33.2722)\n",
      "9202 Traning Loss: tensor(33.2632)\n",
      "9203 Traning Loss: tensor(33.2542)\n",
      "9204 Traning Loss: tensor(33.2453)\n",
      "9205 Traning Loss: tensor(33.2363)\n",
      "9206 Traning Loss: tensor(33.2273)\n",
      "9207 Traning Loss: tensor(33.2184)\n",
      "9208 Traning Loss: tensor(33.2094)\n",
      "9209 Traning Loss: tensor(33.2005)\n",
      "9210 Traning Loss: tensor(33.1915)\n",
      "9211 Traning Loss: tensor(33.1825)\n",
      "9212 Traning Loss: tensor(33.1736)\n",
      "9213 Traning Loss: tensor(33.1646)\n",
      "9214 Traning Loss: tensor(33.1557)\n",
      "9215 Traning Loss: tensor(33.1467)\n",
      "9216 Traning Loss: tensor(33.1378)\n",
      "9217 Traning Loss: tensor(33.1288)\n",
      "9218 Traning Loss: tensor(33.1198)\n",
      "9219 Traning Loss: tensor(33.1109)\n",
      "9220 Traning Loss: tensor(33.1019)\n",
      "9221 Traning Loss: tensor(33.0930)\n",
      "9222 Traning Loss: tensor(33.0840)\n",
      "9223 Traning Loss: tensor(33.0751)\n",
      "9224 Traning Loss: tensor(33.0661)\n",
      "9225 Traning Loss: tensor(33.0568)\n",
      "9226 Traning Loss: tensor(33.0479)\n",
      "9227 Traning Loss: tensor(33.0390)\n",
      "9228 Traning Loss: tensor(33.0300)\n",
      "9229 Traning Loss: tensor(33.0211)\n",
      "9230 Traning Loss: tensor(33.0121)\n",
      "9231 Traning Loss: tensor(33.0032)\n",
      "9232 Traning Loss: tensor(32.9943)\n",
      "9233 Traning Loss: tensor(32.9853)\n",
      "9234 Traning Loss: tensor(32.9764)\n",
      "9235 Traning Loss: tensor(32.9675)\n",
      "9236 Traning Loss: tensor(32.9573)\n",
      "9237 Traning Loss: tensor(32.9483)\n",
      "9238 Traning Loss: tensor(32.9394)\n",
      "9239 Traning Loss: tensor(32.9304)\n",
      "9240 Traning Loss: tensor(32.9215)\n",
      "9241 Traning Loss: tensor(32.9126)\n",
      "9242 Traning Loss: tensor(32.9036)\n",
      "9243 Traning Loss: tensor(32.8947)\n",
      "9244 Traning Loss: tensor(32.8858)\n",
      "9245 Traning Loss: tensor(32.8768)\n",
      "9246 Traning Loss: tensor(32.8679)\n",
      "9247 Traning Loss: tensor(32.8590)\n",
      "9248 Traning Loss: tensor(32.8501)\n",
      "9249 Traning Loss: tensor(32.8411)\n",
      "9250 Traning Loss: tensor(32.8322)\n",
      "9251 Traning Loss: tensor(32.8233)\n",
      "9252 Traning Loss: tensor(32.8143)\n",
      "9253 Traning Loss: tensor(32.8054)\n",
      "9254 Traning Loss: tensor(32.7965)\n",
      "9255 Traning Loss: tensor(32.7876)\n",
      "9256 Traning Loss: tensor(32.7786)\n",
      "9257 Traning Loss: tensor(32.7697)\n",
      "9258 Traning Loss: tensor(32.7608)\n",
      "9259 Traning Loss: tensor(32.7519)\n",
      "9260 Traning Loss: tensor(32.7429)\n",
      "9261 Traning Loss: tensor(32.7340)\n",
      "9262 Traning Loss: tensor(32.7251)\n",
      "9263 Traning Loss: tensor(32.7162)\n",
      "9264 Traning Loss: tensor(32.7072)\n",
      "9265 Traning Loss: tensor(32.6983)\n",
      "9266 Traning Loss: tensor(32.6894)\n",
      "9267 Traning Loss: tensor(32.6805)\n",
      "9268 Traning Loss: tensor(32.6716)\n",
      "9269 Traning Loss: tensor(32.6626)\n",
      "9270 Traning Loss: tensor(32.6537)\n",
      "9271 Traning Loss: tensor(32.6448)\n",
      "9272 Traning Loss: tensor(32.6359)\n",
      "9273 Traning Loss: tensor(32.6270)\n",
      "9274 Traning Loss: tensor(32.6180)\n",
      "9275 Traning Loss: tensor(32.6091)\n",
      "9276 Traning Loss: tensor(32.6002)\n",
      "9277 Traning Loss: tensor(32.5913)\n",
      "9278 Traning Loss: tensor(32.5824)\n",
      "9279 Traning Loss: tensor(32.5735)\n",
      "9280 Traning Loss: tensor(32.5643)\n",
      "9281 Traning Loss: tensor(32.5554)\n",
      "9282 Traning Loss: tensor(32.5464)\n",
      "9283 Traning Loss: tensor(32.5375)\n",
      "9284 Traning Loss: tensor(32.5286)\n",
      "9285 Traning Loss: tensor(32.5197)\n",
      "9286 Traning Loss: tensor(32.5108)\n",
      "9287 Traning Loss: tensor(32.5020)\n",
      "9288 Traning Loss: tensor(32.4931)\n",
      "9289 Traning Loss: tensor(32.4842)\n",
      "9290 Traning Loss: tensor(32.4753)\n",
      "9291 Traning Loss: tensor(32.4664)\n",
      "9292 Traning Loss: tensor(32.4575)\n",
      "9293 Traning Loss: tensor(32.4486)\n",
      "9294 Traning Loss: tensor(32.4397)\n",
      "9295 Traning Loss: tensor(32.4308)\n",
      "9296 Traning Loss: tensor(32.4219)\n",
      "9297 Traning Loss: tensor(32.4130)\n",
      "9298 Traning Loss: tensor(32.4041)\n",
      "9299 Traning Loss: tensor(32.3952)\n",
      "9300 Traning Loss: tensor(32.3864)\n",
      "9301 Traning Loss: tensor(32.3775)\n",
      "9302 Traning Loss: tensor(32.3686)\n",
      "9303 Traning Loss: tensor(32.3597)\n",
      "9304 Traning Loss: tensor(32.3508)\n",
      "9305 Traning Loss: tensor(32.3419)\n",
      "9306 Traning Loss: tensor(32.3331)\n",
      "9307 Traning Loss: tensor(32.3242)\n",
      "9308 Traning Loss: tensor(32.3153)\n",
      "9309 Traning Loss: tensor(32.3064)\n",
      "9310 Traning Loss: tensor(32.2975)\n",
      "9311 Traning Loss: tensor(32.2887)\n",
      "9312 Traning Loss: tensor(32.2798)\n",
      "9313 Traning Loss: tensor(32.2709)\n",
      "9314 Traning Loss: tensor(32.2620)\n",
      "9315 Traning Loss: tensor(32.2531)\n",
      "9316 Traning Loss: tensor(32.2443)\n",
      "9317 Traning Loss: tensor(32.2354)\n",
      "9318 Traning Loss: tensor(32.2265)\n",
      "9319 Traning Loss: tensor(32.2176)\n",
      "9320 Traning Loss: tensor(32.2088)\n",
      "9321 Traning Loss: tensor(32.1999)\n",
      "9322 Traning Loss: tensor(32.1910)\n",
      "9323 Traning Loss: tensor(32.1822)\n",
      "9324 Traning Loss: tensor(32.1733)\n",
      "9325 Traning Loss: tensor(32.1644)\n",
      "9326 Traning Loss: tensor(32.1556)\n",
      "9327 Traning Loss: tensor(32.1467)\n",
      "9328 Traning Loss: tensor(32.1378)\n",
      "9329 Traning Loss: tensor(32.1289)\n",
      "9330 Traning Loss: tensor(32.1201)\n",
      "9331 Traning Loss: tensor(32.1112)\n",
      "9332 Traning Loss: tensor(32.1023)\n",
      "9333 Traning Loss: tensor(32.0935)\n",
      "9334 Traning Loss: tensor(32.0846)\n",
      "9335 Traning Loss: tensor(32.0757)\n",
      "9336 Traning Loss: tensor(32.0665)\n",
      "9337 Traning Loss: tensor(32.0577)\n",
      "9338 Traning Loss: tensor(32.0488)\n",
      "9339 Traning Loss: tensor(32.0400)\n",
      "9340 Traning Loss: tensor(32.0311)\n",
      "9341 Traning Loss: tensor(32.0223)\n",
      "9342 Traning Loss: tensor(32.0134)\n",
      "9343 Traning Loss: tensor(32.0046)\n",
      "9344 Traning Loss: tensor(31.9957)\n",
      "9345 Traning Loss: tensor(31.9869)\n",
      "9346 Traning Loss: tensor(31.9780)\n",
      "9347 Traning Loss: tensor(31.9692)\n",
      "9348 Traning Loss: tensor(31.9604)\n",
      "9349 Traning Loss: tensor(31.9515)\n",
      "9350 Traning Loss: tensor(31.9427)\n",
      "9351 Traning Loss: tensor(31.9338)\n",
      "9352 Traning Loss: tensor(31.9250)\n",
      "9353 Traning Loss: tensor(31.9162)\n",
      "9354 Traning Loss: tensor(31.9073)\n",
      "9355 Traning Loss: tensor(31.8985)\n",
      "9356 Traning Loss: tensor(31.8896)\n",
      "9357 Traning Loss: tensor(31.8808)\n",
      "9358 Traning Loss: tensor(31.8720)\n",
      "9359 Traning Loss: tensor(31.8631)\n",
      "9360 Traning Loss: tensor(31.8543)\n",
      "9361 Traning Loss: tensor(31.8454)\n",
      "9362 Traning Loss: tensor(31.8366)\n",
      "9363 Traning Loss: tensor(31.8278)\n",
      "9364 Traning Loss: tensor(31.8190)\n",
      "9365 Traning Loss: tensor(31.8101)\n",
      "9366 Traning Loss: tensor(31.8013)\n",
      "9367 Traning Loss: tensor(31.7925)\n",
      "9368 Traning Loss: tensor(31.7836)\n",
      "9369 Traning Loss: tensor(31.7748)\n",
      "9370 Traning Loss: tensor(31.7660)\n",
      "9371 Traning Loss: tensor(31.7571)\n",
      "9372 Traning Loss: tensor(31.7483)\n",
      "9373 Traning Loss: tensor(31.7395)\n",
      "9374 Traning Loss: tensor(31.7307)\n",
      "9375 Traning Loss: tensor(31.7218)\n",
      "9376 Traning Loss: tensor(31.7130)\n",
      "9377 Traning Loss: tensor(31.7042)\n",
      "9378 Traning Loss: tensor(31.6954)\n",
      "9379 Traning Loss: tensor(31.6866)\n",
      "9380 Traning Loss: tensor(31.6777)\n",
      "9381 Traning Loss: tensor(31.6689)\n",
      "9382 Traning Loss: tensor(31.6601)\n",
      "9383 Traning Loss: tensor(31.6513)\n",
      "9384 Traning Loss: tensor(31.6425)\n",
      "9385 Traning Loss: tensor(31.6336)\n",
      "9386 Traning Loss: tensor(31.6248)\n",
      "9387 Traning Loss: tensor(31.6160)\n",
      "9388 Traning Loss: tensor(31.6072)\n",
      "9389 Traning Loss: tensor(31.5984)\n",
      "9390 Traning Loss: tensor(31.5896)\n",
      "9391 Traning Loss: tensor(31.5808)\n",
      "9392 Traning Loss: tensor(31.5719)\n",
      "9393 Traning Loss: tensor(31.5628)\n",
      "9394 Traning Loss: tensor(31.5540)\n",
      "9395 Traning Loss: tensor(31.5452)\n",
      "9396 Traning Loss: tensor(31.5364)\n",
      "9397 Traning Loss: tensor(31.5276)\n",
      "9398 Traning Loss: tensor(31.5188)\n",
      "9399 Traning Loss: tensor(31.5100)\n",
      "9400 Traning Loss: tensor(31.5012)\n",
      "9401 Traning Loss: tensor(31.4924)\n",
      "9402 Traning Loss: tensor(31.4836)\n",
      "9403 Traning Loss: tensor(31.4748)\n",
      "9404 Traning Loss: tensor(31.4660)\n",
      "9405 Traning Loss: tensor(31.4572)\n",
      "9406 Traning Loss: tensor(31.4484)\n",
      "9407 Traning Loss: tensor(31.4396)\n",
      "9408 Traning Loss: tensor(31.4308)\n",
      "9409 Traning Loss: tensor(31.4220)\n",
      "9410 Traning Loss: tensor(31.4132)\n",
      "9411 Traning Loss: tensor(31.4045)\n",
      "9412 Traning Loss: tensor(31.3957)\n",
      "9413 Traning Loss: tensor(31.3869)\n",
      "9414 Traning Loss: tensor(31.3781)\n",
      "9415 Traning Loss: tensor(31.3693)\n",
      "9416 Traning Loss: tensor(31.3605)\n",
      "9417 Traning Loss: tensor(31.3518)\n",
      "9418 Traning Loss: tensor(31.3430)\n",
      "9419 Traning Loss: tensor(31.3342)\n",
      "9420 Traning Loss: tensor(31.3254)\n",
      "9421 Traning Loss: tensor(31.3166)\n",
      "9422 Traning Loss: tensor(31.3078)\n",
      "9423 Traning Loss: tensor(31.2991)\n",
      "9424 Traning Loss: tensor(31.2903)\n",
      "9425 Traning Loss: tensor(31.2815)\n",
      "9426 Traning Loss: tensor(31.2727)\n",
      "9427 Traning Loss: tensor(31.2640)\n",
      "9428 Traning Loss: tensor(31.2552)\n",
      "9429 Traning Loss: tensor(31.2464)\n",
      "9430 Traning Loss: tensor(31.2376)\n",
      "9431 Traning Loss: tensor(31.2289)\n",
      "9432 Traning Loss: tensor(31.2201)\n",
      "9433 Traning Loss: tensor(31.2113)\n",
      "9434 Traning Loss: tensor(31.2026)\n",
      "9435 Traning Loss: tensor(31.1938)\n",
      "9436 Traning Loss: tensor(31.1850)\n",
      "9437 Traning Loss: tensor(31.1762)\n",
      "9438 Traning Loss: tensor(31.1675)\n",
      "9439 Traning Loss: tensor(31.1587)\n",
      "9440 Traning Loss: tensor(31.1499)\n",
      "9441 Traning Loss: tensor(31.1412)\n",
      "9442 Traning Loss: tensor(31.1324)\n",
      "9443 Traning Loss: tensor(31.1237)\n",
      "9444 Traning Loss: tensor(31.1149)\n",
      "9445 Traning Loss: tensor(31.1061)\n",
      "9446 Traning Loss: tensor(31.0974)\n",
      "9447 Traning Loss: tensor(31.0886)\n",
      "9448 Traning Loss: tensor(31.0798)\n",
      "9449 Traning Loss: tensor(31.0711)\n",
      "9450 Traning Loss: tensor(31.0623)\n",
      "9451 Traning Loss: tensor(31.0536)\n",
      "9452 Traning Loss: tensor(31.0444)\n",
      "9453 Traning Loss: tensor(31.0357)\n",
      "9454 Traning Loss: tensor(31.0269)\n",
      "9455 Traning Loss: tensor(31.0182)\n",
      "9456 Traning Loss: tensor(31.0095)\n",
      "9457 Traning Loss: tensor(31.0007)\n",
      "9458 Traning Loss: tensor(30.9919)\n",
      "9459 Traning Loss: tensor(30.9832)\n",
      "9460 Traning Loss: tensor(30.9745)\n",
      "9461 Traning Loss: tensor(30.9657)\n",
      "9462 Traning Loss: tensor(30.9570)\n",
      "9463 Traning Loss: tensor(30.9482)\n",
      "9464 Traning Loss: tensor(30.9395)\n",
      "9465 Traning Loss: tensor(30.9308)\n",
      "9466 Traning Loss: tensor(30.9220)\n",
      "9467 Traning Loss: tensor(30.9133)\n",
      "9468 Traning Loss: tensor(30.9046)\n",
      "9469 Traning Loss: tensor(30.8958)\n",
      "9470 Traning Loss: tensor(30.8871)\n",
      "9471 Traning Loss: tensor(30.8784)\n",
      "9472 Traning Loss: tensor(30.8696)\n",
      "9473 Traning Loss: tensor(30.8609)\n",
      "9474 Traning Loss: tensor(30.8522)\n",
      "9475 Traning Loss: tensor(30.8434)\n",
      "9476 Traning Loss: tensor(30.8347)\n",
      "9477 Traning Loss: tensor(30.8260)\n",
      "9478 Traning Loss: tensor(30.8173)\n",
      "9479 Traning Loss: tensor(30.8085)\n",
      "9480 Traning Loss: tensor(30.7998)\n",
      "9481 Traning Loss: tensor(30.7911)\n",
      "9482 Traning Loss: tensor(30.7824)\n",
      "9483 Traning Loss: tensor(30.7737)\n",
      "9484 Traning Loss: tensor(30.7649)\n",
      "9485 Traning Loss: tensor(30.7562)\n",
      "9486 Traning Loss: tensor(30.7475)\n",
      "9487 Traning Loss: tensor(30.7388)\n",
      "9488 Traning Loss: tensor(30.7300)\n",
      "9489 Traning Loss: tensor(30.7213)\n",
      "9490 Traning Loss: tensor(30.7126)\n",
      "9491 Traning Loss: tensor(30.7039)\n",
      "9492 Traning Loss: tensor(30.6952)\n",
      "9493 Traning Loss: tensor(30.6865)\n",
      "9494 Traning Loss: tensor(30.6777)\n",
      "9495 Traning Loss: tensor(30.6690)\n",
      "9496 Traning Loss: tensor(30.6603)\n",
      "9497 Traning Loss: tensor(30.6516)\n",
      "9498 Traning Loss: tensor(30.6429)\n",
      "9499 Traning Loss: tensor(30.6342)\n",
      "9500 Traning Loss: tensor(30.6255)\n",
      "9501 Traning Loss: tensor(30.6168)\n",
      "9502 Traning Loss: tensor(30.6081)\n",
      "9503 Traning Loss: tensor(30.5994)\n",
      "9504 Traning Loss: tensor(30.5906)\n",
      "9505 Traning Loss: tensor(30.5819)\n",
      "9506 Traning Loss: tensor(30.5732)\n",
      "9507 Traning Loss: tensor(30.5645)\n",
      "9508 Traning Loss: tensor(30.5558)\n",
      "9509 Traning Loss: tensor(30.5471)\n",
      "9510 Traning Loss: tensor(30.5384)\n",
      "9511 Traning Loss: tensor(30.5293)\n",
      "9512 Traning Loss: tensor(30.5206)\n",
      "9513 Traning Loss: tensor(30.5119)\n",
      "9514 Traning Loss: tensor(30.5032)\n",
      "9515 Traning Loss: tensor(30.4946)\n",
      "9516 Traning Loss: tensor(30.4859)\n",
      "9517 Traning Loss: tensor(30.4772)\n",
      "9518 Traning Loss: tensor(30.4685)\n",
      "9519 Traning Loss: tensor(30.4598)\n",
      "9520 Traning Loss: tensor(30.4511)\n",
      "9521 Traning Loss: tensor(30.4424)\n",
      "9522 Traning Loss: tensor(30.4338)\n",
      "9523 Traning Loss: tensor(30.4251)\n",
      "9524 Traning Loss: tensor(30.4164)\n",
      "9525 Traning Loss: tensor(30.4077)\n",
      "9526 Traning Loss: tensor(30.3990)\n",
      "9527 Traning Loss: tensor(30.3904)\n",
      "9528 Traning Loss: tensor(30.3817)\n",
      "9529 Traning Loss: tensor(30.3730)\n",
      "9530 Traning Loss: tensor(30.3643)\n",
      "9531 Traning Loss: tensor(30.3557)\n",
      "9532 Traning Loss: tensor(30.3470)\n",
      "9533 Traning Loss: tensor(30.3383)\n",
      "9534 Traning Loss: tensor(30.3297)\n",
      "9535 Traning Loss: tensor(30.3210)\n",
      "9536 Traning Loss: tensor(30.3123)\n",
      "9537 Traning Loss: tensor(30.3036)\n",
      "9538 Traning Loss: tensor(30.2950)\n",
      "9539 Traning Loss: tensor(30.2863)\n",
      "9540 Traning Loss: tensor(30.2776)\n",
      "9541 Traning Loss: tensor(30.2690)\n",
      "9542 Traning Loss: tensor(30.2603)\n",
      "9543 Traning Loss: tensor(30.2516)\n",
      "9544 Traning Loss: tensor(30.2430)\n",
      "9545 Traning Loss: tensor(30.2343)\n",
      "9546 Traning Loss: tensor(30.2256)\n",
      "9547 Traning Loss: tensor(30.2170)\n",
      "9548 Traning Loss: tensor(30.2083)\n",
      "9549 Traning Loss: tensor(30.1997)\n",
      "9550 Traning Loss: tensor(30.1910)\n",
      "9551 Traning Loss: tensor(30.1823)\n",
      "9552 Traning Loss: tensor(30.1737)\n",
      "9553 Traning Loss: tensor(30.1650)\n",
      "9554 Traning Loss: tensor(30.1564)\n",
      "9555 Traning Loss: tensor(30.1477)\n",
      "9556 Traning Loss: tensor(30.1390)\n",
      "9557 Traning Loss: tensor(30.1304)\n",
      "9558 Traning Loss: tensor(30.1217)\n",
      "9559 Traning Loss: tensor(30.1131)\n",
      "9560 Traning Loss: tensor(30.1044)\n",
      "9561 Traning Loss: tensor(30.0958)\n",
      "9562 Traning Loss: tensor(30.0871)\n",
      "9563 Traning Loss: tensor(30.0785)\n",
      "9564 Traning Loss: tensor(30.0698)\n",
      "9565 Traning Loss: tensor(30.0612)\n",
      "9566 Traning Loss: tensor(30.0525)\n",
      "9567 Traning Loss: tensor(30.0439)\n",
      "9568 Traning Loss: tensor(30.0352)\n",
      "9569 Traning Loss: tensor(30.0266)\n",
      "9570 Traning Loss: tensor(30.0180)\n",
      "9571 Traning Loss: tensor(30.0093)\n",
      "9572 Traning Loss: tensor(30.0003)\n",
      "9573 Traning Loss: tensor(29.9916)\n",
      "9574 Traning Loss: tensor(29.9830)\n",
      "9575 Traning Loss: tensor(29.9744)\n",
      "9576 Traning Loss: tensor(29.9657)\n",
      "9577 Traning Loss: tensor(29.9571)\n",
      "9578 Traning Loss: tensor(29.9485)\n",
      "9579 Traning Loss: tensor(29.9399)\n",
      "9580 Traning Loss: tensor(29.9312)\n",
      "9581 Traning Loss: tensor(29.9226)\n",
      "9582 Traning Loss: tensor(29.9140)\n",
      "9583 Traning Loss: tensor(29.9054)\n",
      "9584 Traning Loss: tensor(29.8967)\n",
      "9585 Traning Loss: tensor(29.8881)\n",
      "9586 Traning Loss: tensor(29.8795)\n",
      "9587 Traning Loss: tensor(29.8709)\n",
      "9588 Traning Loss: tensor(29.8623)\n",
      "9589 Traning Loss: tensor(29.8536)\n",
      "9590 Traning Loss: tensor(29.8450)\n",
      "9591 Traning Loss: tensor(29.8364)\n",
      "9592 Traning Loss: tensor(29.8278)\n",
      "9593 Traning Loss: tensor(29.8192)\n",
      "9594 Traning Loss: tensor(29.8106)\n",
      "9595 Traning Loss: tensor(29.8020)\n",
      "9596 Traning Loss: tensor(29.7934)\n",
      "9597 Traning Loss: tensor(29.7847)\n",
      "9598 Traning Loss: tensor(29.7761)\n",
      "9599 Traning Loss: tensor(29.7675)\n",
      "9600 Traning Loss: tensor(29.7589)\n",
      "9601 Traning Loss: tensor(29.7503)\n",
      "9602 Traning Loss: tensor(29.7417)\n",
      "9603 Traning Loss: tensor(29.7331)\n",
      "9604 Traning Loss: tensor(29.7245)\n",
      "9605 Traning Loss: tensor(29.7159)\n",
      "9606 Traning Loss: tensor(29.7073)\n",
      "9607 Traning Loss: tensor(29.6987)\n",
      "9608 Traning Loss: tensor(29.6901)\n",
      "9609 Traning Loss: tensor(29.6815)\n",
      "9610 Traning Loss: tensor(29.6729)\n",
      "9611 Traning Loss: tensor(29.6643)\n",
      "9612 Traning Loss: tensor(29.6557)\n",
      "9613 Traning Loss: tensor(29.6471)\n",
      "9614 Traning Loss: tensor(29.6385)\n",
      "9615 Traning Loss: tensor(29.6299)\n",
      "9616 Traning Loss: tensor(29.6213)\n",
      "9617 Traning Loss: tensor(29.6127)\n",
      "9618 Traning Loss: tensor(29.6041)\n",
      "9619 Traning Loss: tensor(29.5955)\n",
      "9620 Traning Loss: tensor(29.5869)\n",
      "9621 Traning Loss: tensor(29.5783)\n",
      "9622 Traning Loss: tensor(29.5697)\n",
      "9623 Traning Loss: tensor(29.5611)\n",
      "9624 Traning Loss: tensor(29.5525)\n",
      "9625 Traning Loss: tensor(29.5440)\n",
      "9626 Traning Loss: tensor(29.5354)\n",
      "9627 Traning Loss: tensor(29.5268)\n",
      "9628 Traning Loss: tensor(29.5182)\n",
      "9629 Traning Loss: tensor(29.5096)\n",
      "9630 Traning Loss: tensor(29.5010)\n",
      "9631 Traning Loss: tensor(29.4924)\n",
      "9632 Traning Loss: tensor(29.4839)\n",
      "9633 Traning Loss: tensor(29.4753)\n",
      "9634 Traning Loss: tensor(29.4663)\n",
      "9635 Traning Loss: tensor(29.4577)\n",
      "9636 Traning Loss: tensor(29.4491)\n",
      "9637 Traning Loss: tensor(29.4406)\n",
      "9638 Traning Loss: tensor(29.4320)\n",
      "9639 Traning Loss: tensor(29.4234)\n",
      "9640 Traning Loss: tensor(29.4149)\n",
      "9641 Traning Loss: tensor(29.4063)\n",
      "9642 Traning Loss: tensor(29.3977)\n",
      "9643 Traning Loss: tensor(29.3892)\n",
      "9644 Traning Loss: tensor(29.3806)\n",
      "9645 Traning Loss: tensor(29.3721)\n",
      "9646 Traning Loss: tensor(29.3635)\n",
      "9647 Traning Loss: tensor(29.3549)\n",
      "9648 Traning Loss: tensor(29.3464)\n",
      "9649 Traning Loss: tensor(29.3378)\n",
      "9650 Traning Loss: tensor(29.3293)\n",
      "9651 Traning Loss: tensor(29.3207)\n",
      "9652 Traning Loss: tensor(29.3122)\n",
      "9653 Traning Loss: tensor(29.3036)\n",
      "9654 Traning Loss: tensor(29.2950)\n",
      "9655 Traning Loss: tensor(29.2865)\n",
      "9656 Traning Loss: tensor(29.2780)\n",
      "9657 Traning Loss: tensor(29.2694)\n",
      "9658 Traning Loss: tensor(29.2608)\n",
      "9659 Traning Loss: tensor(29.2523)\n",
      "9660 Traning Loss: tensor(29.2438)\n",
      "9661 Traning Loss: tensor(29.2352)\n",
      "9662 Traning Loss: tensor(29.2267)\n",
      "9663 Traning Loss: tensor(29.2181)\n",
      "9664 Traning Loss: tensor(29.2096)\n",
      "9665 Traning Loss: tensor(29.2010)\n",
      "9666 Traning Loss: tensor(29.1925)\n",
      "9667 Traning Loss: tensor(29.1839)\n",
      "9668 Traning Loss: tensor(29.1754)\n",
      "9669 Traning Loss: tensor(29.1669)\n",
      "9670 Traning Loss: tensor(29.1583)\n",
      "9671 Traning Loss: tensor(29.1498)\n",
      "9672 Traning Loss: tensor(29.1413)\n",
      "9673 Traning Loss: tensor(29.1327)\n",
      "9674 Traning Loss: tensor(29.1242)\n",
      "9675 Traning Loss: tensor(29.1156)\n",
      "9676 Traning Loss: tensor(29.1071)\n",
      "9677 Traning Loss: tensor(29.0986)\n",
      "9678 Traning Loss: tensor(29.0900)\n",
      "9679 Traning Loss: tensor(29.0815)\n",
      "9680 Traning Loss: tensor(29.0730)\n",
      "9681 Traning Loss: tensor(29.0644)\n",
      "9682 Traning Loss: tensor(29.0559)\n",
      "9683 Traning Loss: tensor(29.0474)\n",
      "9684 Traning Loss: tensor(29.0389)\n",
      "9685 Traning Loss: tensor(29.0303)\n",
      "9686 Traning Loss: tensor(29.0218)\n",
      "9687 Traning Loss: tensor(29.0133)\n",
      "9688 Traning Loss: tensor(29.0048)\n",
      "9689 Traning Loss: tensor(28.9962)\n",
      "9690 Traning Loss: tensor(28.9877)\n",
      "9691 Traning Loss: tensor(28.9792)\n",
      "9692 Traning Loss: tensor(28.9707)\n",
      "9693 Traning Loss: tensor(28.9622)\n",
      "9694 Traning Loss: tensor(28.9536)\n",
      "9695 Traning Loss: tensor(28.9451)\n",
      "9696 Traning Loss: tensor(28.9366)\n",
      "9697 Traning Loss: tensor(28.9281)\n",
      "9698 Traning Loss: tensor(28.9191)\n",
      "9699 Traning Loss: tensor(28.9106)\n",
      "9700 Traning Loss: tensor(28.9021)\n",
      "9701 Traning Loss: tensor(28.8936)\n",
      "9702 Traning Loss: tensor(28.8851)\n",
      "9703 Traning Loss: tensor(28.8766)\n",
      "9704 Traning Loss: tensor(28.8681)\n",
      "9705 Traning Loss: tensor(28.8596)\n",
      "9706 Traning Loss: tensor(28.8511)\n",
      "9707 Traning Loss: tensor(28.8426)\n",
      "9708 Traning Loss: tensor(28.8341)\n",
      "9709 Traning Loss: tensor(28.8256)\n",
      "9710 Traning Loss: tensor(28.8171)\n",
      "9711 Traning Loss: tensor(28.8086)\n",
      "9712 Traning Loss: tensor(28.8001)\n",
      "9713 Traning Loss: tensor(28.7917)\n",
      "9714 Traning Loss: tensor(28.7832)\n",
      "9715 Traning Loss: tensor(28.7747)\n",
      "9716 Traning Loss: tensor(28.7662)\n",
      "9717 Traning Loss: tensor(28.7577)\n",
      "9718 Traning Loss: tensor(28.7492)\n",
      "9719 Traning Loss: tensor(28.7407)\n",
      "9720 Traning Loss: tensor(28.7322)\n",
      "9721 Traning Loss: tensor(28.7238)\n",
      "9722 Traning Loss: tensor(28.7153)\n",
      "9723 Traning Loss: tensor(28.7068)\n",
      "9724 Traning Loss: tensor(28.6983)\n",
      "9725 Traning Loss: tensor(28.6898)\n",
      "9726 Traning Loss: tensor(28.6813)\n",
      "9727 Traning Loss: tensor(28.6729)\n",
      "9728 Traning Loss: tensor(28.6644)\n",
      "9729 Traning Loss: tensor(28.6559)\n",
      "9730 Traning Loss: tensor(28.6474)\n",
      "9731 Traning Loss: tensor(28.6390)\n",
      "9732 Traning Loss: tensor(28.6305)\n",
      "9733 Traning Loss: tensor(28.6220)\n",
      "9734 Traning Loss: tensor(28.6135)\n",
      "9735 Traning Loss: tensor(28.6051)\n",
      "9736 Traning Loss: tensor(28.5966)\n",
      "9737 Traning Loss: tensor(28.5881)\n",
      "9738 Traning Loss: tensor(28.5796)\n",
      "9739 Traning Loss: tensor(28.5712)\n",
      "9740 Traning Loss: tensor(28.5627)\n",
      "9741 Traning Loss: tensor(28.5542)\n",
      "9742 Traning Loss: tensor(28.5458)\n",
      "9743 Traning Loss: tensor(28.5373)\n",
      "9744 Traning Loss: tensor(28.5288)\n",
      "9745 Traning Loss: tensor(28.5204)\n",
      "9746 Traning Loss: tensor(28.5119)\n",
      "9747 Traning Loss: tensor(28.5034)\n",
      "9748 Traning Loss: tensor(28.4950)\n",
      "9749 Traning Loss: tensor(28.4865)\n",
      "9750 Traning Loss: tensor(28.4781)\n",
      "9751 Traning Loss: tensor(28.4696)\n",
      "9752 Traning Loss: tensor(28.4611)\n",
      "9753 Traning Loss: tensor(28.4527)\n",
      "9754 Traning Loss: tensor(28.4442)\n",
      "9755 Traning Loss: tensor(28.4358)\n",
      "9756 Traning Loss: tensor(28.4273)\n",
      "9757 Traning Loss: tensor(28.4189)\n",
      "9758 Traning Loss: tensor(28.4104)\n",
      "9759 Traning Loss: tensor(28.4020)\n",
      "9760 Traning Loss: tensor(28.3935)\n",
      "9761 Traning Loss: tensor(28.3851)\n",
      "9762 Traning Loss: tensor(28.3762)\n",
      "9763 Traning Loss: tensor(28.3677)\n",
      "9764 Traning Loss: tensor(28.3593)\n",
      "9765 Traning Loss: tensor(28.3508)\n",
      "9766 Traning Loss: tensor(28.3424)\n",
      "9767 Traning Loss: tensor(28.3340)\n",
      "9768 Traning Loss: tensor(28.3255)\n",
      "9769 Traning Loss: tensor(28.3171)\n",
      "9770 Traning Loss: tensor(28.3087)\n",
      "9771 Traning Loss: tensor(28.3003)\n",
      "9772 Traning Loss: tensor(28.2918)\n",
      "9773 Traning Loss: tensor(28.2834)\n",
      "9774 Traning Loss: tensor(28.2750)\n",
      "9775 Traning Loss: tensor(28.2665)\n",
      "9776 Traning Loss: tensor(28.2581)\n",
      "9777 Traning Loss: tensor(28.2497)\n",
      "9778 Traning Loss: tensor(28.2413)\n",
      "9779 Traning Loss: tensor(28.2328)\n",
      "9780 Traning Loss: tensor(28.2244)\n",
      "9781 Traning Loss: tensor(28.2160)\n",
      "9782 Traning Loss: tensor(28.2076)\n",
      "9783 Traning Loss: tensor(28.1992)\n",
      "9784 Traning Loss: tensor(28.1908)\n",
      "9785 Traning Loss: tensor(28.1823)\n",
      "9786 Traning Loss: tensor(28.1739)\n",
      "9787 Traning Loss: tensor(28.1655)\n",
      "9788 Traning Loss: tensor(28.1571)\n",
      "9789 Traning Loss: tensor(28.1487)\n",
      "9790 Traning Loss: tensor(28.1403)\n",
      "9791 Traning Loss: tensor(28.1319)\n",
      "9792 Traning Loss: tensor(28.1234)\n",
      "9793 Traning Loss: tensor(28.1150)\n",
      "9794 Traning Loss: tensor(28.1066)\n",
      "9795 Traning Loss: tensor(28.0982)\n",
      "9796 Traning Loss: tensor(28.0898)\n",
      "9797 Traning Loss: tensor(28.0814)\n",
      "9798 Traning Loss: tensor(28.0730)\n",
      "9799 Traning Loss: tensor(28.0646)\n",
      "9800 Traning Loss: tensor(28.0562)\n",
      "9801 Traning Loss: tensor(28.0478)\n",
      "9802 Traning Loss: tensor(28.0394)\n",
      "9803 Traning Loss: tensor(28.0310)\n",
      "9804 Traning Loss: tensor(28.0226)\n",
      "9805 Traning Loss: tensor(28.0142)\n",
      "9806 Traning Loss: tensor(28.0058)\n",
      "9807 Traning Loss: tensor(27.9974)\n",
      "9808 Traning Loss: tensor(27.9890)\n",
      "9809 Traning Loss: tensor(27.9806)\n",
      "9810 Traning Loss: tensor(27.9722)\n",
      "9811 Traning Loss: tensor(27.9638)\n",
      "9812 Traning Loss: tensor(27.9554)\n",
      "9813 Traning Loss: tensor(27.9470)\n",
      "9814 Traning Loss: tensor(27.9386)\n",
      "9815 Traning Loss: tensor(27.9302)\n",
      "9816 Traning Loss: tensor(27.9218)\n",
      "9817 Traning Loss: tensor(27.9134)\n",
      "9818 Traning Loss: tensor(27.9051)\n",
      "9819 Traning Loss: tensor(27.8967)\n",
      "9820 Traning Loss: tensor(27.8883)\n",
      "9821 Traning Loss: tensor(27.8799)\n",
      "9822 Traning Loss: tensor(27.8715)\n",
      "9823 Traning Loss: tensor(27.8631)\n",
      "9824 Traning Loss: tensor(27.8548)\n",
      "9825 Traning Loss: tensor(27.8464)\n",
      "9826 Traning Loss: tensor(27.8380)\n",
      "9827 Traning Loss: tensor(27.8296)\n",
      "9828 Traning Loss: tensor(27.8208)\n",
      "9829 Traning Loss: tensor(27.8124)\n",
      "9830 Traning Loss: tensor(27.8040)\n",
      "9831 Traning Loss: tensor(27.7957)\n",
      "9832 Traning Loss: tensor(27.7873)\n",
      "9833 Traning Loss: tensor(27.7789)\n",
      "9834 Traning Loss: tensor(27.7706)\n",
      "9835 Traning Loss: tensor(27.7622)\n",
      "9836 Traning Loss: tensor(27.7538)\n",
      "9837 Traning Loss: tensor(27.7455)\n",
      "9838 Traning Loss: tensor(27.7371)\n",
      "9839 Traning Loss: tensor(27.7288)\n",
      "9840 Traning Loss: tensor(27.7204)\n",
      "9841 Traning Loss: tensor(27.7121)\n",
      "9842 Traning Loss: tensor(27.7037)\n",
      "9843 Traning Loss: tensor(27.6954)\n",
      "9844 Traning Loss: tensor(27.6870)\n",
      "9845 Traning Loss: tensor(27.6786)\n",
      "9846 Traning Loss: tensor(27.6703)\n",
      "9847 Traning Loss: tensor(27.6619)\n",
      "9848 Traning Loss: tensor(27.6536)\n",
      "9849 Traning Loss: tensor(27.6452)\n",
      "9850 Traning Loss: tensor(27.6369)\n",
      "9851 Traning Loss: tensor(27.6286)\n",
      "9852 Traning Loss: tensor(27.6202)\n",
      "9853 Traning Loss: tensor(27.6119)\n",
      "9854 Traning Loss: tensor(27.6035)\n",
      "9855 Traning Loss: tensor(27.5952)\n",
      "9856 Traning Loss: tensor(27.5868)\n",
      "9857 Traning Loss: tensor(27.5785)\n",
      "9858 Traning Loss: tensor(27.5702)\n",
      "9859 Traning Loss: tensor(27.5618)\n",
      "9860 Traning Loss: tensor(27.5535)\n",
      "9861 Traning Loss: tensor(27.5451)\n",
      "9862 Traning Loss: tensor(27.5368)\n",
      "9863 Traning Loss: tensor(27.5285)\n",
      "9864 Traning Loss: tensor(27.5201)\n",
      "9865 Traning Loss: tensor(27.5118)\n",
      "9866 Traning Loss: tensor(27.5035)\n",
      "9867 Traning Loss: tensor(27.4951)\n",
      "9868 Traning Loss: tensor(27.4868)\n",
      "9869 Traning Loss: tensor(27.4785)\n",
      "9870 Traning Loss: tensor(27.4701)\n",
      "9871 Traning Loss: tensor(27.4618)\n",
      "9872 Traning Loss: tensor(27.4535)\n",
      "9873 Traning Loss: tensor(27.4452)\n",
      "9874 Traning Loss: tensor(27.4368)\n",
      "9875 Traning Loss: tensor(27.4285)\n",
      "9876 Traning Loss: tensor(27.4181)\n",
      "9877 Traning Loss: tensor(27.4097)\n",
      "9878 Traning Loss: tensor(27.4014)\n",
      "9879 Traning Loss: tensor(27.3931)\n",
      "9880 Traning Loss: tensor(27.3848)\n",
      "9881 Traning Loss: tensor(27.3764)\n",
      "9882 Traning Loss: tensor(27.3681)\n",
      "9883 Traning Loss: tensor(27.3598)\n",
      "9884 Traning Loss: tensor(27.3515)\n",
      "9885 Traning Loss: tensor(27.3431)\n",
      "9886 Traning Loss: tensor(27.3348)\n",
      "9887 Traning Loss: tensor(27.3265)\n",
      "9888 Traning Loss: tensor(27.3182)\n",
      "9889 Traning Loss: tensor(27.3099)\n",
      "9890 Traning Loss: tensor(27.3015)\n",
      "9891 Traning Loss: tensor(27.2932)\n",
      "9892 Traning Loss: tensor(27.2849)\n",
      "9893 Traning Loss: tensor(27.2766)\n",
      "9894 Traning Loss: tensor(27.2683)\n",
      "9895 Traning Loss: tensor(27.2599)\n",
      "9896 Traning Loss: tensor(27.2511)\n",
      "9897 Traning Loss: tensor(27.2428)\n",
      "9898 Traning Loss: tensor(27.2345)\n",
      "9899 Traning Loss: tensor(27.2262)\n",
      "9900 Traning Loss: tensor(27.2179)\n",
      "9901 Traning Loss: tensor(27.2096)\n",
      "9902 Traning Loss: tensor(27.2013)\n",
      "9903 Traning Loss: tensor(27.1930)\n",
      "9904 Traning Loss: tensor(27.1847)\n",
      "9905 Traning Loss: tensor(27.1764)\n",
      "9906 Traning Loss: tensor(27.1681)\n",
      "9907 Traning Loss: tensor(27.1598)\n",
      "9908 Traning Loss: tensor(27.1515)\n",
      "9909 Traning Loss: tensor(27.1432)\n",
      "9910 Traning Loss: tensor(27.1350)\n",
      "9911 Traning Loss: tensor(27.1267)\n",
      "9912 Traning Loss: tensor(27.1184)\n",
      "9913 Traning Loss: tensor(27.1101)\n",
      "9914 Traning Loss: tensor(27.1018)\n",
      "9915 Traning Loss: tensor(27.0935)\n",
      "9916 Traning Loss: tensor(27.0852)\n",
      "9917 Traning Loss: tensor(27.0769)\n",
      "9918 Traning Loss: tensor(27.0687)\n",
      "9919 Traning Loss: tensor(27.0604)\n",
      "9920 Traning Loss: tensor(27.0521)\n",
      "9921 Traning Loss: tensor(27.0438)\n",
      "9922 Traning Loss: tensor(27.0355)\n",
      "9923 Traning Loss: tensor(27.0273)\n",
      "9924 Traning Loss: tensor(27.0190)\n",
      "9925 Traning Loss: tensor(27.0107)\n",
      "9926 Traning Loss: tensor(27.0024)\n",
      "9927 Traning Loss: tensor(26.9941)\n",
      "9928 Traning Loss: tensor(26.9859)\n",
      "9929 Traning Loss: tensor(26.9776)\n",
      "9930 Traning Loss: tensor(26.9693)\n",
      "9931 Traning Loss: tensor(26.9611)\n",
      "9932 Traning Loss: tensor(26.9528)\n",
      "9933 Traning Loss: tensor(26.9445)\n",
      "9934 Traning Loss: tensor(26.9362)\n",
      "9935 Traning Loss: tensor(26.9280)\n",
      "9936 Traning Loss: tensor(26.9197)\n",
      "9937 Traning Loss: tensor(26.9114)\n",
      "9938 Traning Loss: tensor(26.9032)\n",
      "9939 Traning Loss: tensor(26.8949)\n",
      "9940 Traning Loss: tensor(26.8866)\n",
      "9941 Traning Loss: tensor(26.8784)\n",
      "9942 Traning Loss: tensor(26.8701)\n",
      "9943 Traning Loss: tensor(26.8619)\n",
      "9944 Traning Loss: tensor(26.8536)\n",
      "9945 Traning Loss: tensor(26.8453)\n",
      "9946 Traning Loss: tensor(26.8371)\n",
      "9947 Traning Loss: tensor(26.8288)\n",
      "9948 Traning Loss: tensor(26.8206)\n",
      "9949 Traning Loss: tensor(26.8123)\n",
      "9950 Traning Loss: tensor(26.8041)\n",
      "9951 Traning Loss: tensor(26.7958)\n",
      "9952 Traning Loss: tensor(26.7876)\n",
      "9953 Traning Loss: tensor(26.7793)\n",
      "9954 Traning Loss: tensor(26.7711)\n",
      "9955 Traning Loss: tensor(26.7628)\n",
      "9956 Traning Loss: tensor(26.7546)\n",
      "9957 Traning Loss: tensor(26.7463)\n",
      "9958 Traning Loss: tensor(26.7381)\n",
      "9959 Traning Loss: tensor(26.7298)\n",
      "9960 Traning Loss: tensor(26.7216)\n",
      "9961 Traning Loss: tensor(26.7133)\n",
      "9962 Traning Loss: tensor(26.7051)\n",
      "9963 Traning Loss: tensor(26.6968)\n",
      "9964 Traning Loss: tensor(26.6886)\n",
      "9965 Traning Loss: tensor(26.6804)\n",
      "9966 Traning Loss: tensor(26.6716)\n",
      "9967 Traning Loss: tensor(26.6634)\n",
      "9968 Traning Loss: tensor(26.6552)\n",
      "9969 Traning Loss: tensor(26.6469)\n",
      "9970 Traning Loss: tensor(26.6387)\n",
      "9971 Traning Loss: tensor(26.6305)\n",
      "9972 Traning Loss: tensor(26.6223)\n",
      "9973 Traning Loss: tensor(26.6140)\n",
      "9974 Traning Loss: tensor(26.6058)\n",
      "9975 Traning Loss: tensor(26.5976)\n",
      "9976 Traning Loss: tensor(26.5894)\n",
      "9977 Traning Loss: tensor(26.5812)\n",
      "9978 Traning Loss: tensor(26.5729)\n",
      "9979 Traning Loss: tensor(26.5647)\n",
      "9980 Traning Loss: tensor(26.5565)\n",
      "9981 Traning Loss: tensor(26.5483)\n",
      "9982 Traning Loss: tensor(26.5401)\n",
      "9983 Traning Loss: tensor(26.5319)\n",
      "9984 Traning Loss: tensor(26.5237)\n",
      "9985 Traning Loss: tensor(26.5154)\n",
      "9986 Traning Loss: tensor(26.5072)\n",
      "9987 Traning Loss: tensor(26.4990)\n",
      "9988 Traning Loss: tensor(26.4908)\n",
      "9989 Traning Loss: tensor(26.4826)\n",
      "9990 Traning Loss: tensor(26.4744)\n",
      "9991 Traning Loss: tensor(26.4662)\n",
      "9992 Traning Loss: tensor(26.4580)\n",
      "9993 Traning Loss: tensor(26.4498)\n",
      "9994 Traning Loss: tensor(26.4416)\n",
      "9995 Traning Loss: tensor(26.4334)\n",
      "9996 Traning Loss: tensor(26.4252)\n",
      "9997 Traning Loss: tensor(26.4170)\n",
      "9998 Traning Loss: tensor(26.4088)\n",
      "9999 Traning Loss: tensor(26.4006)\n",
      "10000 Traning Loss: tensor(26.3924)\n",
      "10001 Traning Loss: tensor(26.3843)\n",
      "10002 Traning Loss: tensor(26.3760)\n",
      "10003 Traning Loss: tensor(26.3679)\n",
      "10004 Traning Loss: tensor(26.3597)\n",
      "10005 Traning Loss: tensor(26.3515)\n",
      "10006 Traning Loss: tensor(26.3433)\n",
      "10007 Traning Loss: tensor(26.3351)\n",
      "10008 Traning Loss: tensor(26.3269)\n",
      "10009 Traning Loss: tensor(26.3187)\n",
      "10010 Traning Loss: tensor(26.3106)\n",
      "10011 Traning Loss: tensor(26.3024)\n",
      "10012 Traning Loss: tensor(26.2942)\n",
      "10013 Traning Loss: tensor(26.2860)\n",
      "10014 Traning Loss: tensor(26.2778)\n",
      "10015 Traning Loss: tensor(26.2696)\n",
      "10016 Traning Loss: tensor(26.2615)\n",
      "10017 Traning Loss: tensor(26.2533)\n",
      "10018 Traning Loss: tensor(26.2451)\n",
      "10019 Traning Loss: tensor(26.2369)\n",
      "10020 Traning Loss: tensor(26.2288)\n",
      "10021 Traning Loss: tensor(26.2206)\n",
      "10022 Traning Loss: tensor(26.2124)\n",
      "10023 Traning Loss: tensor(26.2042)\n",
      "10024 Traning Loss: tensor(26.1960)\n",
      "10025 Traning Loss: tensor(26.1879)\n",
      "10026 Traning Loss: tensor(26.1797)\n",
      "10027 Traning Loss: tensor(26.1715)\n",
      "10028 Traning Loss: tensor(26.1634)\n",
      "10029 Traning Loss: tensor(26.1552)\n",
      "10030 Traning Loss: tensor(26.1470)\n",
      "10031 Traning Loss: tensor(26.1389)\n",
      "10032 Traning Loss: tensor(26.1307)\n",
      "10033 Traning Loss: tensor(26.1225)\n",
      "10034 Traning Loss: tensor(26.1144)\n",
      "10035 Traning Loss: tensor(26.1062)\n",
      "10036 Traning Loss: tensor(26.0980)\n",
      "10037 Traning Loss: tensor(26.0899)\n",
      "10038 Traning Loss: tensor(26.0812)\n",
      "10039 Traning Loss: tensor(26.0730)\n",
      "10040 Traning Loss: tensor(26.0649)\n",
      "10041 Traning Loss: tensor(26.0567)\n",
      "10042 Traning Loss: tensor(26.0486)\n",
      "10043 Traning Loss: tensor(26.0404)\n",
      "10044 Traning Loss: tensor(26.0323)\n",
      "10045 Traning Loss: tensor(26.0241)\n",
      "10046 Traning Loss: tensor(26.0160)\n",
      "10047 Traning Loss: tensor(26.0079)\n",
      "10048 Traning Loss: tensor(25.9997)\n",
      "10049 Traning Loss: tensor(25.9916)\n",
      "10050 Traning Loss: tensor(25.9835)\n",
      "10051 Traning Loss: tensor(25.9753)\n",
      "10052 Traning Loss: tensor(25.9672)\n",
      "10053 Traning Loss: tensor(25.9591)\n",
      "10054 Traning Loss: tensor(25.9509)\n",
      "10055 Traning Loss: tensor(25.9428)\n",
      "10056 Traning Loss: tensor(25.9347)\n",
      "10057 Traning Loss: tensor(25.9265)\n",
      "10058 Traning Loss: tensor(25.9184)\n",
      "10059 Traning Loss: tensor(25.9103)\n",
      "10060 Traning Loss: tensor(25.9022)\n",
      "10061 Traning Loss: tensor(25.8940)\n",
      "10062 Traning Loss: tensor(25.8859)\n",
      "10063 Traning Loss: tensor(25.8778)\n",
      "10064 Traning Loss: tensor(25.8697)\n",
      "10065 Traning Loss: tensor(25.8615)\n",
      "10066 Traning Loss: tensor(25.8534)\n",
      "10067 Traning Loss: tensor(25.8453)\n",
      "10068 Traning Loss: tensor(25.8372)\n",
      "10069 Traning Loss: tensor(25.8291)\n",
      "10070 Traning Loss: tensor(25.8209)\n",
      "10071 Traning Loss: tensor(25.8128)\n",
      "10072 Traning Loss: tensor(25.8047)\n",
      "10073 Traning Loss: tensor(25.7966)\n",
      "10074 Traning Loss: tensor(25.7885)\n",
      "10075 Traning Loss: tensor(25.7804)\n",
      "10076 Traning Loss: tensor(25.7723)\n",
      "10077 Traning Loss: tensor(25.7642)\n",
      "10078 Traning Loss: tensor(25.7561)\n",
      "10079 Traning Loss: tensor(25.7480)\n",
      "10080 Traning Loss: tensor(25.7398)\n",
      "10081 Traning Loss: tensor(25.7317)\n",
      "10082 Traning Loss: tensor(25.7236)\n",
      "10083 Traning Loss: tensor(25.7155)\n",
      "10084 Traning Loss: tensor(25.7074)\n",
      "10085 Traning Loss: tensor(25.6993)\n",
      "10086 Traning Loss: tensor(25.6912)\n",
      "10087 Traning Loss: tensor(25.6831)\n",
      "10088 Traning Loss: tensor(25.6750)\n",
      "10089 Traning Loss: tensor(25.6669)\n",
      "10090 Traning Loss: tensor(25.6588)\n",
      "10091 Traning Loss: tensor(25.6508)\n",
      "10092 Traning Loss: tensor(25.6427)\n",
      "10093 Traning Loss: tensor(25.6346)\n",
      "10094 Traning Loss: tensor(25.6265)\n",
      "10095 Traning Loss: tensor(25.6184)\n",
      "10096 Traning Loss: tensor(25.6103)\n",
      "10097 Traning Loss: tensor(25.6022)\n",
      "10098 Traning Loss: tensor(25.5941)\n",
      "10099 Traning Loss: tensor(25.5860)\n",
      "10100 Traning Loss: tensor(25.5779)\n",
      "10101 Traning Loss: tensor(25.5698)\n",
      "10102 Traning Loss: tensor(25.5617)\n",
      "10103 Traning Loss: tensor(25.5537)\n",
      "10104 Traning Loss: tensor(25.5456)\n",
      "10105 Traning Loss: tensor(25.5375)\n",
      "10106 Traning Loss: tensor(25.5294)\n",
      "10107 Traning Loss: tensor(25.5213)\n",
      "10108 Traning Loss: tensor(25.5132)\n",
      "10109 Traning Loss: tensor(25.5052)\n",
      "10110 Traning Loss: tensor(25.4971)\n",
      "10111 Traning Loss: tensor(25.4884)\n",
      "10112 Traning Loss: tensor(25.4804)\n",
      "10113 Traning Loss: tensor(25.4723)\n",
      "10114 Traning Loss: tensor(25.4642)\n",
      "10115 Traning Loss: tensor(25.4562)\n",
      "10116 Traning Loss: tensor(25.4481)\n",
      "10117 Traning Loss: tensor(25.4401)\n",
      "10118 Traning Loss: tensor(25.4320)\n",
      "10119 Traning Loss: tensor(25.4239)\n",
      "10120 Traning Loss: tensor(25.4159)\n",
      "10121 Traning Loss: tensor(25.4078)\n",
      "10122 Traning Loss: tensor(25.3998)\n",
      "10123 Traning Loss: tensor(25.3917)\n",
      "10124 Traning Loss: tensor(25.3837)\n",
      "10125 Traning Loss: tensor(25.3756)\n",
      "10126 Traning Loss: tensor(25.3676)\n",
      "10127 Traning Loss: tensor(25.3595)\n",
      "10128 Traning Loss: tensor(25.3515)\n",
      "10129 Traning Loss: tensor(25.3434)\n",
      "10130 Traning Loss: tensor(25.3354)\n",
      "10131 Traning Loss: tensor(25.3273)\n",
      "10132 Traning Loss: tensor(25.3193)\n",
      "10133 Traning Loss: tensor(25.3113)\n",
      "10134 Traning Loss: tensor(25.3032)\n",
      "10135 Traning Loss: tensor(25.2952)\n",
      "10136 Traning Loss: tensor(25.2871)\n",
      "10137 Traning Loss: tensor(25.2791)\n",
      "10138 Traning Loss: tensor(25.2711)\n",
      "10139 Traning Loss: tensor(25.2630)\n",
      "10140 Traning Loss: tensor(25.2550)\n",
      "10141 Traning Loss: tensor(25.2470)\n",
      "10142 Traning Loss: tensor(25.2389)\n",
      "10143 Traning Loss: tensor(25.2309)\n",
      "10144 Traning Loss: tensor(25.2229)\n",
      "10145 Traning Loss: tensor(25.2148)\n",
      "10146 Traning Loss: tensor(25.2068)\n",
      "10147 Traning Loss: tensor(25.1988)\n",
      "10148 Traning Loss: tensor(25.1907)\n",
      "10149 Traning Loss: tensor(25.1827)\n",
      "10150 Traning Loss: tensor(25.1747)\n",
      "10151 Traning Loss: tensor(25.1667)\n",
      "10152 Traning Loss: tensor(25.1586)\n",
      "10153 Traning Loss: tensor(25.1506)\n",
      "10154 Traning Loss: tensor(25.1426)\n",
      "10155 Traning Loss: tensor(25.1346)\n",
      "10156 Traning Loss: tensor(25.1266)\n",
      "10157 Traning Loss: tensor(25.1186)\n",
      "10158 Traning Loss: tensor(25.1105)\n",
      "10159 Traning Loss: tensor(25.1025)\n",
      "10160 Traning Loss: tensor(25.0945)\n",
      "10161 Traning Loss: tensor(25.0865)\n",
      "10162 Traning Loss: tensor(25.0785)\n",
      "10163 Traning Loss: tensor(25.0705)\n",
      "10164 Traning Loss: tensor(25.0625)\n",
      "10165 Traning Loss: tensor(25.0544)\n",
      "10166 Traning Loss: tensor(25.0464)\n",
      "10167 Traning Loss: tensor(25.0384)\n",
      "10168 Traning Loss: tensor(25.0304)\n",
      "10169 Traning Loss: tensor(25.0224)\n",
      "10170 Traning Loss: tensor(25.0144)\n",
      "10171 Traning Loss: tensor(25.0064)\n",
      "10172 Traning Loss: tensor(24.9984)\n",
      "10173 Traning Loss: tensor(24.9904)\n",
      "10174 Traning Loss: tensor(24.9824)\n",
      "10175 Traning Loss: tensor(24.9744)\n",
      "10176 Traning Loss: tensor(24.9664)\n",
      "10177 Traning Loss: tensor(24.9584)\n",
      "10178 Traning Loss: tensor(24.9504)\n",
      "10179 Traning Loss: tensor(24.9424)\n",
      "10180 Traning Loss: tensor(24.9344)\n",
      "10181 Traning Loss: tensor(24.9264)\n",
      "10182 Traning Loss: tensor(24.9184)\n",
      "10183 Traning Loss: tensor(24.9104)\n",
      "10184 Traning Loss: tensor(24.9024)\n",
      "10185 Traning Loss: tensor(24.8944)\n",
      "10186 Traning Loss: tensor(24.8858)\n",
      "10187 Traning Loss: tensor(24.8779)\n",
      "10188 Traning Loss: tensor(24.8699)\n",
      "10189 Traning Loss: tensor(24.8619)\n",
      "10190 Traning Loss: tensor(24.8539)\n",
      "10191 Traning Loss: tensor(24.8460)\n",
      "10192 Traning Loss: tensor(24.8380)\n",
      "10193 Traning Loss: tensor(24.8300)\n",
      "10194 Traning Loss: tensor(24.8220)\n",
      "10195 Traning Loss: tensor(24.8141)\n",
      "10196 Traning Loss: tensor(24.8061)\n",
      "10197 Traning Loss: tensor(24.7981)\n",
      "10198 Traning Loss: tensor(24.7902)\n",
      "10199 Traning Loss: tensor(24.7822)\n",
      "10200 Traning Loss: tensor(24.7742)\n",
      "10201 Traning Loss: tensor(24.7663)\n",
      "10202 Traning Loss: tensor(24.7583)\n",
      "10203 Traning Loss: tensor(24.7503)\n",
      "10204 Traning Loss: tensor(24.7424)\n",
      "10205 Traning Loss: tensor(24.7344)\n",
      "10206 Traning Loss: tensor(24.7265)\n",
      "10207 Traning Loss: tensor(24.7185)\n",
      "10208 Traning Loss: tensor(24.7106)\n",
      "10209 Traning Loss: tensor(24.7026)\n",
      "10210 Traning Loss: tensor(24.6947)\n",
      "10211 Traning Loss: tensor(24.6867)\n",
      "10212 Traning Loss: tensor(24.6788)\n",
      "10213 Traning Loss: tensor(24.6708)\n",
      "10214 Traning Loss: tensor(24.6629)\n",
      "10215 Traning Loss: tensor(24.6549)\n",
      "10216 Traning Loss: tensor(24.6470)\n",
      "10217 Traning Loss: tensor(24.6390)\n",
      "10218 Traning Loss: tensor(24.6311)\n",
      "10219 Traning Loss: tensor(24.6232)\n",
      "10220 Traning Loss: tensor(24.6152)\n",
      "10221 Traning Loss: tensor(24.6073)\n",
      "10222 Traning Loss: tensor(24.5993)\n",
      "10223 Traning Loss: tensor(24.5914)\n",
      "10224 Traning Loss: tensor(24.5834)\n",
      "10225 Traning Loss: tensor(24.5755)\n",
      "10226 Traning Loss: tensor(24.5676)\n",
      "10227 Traning Loss: tensor(24.5596)\n",
      "10228 Traning Loss: tensor(24.5517)\n",
      "10229 Traning Loss: tensor(24.5438)\n",
      "10230 Traning Loss: tensor(24.5358)\n",
      "10231 Traning Loss: tensor(24.5279)\n",
      "10232 Traning Loss: tensor(24.5200)\n",
      "10233 Traning Loss: tensor(24.5120)\n",
      "10234 Traning Loss: tensor(24.5041)\n",
      "10235 Traning Loss: tensor(24.4962)\n",
      "10236 Traning Loss: tensor(24.4882)\n",
      "10237 Traning Loss: tensor(24.4803)\n",
      "10238 Traning Loss: tensor(24.4724)\n",
      "10239 Traning Loss: tensor(24.4645)\n",
      "10240 Traning Loss: tensor(24.4565)\n",
      "10241 Traning Loss: tensor(24.4486)\n",
      "10242 Traning Loss: tensor(24.4407)\n",
      "10243 Traning Loss: tensor(24.4328)\n",
      "10244 Traning Loss: tensor(24.4249)\n",
      "10245 Traning Loss: tensor(24.4169)\n",
      "10246 Traning Loss: tensor(24.4090)\n",
      "10247 Traning Loss: tensor(24.4011)\n",
      "10248 Traning Loss: tensor(24.3932)\n",
      "10249 Traning Loss: tensor(24.3853)\n",
      "10250 Traning Loss: tensor(24.3774)\n",
      "10251 Traning Loss: tensor(24.3695)\n",
      "10252 Traning Loss: tensor(24.3615)\n",
      "10253 Traning Loss: tensor(24.3536)\n",
      "10254 Traning Loss: tensor(24.3457)\n",
      "10255 Traning Loss: tensor(24.3378)\n",
      "10256 Traning Loss: tensor(24.3299)\n",
      "10257 Traning Loss: tensor(24.3220)\n",
      "10258 Traning Loss: tensor(24.3141)\n",
      "10259 Traning Loss: tensor(24.3062)\n",
      "10260 Traning Loss: tensor(24.2983)\n",
      "10261 Traning Loss: tensor(24.2904)\n",
      "10262 Traning Loss: tensor(24.2825)\n",
      "10263 Traning Loss: tensor(24.2739)\n",
      "10264 Traning Loss: tensor(24.2661)\n",
      "10265 Traning Loss: tensor(24.2582)\n",
      "10266 Traning Loss: tensor(24.2503)\n",
      "10267 Traning Loss: tensor(24.2424)\n",
      "10268 Traning Loss: tensor(24.2345)\n",
      "10269 Traning Loss: tensor(24.2266)\n",
      "10270 Traning Loss: tensor(24.2187)\n",
      "10271 Traning Loss: tensor(24.2109)\n",
      "10272 Traning Loss: tensor(24.2030)\n",
      "10273 Traning Loss: tensor(24.1951)\n",
      "10274 Traning Loss: tensor(24.1872)\n",
      "10275 Traning Loss: tensor(24.1793)\n",
      "10276 Traning Loss: tensor(24.1715)\n",
      "10277 Traning Loss: tensor(24.1636)\n",
      "10278 Traning Loss: tensor(24.1557)\n",
      "10279 Traning Loss: tensor(24.1478)\n",
      "10280 Traning Loss: tensor(24.1400)\n",
      "10281 Traning Loss: tensor(24.1321)\n",
      "10282 Traning Loss: tensor(24.1242)\n",
      "10283 Traning Loss: tensor(24.1164)\n",
      "10284 Traning Loss: tensor(24.1085)\n",
      "10285 Traning Loss: tensor(24.1006)\n",
      "10286 Traning Loss: tensor(24.0928)\n",
      "10287 Traning Loss: tensor(24.0849)\n",
      "10288 Traning Loss: tensor(24.0771)\n",
      "10289 Traning Loss: tensor(24.0692)\n",
      "10290 Traning Loss: tensor(24.0613)\n",
      "10291 Traning Loss: tensor(24.0535)\n",
      "10292 Traning Loss: tensor(24.0456)\n",
      "10293 Traning Loss: tensor(24.0378)\n",
      "10294 Traning Loss: tensor(24.0299)\n",
      "10295 Traning Loss: tensor(24.0221)\n",
      "10296 Traning Loss: tensor(24.0142)\n",
      "10297 Traning Loss: tensor(24.0064)\n",
      "10298 Traning Loss: tensor(23.9985)\n",
      "10299 Traning Loss: tensor(23.9907)\n",
      "10300 Traning Loss: tensor(23.9828)\n",
      "10301 Traning Loss: tensor(23.9750)\n",
      "10302 Traning Loss: tensor(23.9671)\n",
      "10303 Traning Loss: tensor(23.9593)\n",
      "10304 Traning Loss: tensor(23.9514)\n",
      "10305 Traning Loss: tensor(23.9436)\n",
      "10306 Traning Loss: tensor(23.9357)\n",
      "10307 Traning Loss: tensor(23.9279)\n",
      "10308 Traning Loss: tensor(23.9201)\n",
      "10309 Traning Loss: tensor(23.9122)\n",
      "10310 Traning Loss: tensor(23.9044)\n",
      "10311 Traning Loss: tensor(23.8965)\n",
      "10312 Traning Loss: tensor(23.8887)\n",
      "10313 Traning Loss: tensor(23.8809)\n",
      "10314 Traning Loss: tensor(23.8730)\n",
      "10315 Traning Loss: tensor(23.8652)\n",
      "10316 Traning Loss: tensor(23.8574)\n",
      "10317 Traning Loss: tensor(23.8495)\n",
      "10318 Traning Loss: tensor(23.8417)\n",
      "10319 Traning Loss: tensor(23.8339)\n",
      "10320 Traning Loss: tensor(23.8260)\n",
      "10321 Traning Loss: tensor(23.8182)\n",
      "10322 Traning Loss: tensor(23.8104)\n",
      "10323 Traning Loss: tensor(23.8026)\n",
      "10324 Traning Loss: tensor(23.7947)\n",
      "10325 Traning Loss: tensor(23.7869)\n",
      "10326 Traning Loss: tensor(23.7791)\n",
      "10327 Traning Loss: tensor(23.7713)\n",
      "10328 Traning Loss: tensor(23.7634)\n",
      "10329 Traning Loss: tensor(23.7556)\n",
      "10330 Traning Loss: tensor(23.7478)\n",
      "10331 Traning Loss: tensor(23.7400)\n",
      "10332 Traning Loss: tensor(23.7322)\n",
      "10333 Traning Loss: tensor(23.7244)\n",
      "10334 Traning Loss: tensor(23.7165)\n",
      "10335 Traning Loss: tensor(23.7087)\n",
      "10336 Traning Loss: tensor(23.7009)\n",
      "10337 Traning Loss: tensor(23.6931)\n",
      "10338 Traning Loss: tensor(23.6853)\n",
      "10339 Traning Loss: tensor(23.6775)\n",
      "10340 Traning Loss: tensor(23.6697)\n",
      "10341 Traning Loss: tensor(23.6618)\n",
      "10342 Traning Loss: tensor(23.6534)\n",
      "10343 Traning Loss: tensor(23.6456)\n",
      "10344 Traning Loss: tensor(23.6378)\n",
      "10345 Traning Loss: tensor(23.6300)\n",
      "10346 Traning Loss: tensor(23.6222)\n",
      "10347 Traning Loss: tensor(23.6144)\n",
      "10348 Traning Loss: tensor(23.6066)\n",
      "10349 Traning Loss: tensor(23.5988)\n",
      "10350 Traning Loss: tensor(23.5911)\n",
      "10351 Traning Loss: tensor(23.5833)\n",
      "10352 Traning Loss: tensor(23.5755)\n",
      "10353 Traning Loss: tensor(23.5677)\n",
      "10354 Traning Loss: tensor(23.5599)\n",
      "10355 Traning Loss: tensor(23.5521)\n",
      "10356 Traning Loss: tensor(23.5444)\n",
      "10357 Traning Loss: tensor(23.5366)\n",
      "10358 Traning Loss: tensor(23.5288)\n",
      "10359 Traning Loss: tensor(23.5210)\n",
      "10360 Traning Loss: tensor(23.5132)\n",
      "10361 Traning Loss: tensor(23.5055)\n",
      "10362 Traning Loss: tensor(23.4977)\n",
      "10363 Traning Loss: tensor(23.4899)\n",
      "10364 Traning Loss: tensor(23.4822)\n",
      "10365 Traning Loss: tensor(23.4744)\n",
      "10366 Traning Loss: tensor(23.4666)\n",
      "10367 Traning Loss: tensor(23.4589)\n",
      "10368 Traning Loss: tensor(23.4511)\n",
      "10369 Traning Loss: tensor(23.4433)\n",
      "10370 Traning Loss: tensor(23.4356)\n",
      "10371 Traning Loss: tensor(23.4278)\n",
      "10372 Traning Loss: tensor(23.4201)\n",
      "10373 Traning Loss: tensor(23.4123)\n",
      "10374 Traning Loss: tensor(23.4045)\n",
      "10375 Traning Loss: tensor(23.3968)\n",
      "10376 Traning Loss: tensor(23.3890)\n",
      "10377 Traning Loss: tensor(23.3813)\n",
      "10378 Traning Loss: tensor(23.3735)\n",
      "10379 Traning Loss: tensor(23.3657)\n",
      "10380 Traning Loss: tensor(23.3580)\n",
      "10381 Traning Loss: tensor(23.3502)\n",
      "10382 Traning Loss: tensor(23.3425)\n",
      "10383 Traning Loss: tensor(23.3347)\n",
      "10384 Traning Loss: tensor(23.3270)\n",
      "10385 Traning Loss: tensor(23.3192)\n",
      "10386 Traning Loss: tensor(23.3115)\n",
      "10387 Traning Loss: tensor(23.3037)\n",
      "10388 Traning Loss: tensor(23.2960)\n",
      "10389 Traning Loss: tensor(23.2883)\n",
      "10390 Traning Loss: tensor(23.2805)\n",
      "10391 Traning Loss: tensor(23.2728)\n",
      "10392 Traning Loss: tensor(23.2650)\n",
      "10393 Traning Loss: tensor(23.2573)\n",
      "10394 Traning Loss: tensor(23.2496)\n",
      "10395 Traning Loss: tensor(23.2418)\n",
      "10396 Traning Loss: tensor(23.2341)\n",
      "10397 Traning Loss: tensor(23.2263)\n",
      "10398 Traning Loss: tensor(23.2186)\n",
      "10399 Traning Loss: tensor(23.2109)\n",
      "10400 Traning Loss: tensor(23.2031)\n",
      "10401 Traning Loss: tensor(23.1954)\n",
      "10402 Traning Loss: tensor(23.1877)\n",
      "10403 Traning Loss: tensor(23.1799)\n",
      "10404 Traning Loss: tensor(23.1722)\n",
      "10405 Traning Loss: tensor(23.1645)\n",
      "10406 Traning Loss: tensor(23.1567)\n",
      "10407 Traning Loss: tensor(23.1490)\n",
      "10408 Traning Loss: tensor(23.1413)\n",
      "10409 Traning Loss: tensor(23.1336)\n",
      "10410 Traning Loss: tensor(23.1258)\n",
      "10411 Traning Loss: tensor(23.1181)\n",
      "10412 Traning Loss: tensor(23.1104)\n",
      "10413 Traning Loss: tensor(23.1027)\n",
      "10414 Traning Loss: tensor(23.0950)\n",
      "10415 Traning Loss: tensor(23.0873)\n",
      "10416 Traning Loss: tensor(23.0795)\n",
      "10417 Traning Loss: tensor(23.0718)\n",
      "10418 Traning Loss: tensor(23.0641)\n",
      "10419 Traning Loss: tensor(23.0564)\n",
      "10420 Traning Loss: tensor(23.0487)\n",
      "10421 Traning Loss: tensor(23.0410)\n",
      "10422 Traning Loss: tensor(23.0332)\n",
      "10423 Traning Loss: tensor(23.0248)\n",
      "10424 Traning Loss: tensor(23.0172)\n",
      "10425 Traning Loss: tensor(23.0094)\n",
      "10426 Traning Loss: tensor(23.0018)\n",
      "10427 Traning Loss: tensor(22.9941)\n",
      "10428 Traning Loss: tensor(22.9864)\n",
      "10429 Traning Loss: tensor(22.9787)\n",
      "10430 Traning Loss: tensor(22.9710)\n",
      "10431 Traning Loss: tensor(22.9633)\n",
      "10432 Traning Loss: tensor(22.9556)\n",
      "10433 Traning Loss: tensor(22.9479)\n",
      "10434 Traning Loss: tensor(22.9402)\n",
      "10435 Traning Loss: tensor(22.9326)\n",
      "10436 Traning Loss: tensor(22.9249)\n",
      "10437 Traning Loss: tensor(22.9172)\n",
      "10438 Traning Loss: tensor(22.9095)\n",
      "10439 Traning Loss: tensor(22.9018)\n",
      "10440 Traning Loss: tensor(22.8942)\n",
      "10441 Traning Loss: tensor(22.8865)\n",
      "10442 Traning Loss: tensor(22.8788)\n",
      "10443 Traning Loss: tensor(22.8711)\n",
      "10444 Traning Loss: tensor(22.8635)\n",
      "10445 Traning Loss: tensor(22.8558)\n",
      "10446 Traning Loss: tensor(22.8481)\n",
      "10447 Traning Loss: tensor(22.8405)\n",
      "10448 Traning Loss: tensor(22.8328)\n",
      "10449 Traning Loss: tensor(22.8251)\n",
      "10450 Traning Loss: tensor(22.8174)\n",
      "10451 Traning Loss: tensor(22.8098)\n",
      "10452 Traning Loss: tensor(22.8021)\n",
      "10453 Traning Loss: tensor(22.7944)\n",
      "10454 Traning Loss: tensor(22.7868)\n",
      "10455 Traning Loss: tensor(22.7791)\n",
      "10456 Traning Loss: tensor(22.7715)\n",
      "10457 Traning Loss: tensor(22.7638)\n",
      "10458 Traning Loss: tensor(22.7561)\n",
      "10459 Traning Loss: tensor(22.7485)\n",
      "10460 Traning Loss: tensor(22.7408)\n",
      "10461 Traning Loss: tensor(22.7332)\n",
      "10462 Traning Loss: tensor(22.7255)\n",
      "10463 Traning Loss: tensor(22.7179)\n",
      "10464 Traning Loss: tensor(22.7102)\n",
      "10465 Traning Loss: tensor(22.7026)\n",
      "10466 Traning Loss: tensor(22.6949)\n",
      "10467 Traning Loss: tensor(22.6873)\n",
      "10468 Traning Loss: tensor(22.6796)\n",
      "10469 Traning Loss: tensor(22.6720)\n",
      "10470 Traning Loss: tensor(22.6643)\n",
      "10471 Traning Loss: tensor(22.6567)\n",
      "10472 Traning Loss: tensor(22.6490)\n",
      "10473 Traning Loss: tensor(22.6414)\n",
      "10474 Traning Loss: tensor(22.6337)\n",
      "10475 Traning Loss: tensor(22.6261)\n",
      "10476 Traning Loss: tensor(22.6185)\n",
      "10477 Traning Loss: tensor(22.6108)\n",
      "10478 Traning Loss: tensor(22.6032)\n",
      "10479 Traning Loss: tensor(22.5956)\n",
      "10480 Traning Loss: tensor(22.5879)\n",
      "10481 Traning Loss: tensor(22.5803)\n",
      "10482 Traning Loss: tensor(22.5726)\n",
      "10483 Traning Loss: tensor(22.5650)\n",
      "10484 Traning Loss: tensor(22.5574)\n",
      "10485 Traning Loss: tensor(22.5497)\n",
      "10486 Traning Loss: tensor(22.5421)\n",
      "10487 Traning Loss: tensor(22.5345)\n",
      "10488 Traning Loss: tensor(22.5269)\n",
      "10489 Traning Loss: tensor(22.5192)\n",
      "10490 Traning Loss: tensor(22.5116)\n",
      "10491 Traning Loss: tensor(22.5040)\n",
      "10492 Traning Loss: tensor(22.4963)\n",
      "10493 Traning Loss: tensor(22.4887)\n",
      "10494 Traning Loss: tensor(22.4811)\n",
      "10495 Traning Loss: tensor(22.4735)\n",
      "10496 Traning Loss: tensor(22.4659)\n",
      "10497 Traning Loss: tensor(22.4582)\n",
      "10498 Traning Loss: tensor(22.4506)\n",
      "10499 Traning Loss: tensor(22.4430)\n",
      "10500 Traning Loss: tensor(22.4354)\n",
      "10501 Traning Loss: tensor(22.4278)\n",
      "10502 Traning Loss: tensor(22.4202)\n",
      "10503 Traning Loss: tensor(22.4126)\n",
      "10504 Traning Loss: tensor(22.4049)\n",
      "10505 Traning Loss: tensor(22.3973)\n",
      "10506 Traning Loss: tensor(22.3890)\n",
      "10507 Traning Loss: tensor(22.3814)\n",
      "10508 Traning Loss: tensor(22.3738)\n",
      "10509 Traning Loss: tensor(22.3662)\n",
      "10510 Traning Loss: tensor(22.3586)\n",
      "10511 Traning Loss: tensor(22.3510)\n",
      "10512 Traning Loss: tensor(22.3434)\n",
      "10513 Traning Loss: tensor(22.3358)\n",
      "10514 Traning Loss: tensor(22.3283)\n",
      "10515 Traning Loss: tensor(22.3207)\n",
      "10516 Traning Loss: tensor(22.3131)\n",
      "10517 Traning Loss: tensor(22.3055)\n",
      "10518 Traning Loss: tensor(22.2979)\n",
      "10519 Traning Loss: tensor(22.2903)\n",
      "10520 Traning Loss: tensor(22.2828)\n",
      "10521 Traning Loss: tensor(22.2752)\n",
      "10522 Traning Loss: tensor(22.2676)\n",
      "10523 Traning Loss: tensor(22.2600)\n",
      "10524 Traning Loss: tensor(22.2524)\n",
      "10525 Traning Loss: tensor(22.2449)\n",
      "10526 Traning Loss: tensor(22.2373)\n",
      "10527 Traning Loss: tensor(22.2297)\n",
      "10528 Traning Loss: tensor(22.2221)\n",
      "10529 Traning Loss: tensor(22.2146)\n",
      "10530 Traning Loss: tensor(22.2070)\n",
      "10531 Traning Loss: tensor(22.1994)\n",
      "10532 Traning Loss: tensor(22.1919)\n",
      "10533 Traning Loss: tensor(22.1843)\n",
      "10534 Traning Loss: tensor(22.1768)\n",
      "10535 Traning Loss: tensor(22.1692)\n",
      "10536 Traning Loss: tensor(22.1616)\n",
      "10537 Traning Loss: tensor(22.1541)\n",
      "10538 Traning Loss: tensor(22.1465)\n",
      "10539 Traning Loss: tensor(22.1390)\n",
      "10540 Traning Loss: tensor(22.1314)\n",
      "10541 Traning Loss: tensor(22.1238)\n",
      "10542 Traning Loss: tensor(22.1163)\n",
      "10543 Traning Loss: tensor(22.1052)\n",
      "10544 Traning Loss: tensor(22.0976)\n",
      "10545 Traning Loss: tensor(22.0901)\n",
      "10546 Traning Loss: tensor(22.0825)\n",
      "10547 Traning Loss: tensor(22.0749)\n",
      "10548 Traning Loss: tensor(22.0674)\n",
      "10549 Traning Loss: tensor(22.0598)\n",
      "10550 Traning Loss: tensor(22.0522)\n",
      "10551 Traning Loss: tensor(22.0447)\n",
      "10552 Traning Loss: tensor(22.0371)\n",
      "10553 Traning Loss: tensor(22.0296)\n",
      "10554 Traning Loss: tensor(22.0220)\n",
      "10555 Traning Loss: tensor(22.0145)\n",
      "10556 Traning Loss: tensor(22.0069)\n",
      "10557 Traning Loss: tensor(21.9993)\n",
      "10558 Traning Loss: tensor(21.9918)\n",
      "10559 Traning Loss: tensor(21.9842)\n",
      "10560 Traning Loss: tensor(21.9767)\n",
      "10561 Traning Loss: tensor(21.9691)\n",
      "10562 Traning Loss: tensor(21.9616)\n",
      "10563 Traning Loss: tensor(21.9540)\n",
      "10564 Traning Loss: tensor(21.9465)\n",
      "10565 Traning Loss: tensor(21.9389)\n",
      "10566 Traning Loss: tensor(21.9314)\n",
      "10567 Traning Loss: tensor(21.9238)\n",
      "10568 Traning Loss: tensor(21.9163)\n",
      "10569 Traning Loss: tensor(21.9088)\n",
      "10570 Traning Loss: tensor(21.9012)\n",
      "10571 Traning Loss: tensor(21.8937)\n",
      "10572 Traning Loss: tensor(21.8861)\n",
      "10573 Traning Loss: tensor(21.8786)\n",
      "10574 Traning Loss: tensor(21.8710)\n",
      "10575 Traning Loss: tensor(21.8635)\n",
      "10576 Traning Loss: tensor(21.8560)\n",
      "10577 Traning Loss: tensor(21.8484)\n",
      "10578 Traning Loss: tensor(21.8409)\n",
      "10579 Traning Loss: tensor(21.8334)\n",
      "10580 Traning Loss: tensor(21.8258)\n",
      "10581 Traning Loss: tensor(21.8183)\n",
      "10582 Traning Loss: tensor(21.8108)\n",
      "10583 Traning Loss: tensor(21.8032)\n",
      "10584 Traning Loss: tensor(21.7957)\n",
      "10585 Traning Loss: tensor(21.7882)\n",
      "10586 Traning Loss: tensor(21.7807)\n",
      "10587 Traning Loss: tensor(21.7731)\n",
      "10588 Traning Loss: tensor(21.7656)\n",
      "10589 Traning Loss: tensor(21.7581)\n",
      "10590 Traning Loss: tensor(21.7505)\n",
      "10591 Traning Loss: tensor(21.7430)\n",
      "10592 Traning Loss: tensor(21.7347)\n",
      "10593 Traning Loss: tensor(21.7272)\n",
      "10594 Traning Loss: tensor(21.7197)\n",
      "10595 Traning Loss: tensor(21.7122)\n",
      "10596 Traning Loss: tensor(21.7047)\n",
      "10597 Traning Loss: tensor(21.6972)\n",
      "10598 Traning Loss: tensor(21.6897)\n",
      "10599 Traning Loss: tensor(21.6822)\n",
      "10600 Traning Loss: tensor(21.6747)\n",
      "10601 Traning Loss: tensor(21.6672)\n",
      "10602 Traning Loss: tensor(21.6597)\n",
      "10603 Traning Loss: tensor(21.6522)\n",
      "10604 Traning Loss: tensor(21.6447)\n",
      "10605 Traning Loss: tensor(21.6372)\n",
      "10606 Traning Loss: tensor(21.6297)\n",
      "10607 Traning Loss: tensor(21.6222)\n",
      "10608 Traning Loss: tensor(21.6148)\n",
      "10609 Traning Loss: tensor(21.6073)\n",
      "10610 Traning Loss: tensor(21.5998)\n",
      "10611 Traning Loss: tensor(21.5923)\n",
      "10612 Traning Loss: tensor(21.5848)\n",
      "10613 Traning Loss: tensor(21.5773)\n",
      "10614 Traning Loss: tensor(21.5699)\n",
      "10615 Traning Loss: tensor(21.5624)\n",
      "10616 Traning Loss: tensor(21.5549)\n",
      "10617 Traning Loss: tensor(21.5474)\n",
      "10618 Traning Loss: tensor(21.5399)\n",
      "10619 Traning Loss: tensor(21.5325)\n",
      "10620 Traning Loss: tensor(21.5250)\n",
      "10621 Traning Loss: tensor(21.5175)\n",
      "10622 Traning Loss: tensor(21.5100)\n",
      "10623 Traning Loss: tensor(21.5026)\n",
      "10624 Traning Loss: tensor(21.4951)\n",
      "10625 Traning Loss: tensor(21.4876)\n",
      "10626 Traning Loss: tensor(21.4802)\n",
      "10627 Traning Loss: tensor(21.4727)\n",
      "10628 Traning Loss: tensor(21.4652)\n",
      "10629 Traning Loss: tensor(21.4578)\n",
      "10630 Traning Loss: tensor(21.4503)\n",
      "10631 Traning Loss: tensor(21.4429)\n",
      "10632 Traning Loss: tensor(21.4354)\n",
      "10633 Traning Loss: tensor(21.4279)\n",
      "10634 Traning Loss: tensor(21.4205)\n",
      "10635 Traning Loss: tensor(21.4130)\n",
      "10636 Traning Loss: tensor(21.4055)\n",
      "10637 Traning Loss: tensor(21.3981)\n",
      "10638 Traning Loss: tensor(21.3906)\n",
      "10639 Traning Loss: tensor(21.3832)\n",
      "10640 Traning Loss: tensor(21.3757)\n",
      "10641 Traning Loss: tensor(21.3683)\n",
      "10642 Traning Loss: tensor(21.3608)\n",
      "10643 Traning Loss: tensor(21.3534)\n",
      "10644 Traning Loss: tensor(21.3459)\n",
      "10645 Traning Loss: tensor(21.3385)\n",
      "10646 Traning Loss: tensor(21.3310)\n",
      "10647 Traning Loss: tensor(21.3236)\n",
      "10648 Traning Loss: tensor(21.3161)\n",
      "10649 Traning Loss: tensor(21.3087)\n",
      "10650 Traning Loss: tensor(21.3012)\n",
      "10651 Traning Loss: tensor(21.2938)\n",
      "10652 Traning Loss: tensor(21.2864)\n",
      "10653 Traning Loss: tensor(21.2789)\n",
      "10654 Traning Loss: tensor(21.2715)\n",
      "10655 Traning Loss: tensor(21.2640)\n",
      "10656 Traning Loss: tensor(21.2566)\n",
      "10657 Traning Loss: tensor(21.2492)\n",
      "10658 Traning Loss: tensor(21.2417)\n",
      "10659 Traning Loss: tensor(21.2343)\n",
      "10660 Traning Loss: tensor(21.2269)\n",
      "10661 Traning Loss: tensor(21.2194)\n",
      "10662 Traning Loss: tensor(21.2120)\n",
      "10663 Traning Loss: tensor(21.2046)\n",
      "10664 Traning Loss: tensor(21.1971)\n",
      "10665 Traning Loss: tensor(21.1897)\n",
      "10666 Traning Loss: tensor(21.1823)\n",
      "10667 Traning Loss: tensor(21.1749)\n",
      "10668 Traning Loss: tensor(21.1674)\n",
      "10669 Traning Loss: tensor(21.1600)\n",
      "10670 Traning Loss: tensor(21.1526)\n",
      "10671 Traning Loss: tensor(21.1452)\n",
      "10672 Traning Loss: tensor(21.1377)\n",
      "10673 Traning Loss: tensor(21.1303)\n",
      "10674 Traning Loss: tensor(21.1229)\n",
      "10675 Traning Loss: tensor(21.1155)\n",
      "10676 Traning Loss: tensor(21.1081)\n",
      "10677 Traning Loss: tensor(21.1006)\n",
      "10678 Traning Loss: tensor(21.0932)\n",
      "10679 Traning Loss: tensor(21.0858)\n",
      "10680 Traning Loss: tensor(21.0784)\n",
      "10681 Traning Loss: tensor(21.0710)\n",
      "10682 Traning Loss: tensor(21.0628)\n",
      "10683 Traning Loss: tensor(21.0554)\n",
      "10684 Traning Loss: tensor(21.0480)\n",
      "10685 Traning Loss: tensor(21.0406)\n",
      "10686 Traning Loss: tensor(21.0332)\n",
      "10687 Traning Loss: tensor(21.0258)\n",
      "10688 Traning Loss: tensor(21.0184)\n",
      "10689 Traning Loss: tensor(21.0110)\n",
      "10690 Traning Loss: tensor(21.0036)\n",
      "10691 Traning Loss: tensor(20.9962)\n",
      "10692 Traning Loss: tensor(20.9889)\n",
      "10693 Traning Loss: tensor(20.9815)\n",
      "10694 Traning Loss: tensor(20.9741)\n",
      "10695 Traning Loss: tensor(20.9667)\n",
      "10696 Traning Loss: tensor(20.9593)\n",
      "10697 Traning Loss: tensor(20.9520)\n",
      "10698 Traning Loss: tensor(20.9446)\n",
      "10699 Traning Loss: tensor(20.9372)\n",
      "10700 Traning Loss: tensor(20.9298)\n",
      "10701 Traning Loss: tensor(20.9225)\n",
      "10702 Traning Loss: tensor(20.9151)\n",
      "10703 Traning Loss: tensor(20.9077)\n",
      "10704 Traning Loss: tensor(20.9003)\n",
      "10705 Traning Loss: tensor(20.8930)\n",
      "10706 Traning Loss: tensor(20.8856)\n",
      "10707 Traning Loss: tensor(20.8782)\n",
      "10708 Traning Loss: tensor(20.8709)\n",
      "10709 Traning Loss: tensor(20.8635)\n",
      "10710 Traning Loss: tensor(20.8562)\n",
      "10711 Traning Loss: tensor(20.8488)\n",
      "10712 Traning Loss: tensor(20.8414)\n",
      "10713 Traning Loss: tensor(20.8341)\n",
      "10714 Traning Loss: tensor(20.8267)\n",
      "10715 Traning Loss: tensor(20.8194)\n",
      "10716 Traning Loss: tensor(20.8120)\n",
      "10717 Traning Loss: tensor(20.8046)\n",
      "10718 Traning Loss: tensor(20.7973)\n",
      "10719 Traning Loss: tensor(20.7899)\n",
      "10720 Traning Loss: tensor(20.7826)\n",
      "10721 Traning Loss: tensor(20.7752)\n",
      "10722 Traning Loss: tensor(20.7679)\n",
      "10723 Traning Loss: tensor(20.7605)\n",
      "10724 Traning Loss: tensor(20.7532)\n",
      "10725 Traning Loss: tensor(20.7458)\n",
      "10726 Traning Loss: tensor(20.7385)\n",
      "10727 Traning Loss: tensor(20.7311)\n",
      "10728 Traning Loss: tensor(20.7238)\n",
      "10729 Traning Loss: tensor(20.7165)\n",
      "10730 Traning Loss: tensor(20.7091)\n",
      "10731 Traning Loss: tensor(20.7018)\n",
      "10732 Traning Loss: tensor(20.6944)\n",
      "10733 Traning Loss: tensor(20.6871)\n",
      "10734 Traning Loss: tensor(20.6798)\n",
      "10735 Traning Loss: tensor(20.6724)\n",
      "10736 Traning Loss: tensor(20.6651)\n",
      "10737 Traning Loss: tensor(20.6577)\n",
      "10738 Traning Loss: tensor(20.6504)\n",
      "10739 Traning Loss: tensor(20.6431)\n",
      "10740 Traning Loss: tensor(20.6357)\n",
      "10741 Traning Loss: tensor(20.6284)\n",
      "10742 Traning Loss: tensor(20.6211)\n",
      "10743 Traning Loss: tensor(20.6138)\n",
      "10744 Traning Loss: tensor(20.6064)\n",
      "10745 Traning Loss: tensor(20.5991)\n",
      "10746 Traning Loss: tensor(20.5918)\n",
      "10747 Traning Loss: tensor(20.5845)\n",
      "10748 Traning Loss: tensor(20.5771)\n",
      "10749 Traning Loss: tensor(20.5698)\n",
      "10750 Traning Loss: tensor(20.5625)\n",
      "10751 Traning Loss: tensor(20.5552)\n",
      "10752 Traning Loss: tensor(20.5478)\n",
      "10753 Traning Loss: tensor(20.5405)\n",
      "10754 Traning Loss: tensor(20.5332)\n",
      "10755 Traning Loss: tensor(20.5259)\n",
      "10756 Traning Loss: tensor(20.5186)\n",
      "10757 Traning Loss: tensor(20.5113)\n",
      "10758 Traning Loss: tensor(20.5039)\n",
      "10759 Traning Loss: tensor(20.4966)\n",
      "10760 Traning Loss: tensor(20.4893)\n",
      "10761 Traning Loss: tensor(20.4820)\n",
      "10762 Traning Loss: tensor(20.4747)\n",
      "10763 Traning Loss: tensor(20.4674)\n",
      "10764 Traning Loss: tensor(20.4601)\n",
      "10765 Traning Loss: tensor(20.4528)\n",
      "10766 Traning Loss: tensor(20.4455)\n",
      "10767 Traning Loss: tensor(20.4382)\n",
      "10768 Traning Loss: tensor(20.4309)\n",
      "10769 Traning Loss: tensor(20.4236)\n",
      "10770 Traning Loss: tensor(20.4163)\n",
      "10771 Traning Loss: tensor(20.4090)\n",
      "10772 Traning Loss: tensor(20.4017)\n",
      "10773 Traning Loss: tensor(20.3944)\n",
      "10774 Traning Loss: tensor(20.3862)\n",
      "10775 Traning Loss: tensor(20.3789)\n",
      "10776 Traning Loss: tensor(20.3716)\n",
      "10777 Traning Loss: tensor(20.3644)\n",
      "10778 Traning Loss: tensor(20.3571)\n",
      "10779 Traning Loss: tensor(20.3498)\n",
      "10780 Traning Loss: tensor(20.3425)\n",
      "10781 Traning Loss: tensor(20.3353)\n",
      "10782 Traning Loss: tensor(20.3280)\n",
      "10783 Traning Loss: tensor(20.3207)\n",
      "10784 Traning Loss: tensor(20.3134)\n",
      "10785 Traning Loss: tensor(20.3062)\n",
      "10786 Traning Loss: tensor(20.2989)\n",
      "10787 Traning Loss: tensor(20.2916)\n",
      "10788 Traning Loss: tensor(20.2844)\n",
      "10789 Traning Loss: tensor(20.2771)\n",
      "10790 Traning Loss: tensor(20.2699)\n",
      "10791 Traning Loss: tensor(20.2626)\n",
      "10792 Traning Loss: tensor(20.2553)\n",
      "10793 Traning Loss: tensor(20.2481)\n",
      "10794 Traning Loss: tensor(20.2408)\n",
      "10795 Traning Loss: tensor(20.2336)\n",
      "10796 Traning Loss: tensor(20.2263)\n",
      "10797 Traning Loss: tensor(20.2191)\n",
      "10798 Traning Loss: tensor(20.2118)\n",
      "10799 Traning Loss: tensor(20.2045)\n",
      "10800 Traning Loss: tensor(20.1973)\n",
      "10801 Traning Loss: tensor(20.1900)\n",
      "10802 Traning Loss: tensor(20.1828)\n",
      "10803 Traning Loss: tensor(20.1756)\n",
      "10804 Traning Loss: tensor(20.1683)\n",
      "10805 Traning Loss: tensor(20.1611)\n",
      "10806 Traning Loss: tensor(20.1538)\n",
      "10807 Traning Loss: tensor(20.1466)\n",
      "10808 Traning Loss: tensor(20.1393)\n",
      "10809 Traning Loss: tensor(20.1321)\n",
      "10810 Traning Loss: tensor(20.1249)\n",
      "10811 Traning Loss: tensor(20.1176)\n",
      "10812 Traning Loss: tensor(20.1104)\n",
      "10813 Traning Loss: tensor(20.1031)\n",
      "10814 Traning Loss: tensor(20.0959)\n",
      "10815 Traning Loss: tensor(20.0887)\n",
      "10816 Traning Loss: tensor(20.0814)\n",
      "10817 Traning Loss: tensor(20.0742)\n",
      "10818 Traning Loss: tensor(20.0670)\n",
      "10819 Traning Loss: tensor(20.0597)\n",
      "10820 Traning Loss: tensor(20.0525)\n",
      "10821 Traning Loss: tensor(20.0453)\n",
      "10822 Traning Loss: tensor(20.0381)\n",
      "10823 Traning Loss: tensor(20.0308)\n",
      "10824 Traning Loss: tensor(20.0236)\n",
      "10825 Traning Loss: tensor(20.0164)\n",
      "10826 Traning Loss: tensor(20.0092)\n",
      "10827 Traning Loss: tensor(20.0019)\n",
      "10828 Traning Loss: tensor(19.9947)\n",
      "10829 Traning Loss: tensor(19.9875)\n",
      "10830 Traning Loss: tensor(19.9803)\n",
      "10831 Traning Loss: tensor(19.9731)\n",
      "10832 Traning Loss: tensor(19.9658)\n",
      "10833 Traning Loss: tensor(19.9586)\n",
      "10834 Traning Loss: tensor(19.9514)\n",
      "10835 Traning Loss: tensor(19.9442)\n",
      "10836 Traning Loss: tensor(19.9370)\n",
      "10837 Traning Loss: tensor(19.9298)\n",
      "10838 Traning Loss: tensor(19.9226)\n",
      "10839 Traning Loss: tensor(19.9154)\n",
      "10840 Traning Loss: tensor(19.9081)\n",
      "10841 Traning Loss: tensor(19.9009)\n",
      "10842 Traning Loss: tensor(19.8937)\n",
      "10843 Traning Loss: tensor(19.8865)\n",
      "10844 Traning Loss: tensor(19.8793)\n",
      "10845 Traning Loss: tensor(19.8721)\n",
      "10846 Traning Loss: tensor(19.8649)\n",
      "10847 Traning Loss: tensor(19.8577)\n",
      "10848 Traning Loss: tensor(19.8505)\n",
      "10849 Traning Loss: tensor(19.8433)\n",
      "10850 Traning Loss: tensor(19.8361)\n",
      "10851 Traning Loss: tensor(19.8289)\n",
      "10852 Traning Loss: tensor(19.8217)\n",
      "10853 Traning Loss: tensor(19.8145)\n",
      "10854 Traning Loss: tensor(19.8073)\n",
      "10855 Traning Loss: tensor(19.8001)\n",
      "10856 Traning Loss: tensor(19.7929)\n",
      "10857 Traning Loss: tensor(19.7858)\n",
      "10858 Traning Loss: tensor(19.7786)\n",
      "10859 Traning Loss: tensor(19.7714)\n",
      "10860 Traning Loss: tensor(19.7642)\n",
      "10861 Traning Loss: tensor(19.7570)\n",
      "10862 Traning Loss: tensor(19.7498)\n",
      "10863 Traning Loss: tensor(19.7426)\n",
      "10864 Traning Loss: tensor(19.7354)\n",
      "10865 Traning Loss: tensor(19.7283)\n",
      "10866 Traning Loss: tensor(19.7211)\n",
      "10867 Traning Loss: tensor(19.7139)\n",
      "10868 Traning Loss: tensor(19.7067)\n",
      "10869 Traning Loss: tensor(19.6986)\n",
      "10870 Traning Loss: tensor(19.6914)\n",
      "10871 Traning Loss: tensor(19.6843)\n",
      "10872 Traning Loss: tensor(19.6771)\n",
      "10873 Traning Loss: tensor(19.6700)\n",
      "10874 Traning Loss: tensor(19.6628)\n",
      "10875 Traning Loss: tensor(19.6556)\n",
      "10876 Traning Loss: tensor(19.6485)\n",
      "10877 Traning Loss: tensor(19.6413)\n",
      "10878 Traning Loss: tensor(19.6342)\n",
      "10879 Traning Loss: tensor(19.6270)\n",
      "10880 Traning Loss: tensor(19.6199)\n",
      "10881 Traning Loss: tensor(19.6127)\n",
      "10882 Traning Loss: tensor(19.6056)\n",
      "10883 Traning Loss: tensor(19.5984)\n",
      "10884 Traning Loss: tensor(19.5913)\n",
      "10885 Traning Loss: tensor(19.5841)\n",
      "10886 Traning Loss: tensor(19.5770)\n",
      "10887 Traning Loss: tensor(19.5699)\n",
      "10888 Traning Loss: tensor(19.5627)\n",
      "10889 Traning Loss: tensor(19.5556)\n",
      "10890 Traning Loss: tensor(19.5485)\n",
      "10891 Traning Loss: tensor(19.5413)\n",
      "10892 Traning Loss: tensor(19.5342)\n",
      "10893 Traning Loss: tensor(19.5271)\n",
      "10894 Traning Loss: tensor(19.5199)\n",
      "10895 Traning Loss: tensor(19.5128)\n",
      "10896 Traning Loss: tensor(19.5057)\n",
      "10897 Traning Loss: tensor(19.4985)\n",
      "10898 Traning Loss: tensor(19.4914)\n",
      "10899 Traning Loss: tensor(19.4843)\n",
      "10900 Traning Loss: tensor(19.4771)\n",
      "10901 Traning Loss: tensor(19.4700)\n",
      "10902 Traning Loss: tensor(19.4629)\n",
      "10903 Traning Loss: tensor(19.4558)\n",
      "10904 Traning Loss: tensor(19.4487)\n",
      "10905 Traning Loss: tensor(19.4415)\n",
      "10906 Traning Loss: tensor(19.4344)\n",
      "10907 Traning Loss: tensor(19.4273)\n",
      "10908 Traning Loss: tensor(19.4202)\n",
      "10909 Traning Loss: tensor(19.4131)\n",
      "10910 Traning Loss: tensor(19.4059)\n",
      "10911 Traning Loss: tensor(19.3988)\n",
      "10912 Traning Loss: tensor(19.3917)\n",
      "10913 Traning Loss: tensor(19.3846)\n",
      "10914 Traning Loss: tensor(19.3775)\n",
      "10915 Traning Loss: tensor(19.3704)\n",
      "10916 Traning Loss: tensor(19.3633)\n",
      "10917 Traning Loss: tensor(19.3562)\n",
      "10918 Traning Loss: tensor(19.3491)\n",
      "10919 Traning Loss: tensor(19.3420)\n",
      "10920 Traning Loss: tensor(19.3349)\n",
      "10921 Traning Loss: tensor(19.3278)\n",
      "10922 Traning Loss: tensor(19.3206)\n",
      "10923 Traning Loss: tensor(19.3135)\n",
      "10924 Traning Loss: tensor(19.3064)\n",
      "10925 Traning Loss: tensor(19.2993)\n",
      "10926 Traning Loss: tensor(19.2922)\n",
      "10927 Traning Loss: tensor(19.2851)\n",
      "10928 Traning Loss: tensor(19.2780)\n",
      "10929 Traning Loss: tensor(19.2710)\n",
      "10930 Traning Loss: tensor(19.2639)\n",
      "10931 Traning Loss: tensor(19.2568)\n",
      "10932 Traning Loss: tensor(19.2497)\n",
      "10933 Traning Loss: tensor(19.2426)\n",
      "10934 Traning Loss: tensor(19.2355)\n",
      "10935 Traning Loss: tensor(19.2284)\n",
      "10936 Traning Loss: tensor(19.2213)\n",
      "10937 Traning Loss: tensor(19.2142)\n",
      "10938 Traning Loss: tensor(19.2071)\n",
      "10939 Traning Loss: tensor(19.2001)\n",
      "10940 Traning Loss: tensor(19.1930)\n",
      "10941 Traning Loss: tensor(19.1859)\n",
      "10942 Traning Loss: tensor(19.1788)\n",
      "10943 Traning Loss: tensor(19.1717)\n",
      "10944 Traning Loss: tensor(19.1646)\n",
      "10945 Traning Loss: tensor(19.1576)\n",
      "10946 Traning Loss: tensor(19.1505)\n",
      "10947 Traning Loss: tensor(19.1434)\n",
      "10948 Traning Loss: tensor(19.1363)\n",
      "10949 Traning Loss: tensor(19.1293)\n",
      "10950 Traning Loss: tensor(19.1222)\n",
      "10951 Traning Loss: tensor(19.1151)\n",
      "10952 Traning Loss: tensor(19.1080)\n",
      "10953 Traning Loss: tensor(19.1010)\n",
      "10954 Traning Loss: tensor(19.0939)\n",
      "10955 Traning Loss: tensor(19.0868)\n",
      "10956 Traning Loss: tensor(19.0798)\n",
      "10957 Traning Loss: tensor(19.0727)\n",
      "10958 Traning Loss: tensor(19.0656)\n",
      "10959 Traning Loss: tensor(19.0586)\n",
      "10960 Traning Loss: tensor(19.0515)\n",
      "10961 Traning Loss: tensor(19.0444)\n",
      "10962 Traning Loss: tensor(19.0374)\n",
      "10963 Traning Loss: tensor(19.0303)\n",
      "10964 Traning Loss: tensor(19.0232)\n",
      "10965 Traning Loss: tensor(19.0162)\n",
      "10966 Traning Loss: tensor(19.0091)\n",
      "10967 Traning Loss: tensor(19.0011)\n",
      "10968 Traning Loss: tensor(18.9940)\n",
      "10969 Traning Loss: tensor(18.9870)\n",
      "10970 Traning Loss: tensor(18.9800)\n",
      "10971 Traning Loss: tensor(18.9729)\n",
      "10972 Traning Loss: tensor(18.9659)\n",
      "10973 Traning Loss: tensor(18.9588)\n",
      "10974 Traning Loss: tensor(18.9518)\n",
      "10975 Traning Loss: tensor(18.9448)\n",
      "10976 Traning Loss: tensor(18.9377)\n",
      "10977 Traning Loss: tensor(18.9307)\n",
      "10978 Traning Loss: tensor(18.9237)\n",
      "10979 Traning Loss: tensor(18.9167)\n",
      "10980 Traning Loss: tensor(18.9097)\n",
      "10981 Traning Loss: tensor(18.9026)\n",
      "10982 Traning Loss: tensor(18.8956)\n",
      "10983 Traning Loss: tensor(18.8886)\n",
      "10984 Traning Loss: tensor(18.8816)\n",
      "10985 Traning Loss: tensor(18.8746)\n",
      "10986 Traning Loss: tensor(18.8675)\n",
      "10987 Traning Loss: tensor(18.8605)\n",
      "10988 Traning Loss: tensor(18.8535)\n",
      "10989 Traning Loss: tensor(18.8465)\n",
      "10990 Traning Loss: tensor(18.8395)\n",
      "10991 Traning Loss: tensor(18.8325)\n",
      "10992 Traning Loss: tensor(18.8255)\n",
      "10993 Traning Loss: tensor(18.8185)\n",
      "10994 Traning Loss: tensor(18.8115)\n",
      "10995 Traning Loss: tensor(18.8045)\n",
      "10996 Traning Loss: tensor(18.7974)\n",
      "10997 Traning Loss: tensor(18.7904)\n",
      "10998 Traning Loss: tensor(18.7834)\n",
      "10999 Traning Loss: tensor(18.7764)\n",
      "11000 Traning Loss: tensor(18.7694)\n",
      "11001 Traning Loss: tensor(18.7624)\n",
      "11002 Traning Loss: tensor(18.7554)\n",
      "11003 Traning Loss: tensor(18.7484)\n",
      "11004 Traning Loss: tensor(18.7414)\n",
      "11005 Traning Loss: tensor(18.7345)\n",
      "11006 Traning Loss: tensor(18.7275)\n",
      "11007 Traning Loss: tensor(18.7205)\n",
      "11008 Traning Loss: tensor(18.7135)\n",
      "11009 Traning Loss: tensor(18.7065)\n",
      "11010 Traning Loss: tensor(18.6995)\n",
      "11011 Traning Loss: tensor(18.6925)\n",
      "11012 Traning Loss: tensor(18.6855)\n",
      "11013 Traning Loss: tensor(18.6785)\n",
      "11014 Traning Loss: tensor(18.6716)\n",
      "11015 Traning Loss: tensor(18.6646)\n",
      "11016 Traning Loss: tensor(18.6576)\n",
      "11017 Traning Loss: tensor(18.6506)\n",
      "11018 Traning Loss: tensor(18.6436)\n",
      "11019 Traning Loss: tensor(18.6366)\n",
      "11020 Traning Loss: tensor(18.6296)\n",
      "11021 Traning Loss: tensor(18.6227)\n",
      "11022 Traning Loss: tensor(18.6157)\n",
      "11023 Traning Loss: tensor(18.6087)\n",
      "11024 Traning Loss: tensor(18.6017)\n",
      "11025 Traning Loss: tensor(18.5948)\n",
      "11026 Traning Loss: tensor(18.5878)\n",
      "11027 Traning Loss: tensor(18.5808)\n",
      "11028 Traning Loss: tensor(18.5739)\n",
      "11029 Traning Loss: tensor(18.5669)\n",
      "11030 Traning Loss: tensor(18.5599)\n",
      "11031 Traning Loss: tensor(18.5529)\n",
      "11032 Traning Loss: tensor(18.5460)\n",
      "11033 Traning Loss: tensor(18.5390)\n",
      "11034 Traning Loss: tensor(18.5320)\n",
      "11035 Traning Loss: tensor(18.5251)\n",
      "11036 Traning Loss: tensor(18.5181)\n",
      "11037 Traning Loss: tensor(18.5112)\n",
      "11038 Traning Loss: tensor(18.5042)\n",
      "11039 Traning Loss: tensor(18.4972)\n",
      "11040 Traning Loss: tensor(18.4903)\n",
      "11041 Traning Loss: tensor(18.4833)\n",
      "11042 Traning Loss: tensor(18.4764)\n",
      "11043 Traning Loss: tensor(18.4694)\n",
      "11044 Traning Loss: tensor(18.4625)\n",
      "11045 Traning Loss: tensor(18.4555)\n",
      "11046 Traning Loss: tensor(18.4486)\n",
      "11047 Traning Loss: tensor(18.4416)\n",
      "11048 Traning Loss: tensor(18.4346)\n",
      "11049 Traning Loss: tensor(18.4277)\n",
      "11050 Traning Loss: tensor(18.4208)\n",
      "11051 Traning Loss: tensor(18.4138)\n",
      "11052 Traning Loss: tensor(18.4069)\n",
      "11053 Traning Loss: tensor(18.3999)\n",
      "11054 Traning Loss: tensor(18.3930)\n",
      "11055 Traning Loss: tensor(18.3860)\n",
      "11056 Traning Loss: tensor(18.3791)\n",
      "11057 Traning Loss: tensor(18.3721)\n",
      "11058 Traning Loss: tensor(18.3652)\n",
      "11059 Traning Loss: tensor(18.3583)\n",
      "11060 Traning Loss: tensor(18.3513)\n",
      "11061 Traning Loss: tensor(18.3444)\n",
      "11062 Traning Loss: tensor(18.3375)\n",
      "11063 Traning Loss: tensor(18.3305)\n",
      "11064 Traning Loss: tensor(18.3236)\n",
      "11065 Traning Loss: tensor(18.3166)\n",
      "11066 Traning Loss: tensor(18.3097)\n",
      "11067 Traning Loss: tensor(18.3028)\n",
      "11068 Traning Loss: tensor(18.2948)\n",
      "11069 Traning Loss: tensor(18.2879)\n",
      "11070 Traning Loss: tensor(18.2810)\n",
      "11071 Traning Loss: tensor(18.2740)\n",
      "11072 Traning Loss: tensor(18.2671)\n",
      "11073 Traning Loss: tensor(18.2602)\n",
      "11074 Traning Loss: tensor(18.2533)\n",
      "11075 Traning Loss: tensor(18.2464)\n",
      "11076 Traning Loss: tensor(18.2395)\n",
      "11077 Traning Loss: tensor(18.2326)\n",
      "11078 Traning Loss: tensor(18.2257)\n",
      "11079 Traning Loss: tensor(18.2188)\n",
      "11080 Traning Loss: tensor(18.2119)\n",
      "11081 Traning Loss: tensor(18.2050)\n",
      "11082 Traning Loss: tensor(18.1981)\n",
      "11083 Traning Loss: tensor(18.1912)\n",
      "11084 Traning Loss: tensor(18.1843)\n",
      "11085 Traning Loss: tensor(18.1774)\n",
      "11086 Traning Loss: tensor(18.1706)\n",
      "11087 Traning Loss: tensor(18.1637)\n",
      "11088 Traning Loss: tensor(18.1568)\n",
      "11089 Traning Loss: tensor(18.1499)\n",
      "11090 Traning Loss: tensor(18.1430)\n",
      "11091 Traning Loss: tensor(18.1361)\n",
      "11092 Traning Loss: tensor(18.1292)\n",
      "11093 Traning Loss: tensor(18.1224)\n",
      "11094 Traning Loss: tensor(18.1155)\n",
      "11095 Traning Loss: tensor(18.1086)\n",
      "11096 Traning Loss: tensor(18.1017)\n",
      "11097 Traning Loss: tensor(18.0948)\n",
      "11098 Traning Loss: tensor(18.0880)\n",
      "11099 Traning Loss: tensor(18.0811)\n",
      "11100 Traning Loss: tensor(18.0742)\n",
      "11101 Traning Loss: tensor(18.0673)\n",
      "11102 Traning Loss: tensor(18.0605)\n",
      "11103 Traning Loss: tensor(18.0536)\n",
      "11104 Traning Loss: tensor(18.0467)\n",
      "11105 Traning Loss: tensor(18.0399)\n",
      "11106 Traning Loss: tensor(18.0330)\n",
      "11107 Traning Loss: tensor(18.0261)\n",
      "11108 Traning Loss: tensor(18.0193)\n",
      "11109 Traning Loss: tensor(18.0124)\n",
      "11110 Traning Loss: tensor(18.0055)\n",
      "11111 Traning Loss: tensor(17.9987)\n",
      "11112 Traning Loss: tensor(17.9918)\n",
      "11113 Traning Loss: tensor(17.9849)\n",
      "11114 Traning Loss: tensor(17.9781)\n",
      "11115 Traning Loss: tensor(17.9712)\n",
      "11116 Traning Loss: tensor(17.9644)\n",
      "11117 Traning Loss: tensor(17.9575)\n",
      "11118 Traning Loss: tensor(17.9507)\n",
      "11119 Traning Loss: tensor(17.9438)\n",
      "11120 Traning Loss: tensor(17.9369)\n",
      "11121 Traning Loss: tensor(17.9301)\n",
      "11122 Traning Loss: tensor(17.9232)\n",
      "11123 Traning Loss: tensor(17.9164)\n",
      "11124 Traning Loss: tensor(17.9095)\n",
      "11125 Traning Loss: tensor(17.9027)\n",
      "11126 Traning Loss: tensor(17.8959)\n",
      "11127 Traning Loss: tensor(17.8890)\n",
      "11128 Traning Loss: tensor(17.8822)\n",
      "11129 Traning Loss: tensor(17.8753)\n",
      "11130 Traning Loss: tensor(17.8685)\n",
      "11131 Traning Loss: tensor(17.8616)\n",
      "11132 Traning Loss: tensor(17.8548)\n",
      "11133 Traning Loss: tensor(17.8479)\n",
      "11134 Traning Loss: tensor(17.8411)\n",
      "11135 Traning Loss: tensor(17.8343)\n",
      "11136 Traning Loss: tensor(17.8274)\n",
      "11137 Traning Loss: tensor(17.8206)\n",
      "11138 Traning Loss: tensor(17.8138)\n",
      "11139 Traning Loss: tensor(17.8069)\n",
      "11140 Traning Loss: tensor(17.8001)\n",
      "11141 Traning Loss: tensor(17.7933)\n",
      "11142 Traning Loss: tensor(17.7864)\n",
      "11143 Traning Loss: tensor(17.7796)\n",
      "11144 Traning Loss: tensor(17.7728)\n",
      "11145 Traning Loss: tensor(17.7659)\n",
      "11146 Traning Loss: tensor(17.7591)\n",
      "11147 Traning Loss: tensor(17.7523)\n",
      "11148 Traning Loss: tensor(17.7455)\n",
      "11149 Traning Loss: tensor(17.7387)\n",
      "11150 Traning Loss: tensor(17.7318)\n",
      "11151 Traning Loss: tensor(17.7250)\n",
      "11152 Traning Loss: tensor(17.7182)\n",
      "11153 Traning Loss: tensor(17.7114)\n",
      "11154 Traning Loss: tensor(17.7045)\n",
      "11155 Traning Loss: tensor(17.6977)\n",
      "11156 Traning Loss: tensor(17.6909)\n",
      "11157 Traning Loss: tensor(17.6841)\n",
      "11158 Traning Loss: tensor(17.6773)\n",
      "11159 Traning Loss: tensor(17.6705)\n",
      "11160 Traning Loss: tensor(17.6637)\n",
      "11161 Traning Loss: tensor(17.6568)\n",
      "11162 Traning Loss: tensor(17.6500)\n",
      "11163 Traning Loss: tensor(17.6432)\n",
      "11164 Traning Loss: tensor(17.6364)\n",
      "11165 Traning Loss: tensor(17.6296)\n",
      "11166 Traning Loss: tensor(17.6228)\n",
      "11167 Traning Loss: tensor(17.6160)\n",
      "11168 Traning Loss: tensor(17.6092)\n",
      "11169 Traning Loss: tensor(17.6024)\n",
      "11170 Traning Loss: tensor(17.5956)\n",
      "11171 Traning Loss: tensor(17.5888)\n",
      "11172 Traning Loss: tensor(17.5808)\n",
      "11173 Traning Loss: tensor(17.5741)\n",
      "11174 Traning Loss: tensor(17.5673)\n",
      "11175 Traning Loss: tensor(17.5605)\n",
      "11176 Traning Loss: tensor(17.5537)\n",
      "11177 Traning Loss: tensor(17.5469)\n",
      "11178 Traning Loss: tensor(17.5402)\n",
      "11179 Traning Loss: tensor(17.5334)\n",
      "11180 Traning Loss: tensor(17.5266)\n",
      "11181 Traning Loss: tensor(17.5198)\n",
      "11182 Traning Loss: tensor(17.5131)\n",
      "11183 Traning Loss: tensor(17.5063)\n",
      "11184 Traning Loss: tensor(17.4995)\n",
      "11185 Traning Loss: tensor(17.4928)\n",
      "11186 Traning Loss: tensor(17.4860)\n",
      "11187 Traning Loss: tensor(17.4792)\n",
      "11188 Traning Loss: tensor(17.4725)\n",
      "11189 Traning Loss: tensor(17.4657)\n",
      "11190 Traning Loss: tensor(17.4590)\n",
      "11191 Traning Loss: tensor(17.4522)\n",
      "11192 Traning Loss: tensor(17.4454)\n",
      "11193 Traning Loss: tensor(17.4387)\n",
      "11194 Traning Loss: tensor(17.4319)\n",
      "11195 Traning Loss: tensor(17.4252)\n",
      "11196 Traning Loss: tensor(17.4184)\n",
      "11197 Traning Loss: tensor(17.4117)\n",
      "11198 Traning Loss: tensor(17.4049)\n",
      "11199 Traning Loss: tensor(17.3982)\n",
      "11200 Traning Loss: tensor(17.3914)\n",
      "11201 Traning Loss: tensor(17.3847)\n",
      "11202 Traning Loss: tensor(17.3779)\n",
      "11203 Traning Loss: tensor(17.3712)\n",
      "11204 Traning Loss: tensor(17.3645)\n",
      "11205 Traning Loss: tensor(17.3577)\n",
      "11206 Traning Loss: tensor(17.3510)\n",
      "11207 Traning Loss: tensor(17.3442)\n",
      "11208 Traning Loss: tensor(17.3375)\n",
      "11209 Traning Loss: tensor(17.3308)\n",
      "11210 Traning Loss: tensor(17.3240)\n",
      "11211 Traning Loss: tensor(17.3173)\n",
      "11212 Traning Loss: tensor(17.3105)\n",
      "11213 Traning Loss: tensor(17.3038)\n",
      "11214 Traning Loss: tensor(17.2971)\n",
      "11215 Traning Loss: tensor(17.2903)\n",
      "11216 Traning Loss: tensor(17.2836)\n",
      "11217 Traning Loss: tensor(17.2769)\n",
      "11218 Traning Loss: tensor(17.2702)\n",
      "11219 Traning Loss: tensor(17.2634)\n",
      "11220 Traning Loss: tensor(17.2567)\n",
      "11221 Traning Loss: tensor(17.2500)\n",
      "11222 Traning Loss: tensor(17.2432)\n",
      "11223 Traning Loss: tensor(17.2365)\n",
      "11224 Traning Loss: tensor(17.2298)\n",
      "11225 Traning Loss: tensor(17.2231)\n",
      "11226 Traning Loss: tensor(17.2164)\n",
      "11227 Traning Loss: tensor(17.2096)\n",
      "11228 Traning Loss: tensor(17.2029)\n",
      "11229 Traning Loss: tensor(17.1962)\n",
      "11230 Traning Loss: tensor(17.1895)\n",
      "11231 Traning Loss: tensor(17.1828)\n",
      "11232 Traning Loss: tensor(17.1761)\n",
      "11233 Traning Loss: tensor(17.1693)\n",
      "11234 Traning Loss: tensor(17.1626)\n",
      "11235 Traning Loss: tensor(17.1559)\n",
      "11236 Traning Loss: tensor(17.1492)\n",
      "11237 Traning Loss: tensor(17.1425)\n",
      "11238 Traning Loss: tensor(17.1358)\n",
      "11239 Traning Loss: tensor(17.1291)\n",
      "11240 Traning Loss: tensor(17.1224)\n",
      "11241 Traning Loss: tensor(17.1157)\n",
      "11242 Traning Loss: tensor(17.1090)\n",
      "11243 Traning Loss: tensor(17.1023)\n",
      "11244 Traning Loss: tensor(17.0956)\n",
      "11245 Traning Loss: tensor(17.0889)\n",
      "11246 Traning Loss: tensor(17.0822)\n",
      "11247 Traning Loss: tensor(17.0755)\n",
      "11248 Traning Loss: tensor(17.0688)\n",
      "11249 Traning Loss: tensor(17.0621)\n",
      "11250 Traning Loss: tensor(17.0554)\n",
      "11251 Traning Loss: tensor(17.0487)\n",
      "11252 Traning Loss: tensor(17.0420)\n",
      "11253 Traning Loss: tensor(17.0353)\n",
      "11254 Traning Loss: tensor(17.0286)\n",
      "11255 Traning Loss: tensor(17.0219)\n",
      "11256 Traning Loss: tensor(17.0152)\n",
      "11257 Traning Loss: tensor(17.0085)\n",
      "11258 Traning Loss: tensor(17.0018)\n",
      "11259 Traning Loss: tensor(16.9951)\n",
      "11260 Traning Loss: tensor(16.9885)\n",
      "11261 Traning Loss: tensor(16.9818)\n",
      "11262 Traning Loss: tensor(16.9751)\n",
      "11263 Traning Loss: tensor(16.9684)\n",
      "11264 Traning Loss: tensor(16.9617)\n",
      "11265 Traning Loss: tensor(16.9550)\n",
      "11266 Traning Loss: tensor(16.9484)\n",
      "11267 Traning Loss: tensor(16.9417)\n",
      "11268 Traning Loss: tensor(16.9350)\n",
      "11269 Traning Loss: tensor(16.9283)\n",
      "11270 Traning Loss: tensor(16.9216)\n",
      "11271 Traning Loss: tensor(16.9150)\n",
      "11272 Traning Loss: tensor(16.9083)\n",
      "11273 Traning Loss: tensor(16.9016)\n",
      "11274 Traning Loss: tensor(16.8950)\n",
      "11275 Traning Loss: tensor(16.8883)\n",
      "11276 Traning Loss: tensor(16.8816)\n",
      "11277 Traning Loss: tensor(16.8749)\n",
      "11278 Traning Loss: tensor(16.8683)\n",
      "11279 Traning Loss: tensor(16.8616)\n",
      "11280 Traning Loss: tensor(16.8537)\n",
      "11281 Traning Loss: tensor(16.8470)\n",
      "11282 Traning Loss: tensor(16.8404)\n",
      "11283 Traning Loss: tensor(16.8337)\n",
      "11284 Traning Loss: tensor(16.8271)\n",
      "11285 Traning Loss: tensor(16.8205)\n",
      "11286 Traning Loss: tensor(16.8138)\n",
      "11287 Traning Loss: tensor(16.8072)\n",
      "11288 Traning Loss: tensor(16.8006)\n",
      "11289 Traning Loss: tensor(16.7939)\n",
      "11290 Traning Loss: tensor(16.7873)\n",
      "11291 Traning Loss: tensor(16.7806)\n",
      "11292 Traning Loss: tensor(16.7740)\n",
      "11293 Traning Loss: tensor(16.7674)\n",
      "11294 Traning Loss: tensor(16.7608)\n",
      "11295 Traning Loss: tensor(16.7541)\n",
      "11296 Traning Loss: tensor(16.7475)\n",
      "11297 Traning Loss: tensor(16.7409)\n",
      "11298 Traning Loss: tensor(16.7342)\n",
      "11299 Traning Loss: tensor(16.7276)\n",
      "11300 Traning Loss: tensor(16.7210)\n",
      "11301 Traning Loss: tensor(16.7144)\n",
      "11302 Traning Loss: tensor(16.7078)\n",
      "11303 Traning Loss: tensor(16.7011)\n",
      "11304 Traning Loss: tensor(16.6945)\n",
      "11305 Traning Loss: tensor(16.6879)\n",
      "11306 Traning Loss: tensor(16.6813)\n",
      "11307 Traning Loss: tensor(16.6747)\n",
      "11308 Traning Loss: tensor(16.6681)\n",
      "11309 Traning Loss: tensor(16.6614)\n",
      "11310 Traning Loss: tensor(16.6548)\n",
      "11311 Traning Loss: tensor(16.6482)\n",
      "11312 Traning Loss: tensor(16.6416)\n",
      "11313 Traning Loss: tensor(16.6350)\n",
      "11314 Traning Loss: tensor(16.6284)\n",
      "11315 Traning Loss: tensor(16.6218)\n",
      "11316 Traning Loss: tensor(16.6152)\n",
      "11317 Traning Loss: tensor(16.6086)\n",
      "11318 Traning Loss: tensor(16.6020)\n",
      "11319 Traning Loss: tensor(16.5954)\n",
      "11320 Traning Loss: tensor(16.5888)\n",
      "11321 Traning Loss: tensor(16.5822)\n",
      "11322 Traning Loss: tensor(16.5756)\n",
      "11323 Traning Loss: tensor(16.5690)\n",
      "11324 Traning Loss: tensor(16.5624)\n",
      "11325 Traning Loss: tensor(16.5558)\n",
      "11326 Traning Loss: tensor(16.5492)\n",
      "11327 Traning Loss: tensor(16.5426)\n",
      "11328 Traning Loss: tensor(16.5360)\n",
      "11329 Traning Loss: tensor(16.5294)\n",
      "11330 Traning Loss: tensor(16.5228)\n",
      "11331 Traning Loss: tensor(16.5162)\n",
      "11332 Traning Loss: tensor(16.5097)\n",
      "11333 Traning Loss: tensor(16.5031)\n",
      "11334 Traning Loss: tensor(16.4965)\n",
      "11335 Traning Loss: tensor(16.4899)\n",
      "11336 Traning Loss: tensor(16.4833)\n",
      "11337 Traning Loss: tensor(16.4767)\n",
      "11338 Traning Loss: tensor(16.4701)\n",
      "11339 Traning Loss: tensor(16.4636)\n",
      "11340 Traning Loss: tensor(16.4570)\n",
      "11341 Traning Loss: tensor(16.4504)\n",
      "11342 Traning Loss: tensor(16.4438)\n",
      "11343 Traning Loss: tensor(16.4372)\n",
      "11344 Traning Loss: tensor(16.4307)\n",
      "11345 Traning Loss: tensor(16.4241)\n",
      "11346 Traning Loss: tensor(16.4175)\n",
      "11347 Traning Loss: tensor(16.4109)\n",
      "11348 Traning Loss: tensor(16.4044)\n",
      "11349 Traning Loss: tensor(16.3978)\n",
      "11350 Traning Loss: tensor(16.3912)\n",
      "11351 Traning Loss: tensor(16.3847)\n",
      "11352 Traning Loss: tensor(16.3781)\n",
      "11353 Traning Loss: tensor(16.3715)\n",
      "11354 Traning Loss: tensor(16.3650)\n",
      "11355 Traning Loss: tensor(16.3584)\n",
      "11356 Traning Loss: tensor(16.3518)\n",
      "11357 Traning Loss: tensor(16.3453)\n",
      "11358 Traning Loss: tensor(16.3387)\n",
      "11359 Traning Loss: tensor(16.3321)\n",
      "11360 Traning Loss: tensor(16.3256)\n",
      "11361 Traning Loss: tensor(16.3190)\n",
      "11362 Traning Loss: tensor(16.3125)\n",
      "11363 Traning Loss: tensor(16.3059)\n",
      "11364 Traning Loss: tensor(16.2993)\n",
      "11365 Traning Loss: tensor(16.2928)\n",
      "11366 Traning Loss: tensor(16.2862)\n",
      "11367 Traning Loss: tensor(16.2797)\n",
      "11368 Traning Loss: tensor(16.2731)\n",
      "11369 Traning Loss: tensor(16.2666)\n",
      "11370 Traning Loss: tensor(16.2600)\n",
      "11371 Traning Loss: tensor(16.2535)\n",
      "11372 Traning Loss: tensor(16.2469)\n",
      "11373 Traning Loss: tensor(16.2404)\n",
      "11374 Traning Loss: tensor(16.2338)\n",
      "11375 Traning Loss: tensor(16.2273)\n",
      "11376 Traning Loss: tensor(16.2207)\n",
      "11377 Traning Loss: tensor(16.2142)\n",
      "11378 Traning Loss: tensor(16.2076)\n",
      "11379 Traning Loss: tensor(16.2011)\n",
      "11380 Traning Loss: tensor(16.1946)\n",
      "11381 Traning Loss: tensor(16.1880)\n",
      "11382 Traning Loss: tensor(16.1815)\n",
      "11383 Traning Loss: tensor(16.1749)\n",
      "11384 Traning Loss: tensor(16.1684)\n",
      "11385 Traning Loss: tensor(16.1619)\n",
      "11386 Traning Loss: tensor(16.1553)\n",
      "11387 Traning Loss: tensor(16.1488)\n",
      "11388 Traning Loss: tensor(16.1423)\n",
      "11389 Traning Loss: tensor(16.1357)\n",
      "11390 Traning Loss: tensor(16.1292)\n",
      "11391 Traning Loss: tensor(16.1227)\n",
      "11392 Traning Loss: tensor(16.1161)\n",
      "11393 Traning Loss: tensor(16.1083)\n",
      "11394 Traning Loss: tensor(16.1017)\n",
      "11395 Traning Loss: tensor(16.0952)\n",
      "11396 Traning Loss: tensor(16.0887)\n",
      "11397 Traning Loss: tensor(16.0822)\n",
      "11398 Traning Loss: tensor(16.0757)\n",
      "11399 Traning Loss: tensor(16.0692)\n",
      "11400 Traning Loss: tensor(16.0627)\n",
      "11401 Traning Loss: tensor(16.0562)\n",
      "11402 Traning Loss: tensor(16.0497)\n",
      "11403 Traning Loss: tensor(16.0432)\n",
      "11404 Traning Loss: tensor(16.0367)\n",
      "11405 Traning Loss: tensor(16.0302)\n",
      "11406 Traning Loss: tensor(16.0237)\n",
      "11407 Traning Loss: tensor(16.0173)\n",
      "11408 Traning Loss: tensor(16.0108)\n",
      "11409 Traning Loss: tensor(16.0043)\n",
      "11410 Traning Loss: tensor(15.9978)\n",
      "11411 Traning Loss: tensor(15.9913)\n",
      "11412 Traning Loss: tensor(15.9848)\n",
      "11413 Traning Loss: tensor(15.9783)\n",
      "11414 Traning Loss: tensor(15.9718)\n",
      "11415 Traning Loss: tensor(15.9654)\n",
      "11416 Traning Loss: tensor(15.9589)\n",
      "11417 Traning Loss: tensor(15.9524)\n",
      "11418 Traning Loss: tensor(15.9459)\n",
      "11419 Traning Loss: tensor(15.9395)\n",
      "11420 Traning Loss: tensor(15.9330)\n",
      "11421 Traning Loss: tensor(15.9265)\n",
      "11422 Traning Loss: tensor(15.9200)\n",
      "11423 Traning Loss: tensor(15.9136)\n",
      "11424 Traning Loss: tensor(15.9071)\n",
      "11425 Traning Loss: tensor(15.9006)\n",
      "11426 Traning Loss: tensor(15.8941)\n",
      "11427 Traning Loss: tensor(15.8877)\n",
      "11428 Traning Loss: tensor(15.8812)\n",
      "11429 Traning Loss: tensor(15.8747)\n",
      "11430 Traning Loss: tensor(15.8683)\n",
      "11431 Traning Loss: tensor(15.8618)\n",
      "11432 Traning Loss: tensor(15.8553)\n",
      "11433 Traning Loss: tensor(15.8489)\n",
      "11434 Traning Loss: tensor(15.8424)\n",
      "11435 Traning Loss: tensor(15.8360)\n",
      "11436 Traning Loss: tensor(15.8295)\n",
      "11437 Traning Loss: tensor(15.8230)\n",
      "11438 Traning Loss: tensor(15.8166)\n",
      "11439 Traning Loss: tensor(15.8101)\n",
      "11440 Traning Loss: tensor(15.8037)\n",
      "11441 Traning Loss: tensor(15.7972)\n",
      "11442 Traning Loss: tensor(15.7908)\n",
      "11443 Traning Loss: tensor(15.7843)\n",
      "11444 Traning Loss: tensor(15.7778)\n",
      "11445 Traning Loss: tensor(15.7714)\n",
      "11446 Traning Loss: tensor(15.7649)\n",
      "11447 Traning Loss: tensor(15.7585)\n",
      "11448 Traning Loss: tensor(15.7520)\n",
      "11449 Traning Loss: tensor(15.7456)\n",
      "11450 Traning Loss: tensor(15.7391)\n",
      "11451 Traning Loss: tensor(15.7327)\n",
      "11452 Traning Loss: tensor(15.7263)\n",
      "11453 Traning Loss: tensor(15.7198)\n",
      "11454 Traning Loss: tensor(15.7134)\n",
      "11455 Traning Loss: tensor(15.7069)\n",
      "11456 Traning Loss: tensor(15.7005)\n",
      "11457 Traning Loss: tensor(15.6940)\n",
      "11458 Traning Loss: tensor(15.6876)\n",
      "11459 Traning Loss: tensor(15.6812)\n",
      "11460 Traning Loss: tensor(15.6747)\n",
      "11461 Traning Loss: tensor(15.6683)\n",
      "11462 Traning Loss: tensor(15.6619)\n",
      "11463 Traning Loss: tensor(15.6554)\n",
      "11464 Traning Loss: tensor(15.6490)\n",
      "11465 Traning Loss: tensor(15.6426)\n",
      "11466 Traning Loss: tensor(15.6361)\n",
      "11467 Traning Loss: tensor(15.6297)\n",
      "11468 Traning Loss: tensor(15.6233)\n",
      "11469 Traning Loss: tensor(15.6168)\n",
      "11470 Traning Loss: tensor(15.6104)\n",
      "11471 Traning Loss: tensor(15.6040)\n",
      "11472 Traning Loss: tensor(15.5976)\n",
      "11473 Traning Loss: tensor(15.5911)\n",
      "11474 Traning Loss: tensor(15.5847)\n",
      "11475 Traning Loss: tensor(15.5783)\n",
      "11476 Traning Loss: tensor(15.5719)\n",
      "11477 Traning Loss: tensor(15.5654)\n",
      "11478 Traning Loss: tensor(15.5590)\n",
      "11479 Traning Loss: tensor(15.5526)\n",
      "11480 Traning Loss: tensor(15.5462)\n",
      "11481 Traning Loss: tensor(15.5398)\n",
      "11482 Traning Loss: tensor(15.5334)\n",
      "11483 Traning Loss: tensor(15.5269)\n",
      "11484 Traning Loss: tensor(15.5205)\n",
      "11485 Traning Loss: tensor(15.5141)\n",
      "11486 Traning Loss: tensor(15.5077)\n",
      "11487 Traning Loss: tensor(15.5013)\n",
      "11488 Traning Loss: tensor(15.4949)\n",
      "11489 Traning Loss: tensor(15.4885)\n",
      "11490 Traning Loss: tensor(15.4821)\n",
      "11491 Traning Loss: tensor(15.4756)\n",
      "11492 Traning Loss: tensor(15.4692)\n",
      "11493 Traning Loss: tensor(15.4628)\n",
      "11494 Traning Loss: tensor(15.4564)\n",
      "11495 Traning Loss: tensor(15.4500)\n",
      "11496 Traning Loss: tensor(15.4436)\n",
      "11497 Traning Loss: tensor(15.4372)\n",
      "11498 Traning Loss: tensor(15.4308)\n",
      "11499 Traning Loss: tensor(15.4244)\n",
      "11500 Traning Loss: tensor(15.4180)\n",
      "11501 Traning Loss: tensor(15.4116)\n",
      "11502 Traning Loss: tensor(15.4052)\n",
      "11503 Traning Loss: tensor(15.3988)\n",
      "11504 Traning Loss: tensor(15.3924)\n",
      "11505 Traning Loss: tensor(15.3860)\n",
      "11506 Traning Loss: tensor(15.3796)\n",
      "11507 Traning Loss: tensor(15.3732)\n",
      "11508 Traning Loss: tensor(15.3668)\n",
      "11509 Traning Loss: tensor(15.3605)\n",
      "11510 Traning Loss: tensor(15.3526)\n",
      "11511 Traning Loss: tensor(15.3462)\n",
      "11512 Traning Loss: tensor(15.3399)\n",
      "11513 Traning Loss: tensor(15.3335)\n",
      "11514 Traning Loss: tensor(15.3271)\n",
      "11515 Traning Loss: tensor(15.3207)\n",
      "11516 Traning Loss: tensor(15.3144)\n",
      "11517 Traning Loss: tensor(15.3080)\n",
      "11518 Traning Loss: tensor(15.3017)\n",
      "11519 Traning Loss: tensor(15.2953)\n",
      "11520 Traning Loss: tensor(15.2890)\n",
      "11521 Traning Loss: tensor(15.2826)\n",
      "11522 Traning Loss: tensor(15.2762)\n",
      "11523 Traning Loss: tensor(15.2699)\n",
      "11524 Traning Loss: tensor(15.2635)\n",
      "11525 Traning Loss: tensor(15.2572)\n",
      "11526 Traning Loss: tensor(15.2508)\n",
      "11527 Traning Loss: tensor(15.2445)\n",
      "11528 Traning Loss: tensor(15.2381)\n",
      "11529 Traning Loss: tensor(15.2318)\n",
      "11530 Traning Loss: tensor(15.2254)\n",
      "11531 Traning Loss: tensor(15.2191)\n",
      "11532 Traning Loss: tensor(15.2128)\n",
      "11533 Traning Loss: tensor(15.2064)\n",
      "11534 Traning Loss: tensor(15.2001)\n",
      "11535 Traning Loss: tensor(15.1937)\n",
      "11536 Traning Loss: tensor(15.1874)\n",
      "11537 Traning Loss: tensor(15.1811)\n",
      "11538 Traning Loss: tensor(15.1747)\n",
      "11539 Traning Loss: tensor(15.1684)\n",
      "11540 Traning Loss: tensor(15.1620)\n",
      "11541 Traning Loss: tensor(15.1557)\n",
      "11542 Traning Loss: tensor(15.1494)\n",
      "11543 Traning Loss: tensor(15.1430)\n",
      "11544 Traning Loss: tensor(15.1367)\n",
      "11545 Traning Loss: tensor(15.1304)\n",
      "11546 Traning Loss: tensor(15.1240)\n",
      "11547 Traning Loss: tensor(15.1177)\n",
      "11548 Traning Loss: tensor(15.1114)\n",
      "11549 Traning Loss: tensor(15.1051)\n",
      "11550 Traning Loss: tensor(15.0987)\n",
      "11551 Traning Loss: tensor(15.0924)\n",
      "11552 Traning Loss: tensor(15.0861)\n",
      "11553 Traning Loss: tensor(15.0798)\n",
      "11554 Traning Loss: tensor(15.0734)\n",
      "11555 Traning Loss: tensor(15.0671)\n",
      "11556 Traning Loss: tensor(15.0608)\n",
      "11557 Traning Loss: tensor(15.0545)\n",
      "11558 Traning Loss: tensor(15.0482)\n",
      "11559 Traning Loss: tensor(15.0418)\n",
      "11560 Traning Loss: tensor(15.0355)\n",
      "11561 Traning Loss: tensor(15.0292)\n",
      "11562 Traning Loss: tensor(15.0229)\n",
      "11563 Traning Loss: tensor(15.0166)\n",
      "11564 Traning Loss: tensor(15.0103)\n",
      "11565 Traning Loss: tensor(15.0040)\n",
      "11566 Traning Loss: tensor(14.9976)\n",
      "11567 Traning Loss: tensor(14.9913)\n",
      "11568 Traning Loss: tensor(14.9850)\n",
      "11569 Traning Loss: tensor(14.9787)\n",
      "11570 Traning Loss: tensor(14.9724)\n",
      "11571 Traning Loss: tensor(14.9661)\n",
      "11572 Traning Loss: tensor(14.9598)\n",
      "11573 Traning Loss: tensor(14.9535)\n",
      "11574 Traning Loss: tensor(14.9472)\n",
      "11575 Traning Loss: tensor(14.9409)\n",
      "11576 Traning Loss: tensor(14.9346)\n",
      "11577 Traning Loss: tensor(14.9283)\n",
      "11578 Traning Loss: tensor(14.9220)\n",
      "11579 Traning Loss: tensor(14.9157)\n",
      "11580 Traning Loss: tensor(14.9094)\n",
      "11581 Traning Loss: tensor(14.9031)\n",
      "11582 Traning Loss: tensor(14.8968)\n",
      "11583 Traning Loss: tensor(14.8905)\n",
      "11584 Traning Loss: tensor(14.8842)\n",
      "11585 Traning Loss: tensor(14.8699)\n",
      "11586 Traning Loss: tensor(14.8636)\n",
      "11587 Traning Loss: tensor(14.8573)\n",
      "11588 Traning Loss: tensor(14.8510)\n",
      "11589 Traning Loss: tensor(14.8447)\n",
      "11590 Traning Loss: tensor(14.8384)\n",
      "11591 Traning Loss: tensor(14.8321)\n",
      "11592 Traning Loss: tensor(14.8258)\n",
      "11593 Traning Loss: tensor(14.8195)\n",
      "11594 Traning Loss: tensor(14.8132)\n",
      "11595 Traning Loss: tensor(14.8069)\n",
      "11596 Traning Loss: tensor(14.8006)\n",
      "11597 Traning Loss: tensor(14.7943)\n",
      "11598 Traning Loss: tensor(14.7880)\n",
      "11599 Traning Loss: tensor(14.7817)\n",
      "11600 Traning Loss: tensor(14.7754)\n",
      "11601 Traning Loss: tensor(14.7690)\n",
      "11602 Traning Loss: tensor(14.7628)\n",
      "11603 Traning Loss: tensor(14.7565)\n",
      "11604 Traning Loss: tensor(14.7501)\n",
      "11605 Traning Loss: tensor(14.7438)\n",
      "11606 Traning Loss: tensor(14.7376)\n",
      "11607 Traning Loss: tensor(14.7313)\n",
      "11608 Traning Loss: tensor(14.7250)\n",
      "11609 Traning Loss: tensor(14.7187)\n",
      "11610 Traning Loss: tensor(14.7124)\n",
      "11611 Traning Loss: tensor(14.7061)\n",
      "11612 Traning Loss: tensor(14.6998)\n",
      "11613 Traning Loss: tensor(14.6935)\n",
      "11614 Traning Loss: tensor(14.6872)\n",
      "11615 Traning Loss: tensor(14.6809)\n",
      "11616 Traning Loss: tensor(14.6746)\n",
      "11617 Traning Loss: tensor(14.6683)\n",
      "11618 Traning Loss: tensor(14.6620)\n",
      "11619 Traning Loss: tensor(14.6557)\n",
      "11620 Traning Loss: tensor(14.6494)\n",
      "11621 Traning Loss: tensor(14.6431)\n",
      "11622 Traning Loss: tensor(14.6368)\n",
      "11623 Traning Loss: tensor(14.6306)\n",
      "11624 Traning Loss: tensor(14.6243)\n",
      "11625 Traning Loss: tensor(14.6180)\n",
      "11626 Traning Loss: tensor(14.6117)\n",
      "11627 Traning Loss: tensor(14.6054)\n",
      "11628 Traning Loss: tensor(14.5991)\n",
      "11629 Traning Loss: tensor(14.5928)\n",
      "11630 Traning Loss: tensor(14.5865)\n",
      "11631 Traning Loss: tensor(14.5801)\n",
      "11632 Traning Loss: tensor(14.5738)\n",
      "11633 Traning Loss: tensor(14.5675)\n",
      "11634 Traning Loss: tensor(14.5612)\n",
      "11635 Traning Loss: tensor(14.5533)\n",
      "11636 Traning Loss: tensor(14.5470)\n",
      "11637 Traning Loss: tensor(14.5407)\n",
      "11638 Traning Loss: tensor(14.5344)\n",
      "11639 Traning Loss: tensor(14.5281)\n",
      "11640 Traning Loss: tensor(14.5218)\n",
      "11641 Traning Loss: tensor(14.5154)\n",
      "11642 Traning Loss: tensor(14.5091)\n",
      "11643 Traning Loss: tensor(14.5028)\n",
      "11644 Traning Loss: tensor(14.4964)\n",
      "11645 Traning Loss: tensor(14.4901)\n",
      "11646 Traning Loss: tensor(14.4837)\n",
      "11647 Traning Loss: tensor(14.4773)\n",
      "11648 Traning Loss: tensor(14.4710)\n",
      "11649 Traning Loss: tensor(14.4646)\n",
      "11650 Traning Loss: tensor(14.4582)\n",
      "11651 Traning Loss: tensor(14.4518)\n",
      "11652 Traning Loss: tensor(14.4453)\n",
      "11653 Traning Loss: tensor(14.4389)\n",
      "11654 Traning Loss: tensor(14.4324)\n",
      "11655 Traning Loss: tensor(14.4260)\n",
      "11656 Traning Loss: tensor(14.4195)\n",
      "11657 Traning Loss: tensor(14.4129)\n",
      "11658 Traning Loss: tensor(14.4064)\n",
      "11659 Traning Loss: tensor(14.3998)\n",
      "11660 Traning Loss: tensor(14.3932)\n",
      "11661 Traning Loss: tensor(14.3866)\n",
      "11662 Traning Loss: tensor(14.3799)\n",
      "11663 Traning Loss: tensor(14.3727)\n",
      "11664 Traning Loss: tensor(14.3650)\n",
      "11665 Traning Loss: tensor(14.3537)\n",
      "11666 Traning Loss: tensor(14.3370)\n",
      "11667 Traning Loss: tensor(14.3179)\n",
      "11668 Traning Loss: tensor(14.2972)\n",
      "11669 Traning Loss: tensor(14.2753)\n",
      "11670 Traning Loss: tensor(14.2525)\n",
      "11671 Traning Loss: tensor(14.2290)\n",
      "11672 Traning Loss: tensor(14.2052)\n",
      "11673 Traning Loss: tensor(14.1810)\n",
      "11674 Traning Loss: tensor(14.1567)\n",
      "11675 Traning Loss: tensor(14.1323)\n",
      "11676 Traning Loss: tensor(14.1079)\n",
      "11677 Traning Loss: tensor(14.0836)\n",
      "11678 Traning Loss: tensor(14.0594)\n",
      "11679 Traning Loss: tensor(14.0353)\n",
      "11680 Traning Loss: tensor(14.0114)\n",
      "11681 Traning Loss: tensor(13.9878)\n",
      "11682 Traning Loss: tensor(13.9643)\n",
      "11683 Traning Loss: tensor(13.9411)\n",
      "11684 Traning Loss: tensor(13.9182)\n",
      "11685 Traning Loss: tensor(13.8955)\n",
      "11686 Traning Loss: tensor(13.8730)\n",
      "11687 Traning Loss: tensor(13.8509)\n",
      "11688 Traning Loss: tensor(13.8290)\n",
      "11689 Traning Loss: tensor(13.8073)\n",
      "11690 Traning Loss: tensor(13.7860)\n",
      "11691 Traning Loss: tensor(13.7649)\n",
      "11692 Traning Loss: tensor(13.7440)\n",
      "11693 Traning Loss: tensor(13.7234)\n",
      "11694 Traning Loss: tensor(13.7030)\n",
      "11695 Traning Loss: tensor(13.6829)\n",
      "11696 Traning Loss: tensor(13.6631)\n",
      "11697 Traning Loss: tensor(13.6434)\n",
      "11698 Traning Loss: tensor(13.6240)\n",
      "11699 Traning Loss: tensor(13.6048)\n",
      "11700 Traning Loss: tensor(13.5859)\n",
      "11701 Traning Loss: tensor(13.5671)\n",
      "11702 Traning Loss: tensor(13.5486)\n",
      "11703 Traning Loss: tensor(13.5302)\n",
      "11704 Traning Loss: tensor(13.5121)\n",
      "11705 Traning Loss: tensor(13.4941)\n",
      "11706 Traning Loss: tensor(13.4764)\n",
      "11707 Traning Loss: tensor(13.4588)\n",
      "11708 Traning Loss: tensor(13.4414)\n",
      "11709 Traning Loss: tensor(13.4241)\n",
      "11710 Traning Loss: tensor(13.4071)\n",
      "11711 Traning Loss: tensor(13.3902)\n",
      "11712 Traning Loss: tensor(13.3734)\n",
      "11713 Traning Loss: tensor(13.3568)\n",
      "11714 Traning Loss: tensor(13.3404)\n",
      "11715 Traning Loss: tensor(13.3241)\n",
      "11716 Traning Loss: tensor(13.3080)\n",
      "11717 Traning Loss: tensor(13.2920)\n",
      "11718 Traning Loss: tensor(13.2761)\n",
      "11719 Traning Loss: tensor(13.2604)\n",
      "11720 Traning Loss: tensor(13.2448)\n",
      "11721 Traning Loss: tensor(13.2293)\n",
      "11722 Traning Loss: tensor(13.2140)\n",
      "11723 Traning Loss: tensor(13.1987)\n",
      "11724 Traning Loss: tensor(13.1836)\n",
      "11725 Traning Loss: tensor(13.1686)\n",
      "11726 Traning Loss: tensor(13.1537)\n",
      "11727 Traning Loss: tensor(13.1390)\n",
      "11728 Traning Loss: tensor(13.1243)\n",
      "11729 Traning Loss: tensor(13.1098)\n",
      "11730 Traning Loss: tensor(13.0953)\n",
      "11731 Traning Loss: tensor(13.0810)\n",
      "11732 Traning Loss: tensor(13.0667)\n",
      "11733 Traning Loss: tensor(13.0526)\n",
      "11734 Traning Loss: tensor(13.0385)\n",
      "11735 Traning Loss: tensor(13.0245)\n",
      "11736 Traning Loss: tensor(13.0107)\n",
      "11737 Traning Loss: tensor(12.9969)\n",
      "11738 Traning Loss: tensor(12.9832)\n",
      "11739 Traning Loss: tensor(12.9696)\n",
      "11740 Traning Loss: tensor(12.9561)\n",
      "11741 Traning Loss: tensor(12.9426)\n",
      "11742 Traning Loss: tensor(12.9292)\n",
      "11743 Traning Loss: tensor(12.9160)\n",
      "11744 Traning Loss: tensor(12.9028)\n",
      "11745 Traning Loss: tensor(12.8896)\n",
      "11746 Traning Loss: tensor(12.8766)\n",
      "11747 Traning Loss: tensor(12.8636)\n",
      "11748 Traning Loss: tensor(12.8507)\n",
      "11749 Traning Loss: tensor(12.8379)\n",
      "11750 Traning Loss: tensor(12.8251)\n",
      "11751 Traning Loss: tensor(12.8124)\n",
      "11752 Traning Loss: tensor(12.7998)\n",
      "11753 Traning Loss: tensor(12.7872)\n",
      "11754 Traning Loss: tensor(12.7747)\n",
      "11755 Traning Loss: tensor(12.7623)\n",
      "11756 Traning Loss: tensor(12.7499)\n",
      "11757 Traning Loss: tensor(12.7376)\n",
      "11758 Traning Loss: tensor(12.7253)\n",
      "11759 Traning Loss: tensor(12.7131)\n",
      "11760 Traning Loss: tensor(12.7010)\n",
      "11761 Traning Loss: tensor(12.6889)\n",
      "11762 Traning Loss: tensor(12.6769)\n",
      "11763 Traning Loss: tensor(12.6649)\n",
      "11764 Traning Loss: tensor(12.6530)\n",
      "11765 Traning Loss: tensor(12.6412)\n",
      "11766 Traning Loss: tensor(12.6294)\n",
      "11767 Traning Loss: tensor(12.6177)\n",
      "11768 Traning Loss: tensor(12.6060)\n",
      "11769 Traning Loss: tensor(12.5943)\n",
      "11770 Traning Loss: tensor(12.5827)\n",
      "11771 Traning Loss: tensor(12.5712)\n",
      "11772 Traning Loss: tensor(12.5597)\n",
      "11773 Traning Loss: tensor(12.5483)\n",
      "11774 Traning Loss: tensor(12.5369)\n",
      "11775 Traning Loss: tensor(12.5255)\n",
      "11776 Traning Loss: tensor(12.5142)\n",
      "11777 Traning Loss: tensor(12.5030)\n",
      "11778 Traning Loss: tensor(12.4918)\n",
      "11779 Traning Loss: tensor(12.4806)\n",
      "11780 Traning Loss: tensor(12.4695)\n",
      "11781 Traning Loss: tensor(12.4584)\n",
      "11782 Traning Loss: tensor(12.4474)\n",
      "11783 Traning Loss: tensor(12.4364)\n",
      "11784 Traning Loss: tensor(12.4254)\n",
      "11785 Traning Loss: tensor(12.4145)\n",
      "11786 Traning Loss: tensor(12.4036)\n",
      "11787 Traning Loss: tensor(12.3928)\n",
      "11788 Traning Loss: tensor(12.3820)\n",
      "11789 Traning Loss: tensor(12.3713)\n",
      "11790 Traning Loss: tensor(12.3606)\n",
      "11791 Traning Loss: tensor(12.3499)\n",
      "11792 Traning Loss: tensor(12.3393)\n",
      "11793 Traning Loss: tensor(12.3287)\n",
      "11794 Traning Loss: tensor(12.3181)\n",
      "11795 Traning Loss: tensor(12.3076)\n",
      "11796 Traning Loss: tensor(12.2971)\n",
      "11797 Traning Loss: tensor(12.2866)\n",
      "11798 Traning Loss: tensor(12.2762)\n",
      "11799 Traning Loss: tensor(12.2658)\n",
      "11800 Traning Loss: tensor(12.2555)\n",
      "11801 Traning Loss: tensor(12.2452)\n",
      "11802 Traning Loss: tensor(12.2349)\n",
      "11803 Traning Loss: tensor(12.2246)\n",
      "11804 Traning Loss: tensor(12.2144)\n",
      "11805 Traning Loss: tensor(12.2042)\n",
      "11806 Traning Loss: tensor(12.1941)\n",
      "11807 Traning Loss: tensor(12.1825)\n",
      "11808 Traning Loss: tensor(12.1724)\n",
      "11809 Traning Loss: tensor(12.1624)\n",
      "11810 Traning Loss: tensor(12.1523)\n",
      "11811 Traning Loss: tensor(12.1424)\n",
      "11812 Traning Loss: tensor(12.1324)\n",
      "11813 Traning Loss: tensor(12.1225)\n",
      "11814 Traning Loss: tensor(12.1126)\n",
      "11815 Traning Loss: tensor(12.1027)\n",
      "11816 Traning Loss: tensor(12.0929)\n",
      "11817 Traning Loss: tensor(12.0831)\n",
      "11818 Traning Loss: tensor(12.0733)\n",
      "11819 Traning Loss: tensor(12.0635)\n",
      "11820 Traning Loss: tensor(12.0538)\n",
      "11821 Traning Loss: tensor(12.0441)\n",
      "11822 Traning Loss: tensor(12.0344)\n",
      "11823 Traning Loss: tensor(12.0248)\n",
      "11824 Traning Loss: tensor(12.0151)\n",
      "11825 Traning Loss: tensor(12.0056)\n",
      "11826 Traning Loss: tensor(11.9960)\n",
      "11827 Traning Loss: tensor(11.9865)\n",
      "11828 Traning Loss: tensor(11.9769)\n",
      "11829 Traning Loss: tensor(11.9674)\n",
      "11830 Traning Loss: tensor(11.9580)\n",
      "11831 Traning Loss: tensor(11.9485)\n",
      "11832 Traning Loss: tensor(11.9391)\n",
      "11833 Traning Loss: tensor(11.9297)\n",
      "11834 Traning Loss: tensor(11.9204)\n",
      "11835 Traning Loss: tensor(11.9110)\n",
      "11836 Traning Loss: tensor(11.9017)\n",
      "11837 Traning Loss: tensor(11.8924)\n",
      "11838 Traning Loss: tensor(11.8831)\n",
      "11839 Traning Loss: tensor(11.8739)\n",
      "11840 Traning Loss: tensor(11.8647)\n",
      "11841 Traning Loss: tensor(11.8555)\n",
      "11842 Traning Loss: tensor(11.8463)\n",
      "11843 Traning Loss: tensor(11.8371)\n",
      "11844 Traning Loss: tensor(11.8280)\n",
      "11845 Traning Loss: tensor(11.8189)\n",
      "11846 Traning Loss: tensor(11.8098)\n",
      "11847 Traning Loss: tensor(11.8007)\n",
      "11848 Traning Loss: tensor(11.7917)\n",
      "11849 Traning Loss: tensor(11.7826)\n",
      "11850 Traning Loss: tensor(11.7736)\n",
      "11851 Traning Loss: tensor(11.7646)\n",
      "11852 Traning Loss: tensor(11.7557)\n",
      "11853 Traning Loss: tensor(11.7467)\n",
      "11854 Traning Loss: tensor(11.7378)\n",
      "11855 Traning Loss: tensor(11.7289)\n",
      "11856 Traning Loss: tensor(11.7200)\n",
      "11857 Traning Loss: tensor(11.7112)\n",
      "11858 Traning Loss: tensor(11.7023)\n",
      "11859 Traning Loss: tensor(11.6935)\n",
      "11860 Traning Loss: tensor(11.6847)\n",
      "11861 Traning Loss: tensor(11.6759)\n",
      "11862 Traning Loss: tensor(11.6671)\n",
      "11863 Traning Loss: tensor(11.6584)\n",
      "11864 Traning Loss: tensor(11.6496)\n",
      "11865 Traning Loss: tensor(11.6409)\n",
      "11866 Traning Loss: tensor(11.6322)\n",
      "11867 Traning Loss: tensor(11.6236)\n",
      "11868 Traning Loss: tensor(11.6149)\n",
      "11869 Traning Loss: tensor(11.6063)\n",
      "11870 Traning Loss: tensor(11.5976)\n",
      "11871 Traning Loss: tensor(11.5890)\n",
      "11872 Traning Loss: tensor(11.5804)\n",
      "11873 Traning Loss: tensor(11.5719)\n",
      "11874 Traning Loss: tensor(11.5633)\n",
      "11875 Traning Loss: tensor(11.5548)\n",
      "11876 Traning Loss: tensor(11.5463)\n",
      "11877 Traning Loss: tensor(11.5378)\n",
      "11878 Traning Loss: tensor(11.5293)\n",
      "11879 Traning Loss: tensor(11.5208)\n",
      "11880 Traning Loss: tensor(11.5124)\n",
      "11881 Traning Loss: tensor(11.5039)\n",
      "11882 Traning Loss: tensor(11.4955)\n",
      "11883 Traning Loss: tensor(11.4871)\n",
      "11884 Traning Loss: tensor(11.4787)\n",
      "11885 Traning Loss: tensor(11.4704)\n",
      "11886 Traning Loss: tensor(11.4620)\n",
      "11887 Traning Loss: tensor(11.4537)\n",
      "11888 Traning Loss: tensor(11.4454)\n",
      "11889 Traning Loss: tensor(11.4371)\n",
      "11890 Traning Loss: tensor(11.4288)\n",
      "11891 Traning Loss: tensor(11.4205)\n",
      "11892 Traning Loss: tensor(11.4122)\n",
      "11893 Traning Loss: tensor(11.4040)\n",
      "11894 Traning Loss: tensor(11.3958)\n",
      "11895 Traning Loss: tensor(11.3875)\n",
      "11896 Traning Loss: tensor(11.3793)\n",
      "11897 Traning Loss: tensor(11.3712)\n",
      "11898 Traning Loss: tensor(11.3630)\n",
      "11899 Traning Loss: tensor(11.3548)\n",
      "11900 Traning Loss: tensor(11.3467)\n",
      "11901 Traning Loss: tensor(11.3386)\n",
      "11902 Traning Loss: tensor(11.3304)\n",
      "11903 Traning Loss: tensor(11.3223)\n",
      "11904 Traning Loss: tensor(11.3143)\n",
      "11905 Traning Loss: tensor(11.3062)\n",
      "11906 Traning Loss: tensor(11.2981)\n",
      "11907 Traning Loss: tensor(11.2901)\n",
      "11908 Traning Loss: tensor(11.2821)\n",
      "11909 Traning Loss: tensor(11.2741)\n",
      "11910 Traning Loss: tensor(11.2661)\n",
      "11911 Traning Loss: tensor(11.2581)\n",
      "11912 Traning Loss: tensor(11.2501)\n",
      "11913 Traning Loss: tensor(11.2421)\n",
      "11914 Traning Loss: tensor(11.2342)\n",
      "11915 Traning Loss: tensor(11.2262)\n",
      "11916 Traning Loss: tensor(11.2183)\n",
      "11917 Traning Loss: tensor(11.2104)\n",
      "11918 Traning Loss: tensor(11.2025)\n",
      "11919 Traning Loss: tensor(11.1946)\n",
      "11920 Traning Loss: tensor(11.1868)\n",
      "11921 Traning Loss: tensor(11.1789)\n",
      "11922 Traning Loss: tensor(11.1711)\n",
      "11923 Traning Loss: tensor(11.1632)\n",
      "11924 Traning Loss: tensor(11.1554)\n",
      "11925 Traning Loss: tensor(11.1476)\n",
      "11926 Traning Loss: tensor(11.1398)\n",
      "11927 Traning Loss: tensor(11.1320)\n",
      "11928 Traning Loss: tensor(11.1242)\n",
      "11929 Traning Loss: tensor(11.1165)\n",
      "11930 Traning Loss: tensor(11.1087)\n",
      "11931 Traning Loss: tensor(11.1010)\n",
      "11932 Traning Loss: tensor(11.0933)\n",
      "11933 Traning Loss: tensor(11.0856)\n",
      "11934 Traning Loss: tensor(11.0779)\n",
      "11935 Traning Loss: tensor(11.0702)\n",
      "11936 Traning Loss: tensor(11.0625)\n",
      "11937 Traning Loss: tensor(11.0548)\n",
      "11938 Traning Loss: tensor(11.0472)\n",
      "11939 Traning Loss: tensor(11.0396)\n",
      "11940 Traning Loss: tensor(11.0319)\n",
      "11941 Traning Loss: tensor(11.0243)\n",
      "11942 Traning Loss: tensor(11.0167)\n",
      "11943 Traning Loss: tensor(11.0091)\n",
      "11944 Traning Loss: tensor(11.0015)\n",
      "11945 Traning Loss: tensor(10.9939)\n",
      "11946 Traning Loss: tensor(10.9864)\n",
      "11947 Traning Loss: tensor(10.9788)\n",
      "11948 Traning Loss: tensor(10.9713)\n",
      "11949 Traning Loss: tensor(10.9637)\n",
      "11950 Traning Loss: tensor(10.9562)\n",
      "11951 Traning Loss: tensor(10.9487)\n",
      "11952 Traning Loss: tensor(10.9412)\n",
      "11953 Traning Loss: tensor(10.9337)\n",
      "11954 Traning Loss: tensor(10.9263)\n",
      "11955 Traning Loss: tensor(10.9188)\n",
      "11956 Traning Loss: tensor(10.9113)\n",
      "11957 Traning Loss: tensor(10.9039)\n",
      "11958 Traning Loss: tensor(10.8965)\n",
      "11959 Traning Loss: tensor(10.8890)\n",
      "11960 Traning Loss: tensor(10.8816)\n",
      "11961 Traning Loss: tensor(10.8742)\n",
      "11962 Traning Loss: tensor(10.8668)\n",
      "11963 Traning Loss: tensor(10.8594)\n",
      "11964 Traning Loss: tensor(10.8520)\n",
      "11965 Traning Loss: tensor(10.8447)\n",
      "11966 Traning Loss: tensor(10.8373)\n",
      "11967 Traning Loss: tensor(10.8300)\n",
      "11968 Traning Loss: tensor(10.8226)\n",
      "11969 Traning Loss: tensor(10.8153)\n",
      "11970 Traning Loss: tensor(10.8080)\n",
      "11971 Traning Loss: tensor(10.8007)\n",
      "11972 Traning Loss: tensor(10.7934)\n",
      "11973 Traning Loss: tensor(10.7861)\n",
      "11974 Traning Loss: tensor(10.7788)\n",
      "11975 Traning Loss: tensor(10.7716)\n",
      "11976 Traning Loss: tensor(10.7643)\n",
      "11977 Traning Loss: tensor(10.7571)\n",
      "11978 Traning Loss: tensor(10.7498)\n",
      "11979 Traning Loss: tensor(10.7426)\n",
      "11980 Traning Loss: tensor(10.7354)\n",
      "11981 Traning Loss: tensor(10.7282)\n",
      "11982 Traning Loss: tensor(10.7210)\n",
      "11983 Traning Loss: tensor(10.7138)\n",
      "11984 Traning Loss: tensor(10.7066)\n",
      "11985 Traning Loss: tensor(10.6994)\n",
      "11986 Traning Loss: tensor(10.6922)\n",
      "11987 Traning Loss: tensor(10.6851)\n",
      "11988 Traning Loss: tensor(10.6779)\n",
      "11989 Traning Loss: tensor(10.6708)\n",
      "11990 Traning Loss: tensor(10.6637)\n",
      "11991 Traning Loss: tensor(10.6565)\n",
      "11992 Traning Loss: tensor(10.6494)\n",
      "11993 Traning Loss: tensor(10.6423)\n",
      "11994 Traning Loss: tensor(10.6352)\n",
      "11995 Traning Loss: tensor(10.6281)\n",
      "11996 Traning Loss: tensor(10.6210)\n",
      "11997 Traning Loss: tensor(10.6140)\n",
      "11998 Traning Loss: tensor(10.6069)\n",
      "11999 Traning Loss: tensor(10.5999)\n",
      "12000 Traning Loss: tensor(10.5928)\n",
      "12001 Traning Loss: tensor(10.5858)\n",
      "12002 Traning Loss: tensor(10.5787)\n",
      "12003 Traning Loss: tensor(10.5717)\n",
      "12004 Traning Loss: tensor(10.5647)\n",
      "12005 Traning Loss: tensor(10.5577)\n",
      "12006 Traning Loss: tensor(10.5507)\n",
      "12007 Traning Loss: tensor(10.5437)\n",
      "12008 Traning Loss: tensor(10.5367)\n",
      "12009 Traning Loss: tensor(10.5298)\n",
      "12010 Traning Loss: tensor(10.5228)\n",
      "12011 Traning Loss: tensor(10.5158)\n",
      "12012 Traning Loss: tensor(10.5089)\n",
      "12013 Traning Loss: tensor(10.5020)\n",
      "12014 Traning Loss: tensor(10.4950)\n",
      "12015 Traning Loss: tensor(10.4881)\n",
      "12016 Traning Loss: tensor(10.4812)\n",
      "12017 Traning Loss: tensor(10.4743)\n",
      "12018 Traning Loss: tensor(10.4674)\n",
      "12019 Traning Loss: tensor(10.4605)\n",
      "12020 Traning Loss: tensor(10.4536)\n",
      "12021 Traning Loss: tensor(10.4467)\n",
      "12022 Traning Loss: tensor(10.4399)\n",
      "12023 Traning Loss: tensor(10.4330)\n",
      "12024 Traning Loss: tensor(10.4261)\n",
      "12025 Traning Loss: tensor(10.4193)\n",
      "12026 Traning Loss: tensor(10.4125)\n",
      "12027 Traning Loss: tensor(10.4056)\n",
      "12028 Traning Loss: tensor(10.3988)\n",
      "12029 Traning Loss: tensor(10.3920)\n",
      "12030 Traning Loss: tensor(10.3852)\n",
      "12031 Traning Loss: tensor(10.3784)\n",
      "12032 Traning Loss: tensor(10.3716)\n",
      "12033 Traning Loss: tensor(10.3648)\n",
      "12034 Traning Loss: tensor(10.3580)\n",
      "12035 Traning Loss: tensor(10.3512)\n",
      "12036 Traning Loss: tensor(10.3445)\n",
      "12037 Traning Loss: tensor(10.3377)\n",
      "12038 Traning Loss: tensor(10.3310)\n",
      "12039 Traning Loss: tensor(10.3242)\n",
      "12040 Traning Loss: tensor(10.3175)\n",
      "12041 Traning Loss: tensor(10.3107)\n",
      "12042 Traning Loss: tensor(10.3040)\n",
      "12043 Traning Loss: tensor(10.2973)\n",
      "12044 Traning Loss: tensor(10.2906)\n",
      "12045 Traning Loss: tensor(10.2839)\n",
      "12046 Traning Loss: tensor(10.2772)\n",
      "12047 Traning Loss: tensor(10.2705)\n",
      "12048 Traning Loss: tensor(10.2638)\n",
      "12049 Traning Loss: tensor(10.2572)\n",
      "12050 Traning Loss: tensor(10.2505)\n",
      "12051 Traning Loss: tensor(10.2438)\n",
      "12052 Traning Loss: tensor(10.2372)\n",
      "12053 Traning Loss: tensor(10.2305)\n",
      "12054 Traning Loss: tensor(10.2239)\n",
      "12055 Traning Loss: tensor(10.2173)\n",
      "12056 Traning Loss: tensor(10.2106)\n",
      "12057 Traning Loss: tensor(10.2040)\n",
      "12058 Traning Loss: tensor(10.1974)\n",
      "12059 Traning Loss: tensor(10.1908)\n",
      "12060 Traning Loss: tensor(10.1842)\n",
      "12061 Traning Loss: tensor(10.1776)\n",
      "12062 Traning Loss: tensor(10.1710)\n",
      "12063 Traning Loss: tensor(10.1644)\n",
      "12064 Traning Loss: tensor(10.1579)\n",
      "12065 Traning Loss: tensor(10.1513)\n",
      "12066 Traning Loss: tensor(10.1447)\n",
      "12067 Traning Loss: tensor(10.1382)\n",
      "12068 Traning Loss: tensor(10.1316)\n",
      "12069 Traning Loss: tensor(10.1251)\n",
      "12070 Traning Loss: tensor(10.1185)\n",
      "12071 Traning Loss: tensor(10.1120)\n",
      "12072 Traning Loss: tensor(10.1055)\n",
      "12073 Traning Loss: tensor(10.0990)\n",
      "12074 Traning Loss: tensor(10.0925)\n",
      "12075 Traning Loss: tensor(10.0860)\n",
      "12076 Traning Loss: tensor(10.0795)\n",
      "12077 Traning Loss: tensor(10.0730)\n",
      "12078 Traning Loss: tensor(10.0665)\n",
      "12079 Traning Loss: tensor(10.0600)\n",
      "12080 Traning Loss: tensor(10.0535)\n",
      "12081 Traning Loss: tensor(10.0471)\n",
      "12082 Traning Loss: tensor(10.0406)\n",
      "12083 Traning Loss: tensor(10.0341)\n",
      "12084 Traning Loss: tensor(10.0277)\n",
      "12085 Traning Loss: tensor(10.0212)\n",
      "12086 Traning Loss: tensor(10.0148)\n",
      "12087 Traning Loss: tensor(10.0084)\n",
      "12088 Traning Loss: tensor(10.0020)\n",
      "12089 Traning Loss: tensor(9.9955)\n",
      "12090 Traning Loss: tensor(9.9891)\n",
      "12091 Traning Loss: tensor(9.9827)\n",
      "12092 Traning Loss: tensor(9.9763)\n",
      "12093 Traning Loss: tensor(9.9699)\n",
      "12094 Traning Loss: tensor(9.9635)\n",
      "12095 Traning Loss: tensor(9.9571)\n",
      "12096 Traning Loss: tensor(9.9508)\n",
      "12097 Traning Loss: tensor(9.9429)\n",
      "12098 Traning Loss: tensor(9.9365)\n",
      "12099 Traning Loss: tensor(9.9302)\n",
      "12100 Traning Loss: tensor(9.9238)\n",
      "12101 Traning Loss: tensor(9.9175)\n",
      "12102 Traning Loss: tensor(9.9112)\n",
      "12103 Traning Loss: tensor(9.9048)\n",
      "12104 Traning Loss: tensor(9.8985)\n",
      "12105 Traning Loss: tensor(9.8922)\n",
      "12106 Traning Loss: tensor(9.8859)\n",
      "12107 Traning Loss: tensor(9.8795)\n",
      "12108 Traning Loss: tensor(9.8733)\n",
      "12109 Traning Loss: tensor(9.8669)\n",
      "12110 Traning Loss: tensor(9.8607)\n",
      "12111 Traning Loss: tensor(9.8544)\n",
      "12112 Traning Loss: tensor(9.8481)\n",
      "12113 Traning Loss: tensor(9.8418)\n",
      "12114 Traning Loss: tensor(9.8355)\n",
      "12115 Traning Loss: tensor(9.8293)\n",
      "12116 Traning Loss: tensor(9.8230)\n",
      "12117 Traning Loss: tensor(9.8168)\n",
      "12118 Traning Loss: tensor(9.8105)\n",
      "12119 Traning Loss: tensor(9.8043)\n",
      "12120 Traning Loss: tensor(9.7980)\n",
      "12121 Traning Loss: tensor(9.7918)\n",
      "12122 Traning Loss: tensor(9.7856)\n",
      "12123 Traning Loss: tensor(9.7793)\n",
      "12124 Traning Loss: tensor(9.7731)\n",
      "12125 Traning Loss: tensor(9.7669)\n",
      "12126 Traning Loss: tensor(9.7607)\n",
      "12127 Traning Loss: tensor(9.7545)\n",
      "12128 Traning Loss: tensor(9.7483)\n",
      "12129 Traning Loss: tensor(9.7421)\n",
      "12130 Traning Loss: tensor(9.7359)\n",
      "12131 Traning Loss: tensor(9.7297)\n",
      "12132 Traning Loss: tensor(9.7236)\n",
      "12133 Traning Loss: tensor(9.7174)\n",
      "12134 Traning Loss: tensor(9.7112)\n",
      "12135 Traning Loss: tensor(9.7051)\n",
      "12136 Traning Loss: tensor(9.6989)\n",
      "12137 Traning Loss: tensor(9.6928)\n",
      "12138 Traning Loss: tensor(9.6866)\n",
      "12139 Traning Loss: tensor(9.6805)\n",
      "12140 Traning Loss: tensor(9.6743)\n",
      "12141 Traning Loss: tensor(9.6682)\n",
      "12142 Traning Loss: tensor(9.6621)\n",
      "12143 Traning Loss: tensor(9.6560)\n",
      "12144 Traning Loss: tensor(9.6499)\n",
      "12145 Traning Loss: tensor(9.6438)\n",
      "12146 Traning Loss: tensor(9.6376)\n",
      "12147 Traning Loss: tensor(9.6315)\n",
      "12148 Traning Loss: tensor(9.6254)\n",
      "12149 Traning Loss: tensor(9.6194)\n",
      "12150 Traning Loss: tensor(9.6133)\n",
      "12151 Traning Loss: tensor(9.6072)\n",
      "12152 Traning Loss: tensor(9.6011)\n",
      "12153 Traning Loss: tensor(9.5950)\n",
      "12154 Traning Loss: tensor(9.5890)\n",
      "12155 Traning Loss: tensor(9.5829)\n",
      "12156 Traning Loss: tensor(9.5769)\n",
      "12157 Traning Loss: tensor(9.5708)\n",
      "12158 Traning Loss: tensor(9.5648)\n",
      "12159 Traning Loss: tensor(9.5587)\n",
      "12160 Traning Loss: tensor(9.5527)\n",
      "12161 Traning Loss: tensor(9.5466)\n",
      "12162 Traning Loss: tensor(9.5406)\n",
      "12163 Traning Loss: tensor(9.5346)\n",
      "12164 Traning Loss: tensor(9.5286)\n",
      "12165 Traning Loss: tensor(9.5226)\n",
      "12166 Traning Loss: tensor(9.5166)\n",
      "12167 Traning Loss: tensor(9.5105)\n",
      "12168 Traning Loss: tensor(9.5046)\n",
      "12169 Traning Loss: tensor(9.4986)\n",
      "12170 Traning Loss: tensor(9.4926)\n",
      "12171 Traning Loss: tensor(9.4866)\n",
      "12172 Traning Loss: tensor(9.4806)\n",
      "12173 Traning Loss: tensor(9.4746)\n",
      "12174 Traning Loss: tensor(9.4686)\n",
      "12175 Traning Loss: tensor(9.4627)\n",
      "12176 Traning Loss: tensor(9.4567)\n",
      "12177 Traning Loss: tensor(9.4508)\n",
      "12178 Traning Loss: tensor(9.4448)\n",
      "12179 Traning Loss: tensor(9.4389)\n",
      "12180 Traning Loss: tensor(9.4329)\n",
      "12181 Traning Loss: tensor(9.4270)\n",
      "12182 Traning Loss: tensor(9.4210)\n",
      "12183 Traning Loss: tensor(9.4151)\n",
      "12184 Traning Loss: tensor(9.4092)\n",
      "12185 Traning Loss: tensor(9.4032)\n",
      "12186 Traning Loss: tensor(9.3973)\n",
      "12187 Traning Loss: tensor(9.3914)\n",
      "12188 Traning Loss: tensor(9.3855)\n",
      "12189 Traning Loss: tensor(9.3796)\n",
      "12190 Traning Loss: tensor(9.3737)\n",
      "12191 Traning Loss: tensor(9.3678)\n",
      "12192 Traning Loss: tensor(9.3619)\n",
      "12193 Traning Loss: tensor(9.3560)\n",
      "12194 Traning Loss: tensor(9.3501)\n",
      "12195 Traning Loss: tensor(9.3443)\n",
      "12196 Traning Loss: tensor(9.3384)\n",
      "12197 Traning Loss: tensor(9.3325)\n",
      "12198 Traning Loss: tensor(9.3266)\n",
      "12199 Traning Loss: tensor(9.3208)\n",
      "12200 Traning Loss: tensor(9.3149)\n",
      "12201 Traning Loss: tensor(9.3091)\n",
      "12202 Traning Loss: tensor(9.3032)\n",
      "12203 Traning Loss: tensor(9.2974)\n",
      "12204 Traning Loss: tensor(9.2915)\n",
      "12205 Traning Loss: tensor(9.2857)\n",
      "12206 Traning Loss: tensor(9.2799)\n",
      "12207 Traning Loss: tensor(9.2740)\n",
      "12208 Traning Loss: tensor(9.2682)\n",
      "12209 Traning Loss: tensor(9.2624)\n",
      "12210 Traning Loss: tensor(9.2566)\n",
      "12211 Traning Loss: tensor(9.2508)\n",
      "12212 Traning Loss: tensor(9.2450)\n",
      "12213 Traning Loss: tensor(9.2392)\n",
      "12214 Traning Loss: tensor(9.2334)\n",
      "12215 Traning Loss: tensor(9.2276)\n",
      "12216 Traning Loss: tensor(9.2218)\n",
      "12217 Traning Loss: tensor(9.2160)\n",
      "12218 Traning Loss: tensor(9.2102)\n",
      "12219 Traning Loss: tensor(9.2044)\n",
      "12220 Traning Loss: tensor(9.1987)\n",
      "12221 Traning Loss: tensor(9.1929)\n",
      "12222 Traning Loss: tensor(9.1871)\n",
      "12223 Traning Loss: tensor(9.1813)\n",
      "12224 Traning Loss: tensor(9.1756)\n",
      "12225 Traning Loss: tensor(9.1698)\n",
      "12226 Traning Loss: tensor(9.1641)\n",
      "12227 Traning Loss: tensor(9.1583)\n",
      "12228 Traning Loss: tensor(9.1526)\n",
      "12229 Traning Loss: tensor(9.1469)\n",
      "12230 Traning Loss: tensor(9.1411)\n",
      "12231 Traning Loss: tensor(9.1354)\n",
      "12232 Traning Loss: tensor(9.1297)\n",
      "12233 Traning Loss: tensor(9.1239)\n",
      "12234 Traning Loss: tensor(9.1182)\n",
      "12235 Traning Loss: tensor(9.1125)\n",
      "12236 Traning Loss: tensor(9.1068)\n",
      "12237 Traning Loss: tensor(9.1011)\n",
      "12238 Traning Loss: tensor(9.0954)\n",
      "12239 Traning Loss: tensor(9.0897)\n",
      "12240 Traning Loss: tensor(9.0840)\n",
      "12241 Traning Loss: tensor(9.0783)\n",
      "12242 Traning Loss: tensor(9.0726)\n",
      "12243 Traning Loss: tensor(9.0669)\n",
      "12244 Traning Loss: tensor(9.0613)\n",
      "12245 Traning Loss: tensor(9.0556)\n",
      "12246 Traning Loss: tensor(9.0499)\n",
      "12247 Traning Loss: tensor(9.0442)\n",
      "12248 Traning Loss: tensor(9.0386)\n",
      "12249 Traning Loss: tensor(9.0329)\n",
      "12250 Traning Loss: tensor(9.0273)\n",
      "12251 Traning Loss: tensor(9.0216)\n",
      "12252 Traning Loss: tensor(9.0160)\n",
      "12253 Traning Loss: tensor(9.0103)\n",
      "12254 Traning Loss: tensor(9.0047)\n",
      "12255 Traning Loss: tensor(8.9990)\n",
      "12256 Traning Loss: tensor(8.9934)\n",
      "12257 Traning Loss: tensor(8.9878)\n",
      "12258 Traning Loss: tensor(8.9821)\n",
      "12259 Traning Loss: tensor(8.9765)\n",
      "12260 Traning Loss: tensor(8.9709)\n",
      "12261 Traning Loss: tensor(8.9653)\n",
      "12262 Traning Loss: tensor(8.9597)\n",
      "12263 Traning Loss: tensor(8.9541)\n",
      "12264 Traning Loss: tensor(8.9484)\n",
      "12265 Traning Loss: tensor(8.9428)\n",
      "12266 Traning Loss: tensor(8.9372)\n",
      "12267 Traning Loss: tensor(8.9317)\n",
      "12268 Traning Loss: tensor(8.9261)\n",
      "12269 Traning Loss: tensor(8.9205)\n",
      "12270 Traning Loss: tensor(8.9149)\n",
      "12271 Traning Loss: tensor(8.9093)\n",
      "12272 Traning Loss: tensor(8.9037)\n",
      "12273 Traning Loss: tensor(8.8982)\n",
      "12274 Traning Loss: tensor(8.8926)\n",
      "12275 Traning Loss: tensor(8.8870)\n",
      "12276 Traning Loss: tensor(8.8815)\n",
      "12277 Traning Loss: tensor(8.8759)\n",
      "12278 Traning Loss: tensor(8.8703)\n",
      "12279 Traning Loss: tensor(8.8648)\n",
      "12280 Traning Loss: tensor(8.8592)\n",
      "12281 Traning Loss: tensor(8.8537)\n",
      "12282 Traning Loss: tensor(8.8482)\n",
      "12283 Traning Loss: tensor(8.8426)\n",
      "12284 Traning Loss: tensor(8.8371)\n",
      "12285 Traning Loss: tensor(8.8316)\n",
      "12286 Traning Loss: tensor(8.8260)\n",
      "12287 Traning Loss: tensor(8.8205)\n",
      "12288 Traning Loss: tensor(8.8150)\n",
      "12289 Traning Loss: tensor(8.8018)\n",
      "12290 Traning Loss: tensor(8.7963)\n",
      "12291 Traning Loss: tensor(8.7907)\n",
      "12292 Traning Loss: tensor(8.7852)\n",
      "12293 Traning Loss: tensor(8.7797)\n",
      "12294 Traning Loss: tensor(8.7742)\n",
      "12295 Traning Loss: tensor(8.7687)\n",
      "12296 Traning Loss: tensor(8.7632)\n",
      "12297 Traning Loss: tensor(8.7577)\n",
      "12298 Traning Loss: tensor(8.7522)\n",
      "12299 Traning Loss: tensor(8.7467)\n",
      "12300 Traning Loss: tensor(8.7412)\n",
      "12301 Traning Loss: tensor(8.7357)\n",
      "12302 Traning Loss: tensor(8.7302)\n",
      "12303 Traning Loss: tensor(8.7247)\n",
      "12304 Traning Loss: tensor(8.7192)\n",
      "12305 Traning Loss: tensor(8.7137)\n",
      "12306 Traning Loss: tensor(8.7083)\n",
      "12307 Traning Loss: tensor(8.7028)\n",
      "12308 Traning Loss: tensor(8.6973)\n",
      "12309 Traning Loss: tensor(8.6919)\n",
      "12310 Traning Loss: tensor(8.6864)\n",
      "12311 Traning Loss: tensor(8.6809)\n",
      "12312 Traning Loss: tensor(8.6755)\n",
      "12313 Traning Loss: tensor(8.6700)\n",
      "12314 Traning Loss: tensor(8.6646)\n",
      "12315 Traning Loss: tensor(8.6591)\n",
      "12316 Traning Loss: tensor(8.6537)\n",
      "12317 Traning Loss: tensor(8.6482)\n",
      "12318 Traning Loss: tensor(8.6428)\n",
      "12319 Traning Loss: tensor(8.6374)\n",
      "12320 Traning Loss: tensor(8.6319)\n",
      "12321 Traning Loss: tensor(8.6265)\n",
      "12322 Traning Loss: tensor(8.6211)\n",
      "12323 Traning Loss: tensor(8.6157)\n",
      "12324 Traning Loss: tensor(8.6103)\n",
      "12325 Traning Loss: tensor(8.6048)\n",
      "12326 Traning Loss: tensor(8.5994)\n",
      "12327 Traning Loss: tensor(8.5940)\n",
      "12328 Traning Loss: tensor(8.5886)\n",
      "12329 Traning Loss: tensor(8.5832)\n",
      "12330 Traning Loss: tensor(8.5778)\n",
      "12331 Traning Loss: tensor(8.5724)\n",
      "12332 Traning Loss: tensor(8.5670)\n",
      "12333 Traning Loss: tensor(8.5616)\n",
      "12334 Traning Loss: tensor(8.5563)\n",
      "12335 Traning Loss: tensor(8.5509)\n",
      "12336 Traning Loss: tensor(8.5455)\n",
      "12337 Traning Loss: tensor(8.5401)\n",
      "12338 Traning Loss: tensor(8.5348)\n",
      "12339 Traning Loss: tensor(8.5294)\n",
      "12340 Traning Loss: tensor(8.5240)\n",
      "12341 Traning Loss: tensor(8.5187)\n",
      "12342 Traning Loss: tensor(8.5133)\n",
      "12343 Traning Loss: tensor(8.5079)\n",
      "12344 Traning Loss: tensor(8.5026)\n",
      "12345 Traning Loss: tensor(8.4972)\n",
      "12346 Traning Loss: tensor(8.4919)\n",
      "12347 Traning Loss: tensor(8.4866)\n",
      "12348 Traning Loss: tensor(8.4812)\n",
      "12349 Traning Loss: tensor(8.4759)\n",
      "12350 Traning Loss: tensor(8.4705)\n",
      "12351 Traning Loss: tensor(8.4652)\n",
      "12352 Traning Loss: tensor(8.4599)\n",
      "12353 Traning Loss: tensor(8.4545)\n",
      "12354 Traning Loss: tensor(8.4492)\n",
      "12355 Traning Loss: tensor(8.4439)\n",
      "12356 Traning Loss: tensor(8.4386)\n",
      "12357 Traning Loss: tensor(8.4333)\n",
      "12358 Traning Loss: tensor(8.4280)\n",
      "12359 Traning Loss: tensor(8.4227)\n",
      "12360 Traning Loss: tensor(8.4173)\n",
      "12361 Traning Loss: tensor(8.4120)\n",
      "12362 Traning Loss: tensor(8.4067)\n",
      "12363 Traning Loss: tensor(8.4014)\n",
      "12364 Traning Loss: tensor(8.3962)\n",
      "12365 Traning Loss: tensor(8.3909)\n",
      "12366 Traning Loss: tensor(8.3856)\n",
      "12367 Traning Loss: tensor(8.3803)\n",
      "12368 Traning Loss: tensor(8.3750)\n",
      "12369 Traning Loss: tensor(8.3697)\n",
      "12370 Traning Loss: tensor(8.3645)\n",
      "12371 Traning Loss: tensor(8.3592)\n",
      "12372 Traning Loss: tensor(8.3539)\n",
      "12373 Traning Loss: tensor(8.3487)\n",
      "12374 Traning Loss: tensor(8.3434)\n",
      "12375 Traning Loss: tensor(8.3381)\n",
      "12376 Traning Loss: tensor(8.3329)\n",
      "12377 Traning Loss: tensor(8.3276)\n",
      "12378 Traning Loss: tensor(8.3224)\n",
      "12379 Traning Loss: tensor(8.3171)\n",
      "12380 Traning Loss: tensor(8.3119)\n",
      "12381 Traning Loss: tensor(8.3066)\n",
      "12382 Traning Loss: tensor(8.3014)\n",
      "12383 Traning Loss: tensor(8.2962)\n",
      "12384 Traning Loss: tensor(8.2909)\n",
      "12385 Traning Loss: tensor(8.2857)\n",
      "12386 Traning Loss: tensor(8.2805)\n",
      "12387 Traning Loss: tensor(8.2752)\n",
      "12388 Traning Loss: tensor(8.2700)\n",
      "12389 Traning Loss: tensor(8.2648)\n",
      "12390 Traning Loss: tensor(8.2596)\n",
      "12391 Traning Loss: tensor(8.2544)\n",
      "12392 Traning Loss: tensor(8.2492)\n",
      "12393 Traning Loss: tensor(8.2440)\n",
      "12394 Traning Loss: tensor(8.2388)\n",
      "12395 Traning Loss: tensor(8.2336)\n",
      "12396 Traning Loss: tensor(8.2284)\n",
      "12397 Traning Loss: tensor(8.2232)\n",
      "12398 Traning Loss: tensor(8.2180)\n",
      "12399 Traning Loss: tensor(8.2128)\n",
      "12400 Traning Loss: tensor(8.2076)\n",
      "12401 Traning Loss: tensor(8.2024)\n",
      "12402 Traning Loss: tensor(8.1972)\n",
      "12403 Traning Loss: tensor(8.1921)\n",
      "12404 Traning Loss: tensor(8.1869)\n",
      "12405 Traning Loss: tensor(8.1817)\n",
      "12406 Traning Loss: tensor(8.1765)\n",
      "12407 Traning Loss: tensor(8.1714)\n",
      "12408 Traning Loss: tensor(8.1662)\n",
      "12409 Traning Loss: tensor(8.1610)\n",
      "12410 Traning Loss: tensor(8.1559)\n",
      "12411 Traning Loss: tensor(8.1507)\n",
      "12412 Traning Loss: tensor(8.1456)\n",
      "12413 Traning Loss: tensor(8.1404)\n",
      "12414 Traning Loss: tensor(8.1353)\n",
      "12415 Traning Loss: tensor(8.1301)\n",
      "12416 Traning Loss: tensor(8.1250)\n",
      "12417 Traning Loss: tensor(8.1198)\n",
      "12418 Traning Loss: tensor(8.1147)\n",
      "12419 Traning Loss: tensor(8.1096)\n",
      "12420 Traning Loss: tensor(8.1044)\n",
      "12421 Traning Loss: tensor(8.0993)\n",
      "12422 Traning Loss: tensor(8.0942)\n",
      "12423 Traning Loss: tensor(8.0891)\n",
      "12424 Traning Loss: tensor(8.0839)\n",
      "12425 Traning Loss: tensor(8.0788)\n",
      "12426 Traning Loss: tensor(8.0737)\n",
      "12427 Traning Loss: tensor(8.0686)\n",
      "12428 Traning Loss: tensor(8.0635)\n",
      "12429 Traning Loss: tensor(8.0584)\n",
      "12430 Traning Loss: tensor(8.0533)\n",
      "12431 Traning Loss: tensor(8.0482)\n",
      "12432 Traning Loss: tensor(8.0431)\n",
      "12433 Traning Loss: tensor(8.0380)\n",
      "12434 Traning Loss: tensor(8.0329)\n",
      "12435 Traning Loss: tensor(8.0278)\n",
      "12436 Traning Loss: tensor(8.0227)\n",
      "12437 Traning Loss: tensor(8.0176)\n",
      "12438 Traning Loss: tensor(8.0125)\n",
      "12439 Traning Loss: tensor(8.0075)\n",
      "12440 Traning Loss: tensor(8.0024)\n",
      "12441 Traning Loss: tensor(7.9973)\n",
      "12442 Traning Loss: tensor(7.9922)\n",
      "12443 Traning Loss: tensor(7.9872)\n",
      "12444 Traning Loss: tensor(7.9805)\n",
      "12445 Traning Loss: tensor(7.9754)\n",
      "12446 Traning Loss: tensor(7.9704)\n",
      "12447 Traning Loss: tensor(7.9653)\n",
      "12448 Traning Loss: tensor(7.9603)\n",
      "12449 Traning Loss: tensor(7.9552)\n",
      "12450 Traning Loss: tensor(7.9502)\n",
      "12451 Traning Loss: tensor(7.9451)\n",
      "12452 Traning Loss: tensor(7.9401)\n",
      "12453 Traning Loss: tensor(7.9350)\n",
      "12454 Traning Loss: tensor(7.9300)\n",
      "12455 Traning Loss: tensor(7.9250)\n",
      "12456 Traning Loss: tensor(7.9199)\n",
      "12457 Traning Loss: tensor(7.9149)\n",
      "12458 Traning Loss: tensor(7.9099)\n",
      "12459 Traning Loss: tensor(7.9049)\n",
      "12460 Traning Loss: tensor(7.8998)\n",
      "12461 Traning Loss: tensor(7.8948)\n",
      "12462 Traning Loss: tensor(7.8898)\n",
      "12463 Traning Loss: tensor(7.8848)\n",
      "12464 Traning Loss: tensor(7.8798)\n",
      "12465 Traning Loss: tensor(7.8748)\n",
      "12466 Traning Loss: tensor(7.8698)\n",
      "12467 Traning Loss: tensor(7.8648)\n",
      "12468 Traning Loss: tensor(7.8598)\n",
      "12469 Traning Loss: tensor(7.8548)\n",
      "12470 Traning Loss: tensor(7.8498)\n",
      "12471 Traning Loss: tensor(7.8448)\n",
      "12472 Traning Loss: tensor(7.8398)\n",
      "12473 Traning Loss: tensor(7.8348)\n",
      "12474 Traning Loss: tensor(7.8298)\n",
      "12475 Traning Loss: tensor(7.8248)\n",
      "12476 Traning Loss: tensor(7.8199)\n",
      "12477 Traning Loss: tensor(7.8149)\n",
      "12478 Traning Loss: tensor(7.8099)\n",
      "12479 Traning Loss: tensor(7.8049)\n",
      "12480 Traning Loss: tensor(7.8000)\n",
      "12481 Traning Loss: tensor(7.7950)\n",
      "12482 Traning Loss: tensor(7.7900)\n",
      "12483 Traning Loss: tensor(7.7851)\n",
      "12484 Traning Loss: tensor(7.7801)\n",
      "12485 Traning Loss: tensor(7.7752)\n",
      "12486 Traning Loss: tensor(7.7702)\n",
      "12487 Traning Loss: tensor(7.7653)\n",
      "12488 Traning Loss: tensor(7.7603)\n",
      "12489 Traning Loss: tensor(7.7554)\n",
      "12490 Traning Loss: tensor(7.7504)\n",
      "12491 Traning Loss: tensor(7.7455)\n",
      "12492 Traning Loss: tensor(7.7405)\n",
      "12493 Traning Loss: tensor(7.7356)\n",
      "12494 Traning Loss: tensor(7.7307)\n",
      "12495 Traning Loss: tensor(7.7257)\n",
      "12496 Traning Loss: tensor(7.7208)\n",
      "12497 Traning Loss: tensor(7.7159)\n",
      "12498 Traning Loss: tensor(7.7109)\n",
      "12499 Traning Loss: tensor(7.7060)\n",
      "12500 Traning Loss: tensor(7.7011)\n",
      "12501 Traning Loss: tensor(7.6962)\n",
      "12502 Traning Loss: tensor(7.6913)\n",
      "12503 Traning Loss: tensor(7.6863)\n",
      "12504 Traning Loss: tensor(7.6814)\n",
      "12505 Traning Loss: tensor(7.6765)\n",
      "12506 Traning Loss: tensor(7.6716)\n",
      "12507 Traning Loss: tensor(7.6667)\n",
      "12508 Traning Loss: tensor(7.6618)\n",
      "12509 Traning Loss: tensor(7.6569)\n",
      "12510 Traning Loss: tensor(7.6520)\n",
      "12511 Traning Loss: tensor(7.6471)\n",
      "12512 Traning Loss: tensor(7.6422)\n",
      "12513 Traning Loss: tensor(7.6373)\n",
      "12514 Traning Loss: tensor(7.6324)\n",
      "12515 Traning Loss: tensor(7.6276)\n",
      "12516 Traning Loss: tensor(7.6227)\n",
      "12517 Traning Loss: tensor(7.6178)\n",
      "12518 Traning Loss: tensor(7.6129)\n",
      "12519 Traning Loss: tensor(7.6081)\n",
      "12520 Traning Loss: tensor(7.6032)\n",
      "12521 Traning Loss: tensor(7.5983)\n",
      "12522 Traning Loss: tensor(7.5934)\n",
      "12523 Traning Loss: tensor(7.5886)\n",
      "12524 Traning Loss: tensor(7.5837)\n",
      "12525 Traning Loss: tensor(7.5789)\n",
      "12526 Traning Loss: tensor(7.5740)\n",
      "12527 Traning Loss: tensor(7.5691)\n",
      "12528 Traning Loss: tensor(7.5643)\n",
      "12529 Traning Loss: tensor(7.5594)\n",
      "12530 Traning Loss: tensor(7.5546)\n",
      "12531 Traning Loss: tensor(7.5497)\n",
      "12532 Traning Loss: tensor(7.5449)\n",
      "12533 Traning Loss: tensor(7.5400)\n",
      "12534 Traning Loss: tensor(7.5352)\n",
      "12535 Traning Loss: tensor(7.5303)\n",
      "12536 Traning Loss: tensor(7.5255)\n",
      "12537 Traning Loss: tensor(7.5207)\n",
      "12538 Traning Loss: tensor(7.5158)\n",
      "12539 Traning Loss: tensor(7.5110)\n",
      "12540 Traning Loss: tensor(7.5062)\n",
      "12541 Traning Loss: tensor(7.5014)\n",
      "12542 Traning Loss: tensor(7.4965)\n",
      "12543 Traning Loss: tensor(7.4917)\n",
      "12544 Traning Loss: tensor(7.4869)\n",
      "12545 Traning Loss: tensor(7.4821)\n",
      "12546 Traning Loss: tensor(7.4773)\n",
      "12547 Traning Loss: tensor(7.4724)\n",
      "12548 Traning Loss: tensor(7.4676)\n",
      "12549 Traning Loss: tensor(7.4628)\n",
      "12550 Traning Loss: tensor(7.4580)\n",
      "12551 Traning Loss: tensor(7.4532)\n",
      "12552 Traning Loss: tensor(7.4484)\n",
      "12553 Traning Loss: tensor(7.4436)\n",
      "12554 Traning Loss: tensor(7.4388)\n",
      "12555 Traning Loss: tensor(7.4340)\n",
      "12556 Traning Loss: tensor(7.4292)\n",
      "12557 Traning Loss: tensor(7.4244)\n",
      "12558 Traning Loss: tensor(7.4197)\n",
      "12559 Traning Loss: tensor(7.4149)\n",
      "12560 Traning Loss: tensor(7.4101)\n",
      "12561 Traning Loss: tensor(7.4053)\n",
      "12562 Traning Loss: tensor(7.4005)\n",
      "12563 Traning Loss: tensor(7.3957)\n",
      "12564 Traning Loss: tensor(7.3910)\n",
      "12565 Traning Loss: tensor(7.3862)\n",
      "12566 Traning Loss: tensor(7.3814)\n",
      "12567 Traning Loss: tensor(7.3766)\n",
      "12568 Traning Loss: tensor(7.3719)\n",
      "12569 Traning Loss: tensor(7.3671)\n",
      "12570 Traning Loss: tensor(7.3624)\n",
      "12571 Traning Loss: tensor(7.3576)\n",
      "12572 Traning Loss: tensor(7.3528)\n",
      "12573 Traning Loss: tensor(7.3481)\n",
      "12574 Traning Loss: tensor(7.3433)\n",
      "12575 Traning Loss: tensor(7.3386)\n",
      "12576 Traning Loss: tensor(7.3338)\n",
      "12577 Traning Loss: tensor(7.3291)\n",
      "12578 Traning Loss: tensor(7.3243)\n",
      "12579 Traning Loss: tensor(7.3196)\n",
      "12580 Traning Loss: tensor(7.3148)\n",
      "12581 Traning Loss: tensor(7.3101)\n",
      "12582 Traning Loss: tensor(7.3054)\n",
      "12583 Traning Loss: tensor(7.3006)\n",
      "12584 Traning Loss: tensor(7.2959)\n",
      "12585 Traning Loss: tensor(7.2911)\n",
      "12586 Traning Loss: tensor(7.2864)\n",
      "12587 Traning Loss: tensor(7.2817)\n",
      "12588 Traning Loss: tensor(7.2770)\n",
      "12589 Traning Loss: tensor(7.2722)\n",
      "12590 Traning Loss: tensor(7.2675)\n",
      "12591 Traning Loss: tensor(7.2628)\n",
      "12592 Traning Loss: tensor(7.2581)\n",
      "12593 Traning Loss: tensor(7.2534)\n",
      "12594 Traning Loss: tensor(7.2486)\n",
      "12595 Traning Loss: tensor(7.2439)\n",
      "12596 Traning Loss: tensor(7.2392)\n",
      "12597 Traning Loss: tensor(7.2345)\n",
      "12598 Traning Loss: tensor(7.2298)\n",
      "12599 Traning Loss: tensor(7.2251)\n",
      "12600 Traning Loss: tensor(7.2204)\n",
      "12601 Traning Loss: tensor(7.2157)\n",
      "12602 Traning Loss: tensor(7.2110)\n",
      "12603 Traning Loss: tensor(7.2063)\n",
      "12604 Traning Loss: tensor(7.2016)\n",
      "12605 Traning Loss: tensor(7.1969)\n",
      "12606 Traning Loss: tensor(7.1922)\n",
      "12607 Traning Loss: tensor(7.1875)\n",
      "12608 Traning Loss: tensor(7.1828)\n",
      "12609 Traning Loss: tensor(7.1782)\n",
      "12610 Traning Loss: tensor(7.1735)\n",
      "12611 Traning Loss: tensor(7.1688)\n",
      "12612 Traning Loss: tensor(7.1641)\n",
      "12613 Traning Loss: tensor(7.1594)\n",
      "12614 Traning Loss: tensor(7.1548)\n",
      "12615 Traning Loss: tensor(7.1501)\n",
      "12616 Traning Loss: tensor(7.1454)\n",
      "12617 Traning Loss: tensor(7.1407)\n",
      "12618 Traning Loss: tensor(7.1361)\n",
      "12619 Traning Loss: tensor(7.1314)\n",
      "12620 Traning Loss: tensor(7.1267)\n",
      "12621 Traning Loss: tensor(7.1221)\n",
      "12622 Traning Loss: tensor(7.1174)\n",
      "12623 Traning Loss: tensor(7.1127)\n",
      "12624 Traning Loss: tensor(7.1081)\n",
      "12625 Traning Loss: tensor(7.1034)\n",
      "12626 Traning Loss: tensor(7.0988)\n",
      "12627 Traning Loss: tensor(7.0941)\n",
      "12628 Traning Loss: tensor(7.0895)\n",
      "12629 Traning Loss: tensor(7.0848)\n",
      "12630 Traning Loss: tensor(7.0802)\n",
      "12631 Traning Loss: tensor(7.0755)\n",
      "12632 Traning Loss: tensor(7.0709)\n",
      "12633 Traning Loss: tensor(7.0662)\n",
      "12634 Traning Loss: tensor(7.0616)\n",
      "12635 Traning Loss: tensor(7.0570)\n",
      "12636 Traning Loss: tensor(7.0523)\n",
      "12637 Traning Loss: tensor(7.0477)\n",
      "12638 Traning Loss: tensor(7.0431)\n",
      "12639 Traning Loss: tensor(7.0385)\n",
      "12640 Traning Loss: tensor(7.0340)\n",
      "12641 Traning Loss: tensor(7.0294)\n",
      "12642 Traning Loss: tensor(7.0248)\n",
      "12643 Traning Loss: tensor(7.0202)\n",
      "12644 Traning Loss: tensor(7.0157)\n",
      "12645 Traning Loss: tensor(7.0111)\n",
      "12646 Traning Loss: tensor(7.0065)\n",
      "12647 Traning Loss: tensor(7.0020)\n",
      "12648 Traning Loss: tensor(6.9974)\n",
      "12649 Traning Loss: tensor(6.9929)\n",
      "12650 Traning Loss: tensor(6.9883)\n",
      "12651 Traning Loss: tensor(6.9837)\n",
      "12652 Traning Loss: tensor(6.9792)\n",
      "12653 Traning Loss: tensor(6.9746)\n",
      "12654 Traning Loss: tensor(6.9701)\n",
      "12655 Traning Loss: tensor(6.9656)\n",
      "12656 Traning Loss: tensor(6.9610)\n",
      "12657 Traning Loss: tensor(6.9565)\n",
      "12658 Traning Loss: tensor(6.9520)\n",
      "12659 Traning Loss: tensor(6.9474)\n",
      "12660 Traning Loss: tensor(6.9429)\n",
      "12661 Traning Loss: tensor(6.9384)\n",
      "12662 Traning Loss: tensor(6.9338)\n",
      "12663 Traning Loss: tensor(6.9293)\n",
      "12664 Traning Loss: tensor(6.9248)\n",
      "12665 Traning Loss: tensor(6.9203)\n",
      "12666 Traning Loss: tensor(6.9158)\n",
      "12667 Traning Loss: tensor(6.9113)\n",
      "12668 Traning Loss: tensor(6.9068)\n",
      "12669 Traning Loss: tensor(6.9022)\n",
      "12670 Traning Loss: tensor(6.8977)\n",
      "12671 Traning Loss: tensor(6.8932)\n",
      "12672 Traning Loss: tensor(6.8887)\n",
      "12673 Traning Loss: tensor(6.8842)\n",
      "12674 Traning Loss: tensor(6.8797)\n",
      "12675 Traning Loss: tensor(6.8753)\n",
      "12676 Traning Loss: tensor(6.8708)\n",
      "12677 Traning Loss: tensor(6.8663)\n",
      "12678 Traning Loss: tensor(6.8618)\n",
      "12679 Traning Loss: tensor(6.8573)\n",
      "12680 Traning Loss: tensor(6.8528)\n",
      "12681 Traning Loss: tensor(6.8483)\n",
      "12682 Traning Loss: tensor(6.8439)\n",
      "12683 Traning Loss: tensor(6.8394)\n",
      "12684 Traning Loss: tensor(6.8349)\n",
      "12685 Traning Loss: tensor(6.8304)\n",
      "12686 Traning Loss: tensor(6.8260)\n",
      "12687 Traning Loss: tensor(6.8215)\n",
      "12688 Traning Loss: tensor(6.8170)\n",
      "12689 Traning Loss: tensor(6.8126)\n",
      "12690 Traning Loss: tensor(6.8081)\n",
      "12691 Traning Loss: tensor(6.8037)\n",
      "12692 Traning Loss: tensor(6.7992)\n",
      "12693 Traning Loss: tensor(6.7948)\n",
      "12694 Traning Loss: tensor(6.7903)\n",
      "12695 Traning Loss: tensor(6.7859)\n",
      "12696 Traning Loss: tensor(6.7814)\n",
      "12697 Traning Loss: tensor(6.7770)\n",
      "12698 Traning Loss: tensor(6.7725)\n",
      "12699 Traning Loss: tensor(6.7681)\n",
      "12700 Traning Loss: tensor(6.7636)\n",
      "12701 Traning Loss: tensor(6.7592)\n",
      "12702 Traning Loss: tensor(6.7548)\n",
      "12703 Traning Loss: tensor(6.7503)\n",
      "12704 Traning Loss: tensor(6.7459)\n",
      "12705 Traning Loss: tensor(6.7415)\n",
      "12706 Traning Loss: tensor(6.7371)\n",
      "12707 Traning Loss: tensor(6.7326)\n",
      "12708 Traning Loss: tensor(6.7282)\n",
      "12709 Traning Loss: tensor(6.7238)\n",
      "12710 Traning Loss: tensor(6.7194)\n",
      "12711 Traning Loss: tensor(6.7150)\n",
      "12712 Traning Loss: tensor(6.7106)\n",
      "12713 Traning Loss: tensor(6.7061)\n",
      "12714 Traning Loss: tensor(6.7017)\n",
      "12715 Traning Loss: tensor(6.6973)\n",
      "12716 Traning Loss: tensor(6.6929)\n",
      "12717 Traning Loss: tensor(6.6885)\n",
      "12718 Traning Loss: tensor(6.6841)\n",
      "12719 Traning Loss: tensor(6.6797)\n",
      "12720 Traning Loss: tensor(6.6753)\n",
      "12721 Traning Loss: tensor(6.6710)\n",
      "12722 Traning Loss: tensor(6.6666)\n",
      "12723 Traning Loss: tensor(6.6622)\n",
      "12724 Traning Loss: tensor(6.6578)\n",
      "12725 Traning Loss: tensor(6.6534)\n",
      "12726 Traning Loss: tensor(6.6490)\n",
      "12727 Traning Loss: tensor(6.6446)\n",
      "12728 Traning Loss: tensor(6.6403)\n",
      "12729 Traning Loss: tensor(6.6359)\n",
      "12730 Traning Loss: tensor(6.6315)\n",
      "12731 Traning Loss: tensor(6.6272)\n",
      "12732 Traning Loss: tensor(6.6228)\n",
      "12733 Traning Loss: tensor(6.6184)\n",
      "12734 Traning Loss: tensor(6.6141)\n",
      "12735 Traning Loss: tensor(6.6097)\n",
      "12736 Traning Loss: tensor(6.6053)\n",
      "12737 Traning Loss: tensor(6.6010)\n",
      "12738 Traning Loss: tensor(6.5966)\n",
      "12739 Traning Loss: tensor(6.5923)\n",
      "12740 Traning Loss: tensor(6.5879)\n",
      "12741 Traning Loss: tensor(6.5836)\n",
      "12742 Traning Loss: tensor(6.5792)\n",
      "12743 Traning Loss: tensor(6.5749)\n",
      "12744 Traning Loss: tensor(6.5705)\n",
      "12745 Traning Loss: tensor(6.5662)\n",
      "12746 Traning Loss: tensor(6.5619)\n",
      "12747 Traning Loss: tensor(6.5575)\n",
      "12748 Traning Loss: tensor(6.5532)\n",
      "12749 Traning Loss: tensor(6.5489)\n",
      "12750 Traning Loss: tensor(6.5445)\n",
      "12751 Traning Loss: tensor(6.5402)\n",
      "12752 Traning Loss: tensor(6.5359)\n",
      "12753 Traning Loss: tensor(6.5315)\n",
      "12754 Traning Loss: tensor(6.5272)\n",
      "12755 Traning Loss: tensor(6.5229)\n",
      "12756 Traning Loss: tensor(6.5186)\n",
      "12757 Traning Loss: tensor(6.5143)\n",
      "12758 Traning Loss: tensor(6.5100)\n",
      "12759 Traning Loss: tensor(6.5057)\n",
      "12760 Traning Loss: tensor(6.5013)\n",
      "12761 Traning Loss: tensor(6.4970)\n",
      "12762 Traning Loss: tensor(6.4927)\n",
      "12763 Traning Loss: tensor(6.4884)\n",
      "12764 Traning Loss: tensor(6.4841)\n",
      "12765 Traning Loss: tensor(6.4798)\n",
      "12766 Traning Loss: tensor(6.4755)\n",
      "12767 Traning Loss: tensor(6.4712)\n",
      "12768 Traning Loss: tensor(6.4670)\n",
      "12769 Traning Loss: tensor(6.4627)\n",
      "12770 Traning Loss: tensor(6.4584)\n",
      "12771 Traning Loss: tensor(6.4541)\n",
      "12772 Traning Loss: tensor(6.4498)\n",
      "12773 Traning Loss: tensor(6.4455)\n",
      "12774 Traning Loss: tensor(6.4412)\n",
      "12775 Traning Loss: tensor(6.4370)\n",
      "12776 Traning Loss: tensor(6.4327)\n",
      "12777 Traning Loss: tensor(6.4284)\n",
      "12778 Traning Loss: tensor(6.4242)\n",
      "12779 Traning Loss: tensor(6.4199)\n",
      "12780 Traning Loss: tensor(6.4156)\n",
      "12781 Traning Loss: tensor(6.4114)\n",
      "12782 Traning Loss: tensor(6.4071)\n",
      "12783 Traning Loss: tensor(6.4028)\n",
      "12784 Traning Loss: tensor(6.3986)\n",
      "12785 Traning Loss: tensor(6.3943)\n",
      "12786 Traning Loss: tensor(6.3901)\n",
      "12787 Traning Loss: tensor(6.3858)\n",
      "12788 Traning Loss: tensor(6.3816)\n",
      "12789 Traning Loss: tensor(6.3773)\n",
      "12790 Traning Loss: tensor(6.3731)\n",
      "12791 Traning Loss: tensor(6.3688)\n",
      "12792 Traning Loss: tensor(6.3646)\n",
      "12793 Traning Loss: tensor(6.3603)\n",
      "12794 Traning Loss: tensor(6.3561)\n",
      "12795 Traning Loss: tensor(6.3519)\n",
      "12796 Traning Loss: tensor(6.3476)\n",
      "12797 Traning Loss: tensor(6.3434)\n",
      "12798 Traning Loss: tensor(6.3392)\n",
      "12799 Traning Loss: tensor(6.3350)\n",
      "12800 Traning Loss: tensor(6.3307)\n",
      "12801 Traning Loss: tensor(6.3265)\n",
      "12802 Traning Loss: tensor(6.3223)\n",
      "12803 Traning Loss: tensor(6.3162)\n",
      "12804 Traning Loss: tensor(6.3120)\n",
      "12805 Traning Loss: tensor(6.3078)\n",
      "12806 Traning Loss: tensor(6.3036)\n",
      "12807 Traning Loss: tensor(6.2994)\n",
      "12808 Traning Loss: tensor(6.2952)\n",
      "12809 Traning Loss: tensor(6.2910)\n",
      "12810 Traning Loss: tensor(6.2868)\n",
      "12811 Traning Loss: tensor(6.2826)\n",
      "12812 Traning Loss: tensor(6.2784)\n",
      "12813 Traning Loss: tensor(6.2742)\n",
      "12814 Traning Loss: tensor(6.2700)\n",
      "12815 Traning Loss: tensor(6.2658)\n",
      "12816 Traning Loss: tensor(6.2616)\n",
      "12817 Traning Loss: tensor(6.2574)\n",
      "12818 Traning Loss: tensor(6.2532)\n",
      "12819 Traning Loss: tensor(6.2491)\n",
      "12820 Traning Loss: tensor(6.2449)\n",
      "12821 Traning Loss: tensor(6.2407)\n",
      "12822 Traning Loss: tensor(6.2365)\n",
      "12823 Traning Loss: tensor(6.2324)\n",
      "12824 Traning Loss: tensor(6.2282)\n",
      "12825 Traning Loss: tensor(6.2240)\n",
      "12826 Traning Loss: tensor(6.2199)\n",
      "12827 Traning Loss: tensor(6.2157)\n",
      "12828 Traning Loss: tensor(6.2115)\n",
      "12829 Traning Loss: tensor(6.2074)\n",
      "12830 Traning Loss: tensor(6.2032)\n",
      "12831 Traning Loss: tensor(6.1991)\n",
      "12832 Traning Loss: tensor(6.1949)\n",
      "12833 Traning Loss: tensor(6.1908)\n",
      "12834 Traning Loss: tensor(6.1866)\n",
      "12835 Traning Loss: tensor(6.1825)\n",
      "12836 Traning Loss: tensor(6.1783)\n",
      "12837 Traning Loss: tensor(6.1742)\n",
      "12838 Traning Loss: tensor(6.1700)\n",
      "12839 Traning Loss: tensor(6.1659)\n",
      "12840 Traning Loss: tensor(6.1618)\n",
      "12841 Traning Loss: tensor(6.1576)\n",
      "12842 Traning Loss: tensor(6.1535)\n",
      "12843 Traning Loss: tensor(6.1494)\n",
      "12844 Traning Loss: tensor(6.1452)\n",
      "12845 Traning Loss: tensor(6.1411)\n",
      "12846 Traning Loss: tensor(6.1370)\n",
      "12847 Traning Loss: tensor(6.1329)\n",
      "12848 Traning Loss: tensor(6.1287)\n",
      "12849 Traning Loss: tensor(6.1246)\n",
      "12850 Traning Loss: tensor(6.1205)\n",
      "12851 Traning Loss: tensor(6.1164)\n",
      "12852 Traning Loss: tensor(6.1123)\n",
      "12853 Traning Loss: tensor(6.1082)\n",
      "12854 Traning Loss: tensor(6.1041)\n",
      "12855 Traning Loss: tensor(6.0999)\n",
      "12856 Traning Loss: tensor(6.0958)\n",
      "12857 Traning Loss: tensor(6.0917)\n",
      "12858 Traning Loss: tensor(6.0876)\n",
      "12859 Traning Loss: tensor(6.0835)\n",
      "12860 Traning Loss: tensor(6.0794)\n",
      "12861 Traning Loss: tensor(6.0754)\n",
      "12862 Traning Loss: tensor(6.0713)\n",
      "12863 Traning Loss: tensor(6.0672)\n",
      "12864 Traning Loss: tensor(6.0631)\n",
      "12865 Traning Loss: tensor(6.0590)\n",
      "12866 Traning Loss: tensor(6.0549)\n",
      "12867 Traning Loss: tensor(6.0508)\n",
      "12868 Traning Loss: tensor(6.0468)\n",
      "12869 Traning Loss: tensor(6.0427)\n",
      "12870 Traning Loss: tensor(6.0386)\n",
      "12871 Traning Loss: tensor(6.0345)\n",
      "12872 Traning Loss: tensor(6.0305)\n",
      "12873 Traning Loss: tensor(6.0264)\n",
      "12874 Traning Loss: tensor(6.0223)\n",
      "12875 Traning Loss: tensor(6.0183)\n",
      "12876 Traning Loss: tensor(6.0142)\n",
      "12877 Traning Loss: tensor(6.0101)\n",
      "12878 Traning Loss: tensor(6.0061)\n",
      "12879 Traning Loss: tensor(6.0020)\n",
      "12880 Traning Loss: tensor(5.9980)\n",
      "12881 Traning Loss: tensor(5.9939)\n",
      "12882 Traning Loss: tensor(5.9899)\n",
      "12883 Traning Loss: tensor(5.9858)\n",
      "12884 Traning Loss: tensor(5.9818)\n",
      "12885 Traning Loss: tensor(5.9777)\n",
      "12886 Traning Loss: tensor(5.9737)\n",
      "12887 Traning Loss: tensor(5.9696)\n",
      "12888 Traning Loss: tensor(5.9656)\n",
      "12889 Traning Loss: tensor(5.9615)\n",
      "12890 Traning Loss: tensor(5.9575)\n",
      "12891 Traning Loss: tensor(5.9535)\n",
      "12892 Traning Loss: tensor(5.9494)\n",
      "12893 Traning Loss: tensor(5.9454)\n",
      "12894 Traning Loss: tensor(5.9414)\n",
      "12895 Traning Loss: tensor(5.9374)\n",
      "12896 Traning Loss: tensor(5.9333)\n",
      "12897 Traning Loss: tensor(5.9293)\n",
      "12898 Traning Loss: tensor(5.9253)\n",
      "12899 Traning Loss: tensor(5.9213)\n",
      "12900 Traning Loss: tensor(5.9173)\n",
      "12901 Traning Loss: tensor(5.9133)\n",
      "12902 Traning Loss: tensor(5.9092)\n",
      "12903 Traning Loss: tensor(5.9052)\n",
      "12904 Traning Loss: tensor(5.9012)\n",
      "12905 Traning Loss: tensor(5.8972)\n",
      "12906 Traning Loss: tensor(5.8932)\n",
      "12907 Traning Loss: tensor(5.8892)\n",
      "12908 Traning Loss: tensor(5.8852)\n",
      "12909 Traning Loss: tensor(5.8812)\n",
      "12910 Traning Loss: tensor(5.8772)\n",
      "12911 Traning Loss: tensor(5.8732)\n",
      "12912 Traning Loss: tensor(5.8692)\n",
      "12913 Traning Loss: tensor(5.8653)\n",
      "12914 Traning Loss: tensor(5.8613)\n",
      "12915 Traning Loss: tensor(5.8573)\n",
      "12916 Traning Loss: tensor(5.8533)\n",
      "12917 Traning Loss: tensor(5.8493)\n",
      "12918 Traning Loss: tensor(5.8453)\n",
      "12919 Traning Loss: tensor(5.8414)\n",
      "12920 Traning Loss: tensor(5.8374)\n",
      "12921 Traning Loss: tensor(5.8334)\n",
      "12922 Traning Loss: tensor(5.8294)\n",
      "12923 Traning Loss: tensor(5.8255)\n",
      "12924 Traning Loss: tensor(5.8215)\n",
      "12925 Traning Loss: tensor(5.8175)\n",
      "12926 Traning Loss: tensor(5.8136)\n",
      "12927 Traning Loss: tensor(5.8096)\n",
      "12928 Traning Loss: tensor(5.8057)\n",
      "12929 Traning Loss: tensor(5.8017)\n",
      "12930 Traning Loss: tensor(5.7977)\n",
      "12931 Traning Loss: tensor(5.7938)\n",
      "12932 Traning Loss: tensor(5.7898)\n",
      "12933 Traning Loss: tensor(5.7859)\n",
      "12934 Traning Loss: tensor(5.7819)\n",
      "12935 Traning Loss: tensor(5.7780)\n",
      "12936 Traning Loss: tensor(5.7740)\n",
      "12937 Traning Loss: tensor(5.7701)\n",
      "12938 Traning Loss: tensor(5.7662)\n",
      "12939 Traning Loss: tensor(5.7622)\n",
      "12940 Traning Loss: tensor(5.7583)\n",
      "12941 Traning Loss: tensor(5.7544)\n",
      "12942 Traning Loss: tensor(5.7504)\n",
      "12943 Traning Loss: tensor(5.7465)\n",
      "12944 Traning Loss: tensor(5.7426)\n",
      "12945 Traning Loss: tensor(5.7386)\n",
      "12946 Traning Loss: tensor(5.7347)\n",
      "12947 Traning Loss: tensor(5.7308)\n",
      "12948 Traning Loss: tensor(5.7269)\n",
      "12949 Traning Loss: tensor(5.7230)\n",
      "12950 Traning Loss: tensor(5.7190)\n",
      "12951 Traning Loss: tensor(5.7151)\n",
      "12952 Traning Loss: tensor(5.7112)\n",
      "12953 Traning Loss: tensor(5.7073)\n",
      "12954 Traning Loss: tensor(5.7034)\n",
      "12955 Traning Loss: tensor(5.6995)\n",
      "12956 Traning Loss: tensor(5.6956)\n",
      "12957 Traning Loss: tensor(5.6917)\n",
      "12958 Traning Loss: tensor(5.6878)\n",
      "12959 Traning Loss: tensor(5.6839)\n",
      "12960 Traning Loss: tensor(5.6800)\n",
      "12961 Traning Loss: tensor(5.6761)\n",
      "12962 Traning Loss: tensor(5.6722)\n",
      "12963 Traning Loss: tensor(5.6683)\n",
      "12964 Traning Loss: tensor(5.6644)\n",
      "12965 Traning Loss: tensor(5.6605)\n",
      "12966 Traning Loss: tensor(5.6567)\n",
      "12967 Traning Loss: tensor(5.6528)\n",
      "12968 Traning Loss: tensor(5.6489)\n",
      "12969 Traning Loss: tensor(5.6450)\n",
      "12970 Traning Loss: tensor(5.6411)\n",
      "12971 Traning Loss: tensor(5.6373)\n",
      "12972 Traning Loss: tensor(5.6334)\n",
      "12973 Traning Loss: tensor(5.6295)\n",
      "12974 Traning Loss: tensor(5.6257)\n",
      "12975 Traning Loss: tensor(5.6218)\n",
      "12976 Traning Loss: tensor(5.6179)\n",
      "12977 Traning Loss: tensor(5.6141)\n",
      "12978 Traning Loss: tensor(5.6102)\n",
      "12979 Traning Loss: tensor(5.6063)\n",
      "12980 Traning Loss: tensor(5.6025)\n",
      "12981 Traning Loss: tensor(5.5986)\n",
      "12982 Traning Loss: tensor(5.5948)\n",
      "12983 Traning Loss: tensor(5.5909)\n",
      "12984 Traning Loss: tensor(5.5871)\n",
      "12985 Traning Loss: tensor(5.5832)\n",
      "12986 Traning Loss: tensor(5.5794)\n",
      "12987 Traning Loss: tensor(5.5756)\n",
      "12988 Traning Loss: tensor(5.5717)\n",
      "12989 Traning Loss: tensor(5.5679)\n",
      "12990 Traning Loss: tensor(5.5640)\n",
      "12991 Traning Loss: tensor(5.5602)\n",
      "12992 Traning Loss: tensor(5.5564)\n",
      "12993 Traning Loss: tensor(5.5525)\n",
      "12994 Traning Loss: tensor(5.5487)\n",
      "12995 Traning Loss: tensor(5.5449)\n",
      "12996 Traning Loss: tensor(5.5411)\n",
      "12997 Traning Loss: tensor(5.5372)\n",
      "12998 Traning Loss: tensor(5.5334)\n",
      "12999 Traning Loss: tensor(5.5296)\n",
      "13000 Traning Loss: tensor(5.5258)\n",
      "13001 Traning Loss: tensor(5.5220)\n",
      "13002 Traning Loss: tensor(5.5181)\n",
      "13003 Traning Loss: tensor(5.5143)\n",
      "13004 Traning Loss: tensor(5.5105)\n",
      "13005 Traning Loss: tensor(5.5067)\n",
      "13006 Traning Loss: tensor(5.5029)\n",
      "13007 Traning Loss: tensor(5.4991)\n",
      "13008 Traning Loss: tensor(5.4953)\n",
      "13009 Traning Loss: tensor(5.4915)\n",
      "13010 Traning Loss: tensor(5.4877)\n",
      "13011 Traning Loss: tensor(5.4839)\n",
      "13012 Traning Loss: tensor(5.4801)\n",
      "13013 Traning Loss: tensor(5.4763)\n",
      "13014 Traning Loss: tensor(5.4725)\n",
      "13015 Traning Loss: tensor(5.4687)\n",
      "13016 Traning Loss: tensor(5.4650)\n",
      "13017 Traning Loss: tensor(5.4612)\n",
      "13018 Traning Loss: tensor(5.4574)\n",
      "13019 Traning Loss: tensor(5.4536)\n",
      "13020 Traning Loss: tensor(5.4498)\n",
      "13021 Traning Loss: tensor(5.4461)\n",
      "13022 Traning Loss: tensor(5.4423)\n",
      "13023 Traning Loss: tensor(5.4385)\n",
      "13024 Traning Loss: tensor(5.4347)\n",
      "13025 Traning Loss: tensor(5.4310)\n",
      "13026 Traning Loss: tensor(5.4272)\n",
      "13027 Traning Loss: tensor(5.4234)\n",
      "13028 Traning Loss: tensor(5.4197)\n",
      "13029 Traning Loss: tensor(5.4159)\n",
      "13030 Traning Loss: tensor(5.4122)\n",
      "13031 Traning Loss: tensor(5.4084)\n",
      "13032 Traning Loss: tensor(5.4046)\n",
      "13033 Traning Loss: tensor(5.4009)\n",
      "13034 Traning Loss: tensor(5.3971)\n",
      "13035 Traning Loss: tensor(5.3934)\n",
      "13036 Traning Loss: tensor(5.3896)\n",
      "13037 Traning Loss: tensor(5.3859)\n",
      "13038 Traning Loss: tensor(5.3822)\n",
      "13039 Traning Loss: tensor(5.3784)\n",
      "13040 Traning Loss: tensor(5.3747)\n",
      "13041 Traning Loss: tensor(5.3709)\n",
      "13042 Traning Loss: tensor(5.3672)\n",
      "13043 Traning Loss: tensor(5.3635)\n",
      "13044 Traning Loss: tensor(5.3597)\n",
      "13045 Traning Loss: tensor(5.3560)\n",
      "13046 Traning Loss: tensor(5.3523)\n",
      "13047 Traning Loss: tensor(5.3486)\n",
      "13048 Traning Loss: tensor(5.3448)\n",
      "13049 Traning Loss: tensor(5.3411)\n",
      "13050 Traning Loss: tensor(5.3374)\n",
      "13051 Traning Loss: tensor(5.3337)\n",
      "13052 Traning Loss: tensor(5.3300)\n",
      "13053 Traning Loss: tensor(5.3262)\n",
      "13054 Traning Loss: tensor(5.3225)\n",
      "13055 Traning Loss: tensor(5.3188)\n",
      "13056 Traning Loss: tensor(5.3151)\n",
      "13057 Traning Loss: tensor(5.3114)\n",
      "13058 Traning Loss: tensor(5.3077)\n",
      "13059 Traning Loss: tensor(5.3040)\n",
      "13060 Traning Loss: tensor(5.3003)\n",
      "13061 Traning Loss: tensor(5.2966)\n",
      "13062 Traning Loss: tensor(5.2929)\n",
      "13063 Traning Loss: tensor(5.2892)\n",
      "13064 Traning Loss: tensor(5.2855)\n",
      "13065 Traning Loss: tensor(5.2818)\n",
      "13066 Traning Loss: tensor(5.2781)\n",
      "13067 Traning Loss: tensor(5.2744)\n",
      "13068 Traning Loss: tensor(5.2708)\n",
      "13069 Traning Loss: tensor(5.2671)\n",
      "13070 Traning Loss: tensor(5.2634)\n",
      "13071 Traning Loss: tensor(5.2597)\n",
      "13072 Traning Loss: tensor(5.2560)\n",
      "13073 Traning Loss: tensor(5.2524)\n",
      "13074 Traning Loss: tensor(5.2487)\n",
      "13075 Traning Loss: tensor(5.2450)\n",
      "13076 Traning Loss: tensor(5.2414)\n",
      "13077 Traning Loss: tensor(5.2377)\n",
      "13078 Traning Loss: tensor(5.2340)\n",
      "13079 Traning Loss: tensor(5.2304)\n",
      "13080 Traning Loss: tensor(5.2267)\n",
      "13081 Traning Loss: tensor(5.2230)\n",
      "13082 Traning Loss: tensor(5.2194)\n",
      "13083 Traning Loss: tensor(5.2157)\n",
      "13084 Traning Loss: tensor(5.2121)\n",
      "13085 Traning Loss: tensor(5.2084)\n",
      "13086 Traning Loss: tensor(5.2048)\n",
      "13087 Traning Loss: tensor(5.2011)\n",
      "13088 Traning Loss: tensor(5.1975)\n",
      "13089 Traning Loss: tensor(5.1938)\n",
      "13090 Traning Loss: tensor(5.1902)\n",
      "13091 Traning Loss: tensor(5.1865)\n",
      "13092 Traning Loss: tensor(5.1829)\n",
      "13093 Traning Loss: tensor(5.1793)\n",
      "13094 Traning Loss: tensor(5.1756)\n",
      "13095 Traning Loss: tensor(5.1720)\n",
      "13096 Traning Loss: tensor(5.1684)\n",
      "13097 Traning Loss: tensor(5.1647)\n",
      "13098 Traning Loss: tensor(5.1611)\n",
      "13099 Traning Loss: tensor(5.1575)\n",
      "13100 Traning Loss: tensor(5.1539)\n",
      "13101 Traning Loss: tensor(5.1502)\n",
      "13102 Traning Loss: tensor(5.1466)\n",
      "13103 Traning Loss: tensor(5.1430)\n",
      "13104 Traning Loss: tensor(5.1394)\n",
      "13105 Traning Loss: tensor(5.1358)\n",
      "13106 Traning Loss: tensor(5.1322)\n",
      "13107 Traning Loss: tensor(5.1286)\n",
      "13108 Traning Loss: tensor(5.1249)\n",
      "13109 Traning Loss: tensor(5.1213)\n",
      "13110 Traning Loss: tensor(5.1177)\n",
      "13111 Traning Loss: tensor(5.1141)\n",
      "13112 Traning Loss: tensor(5.1105)\n",
      "13113 Traning Loss: tensor(5.1069)\n",
      "13114 Traning Loss: tensor(5.1033)\n",
      "13115 Traning Loss: tensor(5.0997)\n",
      "13116 Traning Loss: tensor(5.0962)\n",
      "13117 Traning Loss: tensor(5.0926)\n",
      "13118 Traning Loss: tensor(5.0890)\n",
      "13119 Traning Loss: tensor(5.0854)\n",
      "13120 Traning Loss: tensor(5.0818)\n",
      "13121 Traning Loss: tensor(5.0782)\n",
      "13122 Traning Loss: tensor(5.0746)\n",
      "13123 Traning Loss: tensor(5.0711)\n",
      "13124 Traning Loss: tensor(5.0675)\n",
      "13125 Traning Loss: tensor(5.0639)\n",
      "13126 Traning Loss: tensor(5.0603)\n",
      "13127 Traning Loss: tensor(5.0568)\n",
      "13128 Traning Loss: tensor(5.0532)\n",
      "13129 Traning Loss: tensor(5.0496)\n",
      "13130 Traning Loss: tensor(5.0461)\n",
      "13131 Traning Loss: tensor(5.0425)\n",
      "13132 Traning Loss: tensor(5.0389)\n",
      "13133 Traning Loss: tensor(5.0354)\n",
      "13134 Traning Loss: tensor(5.0318)\n",
      "13135 Traning Loss: tensor(5.0283)\n",
      "13136 Traning Loss: tensor(5.0247)\n",
      "13137 Traning Loss: tensor(5.0212)\n",
      "13138 Traning Loss: tensor(5.0176)\n",
      "13139 Traning Loss: tensor(5.0141)\n",
      "13140 Traning Loss: tensor(5.0105)\n",
      "13141 Traning Loss: tensor(5.0070)\n",
      "13142 Traning Loss: tensor(5.0034)\n",
      "13143 Traning Loss: tensor(4.9999)\n",
      "13144 Traning Loss: tensor(4.9963)\n",
      "13145 Traning Loss: tensor(4.9928)\n",
      "13146 Traning Loss: tensor(4.9870)\n",
      "13147 Traning Loss: tensor(4.9835)\n",
      "13148 Traning Loss: tensor(4.9800)\n",
      "13149 Traning Loss: tensor(4.9764)\n",
      "13150 Traning Loss: tensor(4.9729)\n",
      "13151 Traning Loss: tensor(4.9694)\n",
      "13152 Traning Loss: tensor(4.9659)\n",
      "13153 Traning Loss: tensor(4.9624)\n",
      "13154 Traning Loss: tensor(4.9589)\n",
      "13155 Traning Loss: tensor(4.9553)\n",
      "13156 Traning Loss: tensor(4.9518)\n",
      "13157 Traning Loss: tensor(4.9483)\n",
      "13158 Traning Loss: tensor(4.9448)\n",
      "13159 Traning Loss: tensor(4.9413)\n",
      "13160 Traning Loss: tensor(4.9378)\n",
      "13161 Traning Loss: tensor(4.9343)\n",
      "13162 Traning Loss: tensor(4.9308)\n",
      "13163 Traning Loss: tensor(4.9273)\n",
      "13164 Traning Loss: tensor(4.9238)\n",
      "13165 Traning Loss: tensor(4.9203)\n",
      "13166 Traning Loss: tensor(4.9168)\n",
      "13167 Traning Loss: tensor(4.9134)\n",
      "13168 Traning Loss: tensor(4.9099)\n",
      "13169 Traning Loss: tensor(4.9064)\n",
      "13170 Traning Loss: tensor(4.9029)\n",
      "13171 Traning Loss: tensor(4.8994)\n",
      "13172 Traning Loss: tensor(4.8959)\n",
      "13173 Traning Loss: tensor(4.8925)\n",
      "13174 Traning Loss: tensor(4.8890)\n",
      "13175 Traning Loss: tensor(4.8855)\n",
      "13176 Traning Loss: tensor(4.8821)\n",
      "13177 Traning Loss: tensor(4.8786)\n",
      "13178 Traning Loss: tensor(4.8751)\n",
      "13179 Traning Loss: tensor(4.8717)\n",
      "13180 Traning Loss: tensor(4.8682)\n",
      "13181 Traning Loss: tensor(4.8647)\n",
      "13182 Traning Loss: tensor(4.8613)\n",
      "13183 Traning Loss: tensor(4.8578)\n",
      "13184 Traning Loss: tensor(4.8544)\n",
      "13185 Traning Loss: tensor(4.8509)\n",
      "13186 Traning Loss: tensor(4.8475)\n",
      "13187 Traning Loss: tensor(4.8440)\n",
      "13188 Traning Loss: tensor(4.8406)\n",
      "13189 Traning Loss: tensor(4.8371)\n",
      "13190 Traning Loss: tensor(4.8337)\n",
      "13191 Traning Loss: tensor(4.8302)\n",
      "13192 Traning Loss: tensor(4.8268)\n",
      "13193 Traning Loss: tensor(4.8234)\n",
      "13194 Traning Loss: tensor(4.8199)\n",
      "13195 Traning Loss: tensor(4.8165)\n",
      "13196 Traning Loss: tensor(4.8131)\n",
      "13197 Traning Loss: tensor(4.8096)\n",
      "13198 Traning Loss: tensor(4.8062)\n",
      "13199 Traning Loss: tensor(4.8028)\n",
      "13200 Traning Loss: tensor(4.7993)\n",
      "13201 Traning Loss: tensor(4.7959)\n",
      "13202 Traning Loss: tensor(4.7925)\n",
      "13203 Traning Loss: tensor(4.7891)\n",
      "13204 Traning Loss: tensor(4.7857)\n",
      "13205 Traning Loss: tensor(4.7822)\n",
      "13206 Traning Loss: tensor(4.7788)\n",
      "13207 Traning Loss: tensor(4.7754)\n",
      "13208 Traning Loss: tensor(4.7720)\n",
      "13209 Traning Loss: tensor(4.7686)\n",
      "13210 Traning Loss: tensor(4.7652)\n",
      "13211 Traning Loss: tensor(4.7618)\n",
      "13212 Traning Loss: tensor(4.7584)\n",
      "13213 Traning Loss: tensor(4.7550)\n",
      "13214 Traning Loss: tensor(4.7516)\n",
      "13215 Traning Loss: tensor(4.7482)\n",
      "13216 Traning Loss: tensor(4.7448)\n",
      "13217 Traning Loss: tensor(4.7414)\n",
      "13218 Traning Loss: tensor(4.7380)\n",
      "13219 Traning Loss: tensor(4.7346)\n",
      "13220 Traning Loss: tensor(4.7313)\n",
      "13221 Traning Loss: tensor(4.7279)\n",
      "13222 Traning Loss: tensor(4.7245)\n",
      "13223 Traning Loss: tensor(4.7211)\n",
      "13224 Traning Loss: tensor(4.7177)\n",
      "13225 Traning Loss: tensor(4.7144)\n",
      "13226 Traning Loss: tensor(4.7110)\n",
      "13227 Traning Loss: tensor(4.7076)\n",
      "13228 Traning Loss: tensor(4.7042)\n",
      "13229 Traning Loss: tensor(4.7009)\n",
      "13230 Traning Loss: tensor(4.6975)\n",
      "13231 Traning Loss: tensor(4.6941)\n",
      "13232 Traning Loss: tensor(4.6908)\n",
      "13233 Traning Loss: tensor(4.6874)\n",
      "13234 Traning Loss: tensor(4.6841)\n",
      "13235 Traning Loss: tensor(4.6807)\n",
      "13236 Traning Loss: tensor(4.6773)\n",
      "13237 Traning Loss: tensor(4.6740)\n",
      "13238 Traning Loss: tensor(4.6706)\n",
      "13239 Traning Loss: tensor(4.6673)\n",
      "13240 Traning Loss: tensor(4.6639)\n",
      "13241 Traning Loss: tensor(4.6606)\n",
      "13242 Traning Loss: tensor(4.6572)\n",
      "13243 Traning Loss: tensor(4.6539)\n",
      "13244 Traning Loss: tensor(4.6506)\n",
      "13245 Traning Loss: tensor(4.6472)\n",
      "13246 Traning Loss: tensor(4.6439)\n",
      "13247 Traning Loss: tensor(4.6406)\n",
      "13248 Traning Loss: tensor(4.6372)\n",
      "13249 Traning Loss: tensor(4.6339)\n",
      "13250 Traning Loss: tensor(4.6306)\n",
      "13251 Traning Loss: tensor(4.6272)\n",
      "13252 Traning Loss: tensor(4.6239)\n",
      "13253 Traning Loss: tensor(4.6206)\n",
      "13254 Traning Loss: tensor(4.6173)\n",
      "13255 Traning Loss: tensor(4.6139)\n",
      "13256 Traning Loss: tensor(4.6106)\n",
      "13257 Traning Loss: tensor(4.6073)\n",
      "13258 Traning Loss: tensor(4.6040)\n",
      "13259 Traning Loss: tensor(4.6007)\n",
      "13260 Traning Loss: tensor(4.5974)\n",
      "13261 Traning Loss: tensor(4.5941)\n",
      "13262 Traning Loss: tensor(4.5908)\n",
      "13263 Traning Loss: tensor(4.5875)\n",
      "13264 Traning Loss: tensor(4.5842)\n",
      "13265 Traning Loss: tensor(4.5809)\n",
      "13266 Traning Loss: tensor(4.5776)\n",
      "13267 Traning Loss: tensor(4.5743)\n",
      "13268 Traning Loss: tensor(4.5710)\n",
      "13269 Traning Loss: tensor(4.5677)\n",
      "13270 Traning Loss: tensor(4.5644)\n",
      "13271 Traning Loss: tensor(4.5611)\n",
      "13272 Traning Loss: tensor(4.5578)\n",
      "13273 Traning Loss: tensor(4.5545)\n",
      "13274 Traning Loss: tensor(4.5512)\n",
      "13275 Traning Loss: tensor(4.5480)\n",
      "13276 Traning Loss: tensor(4.5447)\n",
      "13277 Traning Loss: tensor(4.5414)\n",
      "13278 Traning Loss: tensor(4.5381)\n",
      "13279 Traning Loss: tensor(4.5349)\n",
      "13280 Traning Loss: tensor(4.5316)\n",
      "13281 Traning Loss: tensor(4.5283)\n",
      "13282 Traning Loss: tensor(4.5250)\n",
      "13283 Traning Loss: tensor(4.5218)\n",
      "13284 Traning Loss: tensor(4.5185)\n",
      "13285 Traning Loss: tensor(4.5152)\n",
      "13286 Traning Loss: tensor(4.5120)\n",
      "13287 Traning Loss: tensor(4.5087)\n",
      "13288 Traning Loss: tensor(4.5055)\n",
      "13289 Traning Loss: tensor(4.5022)\n",
      "13290 Traning Loss: tensor(4.4990)\n",
      "13291 Traning Loss: tensor(4.4957)\n",
      "13292 Traning Loss: tensor(4.4925)\n",
      "13293 Traning Loss: tensor(4.4892)\n",
      "13294 Traning Loss: tensor(4.4860)\n",
      "13295 Traning Loss: tensor(4.4827)\n",
      "13296 Traning Loss: tensor(4.4795)\n",
      "13297 Traning Loss: tensor(4.4763)\n",
      "13298 Traning Loss: tensor(4.4730)\n",
      "13299 Traning Loss: tensor(4.4698)\n",
      "13300 Traning Loss: tensor(4.4665)\n",
      "13301 Traning Loss: tensor(4.4633)\n",
      "13302 Traning Loss: tensor(4.4601)\n",
      "13303 Traning Loss: tensor(4.4569)\n",
      "13304 Traning Loss: tensor(4.4536)\n",
      "13305 Traning Loss: tensor(4.4504)\n",
      "13306 Traning Loss: tensor(4.4472)\n",
      "13307 Traning Loss: tensor(4.4440)\n",
      "13308 Traning Loss: tensor(4.4407)\n",
      "13309 Traning Loss: tensor(4.4375)\n",
      "13310 Traning Loss: tensor(4.4343)\n",
      "13311 Traning Loss: tensor(4.4311)\n",
      "13312 Traning Loss: tensor(4.4279)\n",
      "13313 Traning Loss: tensor(4.4247)\n",
      "13314 Traning Loss: tensor(4.4215)\n",
      "13315 Traning Loss: tensor(4.4183)\n",
      "13316 Traning Loss: tensor(4.4151)\n",
      "13317 Traning Loss: tensor(4.4119)\n",
      "13318 Traning Loss: tensor(4.4087)\n",
      "13319 Traning Loss: tensor(4.4055)\n",
      "13320 Traning Loss: tensor(4.4023)\n",
      "13321 Traning Loss: tensor(4.3991)\n",
      "13322 Traning Loss: tensor(4.3959)\n",
      "13323 Traning Loss: tensor(4.3927)\n",
      "13324 Traning Loss: tensor(4.3895)\n",
      "13325 Traning Loss: tensor(4.3863)\n",
      "13326 Traning Loss: tensor(4.3831)\n",
      "13327 Traning Loss: tensor(4.3799)\n",
      "13328 Traning Loss: tensor(4.3768)\n",
      "13329 Traning Loss: tensor(4.3736)\n",
      "13330 Traning Loss: tensor(4.3704)\n",
      "13331 Traning Loss: tensor(4.3672)\n",
      "13332 Traning Loss: tensor(4.3641)\n",
      "13333 Traning Loss: tensor(4.3609)\n",
      "13334 Traning Loss: tensor(4.3577)\n",
      "13335 Traning Loss: tensor(4.3546)\n",
      "13336 Traning Loss: tensor(4.3514)\n",
      "13337 Traning Loss: tensor(4.3482)\n",
      "13338 Traning Loss: tensor(4.3451)\n",
      "13339 Traning Loss: tensor(4.3419)\n",
      "13340 Traning Loss: tensor(4.3387)\n",
      "13341 Traning Loss: tensor(4.3356)\n",
      "13342 Traning Loss: tensor(4.3324)\n",
      "13343 Traning Loss: tensor(4.3293)\n",
      "13344 Traning Loss: tensor(4.3261)\n",
      "13345 Traning Loss: tensor(4.3230)\n",
      "13346 Traning Loss: tensor(4.3198)\n",
      "13347 Traning Loss: tensor(4.3167)\n",
      "13348 Traning Loss: tensor(4.3135)\n",
      "13349 Traning Loss: tensor(4.3104)\n",
      "13350 Traning Loss: tensor(4.3073)\n",
      "13351 Traning Loss: tensor(4.3041)\n",
      "13352 Traning Loss: tensor(4.3010)\n",
      "13353 Traning Loss: tensor(4.2979)\n",
      "13354 Traning Loss: tensor(4.2947)\n",
      "13355 Traning Loss: tensor(4.2916)\n",
      "13356 Traning Loss: tensor(4.2885)\n",
      "13357 Traning Loss: tensor(4.2853)\n",
      "13358 Traning Loss: tensor(4.2822)\n",
      "13359 Traning Loss: tensor(4.2791)\n",
      "13360 Traning Loss: tensor(4.2760)\n",
      "13361 Traning Loss: tensor(4.2729)\n",
      "13362 Traning Loss: tensor(4.2697)\n",
      "13363 Traning Loss: tensor(4.2666)\n",
      "13364 Traning Loss: tensor(4.2635)\n",
      "13365 Traning Loss: tensor(4.2604)\n",
      "13366 Traning Loss: tensor(4.2573)\n",
      "13367 Traning Loss: tensor(4.2542)\n",
      "13368 Traning Loss: tensor(4.2511)\n",
      "13369 Traning Loss: tensor(4.2480)\n",
      "13370 Traning Loss: tensor(4.2449)\n",
      "13371 Traning Loss: tensor(4.2418)\n",
      "13372 Traning Loss: tensor(4.2387)\n",
      "13373 Traning Loss: tensor(4.2356)\n",
      "13374 Traning Loss: tensor(4.2325)\n",
      "13375 Traning Loss: tensor(4.2294)\n",
      "13376 Traning Loss: tensor(4.2263)\n",
      "13377 Traning Loss: tensor(4.2232)\n",
      "13378 Traning Loss: tensor(4.2201)\n",
      "13379 Traning Loss: tensor(4.2170)\n",
      "13380 Traning Loss: tensor(4.2140)\n",
      "13381 Traning Loss: tensor(4.2109)\n",
      "13382 Traning Loss: tensor(4.2078)\n",
      "13383 Traning Loss: tensor(4.2047)\n",
      "13384 Traning Loss: tensor(4.2016)\n",
      "13385 Traning Loss: tensor(4.1986)\n",
      "13386 Traning Loss: tensor(4.1955)\n",
      "13387 Traning Loss: tensor(4.1924)\n",
      "13388 Traning Loss: tensor(4.1894)\n",
      "13389 Traning Loss: tensor(4.1863)\n",
      "13390 Traning Loss: tensor(4.1832)\n",
      "13391 Traning Loss: tensor(4.1802)\n",
      "13392 Traning Loss: tensor(4.1771)\n",
      "13393 Traning Loss: tensor(4.1741)\n",
      "13394 Traning Loss: tensor(4.1710)\n",
      "13395 Traning Loss: tensor(4.1679)\n",
      "13396 Traning Loss: tensor(4.1649)\n",
      "13397 Traning Loss: tensor(4.1618)\n",
      "13398 Traning Loss: tensor(4.1588)\n",
      "13399 Traning Loss: tensor(4.1557)\n",
      "13400 Traning Loss: tensor(4.1527)\n",
      "13401 Traning Loss: tensor(4.1497)\n",
      "13402 Traning Loss: tensor(4.1466)\n",
      "13403 Traning Loss: tensor(4.1436)\n",
      "13404 Traning Loss: tensor(4.1405)\n",
      "13405 Traning Loss: tensor(4.1375)\n",
      "13406 Traning Loss: tensor(4.1345)\n",
      "13407 Traning Loss: tensor(4.1314)\n",
      "13408 Traning Loss: tensor(4.1284)\n",
      "13409 Traning Loss: tensor(4.1254)\n",
      "13410 Traning Loss: tensor(4.1224)\n",
      "13411 Traning Loss: tensor(4.1193)\n",
      "13412 Traning Loss: tensor(4.1163)\n",
      "13413 Traning Loss: tensor(4.1133)\n",
      "13414 Traning Loss: tensor(4.1103)\n",
      "13415 Traning Loss: tensor(4.1072)\n",
      "13416 Traning Loss: tensor(4.1042)\n",
      "13417 Traning Loss: tensor(4.1012)\n",
      "13418 Traning Loss: tensor(4.0982)\n",
      "13419 Traning Loss: tensor(4.0952)\n",
      "13420 Traning Loss: tensor(4.0922)\n",
      "13421 Traning Loss: tensor(4.0892)\n",
      "13422 Traning Loss: tensor(4.0862)\n",
      "13423 Traning Loss: tensor(4.0832)\n",
      "13424 Traning Loss: tensor(4.0802)\n",
      "13425 Traning Loss: tensor(4.0772)\n",
      "13426 Traning Loss: tensor(4.0742)\n",
      "13427 Traning Loss: tensor(4.0712)\n",
      "13428 Traning Loss: tensor(4.0682)\n",
      "13429 Traning Loss: tensor(4.0652)\n",
      "13430 Traning Loss: tensor(4.0622)\n",
      "13431 Traning Loss: tensor(4.0592)\n",
      "13432 Traning Loss: tensor(4.0562)\n",
      "13433 Traning Loss: tensor(4.0533)\n",
      "13434 Traning Loss: tensor(4.0503)\n",
      "13435 Traning Loss: tensor(4.0473)\n",
      "13436 Traning Loss: tensor(4.0443)\n",
      "13437 Traning Loss: tensor(4.0414)\n",
      "13438 Traning Loss: tensor(4.0384)\n",
      "13439 Traning Loss: tensor(4.0354)\n",
      "13440 Traning Loss: tensor(4.0324)\n",
      "13441 Traning Loss: tensor(4.0295)\n",
      "13442 Traning Loss: tensor(4.0265)\n",
      "13443 Traning Loss: tensor(4.0235)\n",
      "13444 Traning Loss: tensor(4.0206)\n",
      "13445 Traning Loss: tensor(4.0176)\n",
      "13446 Traning Loss: tensor(4.0147)\n",
      "13447 Traning Loss: tensor(4.0117)\n",
      "13448 Traning Loss: tensor(4.0087)\n",
      "13449 Traning Loss: tensor(4.0058)\n",
      "13450 Traning Loss: tensor(4.0028)\n",
      "13451 Traning Loss: tensor(3.9999)\n",
      "13452 Traning Loss: tensor(3.9969)\n",
      "13453 Traning Loss: tensor(3.9940)\n",
      "13454 Traning Loss: tensor(3.9910)\n",
      "13455 Traning Loss: tensor(3.9881)\n",
      "13456 Traning Loss: tensor(3.9852)\n",
      "13457 Traning Loss: tensor(3.9822)\n",
      "13458 Traning Loss: tensor(3.9793)\n",
      "13459 Traning Loss: tensor(3.9764)\n",
      "13460 Traning Loss: tensor(3.9734)\n",
      "13461 Traning Loss: tensor(3.9705)\n",
      "13462 Traning Loss: tensor(3.9676)\n",
      "13463 Traning Loss: tensor(3.9646)\n",
      "13464 Traning Loss: tensor(3.9617)\n",
      "13465 Traning Loss: tensor(3.9588)\n",
      "13466 Traning Loss: tensor(3.9559)\n",
      "13467 Traning Loss: tensor(3.9529)\n",
      "13468 Traning Loss: tensor(3.9500)\n",
      "13469 Traning Loss: tensor(3.9471)\n",
      "13470 Traning Loss: tensor(3.9442)\n",
      "13471 Traning Loss: tensor(3.9413)\n",
      "13472 Traning Loss: tensor(3.9384)\n",
      "13473 Traning Loss: tensor(3.9355)\n",
      "13474 Traning Loss: tensor(3.9326)\n",
      "13475 Traning Loss: tensor(3.9297)\n",
      "13476 Traning Loss: tensor(3.9268)\n",
      "13477 Traning Loss: tensor(3.9239)\n",
      "13478 Traning Loss: tensor(3.9182)\n",
      "13479 Traning Loss: tensor(3.9153)\n",
      "13480 Traning Loss: tensor(3.9124)\n",
      "13481 Traning Loss: tensor(3.9095)\n",
      "13482 Traning Loss: tensor(3.9067)\n",
      "13483 Traning Loss: tensor(3.9038)\n",
      "13484 Traning Loss: tensor(3.9009)\n",
      "13485 Traning Loss: tensor(3.8980)\n",
      "13486 Traning Loss: tensor(3.8951)\n",
      "13487 Traning Loss: tensor(3.8923)\n",
      "13488 Traning Loss: tensor(3.8894)\n",
      "13489 Traning Loss: tensor(3.8865)\n",
      "13490 Traning Loss: tensor(3.8836)\n",
      "13491 Traning Loss: tensor(3.8808)\n",
      "13492 Traning Loss: tensor(3.8779)\n",
      "13493 Traning Loss: tensor(3.8750)\n",
      "13494 Traning Loss: tensor(3.8722)\n",
      "13495 Traning Loss: tensor(3.8693)\n",
      "13496 Traning Loss: tensor(3.8665)\n",
      "13497 Traning Loss: tensor(3.8636)\n",
      "13498 Traning Loss: tensor(3.8608)\n",
      "13499 Traning Loss: tensor(3.8579)\n",
      "13500 Traning Loss: tensor(3.8551)\n",
      "13501 Traning Loss: tensor(3.8522)\n",
      "13502 Traning Loss: tensor(3.8494)\n",
      "13503 Traning Loss: tensor(3.8465)\n",
      "13504 Traning Loss: tensor(3.8437)\n",
      "13505 Traning Loss: tensor(3.8408)\n",
      "13506 Traning Loss: tensor(3.8380)\n",
      "13507 Traning Loss: tensor(3.8352)\n",
      "13508 Traning Loss: tensor(3.8323)\n",
      "13509 Traning Loss: tensor(3.8295)\n",
      "13510 Traning Loss: tensor(3.8267)\n",
      "13511 Traning Loss: tensor(3.8238)\n",
      "13512 Traning Loss: tensor(3.8210)\n",
      "13513 Traning Loss: tensor(3.8182)\n",
      "13514 Traning Loss: tensor(3.8154)\n",
      "13515 Traning Loss: tensor(3.8125)\n",
      "13516 Traning Loss: tensor(3.8097)\n",
      "13517 Traning Loss: tensor(3.8069)\n",
      "13518 Traning Loss: tensor(3.8041)\n",
      "13519 Traning Loss: tensor(3.8013)\n",
      "13520 Traning Loss: tensor(3.7984)\n",
      "13521 Traning Loss: tensor(3.7956)\n",
      "13522 Traning Loss: tensor(3.7928)\n",
      "13523 Traning Loss: tensor(3.7900)\n",
      "13524 Traning Loss: tensor(3.7872)\n",
      "13525 Traning Loss: tensor(3.7844)\n",
      "13526 Traning Loss: tensor(3.7816)\n",
      "13527 Traning Loss: tensor(3.7788)\n",
      "13528 Traning Loss: tensor(3.7760)\n",
      "13529 Traning Loss: tensor(3.7732)\n",
      "13530 Traning Loss: tensor(3.7704)\n",
      "13531 Traning Loss: tensor(3.7676)\n",
      "13532 Traning Loss: tensor(3.7648)\n",
      "13533 Traning Loss: tensor(3.7621)\n",
      "13534 Traning Loss: tensor(3.7593)\n",
      "13535 Traning Loss: tensor(3.7565)\n",
      "13536 Traning Loss: tensor(3.7537)\n",
      "13537 Traning Loss: tensor(3.7509)\n",
      "13538 Traning Loss: tensor(3.7481)\n",
      "13539 Traning Loss: tensor(3.7454)\n",
      "13540 Traning Loss: tensor(3.7426)\n",
      "13541 Traning Loss: tensor(3.7398)\n",
      "13542 Traning Loss: tensor(3.7370)\n",
      "13543 Traning Loss: tensor(3.7343)\n",
      "13544 Traning Loss: tensor(3.7315)\n",
      "13545 Traning Loss: tensor(3.7287)\n",
      "13546 Traning Loss: tensor(3.7260)\n",
      "13547 Traning Loss: tensor(3.7232)\n",
      "13548 Traning Loss: tensor(3.7204)\n",
      "13549 Traning Loss: tensor(3.7177)\n",
      "13550 Traning Loss: tensor(3.7149)\n",
      "13551 Traning Loss: tensor(3.7122)\n",
      "13552 Traning Loss: tensor(3.7094)\n",
      "13553 Traning Loss: tensor(3.7067)\n",
      "13554 Traning Loss: tensor(3.7039)\n",
      "13555 Traning Loss: tensor(3.7012)\n",
      "13556 Traning Loss: tensor(3.6984)\n",
      "13557 Traning Loss: tensor(3.6957)\n",
      "13558 Traning Loss: tensor(3.6929)\n",
      "13559 Traning Loss: tensor(3.6902)\n",
      "13560 Traning Loss: tensor(3.6875)\n",
      "13561 Traning Loss: tensor(3.6847)\n",
      "13562 Traning Loss: tensor(3.6820)\n",
      "13563 Traning Loss: tensor(3.6793)\n",
      "13564 Traning Loss: tensor(3.6765)\n",
      "13565 Traning Loss: tensor(3.6738)\n",
      "13566 Traning Loss: tensor(3.6711)\n",
      "13567 Traning Loss: tensor(3.6684)\n",
      "13568 Traning Loss: tensor(3.6656)\n",
      "13569 Traning Loss: tensor(3.6629)\n",
      "13570 Traning Loss: tensor(3.6602)\n",
      "13571 Traning Loss: tensor(3.6575)\n",
      "13572 Traning Loss: tensor(3.6548)\n",
      "13573 Traning Loss: tensor(3.6520)\n",
      "13574 Traning Loss: tensor(3.6493)\n",
      "13575 Traning Loss: tensor(3.6466)\n",
      "13576 Traning Loss: tensor(3.6439)\n",
      "13577 Traning Loss: tensor(3.6412)\n",
      "13578 Traning Loss: tensor(3.6385)\n",
      "13579 Traning Loss: tensor(3.6358)\n",
      "13580 Traning Loss: tensor(3.6331)\n",
      "13581 Traning Loss: tensor(3.6304)\n",
      "13582 Traning Loss: tensor(3.6277)\n",
      "13583 Traning Loss: tensor(3.6250)\n",
      "13584 Traning Loss: tensor(3.6223)\n",
      "13585 Traning Loss: tensor(3.6196)\n",
      "13586 Traning Loss: tensor(3.6169)\n",
      "13587 Traning Loss: tensor(3.6142)\n",
      "13588 Traning Loss: tensor(3.6115)\n",
      "13589 Traning Loss: tensor(3.6089)\n",
      "13590 Traning Loss: tensor(3.6062)\n",
      "13591 Traning Loss: tensor(3.6035)\n",
      "13592 Traning Loss: tensor(3.6008)\n",
      "13593 Traning Loss: tensor(3.5981)\n",
      "13594 Traning Loss: tensor(3.5955)\n",
      "13595 Traning Loss: tensor(3.5928)\n",
      "13596 Traning Loss: tensor(3.5901)\n",
      "13597 Traning Loss: tensor(3.5875)\n",
      "13598 Traning Loss: tensor(3.5848)\n",
      "13599 Traning Loss: tensor(3.5821)\n",
      "13600 Traning Loss: tensor(3.5794)\n",
      "13601 Traning Loss: tensor(3.5768)\n",
      "13602 Traning Loss: tensor(3.5741)\n",
      "13603 Traning Loss: tensor(3.5715)\n",
      "13604 Traning Loss: tensor(3.5688)\n",
      "13605 Traning Loss: tensor(3.5662)\n",
      "13606 Traning Loss: tensor(3.5635)\n",
      "13607 Traning Loss: tensor(3.5608)\n",
      "13608 Traning Loss: tensor(3.5582)\n",
      "13609 Traning Loss: tensor(3.5556)\n",
      "13610 Traning Loss: tensor(3.5529)\n",
      "13611 Traning Loss: tensor(3.5503)\n",
      "13612 Traning Loss: tensor(3.5476)\n",
      "13613 Traning Loss: tensor(3.5450)\n",
      "13614 Traning Loss: tensor(3.5423)\n",
      "13615 Traning Loss: tensor(3.5397)\n",
      "13616 Traning Loss: tensor(3.5371)\n",
      "13617 Traning Loss: tensor(3.5344)\n",
      "13618 Traning Loss: tensor(3.5318)\n",
      "13619 Traning Loss: tensor(3.5292)\n",
      "13620 Traning Loss: tensor(3.5265)\n",
      "13621 Traning Loss: tensor(3.5239)\n",
      "13622 Traning Loss: tensor(3.5213)\n",
      "13623 Traning Loss: tensor(3.5187)\n",
      "13624 Traning Loss: tensor(3.5160)\n",
      "13625 Traning Loss: tensor(3.5134)\n",
      "13626 Traning Loss: tensor(3.5108)\n",
      "13627 Traning Loss: tensor(3.5082)\n",
      "13628 Traning Loss: tensor(3.5056)\n",
      "13629 Traning Loss: tensor(3.5030)\n",
      "13630 Traning Loss: tensor(3.5004)\n",
      "13631 Traning Loss: tensor(3.4978)\n",
      "13632 Traning Loss: tensor(3.4952)\n",
      "13633 Traning Loss: tensor(3.4925)\n",
      "13634 Traning Loss: tensor(3.4899)\n",
      "13635 Traning Loss: tensor(3.4873)\n",
      "13636 Traning Loss: tensor(3.4847)\n",
      "13637 Traning Loss: tensor(3.4822)\n",
      "13638 Traning Loss: tensor(3.4796)\n",
      "13639 Traning Loss: tensor(3.4770)\n",
      "13640 Traning Loss: tensor(3.4744)\n",
      "13641 Traning Loss: tensor(3.4718)\n",
      "13642 Traning Loss: tensor(3.4692)\n",
      "13643 Traning Loss: tensor(3.4666)\n",
      "13644 Traning Loss: tensor(3.4640)\n",
      "13645 Traning Loss: tensor(3.4614)\n",
      "13646 Traning Loss: tensor(3.4589)\n",
      "13647 Traning Loss: tensor(3.4563)\n",
      "13648 Traning Loss: tensor(3.4537)\n",
      "13649 Traning Loss: tensor(3.4511)\n",
      "13650 Traning Loss: tensor(3.4486)\n",
      "13651 Traning Loss: tensor(3.4460)\n",
      "13652 Traning Loss: tensor(3.4434)\n",
      "13653 Traning Loss: tensor(3.4409)\n",
      "13654 Traning Loss: tensor(3.4383)\n",
      "13655 Traning Loss: tensor(3.4357)\n",
      "13656 Traning Loss: tensor(3.4332)\n",
      "13657 Traning Loss: tensor(3.4306)\n",
      "13658 Traning Loss: tensor(3.4280)\n",
      "13659 Traning Loss: tensor(3.4255)\n",
      "13660 Traning Loss: tensor(3.4229)\n",
      "13661 Traning Loss: tensor(3.4204)\n",
      "13662 Traning Loss: tensor(3.4178)\n",
      "13663 Traning Loss: tensor(3.4153)\n",
      "13664 Traning Loss: tensor(3.4127)\n",
      "13665 Traning Loss: tensor(3.4102)\n",
      "13666 Traning Loss: tensor(3.4076)\n",
      "13667 Traning Loss: tensor(3.4051)\n",
      "13668 Traning Loss: tensor(3.4026)\n",
      "13669 Traning Loss: tensor(3.4000)\n",
      "13670 Traning Loss: tensor(3.3975)\n",
      "13671 Traning Loss: tensor(3.3950)\n",
      "13672 Traning Loss: tensor(3.3924)\n",
      "13673 Traning Loss: tensor(3.3899)\n",
      "13674 Traning Loss: tensor(3.3874)\n",
      "13675 Traning Loss: tensor(3.3848)\n",
      "13676 Traning Loss: tensor(3.3823)\n",
      "13677 Traning Loss: tensor(3.3798)\n",
      "13678 Traning Loss: tensor(3.3773)\n",
      "13679 Traning Loss: tensor(3.3747)\n",
      "13680 Traning Loss: tensor(3.3722)\n",
      "13681 Traning Loss: tensor(3.3697)\n",
      "13682 Traning Loss: tensor(3.3672)\n",
      "13683 Traning Loss: tensor(3.3647)\n",
      "13684 Traning Loss: tensor(3.3622)\n",
      "13685 Traning Loss: tensor(3.3597)\n",
      "13686 Traning Loss: tensor(3.3572)\n",
      "13687 Traning Loss: tensor(3.3546)\n",
      "13688 Traning Loss: tensor(3.3521)\n",
      "13689 Traning Loss: tensor(3.3496)\n",
      "13690 Traning Loss: tensor(3.3471)\n",
      "13691 Traning Loss: tensor(3.3446)\n",
      "13692 Traning Loss: tensor(3.3421)\n",
      "13693 Traning Loss: tensor(3.3396)\n",
      "13694 Traning Loss: tensor(3.3372)\n",
      "13695 Traning Loss: tensor(3.3347)\n",
      "13696 Traning Loss: tensor(3.3322)\n",
      "13697 Traning Loss: tensor(3.3297)\n",
      "13698 Traning Loss: tensor(3.3272)\n",
      "13699 Traning Loss: tensor(3.3247)\n",
      "13700 Traning Loss: tensor(3.3222)\n",
      "13701 Traning Loss: tensor(3.3198)\n",
      "13702 Traning Loss: tensor(3.3173)\n",
      "13703 Traning Loss: tensor(3.3148)\n",
      "13704 Traning Loss: tensor(3.3123)\n",
      "13705 Traning Loss: tensor(3.3099)\n",
      "13706 Traning Loss: tensor(3.3074)\n",
      "13707 Traning Loss: tensor(3.3049)\n",
      "13708 Traning Loss: tensor(3.3024)\n",
      "13709 Traning Loss: tensor(3.3000)\n",
      "13710 Traning Loss: tensor(3.2975)\n",
      "13711 Traning Loss: tensor(3.2951)\n",
      "13712 Traning Loss: tensor(3.2926)\n",
      "13713 Traning Loss: tensor(3.2901)\n",
      "13714 Traning Loss: tensor(3.2877)\n",
      "13715 Traning Loss: tensor(3.2852)\n",
      "13716 Traning Loss: tensor(3.2828)\n",
      "13717 Traning Loss: tensor(3.2803)\n",
      "13718 Traning Loss: tensor(3.2779)\n",
      "13719 Traning Loss: tensor(3.2754)\n",
      "13720 Traning Loss: tensor(3.2730)\n",
      "13721 Traning Loss: tensor(3.2705)\n",
      "13722 Traning Loss: tensor(3.2681)\n",
      "13723 Traning Loss: tensor(3.2656)\n",
      "13724 Traning Loss: tensor(3.2632)\n",
      "13725 Traning Loss: tensor(3.2608)\n",
      "13726 Traning Loss: tensor(3.2583)\n",
      "13727 Traning Loss: tensor(3.2559)\n",
      "13728 Traning Loss: tensor(3.2535)\n",
      "13729 Traning Loss: tensor(3.2510)\n",
      "13730 Traning Loss: tensor(3.2486)\n",
      "13731 Traning Loss: tensor(3.2462)\n",
      "13732 Traning Loss: tensor(3.2438)\n",
      "13733 Traning Loss: tensor(3.2413)\n",
      "13734 Traning Loss: tensor(3.2389)\n",
      "13735 Traning Loss: tensor(3.2365)\n",
      "13736 Traning Loss: tensor(3.2341)\n",
      "13737 Traning Loss: tensor(3.2317)\n",
      "13738 Traning Loss: tensor(3.2292)\n",
      "13739 Traning Loss: tensor(3.2268)\n",
      "13740 Traning Loss: tensor(3.2244)\n",
      "13741 Traning Loss: tensor(3.2220)\n",
      "13742 Traning Loss: tensor(3.2196)\n",
      "13743 Traning Loss: tensor(3.2172)\n",
      "13744 Traning Loss: tensor(3.2148)\n",
      "13745 Traning Loss: tensor(3.2124)\n",
      "13746 Traning Loss: tensor(3.2100)\n",
      "13747 Traning Loss: tensor(3.2076)\n",
      "13748 Traning Loss: tensor(3.2052)\n",
      "13749 Traning Loss: tensor(3.2028)\n",
      "13750 Traning Loss: tensor(3.2004)\n",
      "13751 Traning Loss: tensor(3.1980)\n",
      "13752 Traning Loss: tensor(3.1956)\n",
      "13753 Traning Loss: tensor(3.1933)\n",
      "13754 Traning Loss: tensor(3.1909)\n",
      "13755 Traning Loss: tensor(3.1885)\n",
      "13756 Traning Loss: tensor(3.1861)\n",
      "13757 Traning Loss: tensor(3.1837)\n",
      "13758 Traning Loss: tensor(3.1814)\n",
      "13759 Traning Loss: tensor(3.1790)\n",
      "13760 Traning Loss: tensor(3.1766)\n",
      "13761 Traning Loss: tensor(3.1742)\n",
      "13762 Traning Loss: tensor(3.1719)\n",
      "13763 Traning Loss: tensor(3.1695)\n",
      "13764 Traning Loss: tensor(3.1671)\n",
      "13765 Traning Loss: tensor(3.1648)\n",
      "13766 Traning Loss: tensor(3.1624)\n",
      "13767 Traning Loss: tensor(3.1600)\n",
      "13768 Traning Loss: tensor(3.1577)\n",
      "13769 Traning Loss: tensor(3.1553)\n",
      "13770 Traning Loss: tensor(3.1530)\n",
      "13771 Traning Loss: tensor(3.1506)\n",
      "13772 Traning Loss: tensor(3.1483)\n",
      "13773 Traning Loss: tensor(3.1459)\n",
      "13774 Traning Loss: tensor(3.1435)\n",
      "13775 Traning Loss: tensor(3.1412)\n",
      "13776 Traning Loss: tensor(3.1389)\n",
      "13777 Traning Loss: tensor(3.1365)\n",
      "13778 Traning Loss: tensor(3.1342)\n",
      "13779 Traning Loss: tensor(3.1318)\n",
      "13780 Traning Loss: tensor(3.1295)\n",
      "13781 Traning Loss: tensor(3.1272)\n",
      "13782 Traning Loss: tensor(3.1248)\n",
      "13783 Traning Loss: tensor(3.1225)\n",
      "13784 Traning Loss: tensor(3.1202)\n",
      "13785 Traning Loss: tensor(3.1178)\n",
      "13786 Traning Loss: tensor(3.1155)\n",
      "13787 Traning Loss: tensor(3.1132)\n",
      "13788 Traning Loss: tensor(3.1108)\n",
      "13789 Traning Loss: tensor(3.1085)\n",
      "13790 Traning Loss: tensor(3.1062)\n",
      "13791 Traning Loss: tensor(3.1039)\n",
      "13792 Traning Loss: tensor(3.1016)\n",
      "13793 Traning Loss: tensor(3.0993)\n",
      "13794 Traning Loss: tensor(3.0969)\n",
      "13795 Traning Loss: tensor(3.0946)\n",
      "13796 Traning Loss: tensor(3.0923)\n",
      "13797 Traning Loss: tensor(3.0900)\n",
      "13798 Traning Loss: tensor(3.0877)\n",
      "13799 Traning Loss: tensor(3.0854)\n",
      "13800 Traning Loss: tensor(3.0831)\n",
      "13801 Traning Loss: tensor(3.0808)\n",
      "13802 Traning Loss: tensor(3.0785)\n",
      "13803 Traning Loss: tensor(3.0762)\n",
      "13804 Traning Loss: tensor(3.0739)\n",
      "13805 Traning Loss: tensor(3.0716)\n",
      "13806 Traning Loss: tensor(3.0693)\n",
      "13807 Traning Loss: tensor(3.0637)\n",
      "13808 Traning Loss: tensor(3.0614)\n",
      "13809 Traning Loss: tensor(3.0591)\n",
      "13810 Traning Loss: tensor(3.0568)\n",
      "13811 Traning Loss: tensor(3.0546)\n",
      "13812 Traning Loss: tensor(3.0523)\n",
      "13813 Traning Loss: tensor(3.0500)\n",
      "13814 Traning Loss: tensor(3.0477)\n",
      "13815 Traning Loss: tensor(3.0455)\n",
      "13816 Traning Loss: tensor(3.0432)\n",
      "13817 Traning Loss: tensor(3.0409)\n",
      "13818 Traning Loss: tensor(3.0387)\n",
      "13819 Traning Loss: tensor(3.0364)\n",
      "13820 Traning Loss: tensor(3.0342)\n",
      "13821 Traning Loss: tensor(3.0319)\n",
      "13822 Traning Loss: tensor(3.0297)\n",
      "13823 Traning Loss: tensor(3.0274)\n",
      "13824 Traning Loss: tensor(3.0251)\n",
      "13825 Traning Loss: tensor(3.0229)\n",
      "13826 Traning Loss: tensor(3.0207)\n",
      "13827 Traning Loss: tensor(3.0184)\n",
      "13828 Traning Loss: tensor(3.0162)\n",
      "13829 Traning Loss: tensor(3.0139)\n",
      "13830 Traning Loss: tensor(3.0117)\n",
      "13831 Traning Loss: tensor(3.0094)\n",
      "13832 Traning Loss: tensor(3.0072)\n",
      "13833 Traning Loss: tensor(3.0050)\n",
      "13834 Traning Loss: tensor(3.0027)\n",
      "13835 Traning Loss: tensor(3.0005)\n",
      "13836 Traning Loss: tensor(2.9983)\n",
      "13837 Traning Loss: tensor(2.9961)\n",
      "13838 Traning Loss: tensor(2.9938)\n",
      "13839 Traning Loss: tensor(2.9916)\n",
      "13840 Traning Loss: tensor(2.9894)\n",
      "13841 Traning Loss: tensor(2.9872)\n",
      "13842 Traning Loss: tensor(2.9849)\n",
      "13843 Traning Loss: tensor(2.9827)\n",
      "13844 Traning Loss: tensor(2.9805)\n",
      "13845 Traning Loss: tensor(2.9783)\n",
      "13846 Traning Loss: tensor(2.9761)\n",
      "13847 Traning Loss: tensor(2.9739)\n",
      "13848 Traning Loss: tensor(2.9717)\n",
      "13849 Traning Loss: tensor(2.9695)\n",
      "13850 Traning Loss: tensor(2.9673)\n",
      "13851 Traning Loss: tensor(2.9651)\n",
      "13852 Traning Loss: tensor(2.9629)\n",
      "13853 Traning Loss: tensor(2.9607)\n",
      "13854 Traning Loss: tensor(2.9585)\n",
      "13855 Traning Loss: tensor(2.9563)\n",
      "13856 Traning Loss: tensor(2.9541)\n",
      "13857 Traning Loss: tensor(2.9519)\n",
      "13858 Traning Loss: tensor(2.9497)\n",
      "13859 Traning Loss: tensor(2.9475)\n",
      "13860 Traning Loss: tensor(2.9453)\n",
      "13861 Traning Loss: tensor(2.9431)\n",
      "13862 Traning Loss: tensor(2.9409)\n",
      "13863 Traning Loss: tensor(2.9388)\n",
      "13864 Traning Loss: tensor(2.9366)\n",
      "13865 Traning Loss: tensor(2.9344)\n",
      "13866 Traning Loss: tensor(2.9322)\n",
      "13867 Traning Loss: tensor(2.9301)\n",
      "13868 Traning Loss: tensor(2.9279)\n",
      "13869 Traning Loss: tensor(2.9257)\n",
      "13870 Traning Loss: tensor(2.9235)\n",
      "13871 Traning Loss: tensor(2.9214)\n",
      "13872 Traning Loss: tensor(2.9192)\n",
      "13873 Traning Loss: tensor(2.9171)\n",
      "13874 Traning Loss: tensor(2.9149)\n",
      "13875 Traning Loss: tensor(2.9127)\n",
      "13876 Traning Loss: tensor(2.9106)\n",
      "13877 Traning Loss: tensor(2.9084)\n",
      "13878 Traning Loss: tensor(2.9063)\n",
      "13879 Traning Loss: tensor(2.9041)\n",
      "13880 Traning Loss: tensor(2.9020)\n",
      "13881 Traning Loss: tensor(2.8998)\n",
      "13882 Traning Loss: tensor(2.8977)\n",
      "13883 Traning Loss: tensor(2.8955)\n",
      "13884 Traning Loss: tensor(2.8934)\n",
      "13885 Traning Loss: tensor(2.8912)\n",
      "13886 Traning Loss: tensor(2.8891)\n",
      "13887 Traning Loss: tensor(2.8869)\n",
      "13888 Traning Loss: tensor(2.8848)\n",
      "13889 Traning Loss: tensor(2.8827)\n",
      "13890 Traning Loss: tensor(2.8805)\n",
      "13891 Traning Loss: tensor(2.8784)\n",
      "13892 Traning Loss: tensor(2.8763)\n",
      "13893 Traning Loss: tensor(2.8741)\n",
      "13894 Traning Loss: tensor(2.8720)\n",
      "13895 Traning Loss: tensor(2.8699)\n",
      "13896 Traning Loss: tensor(2.8678)\n",
      "13897 Traning Loss: tensor(2.8656)\n",
      "13898 Traning Loss: tensor(2.8635)\n",
      "13899 Traning Loss: tensor(2.8614)\n",
      "13900 Traning Loss: tensor(2.8593)\n",
      "13901 Traning Loss: tensor(2.8572)\n",
      "13902 Traning Loss: tensor(2.8551)\n",
      "13903 Traning Loss: tensor(2.8530)\n",
      "13904 Traning Loss: tensor(2.8508)\n",
      "13905 Traning Loss: tensor(2.8487)\n",
      "13906 Traning Loss: tensor(2.8466)\n",
      "13907 Traning Loss: tensor(2.8445)\n",
      "13908 Traning Loss: tensor(2.8424)\n",
      "13909 Traning Loss: tensor(2.8403)\n",
      "13910 Traning Loss: tensor(2.8382)\n",
      "13911 Traning Loss: tensor(2.8361)\n",
      "13912 Traning Loss: tensor(2.8340)\n",
      "13913 Traning Loss: tensor(2.8319)\n",
      "13914 Traning Loss: tensor(2.8298)\n",
      "13915 Traning Loss: tensor(2.8278)\n",
      "13916 Traning Loss: tensor(2.8257)\n",
      "13917 Traning Loss: tensor(2.8236)\n",
      "13918 Traning Loss: tensor(2.8215)\n",
      "13919 Traning Loss: tensor(2.8194)\n",
      "13920 Traning Loss: tensor(2.8173)\n",
      "13921 Traning Loss: tensor(2.8152)\n",
      "13922 Traning Loss: tensor(2.8132)\n",
      "13923 Traning Loss: tensor(2.8111)\n",
      "13924 Traning Loss: tensor(2.8090)\n",
      "13925 Traning Loss: tensor(2.8069)\n",
      "13926 Traning Loss: tensor(2.8049)\n",
      "13927 Traning Loss: tensor(2.8028)\n",
      "13928 Traning Loss: tensor(2.8007)\n",
      "13929 Traning Loss: tensor(2.7987)\n",
      "13930 Traning Loss: tensor(2.7966)\n",
      "13931 Traning Loss: tensor(2.7945)\n",
      "13932 Traning Loss: tensor(2.7925)\n",
      "13933 Traning Loss: tensor(2.7904)\n",
      "13934 Traning Loss: tensor(2.7884)\n",
      "13935 Traning Loss: tensor(2.7863)\n",
      "13936 Traning Loss: tensor(2.7842)\n",
      "13937 Traning Loss: tensor(2.7822)\n",
      "13938 Traning Loss: tensor(2.7801)\n",
      "13939 Traning Loss: tensor(2.7781)\n",
      "13940 Traning Loss: tensor(2.7760)\n",
      "13941 Traning Loss: tensor(2.7740)\n",
      "13942 Traning Loss: tensor(2.7720)\n",
      "13943 Traning Loss: tensor(2.7699)\n",
      "13944 Traning Loss: tensor(2.7679)\n",
      "13945 Traning Loss: tensor(2.7658)\n",
      "13946 Traning Loss: tensor(2.7638)\n",
      "13947 Traning Loss: tensor(2.7618)\n",
      "13948 Traning Loss: tensor(2.7597)\n",
      "13949 Traning Loss: tensor(2.7577)\n",
      "13950 Traning Loss: tensor(2.7557)\n",
      "13951 Traning Loss: tensor(2.7536)\n",
      "13952 Traning Loss: tensor(2.7516)\n",
      "13953 Traning Loss: tensor(2.7496)\n",
      "13954 Traning Loss: tensor(2.7476)\n",
      "13955 Traning Loss: tensor(2.7455)\n",
      "13956 Traning Loss: tensor(2.7435)\n",
      "13957 Traning Loss: tensor(2.7415)\n",
      "13958 Traning Loss: tensor(2.7395)\n",
      "13959 Traning Loss: tensor(2.7375)\n",
      "13960 Traning Loss: tensor(2.7355)\n",
      "13961 Traning Loss: tensor(2.7334)\n",
      "13962 Traning Loss: tensor(2.7314)\n",
      "13963 Traning Loss: tensor(2.7294)\n",
      "13964 Traning Loss: tensor(2.7274)\n",
      "13965 Traning Loss: tensor(2.7254)\n",
      "13966 Traning Loss: tensor(2.7234)\n",
      "13967 Traning Loss: tensor(2.7214)\n",
      "13968 Traning Loss: tensor(2.7194)\n",
      "13969 Traning Loss: tensor(2.7174)\n",
      "13970 Traning Loss: tensor(2.7154)\n",
      "13971 Traning Loss: tensor(2.7134)\n",
      "13972 Traning Loss: tensor(2.7114)\n",
      "13973 Traning Loss: tensor(2.7094)\n",
      "13974 Traning Loss: tensor(2.7074)\n",
      "13975 Traning Loss: tensor(2.7055)\n",
      "13976 Traning Loss: tensor(2.7035)\n",
      "13977 Traning Loss: tensor(2.7015)\n",
      "13978 Traning Loss: tensor(2.6995)\n",
      "13979 Traning Loss: tensor(2.6975)\n",
      "13980 Traning Loss: tensor(2.6955)\n",
      "13981 Traning Loss: tensor(2.6936)\n",
      "13982 Traning Loss: tensor(2.6916)\n",
      "13983 Traning Loss: tensor(2.6896)\n",
      "13984 Traning Loss: tensor(2.6876)\n",
      "13985 Traning Loss: tensor(2.6857)\n",
      "13986 Traning Loss: tensor(2.6837)\n",
      "13987 Traning Loss: tensor(2.6817)\n",
      "13988 Traning Loss: tensor(2.6798)\n",
      "13989 Traning Loss: tensor(2.6778)\n",
      "13990 Traning Loss: tensor(2.6759)\n",
      "13991 Traning Loss: tensor(2.6739)\n",
      "13992 Traning Loss: tensor(2.6719)\n",
      "13993 Traning Loss: tensor(2.6700)\n",
      "13994 Traning Loss: tensor(2.6680)\n",
      "13995 Traning Loss: tensor(2.6661)\n",
      "13996 Traning Loss: tensor(2.6641)\n",
      "13997 Traning Loss: tensor(2.6622)\n",
      "13998 Traning Loss: tensor(2.6602)\n",
      "13999 Traning Loss: tensor(2.6583)\n",
      "14000 Traning Loss: tensor(2.6563)\n",
      "14001 Traning Loss: tensor(2.6544)\n",
      "14002 Traning Loss: tensor(2.6524)\n",
      "14003 Traning Loss: tensor(2.6505)\n",
      "14004 Traning Loss: tensor(2.6486)\n",
      "14005 Traning Loss: tensor(2.6466)\n",
      "14006 Traning Loss: tensor(2.6447)\n",
      "14007 Traning Loss: tensor(2.6427)\n",
      "14008 Traning Loss: tensor(2.6408)\n",
      "14009 Traning Loss: tensor(2.6389)\n",
      "14010 Traning Loss: tensor(2.6370)\n",
      "14011 Traning Loss: tensor(2.6350)\n",
      "14012 Traning Loss: tensor(2.6331)\n",
      "14013 Traning Loss: tensor(2.6312)\n",
      "14014 Traning Loss: tensor(2.6293)\n",
      "14015 Traning Loss: tensor(2.6273)\n",
      "14016 Traning Loss: tensor(2.6254)\n",
      "14017 Traning Loss: tensor(2.6235)\n",
      "14018 Traning Loss: tensor(2.6216)\n",
      "14019 Traning Loss: tensor(2.6197)\n",
      "14020 Traning Loss: tensor(2.6178)\n",
      "14021 Traning Loss: tensor(2.6159)\n",
      "14022 Traning Loss: tensor(2.6139)\n",
      "14023 Traning Loss: tensor(2.6120)\n",
      "14024 Traning Loss: tensor(2.6101)\n",
      "14025 Traning Loss: tensor(2.6082)\n",
      "14026 Traning Loss: tensor(2.6063)\n",
      "14027 Traning Loss: tensor(2.6044)\n",
      "14028 Traning Loss: tensor(2.6025)\n",
      "14029 Traning Loss: tensor(2.6006)\n",
      "14030 Traning Loss: tensor(2.5987)\n",
      "14031 Traning Loss: tensor(2.5968)\n",
      "14032 Traning Loss: tensor(2.5950)\n",
      "14033 Traning Loss: tensor(2.5931)\n",
      "14034 Traning Loss: tensor(2.5912)\n",
      "14035 Traning Loss: tensor(2.5893)\n",
      "14036 Traning Loss: tensor(2.5874)\n",
      "14037 Traning Loss: tensor(2.5855)\n",
      "14038 Traning Loss: tensor(2.5836)\n",
      "14039 Traning Loss: tensor(2.5818)\n",
      "14040 Traning Loss: tensor(2.5799)\n",
      "14041 Traning Loss: tensor(2.5780)\n",
      "14042 Traning Loss: tensor(2.5761)\n",
      "14043 Traning Loss: tensor(2.5743)\n",
      "14044 Traning Loss: tensor(2.5724)\n",
      "14045 Traning Loss: tensor(2.5705)\n",
      "14046 Traning Loss: tensor(2.5686)\n",
      "14047 Traning Loss: tensor(2.5668)\n",
      "14048 Traning Loss: tensor(2.5649)\n",
      "14049 Traning Loss: tensor(2.5630)\n",
      "14050 Traning Loss: tensor(2.5612)\n",
      "14051 Traning Loss: tensor(2.5593)\n",
      "14052 Traning Loss: tensor(2.5575)\n",
      "14053 Traning Loss: tensor(2.5556)\n",
      "14054 Traning Loss: tensor(2.5538)\n",
      "14055 Traning Loss: tensor(2.5519)\n",
      "14056 Traning Loss: tensor(2.5500)\n",
      "14057 Traning Loss: tensor(2.5482)\n",
      "14058 Traning Loss: tensor(2.5463)\n",
      "14059 Traning Loss: tensor(2.5445)\n",
      "14060 Traning Loss: tensor(2.5427)\n",
      "14061 Traning Loss: tensor(2.5408)\n",
      "14062 Traning Loss: tensor(2.5390)\n",
      "14063 Traning Loss: tensor(2.5371)\n",
      "14064 Traning Loss: tensor(2.5353)\n",
      "14065 Traning Loss: tensor(2.5335)\n",
      "14066 Traning Loss: tensor(2.5316)\n",
      "14067 Traning Loss: tensor(2.5298)\n",
      "14068 Traning Loss: tensor(2.5280)\n",
      "14069 Traning Loss: tensor(2.5261)\n",
      "14070 Traning Loss: tensor(2.5243)\n",
      "14071 Traning Loss: tensor(2.5225)\n",
      "14072 Traning Loss: tensor(2.5206)\n",
      "14073 Traning Loss: tensor(2.5188)\n",
      "14074 Traning Loss: tensor(2.5170)\n",
      "14075 Traning Loss: tensor(2.5152)\n",
      "14076 Traning Loss: tensor(2.5134)\n",
      "14077 Traning Loss: tensor(2.5115)\n",
      "14078 Traning Loss: tensor(2.5097)\n",
      "14079 Traning Loss: tensor(2.5079)\n",
      "14080 Traning Loss: tensor(2.5061)\n",
      "14081 Traning Loss: tensor(2.5043)\n",
      "14082 Traning Loss: tensor(2.5025)\n",
      "14083 Traning Loss: tensor(2.5007)\n",
      "14084 Traning Loss: tensor(2.4989)\n",
      "14085 Traning Loss: tensor(2.4971)\n",
      "14086 Traning Loss: tensor(2.4953)\n",
      "14087 Traning Loss: tensor(2.4935)\n",
      "14088 Traning Loss: tensor(2.4917)\n",
      "14089 Traning Loss: tensor(2.4899)\n",
      "14090 Traning Loss: tensor(2.4881)\n",
      "14091 Traning Loss: tensor(2.4863)\n",
      "14092 Traning Loss: tensor(2.4845)\n",
      "14093 Traning Loss: tensor(2.4827)\n",
      "14094 Traning Loss: tensor(2.4809)\n",
      "14095 Traning Loss: tensor(2.4791)\n",
      "14096 Traning Loss: tensor(2.4773)\n",
      "14097 Traning Loss: tensor(2.4755)\n",
      "14098 Traning Loss: tensor(2.4738)\n",
      "14099 Traning Loss: tensor(2.4720)\n",
      "14100 Traning Loss: tensor(2.4702)\n",
      "14101 Traning Loss: tensor(2.4684)\n",
      "14102 Traning Loss: tensor(2.4666)\n",
      "14103 Traning Loss: tensor(2.4649)\n",
      "14104 Traning Loss: tensor(2.4631)\n",
      "14105 Traning Loss: tensor(2.4613)\n",
      "14106 Traning Loss: tensor(2.4596)\n",
      "14107 Traning Loss: tensor(2.4578)\n",
      "14108 Traning Loss: tensor(2.4560)\n",
      "14109 Traning Loss: tensor(2.4543)\n",
      "14110 Traning Loss: tensor(2.4525)\n",
      "14111 Traning Loss: tensor(2.4507)\n",
      "14112 Traning Loss: tensor(2.4490)\n",
      "14113 Traning Loss: tensor(2.4472)\n",
      "14114 Traning Loss: tensor(2.4455)\n",
      "14115 Traning Loss: tensor(2.4437)\n",
      "14116 Traning Loss: tensor(2.4419)\n",
      "14117 Traning Loss: tensor(2.4402)\n",
      "14118 Traning Loss: tensor(2.4384)\n",
      "14119 Traning Loss: tensor(2.4367)\n",
      "14120 Traning Loss: tensor(2.4349)\n",
      "14121 Traning Loss: tensor(2.4332)\n",
      "14122 Traning Loss: tensor(2.4315)\n",
      "14123 Traning Loss: tensor(2.4297)\n",
      "14124 Traning Loss: tensor(2.4280)\n",
      "14125 Traning Loss: tensor(2.4262)\n",
      "14126 Traning Loss: tensor(2.4245)\n",
      "14127 Traning Loss: tensor(2.4228)\n",
      "14128 Traning Loss: tensor(2.4210)\n",
      "14129 Traning Loss: tensor(2.4193)\n",
      "14130 Traning Loss: tensor(2.4176)\n",
      "14131 Traning Loss: tensor(2.4158)\n",
      "14132 Traning Loss: tensor(2.4141)\n",
      "14133 Traning Loss: tensor(2.4124)\n",
      "14134 Traning Loss: tensor(2.4107)\n",
      "14135 Traning Loss: tensor(2.4089)\n",
      "14136 Traning Loss: tensor(2.4072)\n",
      "14137 Traning Loss: tensor(2.4055)\n",
      "14138 Traning Loss: tensor(2.4038)\n",
      "14139 Traning Loss: tensor(2.4021)\n",
      "14140 Traning Loss: tensor(2.3962)\n",
      "14141 Traning Loss: tensor(2.3945)\n",
      "14142 Traning Loss: tensor(2.3928)\n",
      "14143 Traning Loss: tensor(2.3911)\n",
      "14144 Traning Loss: tensor(2.3894)\n",
      "14145 Traning Loss: tensor(2.3877)\n",
      "14146 Traning Loss: tensor(2.3860)\n",
      "14147 Traning Loss: tensor(2.3843)\n",
      "14148 Traning Loss: tensor(2.3826)\n",
      "14149 Traning Loss: tensor(2.3809)\n",
      "14150 Traning Loss: tensor(2.3793)\n",
      "14151 Traning Loss: tensor(2.3776)\n",
      "14152 Traning Loss: tensor(2.3759)\n",
      "14153 Traning Loss: tensor(2.3742)\n",
      "14154 Traning Loss: tensor(2.3725)\n",
      "14155 Traning Loss: tensor(2.3708)\n",
      "14156 Traning Loss: tensor(2.3692)\n",
      "14157 Traning Loss: tensor(2.3675)\n",
      "14158 Traning Loss: tensor(2.3658)\n",
      "14159 Traning Loss: tensor(2.3641)\n",
      "14160 Traning Loss: tensor(2.3625)\n",
      "14161 Traning Loss: tensor(2.3608)\n",
      "14162 Traning Loss: tensor(2.3591)\n",
      "14163 Traning Loss: tensor(2.3575)\n",
      "14164 Traning Loss: tensor(2.3558)\n",
      "14165 Traning Loss: tensor(2.3541)\n",
      "14166 Traning Loss: tensor(2.3525)\n",
      "14167 Traning Loss: tensor(2.3508)\n",
      "14168 Traning Loss: tensor(2.3492)\n",
      "14169 Traning Loss: tensor(2.3475)\n",
      "14170 Traning Loss: tensor(2.3459)\n",
      "14171 Traning Loss: tensor(2.3442)\n",
      "14172 Traning Loss: tensor(2.3426)\n",
      "14173 Traning Loss: tensor(2.3409)\n",
      "14174 Traning Loss: tensor(2.3393)\n",
      "14175 Traning Loss: tensor(2.3376)\n",
      "14176 Traning Loss: tensor(2.3360)\n",
      "14177 Traning Loss: tensor(2.3343)\n",
      "14178 Traning Loss: tensor(2.3327)\n",
      "14179 Traning Loss: tensor(2.3310)\n",
      "14180 Traning Loss: tensor(2.3294)\n",
      "14181 Traning Loss: tensor(2.3278)\n",
      "14182 Traning Loss: tensor(2.3261)\n",
      "14183 Traning Loss: tensor(2.3245)\n",
      "14184 Traning Loss: tensor(2.3229)\n",
      "14185 Traning Loss: tensor(2.3212)\n",
      "14186 Traning Loss: tensor(2.3196)\n",
      "14187 Traning Loss: tensor(2.3180)\n",
      "14188 Traning Loss: tensor(2.3164)\n",
      "14189 Traning Loss: tensor(2.3147)\n",
      "14190 Traning Loss: tensor(2.3131)\n",
      "14191 Traning Loss: tensor(2.3115)\n",
      "14192 Traning Loss: tensor(2.3099)\n",
      "14193 Traning Loss: tensor(2.3083)\n",
      "14194 Traning Loss: tensor(2.3066)\n",
      "14195 Traning Loss: tensor(2.3050)\n",
      "14196 Traning Loss: tensor(2.3034)\n",
      "14197 Traning Loss: tensor(2.3018)\n",
      "14198 Traning Loss: tensor(2.3002)\n",
      "14199 Traning Loss: tensor(2.2986)\n",
      "14200 Traning Loss: tensor(2.2970)\n",
      "14201 Traning Loss: tensor(2.2954)\n",
      "14202 Traning Loss: tensor(2.2938)\n",
      "14203 Traning Loss: tensor(2.2922)\n",
      "14204 Traning Loss: tensor(2.2906)\n",
      "14205 Traning Loss: tensor(2.2890)\n",
      "14206 Traning Loss: tensor(2.2874)\n",
      "14207 Traning Loss: tensor(2.2858)\n",
      "14208 Traning Loss: tensor(2.2842)\n",
      "14209 Traning Loss: tensor(2.2826)\n",
      "14210 Traning Loss: tensor(2.2810)\n",
      "14211 Traning Loss: tensor(2.2794)\n",
      "14212 Traning Loss: tensor(2.2778)\n",
      "14213 Traning Loss: tensor(2.2762)\n",
      "14214 Traning Loss: tensor(2.2746)\n",
      "14215 Traning Loss: tensor(2.2731)\n",
      "14216 Traning Loss: tensor(2.2715)\n",
      "14217 Traning Loss: tensor(2.2699)\n",
      "14218 Traning Loss: tensor(2.2683)\n",
      "14219 Traning Loss: tensor(2.2667)\n",
      "14220 Traning Loss: tensor(2.2652)\n",
      "14221 Traning Loss: tensor(2.2636)\n",
      "14222 Traning Loss: tensor(2.2620)\n",
      "14223 Traning Loss: tensor(2.2605)\n",
      "14224 Traning Loss: tensor(2.2589)\n",
      "14225 Traning Loss: tensor(2.2573)\n",
      "14226 Traning Loss: tensor(2.2558)\n",
      "14227 Traning Loss: tensor(2.2542)\n",
      "14228 Traning Loss: tensor(2.2526)\n",
      "14229 Traning Loss: tensor(2.2511)\n",
      "14230 Traning Loss: tensor(2.2495)\n",
      "14231 Traning Loss: tensor(2.2479)\n",
      "14232 Traning Loss: tensor(2.2464)\n",
      "14233 Traning Loss: tensor(2.2448)\n",
      "14234 Traning Loss: tensor(2.2433)\n",
      "14235 Traning Loss: tensor(2.2417)\n",
      "14236 Traning Loss: tensor(2.2402)\n",
      "14237 Traning Loss: tensor(2.2386)\n",
      "14238 Traning Loss: tensor(2.2371)\n",
      "14239 Traning Loss: tensor(2.2355)\n",
      "14240 Traning Loss: tensor(2.2340)\n",
      "14241 Traning Loss: tensor(2.2325)\n",
      "14242 Traning Loss: tensor(2.2309)\n",
      "14243 Traning Loss: tensor(2.2294)\n",
      "14244 Traning Loss: tensor(2.2278)\n",
      "14245 Traning Loss: tensor(2.2263)\n",
      "14246 Traning Loss: tensor(2.2248)\n",
      "14247 Traning Loss: tensor(2.2232)\n",
      "14248 Traning Loss: tensor(2.2217)\n",
      "14249 Traning Loss: tensor(2.2202)\n",
      "14250 Traning Loss: tensor(2.2186)\n",
      "14251 Traning Loss: tensor(2.2171)\n",
      "14252 Traning Loss: tensor(2.2156)\n",
      "14253 Traning Loss: tensor(2.2141)\n",
      "14254 Traning Loss: tensor(2.2125)\n",
      "14255 Traning Loss: tensor(2.2110)\n",
      "14256 Traning Loss: tensor(2.2095)\n",
      "14257 Traning Loss: tensor(2.2080)\n",
      "14258 Traning Loss: tensor(2.2065)\n",
      "14259 Traning Loss: tensor(2.2049)\n",
      "14260 Traning Loss: tensor(2.2034)\n",
      "14261 Traning Loss: tensor(2.2019)\n",
      "14262 Traning Loss: tensor(2.2004)\n",
      "14263 Traning Loss: tensor(2.1989)\n",
      "14264 Traning Loss: tensor(2.1974)\n",
      "14265 Traning Loss: tensor(2.1959)\n",
      "14266 Traning Loss: tensor(2.1944)\n",
      "14267 Traning Loss: tensor(2.1929)\n",
      "14268 Traning Loss: tensor(2.1914)\n",
      "14269 Traning Loss: tensor(2.1899)\n",
      "14270 Traning Loss: tensor(2.1884)\n",
      "14271 Traning Loss: tensor(2.1869)\n",
      "14272 Traning Loss: tensor(2.1854)\n",
      "14273 Traning Loss: tensor(2.1839)\n",
      "14274 Traning Loss: tensor(2.1824)\n",
      "14275 Traning Loss: tensor(2.1809)\n",
      "14276 Traning Loss: tensor(2.1794)\n",
      "14277 Traning Loss: tensor(2.1779)\n",
      "14278 Traning Loss: tensor(2.1764)\n",
      "14279 Traning Loss: tensor(2.1750)\n",
      "14280 Traning Loss: tensor(2.1735)\n",
      "14281 Traning Loss: tensor(2.1720)\n",
      "14282 Traning Loss: tensor(2.1705)\n",
      "14283 Traning Loss: tensor(2.1690)\n",
      "14284 Traning Loss: tensor(2.1676)\n",
      "14285 Traning Loss: tensor(2.1661)\n",
      "14286 Traning Loss: tensor(2.1646)\n",
      "14287 Traning Loss: tensor(2.1631)\n",
      "14288 Traning Loss: tensor(2.1617)\n",
      "14289 Traning Loss: tensor(2.1602)\n",
      "14290 Traning Loss: tensor(2.1587)\n",
      "14291 Traning Loss: tensor(2.1573)\n",
      "14292 Traning Loss: tensor(2.1558)\n",
      "14293 Traning Loss: tensor(2.1543)\n",
      "14294 Traning Loss: tensor(2.1529)\n",
      "14295 Traning Loss: tensor(2.1514)\n",
      "14296 Traning Loss: tensor(2.1500)\n",
      "14297 Traning Loss: tensor(2.1485)\n",
      "14298 Traning Loss: tensor(2.1470)\n",
      "14299 Traning Loss: tensor(2.1456)\n",
      "14300 Traning Loss: tensor(2.1441)\n",
      "14301 Traning Loss: tensor(2.1427)\n",
      "14302 Traning Loss: tensor(2.1412)\n",
      "14303 Traning Loss: tensor(2.1398)\n",
      "14304 Traning Loss: tensor(2.1383)\n",
      "14305 Traning Loss: tensor(2.1369)\n",
      "14306 Traning Loss: tensor(2.1354)\n",
      "14307 Traning Loss: tensor(2.1340)\n",
      "14308 Traning Loss: tensor(2.1326)\n",
      "14309 Traning Loss: tensor(2.1311)\n",
      "14310 Traning Loss: tensor(2.1297)\n",
      "14311 Traning Loss: tensor(2.1283)\n",
      "14312 Traning Loss: tensor(2.1268)\n",
      "14313 Traning Loss: tensor(2.1254)\n",
      "14314 Traning Loss: tensor(2.1240)\n",
      "14315 Traning Loss: tensor(2.1225)\n",
      "14316 Traning Loss: tensor(2.1211)\n",
      "14317 Traning Loss: tensor(2.1197)\n",
      "14318 Traning Loss: tensor(2.1182)\n",
      "14319 Traning Loss: tensor(2.1168)\n",
      "14320 Traning Loss: tensor(2.1154)\n",
      "14321 Traning Loss: tensor(2.1140)\n",
      "14322 Traning Loss: tensor(2.1125)\n",
      "14323 Traning Loss: tensor(2.1111)\n",
      "14324 Traning Loss: tensor(2.1097)\n",
      "14325 Traning Loss: tensor(2.1083)\n",
      "14326 Traning Loss: tensor(2.1069)\n",
      "14327 Traning Loss: tensor(2.1055)\n",
      "14328 Traning Loss: tensor(2.1041)\n",
      "14329 Traning Loss: tensor(2.1026)\n",
      "14330 Traning Loss: tensor(2.1012)\n",
      "14331 Traning Loss: tensor(2.0998)\n",
      "14332 Traning Loss: tensor(2.0984)\n",
      "14333 Traning Loss: tensor(2.0970)\n",
      "14334 Traning Loss: tensor(2.0956)\n",
      "14335 Traning Loss: tensor(2.0942)\n",
      "14336 Traning Loss: tensor(2.0928)\n",
      "14337 Traning Loss: tensor(2.0914)\n",
      "14338 Traning Loss: tensor(2.0900)\n",
      "14339 Traning Loss: tensor(2.0886)\n",
      "14340 Traning Loss: tensor(2.0872)\n",
      "14341 Traning Loss: tensor(2.0858)\n",
      "14342 Traning Loss: tensor(2.0844)\n",
      "14343 Traning Loss: tensor(2.0831)\n",
      "14344 Traning Loss: tensor(2.0817)\n",
      "14345 Traning Loss: tensor(2.0803)\n",
      "14346 Traning Loss: tensor(2.0789)\n",
      "14347 Traning Loss: tensor(2.0775)\n",
      "14348 Traning Loss: tensor(2.0761)\n",
      "14349 Traning Loss: tensor(2.0748)\n",
      "14350 Traning Loss: tensor(2.0734)\n",
      "14351 Traning Loss: tensor(2.0720)\n",
      "14352 Traning Loss: tensor(2.0706)\n",
      "14353 Traning Loss: tensor(2.0692)\n",
      "14354 Traning Loss: tensor(2.0679)\n",
      "14355 Traning Loss: tensor(2.0665)\n",
      "14356 Traning Loss: tensor(2.0651)\n",
      "14357 Traning Loss: tensor(2.0638)\n",
      "14358 Traning Loss: tensor(2.0624)\n",
      "14359 Traning Loss: tensor(2.0610)\n",
      "14360 Traning Loss: tensor(2.0597)\n",
      "14361 Traning Loss: tensor(2.0583)\n",
      "14362 Traning Loss: tensor(2.0569)\n",
      "14363 Traning Loss: tensor(2.0556)\n",
      "14364 Traning Loss: tensor(2.0542)\n",
      "14365 Traning Loss: tensor(2.0529)\n",
      "14366 Traning Loss: tensor(2.0515)\n",
      "14367 Traning Loss: tensor(2.0501)\n",
      "14368 Traning Loss: tensor(2.0488)\n",
      "14369 Traning Loss: tensor(2.0474)\n",
      "14370 Traning Loss: tensor(2.0461)\n",
      "14371 Traning Loss: tensor(2.0447)\n",
      "14372 Traning Loss: tensor(2.0434)\n",
      "14373 Traning Loss: tensor(2.0421)\n",
      "14374 Traning Loss: tensor(2.0407)\n",
      "14375 Traning Loss: tensor(2.0394)\n",
      "14376 Traning Loss: tensor(2.0380)\n",
      "14377 Traning Loss: tensor(2.0367)\n",
      "14378 Traning Loss: tensor(2.0353)\n",
      "14379 Traning Loss: tensor(2.0340)\n",
      "14380 Traning Loss: tensor(2.0327)\n",
      "14381 Traning Loss: tensor(2.0313)\n",
      "14382 Traning Loss: tensor(2.0300)\n",
      "14383 Traning Loss: tensor(2.0287)\n",
      "14384 Traning Loss: tensor(2.0273)\n",
      "14385 Traning Loss: tensor(2.0260)\n",
      "14386 Traning Loss: tensor(2.0247)\n",
      "14387 Traning Loss: tensor(2.0234)\n",
      "14388 Traning Loss: tensor(2.0220)\n",
      "14389 Traning Loss: tensor(2.0207)\n",
      "14390 Traning Loss: tensor(2.0194)\n",
      "14391 Traning Loss: tensor(2.0181)\n",
      "14392 Traning Loss: tensor(2.0168)\n",
      "14393 Traning Loss: tensor(2.0154)\n",
      "14394 Traning Loss: tensor(2.0141)\n",
      "14395 Traning Loss: tensor(2.0128)\n",
      "14396 Traning Loss: tensor(2.0115)\n",
      "14397 Traning Loss: tensor(2.0102)\n",
      "14398 Traning Loss: tensor(2.0089)\n",
      "14399 Traning Loss: tensor(2.0076)\n",
      "14400 Traning Loss: tensor(2.0063)\n",
      "14401 Traning Loss: tensor(2.0050)\n",
      "14402 Traning Loss: tensor(2.0036)\n",
      "14403 Traning Loss: tensor(2.0023)\n",
      "14404 Traning Loss: tensor(2.0010)\n",
      "14405 Traning Loss: tensor(1.9997)\n",
      "14406 Traning Loss: tensor(1.9984)\n",
      "14407 Traning Loss: tensor(1.9971)\n",
      "14408 Traning Loss: tensor(1.9958)\n",
      "14409 Traning Loss: tensor(1.9946)\n",
      "14410 Traning Loss: tensor(1.9933)\n",
      "14411 Traning Loss: tensor(1.9920)\n",
      "14412 Traning Loss: tensor(1.9907)\n",
      "14413 Traning Loss: tensor(1.9894)\n",
      "14414 Traning Loss: tensor(1.9881)\n",
      "14415 Traning Loss: tensor(1.9868)\n",
      "14416 Traning Loss: tensor(1.9855)\n",
      "14417 Traning Loss: tensor(1.9842)\n",
      "14418 Traning Loss: tensor(1.9830)\n",
      "14419 Traning Loss: tensor(1.9817)\n",
      "14420 Traning Loss: tensor(1.9804)\n",
      "14421 Traning Loss: tensor(1.9791)\n",
      "14422 Traning Loss: tensor(1.9779)\n",
      "14423 Traning Loss: tensor(1.9766)\n",
      "14424 Traning Loss: tensor(1.9753)\n",
      "14425 Traning Loss: tensor(1.9740)\n",
      "14426 Traning Loss: tensor(1.9728)\n",
      "14427 Traning Loss: tensor(1.9715)\n",
      "14428 Traning Loss: tensor(1.9702)\n",
      "14429 Traning Loss: tensor(1.9690)\n",
      "14430 Traning Loss: tensor(1.9677)\n",
      "14431 Traning Loss: tensor(1.9664)\n",
      "14432 Traning Loss: tensor(1.9652)\n",
      "14433 Traning Loss: tensor(1.9639)\n",
      "14434 Traning Loss: tensor(1.9626)\n",
      "14435 Traning Loss: tensor(1.9614)\n",
      "14436 Traning Loss: tensor(1.9601)\n",
      "14437 Traning Loss: tensor(1.9589)\n",
      "14438 Traning Loss: tensor(1.9576)\n",
      "14439 Traning Loss: tensor(1.9564)\n",
      "14440 Traning Loss: tensor(1.9551)\n",
      "14441 Traning Loss: tensor(1.9539)\n",
      "14442 Traning Loss: tensor(1.9526)\n",
      "14443 Traning Loss: tensor(1.9514)\n",
      "14444 Traning Loss: tensor(1.9501)\n",
      "14445 Traning Loss: tensor(1.9489)\n",
      "14446 Traning Loss: tensor(1.9476)\n",
      "14447 Traning Loss: tensor(1.9464)\n",
      "14448 Traning Loss: tensor(1.9452)\n",
      "14449 Traning Loss: tensor(1.9439)\n",
      "14450 Traning Loss: tensor(1.9427)\n",
      "14451 Traning Loss: tensor(1.9414)\n",
      "14452 Traning Loss: tensor(1.9402)\n",
      "14453 Traning Loss: tensor(1.9390)\n",
      "14454 Traning Loss: tensor(1.9377)\n",
      "14455 Traning Loss: tensor(1.9365)\n",
      "14456 Traning Loss: tensor(1.9353)\n",
      "14457 Traning Loss: tensor(1.9341)\n",
      "14458 Traning Loss: tensor(1.9328)\n",
      "14459 Traning Loss: tensor(1.9316)\n",
      "14460 Traning Loss: tensor(1.9304)\n",
      "14461 Traning Loss: tensor(1.9292)\n",
      "14462 Traning Loss: tensor(1.9279)\n",
      "14463 Traning Loss: tensor(1.9267)\n",
      "14464 Traning Loss: tensor(1.9255)\n",
      "14465 Traning Loss: tensor(1.9243)\n",
      "14466 Traning Loss: tensor(1.9231)\n",
      "14467 Traning Loss: tensor(1.9219)\n",
      "14468 Traning Loss: tensor(1.9206)\n",
      "14469 Traning Loss: tensor(1.9194)\n",
      "14470 Traning Loss: tensor(1.9182)\n",
      "14471 Traning Loss: tensor(1.9170)\n",
      "14472 Traning Loss: tensor(1.9158)\n",
      "14473 Traning Loss: tensor(1.9146)\n",
      "14474 Traning Loss: tensor(1.9134)\n",
      "14475 Traning Loss: tensor(1.9122)\n",
      "14476 Traning Loss: tensor(1.9110)\n",
      "14477 Traning Loss: tensor(1.9098)\n",
      "14478 Traning Loss: tensor(1.9086)\n",
      "14479 Traning Loss: tensor(1.9074)\n",
      "14480 Traning Loss: tensor(1.9062)\n",
      "14481 Traning Loss: tensor(1.9050)\n",
      "14482 Traning Loss: tensor(1.9038)\n",
      "14483 Traning Loss: tensor(1.9026)\n",
      "14484 Traning Loss: tensor(1.9014)\n",
      "14485 Traning Loss: tensor(1.9002)\n",
      "14486 Traning Loss: tensor(1.8940)\n",
      "14487 Traning Loss: tensor(1.8928)\n",
      "14488 Traning Loss: tensor(1.8916)\n",
      "14489 Traning Loss: tensor(1.8904)\n",
      "14490 Traning Loss: tensor(1.8893)\n",
      "14491 Traning Loss: tensor(1.8881)\n",
      "14492 Traning Loss: tensor(1.8869)\n",
      "14493 Traning Loss: tensor(1.8858)\n",
      "14494 Traning Loss: tensor(1.8846)\n",
      "14495 Traning Loss: tensor(1.8834)\n",
      "14496 Traning Loss: tensor(1.8823)\n",
      "14497 Traning Loss: tensor(1.8811)\n",
      "14498 Traning Loss: tensor(1.8799)\n",
      "14499 Traning Loss: tensor(1.8788)\n",
      "14500 Traning Loss: tensor(1.8776)\n",
      "14501 Traning Loss: tensor(1.8765)\n",
      "14502 Traning Loss: tensor(1.8753)\n",
      "14503 Traning Loss: tensor(1.8742)\n",
      "14504 Traning Loss: tensor(1.8730)\n",
      "14505 Traning Loss: tensor(1.8719)\n",
      "14506 Traning Loss: tensor(1.8707)\n",
      "14507 Traning Loss: tensor(1.8696)\n",
      "14508 Traning Loss: tensor(1.8684)\n",
      "14509 Traning Loss: tensor(1.8673)\n",
      "14510 Traning Loss: tensor(1.8662)\n",
      "14511 Traning Loss: tensor(1.8650)\n",
      "14512 Traning Loss: tensor(1.8639)\n",
      "14513 Traning Loss: tensor(1.8627)\n",
      "14514 Traning Loss: tensor(1.8616)\n",
      "14515 Traning Loss: tensor(1.8605)\n",
      "14516 Traning Loss: tensor(1.8593)\n",
      "14517 Traning Loss: tensor(1.8582)\n",
      "14518 Traning Loss: tensor(1.8571)\n",
      "14519 Traning Loss: tensor(1.8559)\n",
      "14520 Traning Loss: tensor(1.8548)\n",
      "14521 Traning Loss: tensor(1.8537)\n",
      "14522 Traning Loss: tensor(1.8526)\n",
      "14523 Traning Loss: tensor(1.8514)\n",
      "14524 Traning Loss: tensor(1.8503)\n",
      "14525 Traning Loss: tensor(1.8492)\n",
      "14526 Traning Loss: tensor(1.8481)\n",
      "14527 Traning Loss: tensor(1.8470)\n",
      "14528 Traning Loss: tensor(1.8458)\n",
      "14529 Traning Loss: tensor(1.8447)\n",
      "14530 Traning Loss: tensor(1.8436)\n",
      "14531 Traning Loss: tensor(1.8425)\n",
      "14532 Traning Loss: tensor(1.8414)\n",
      "14533 Traning Loss: tensor(1.8403)\n",
      "14534 Traning Loss: tensor(1.8392)\n",
      "14535 Traning Loss: tensor(1.8381)\n",
      "14536 Traning Loss: tensor(1.8370)\n",
      "14537 Traning Loss: tensor(1.8359)\n",
      "14538 Traning Loss: tensor(1.8348)\n",
      "14539 Traning Loss: tensor(1.8337)\n",
      "14540 Traning Loss: tensor(1.8325)\n",
      "14541 Traning Loss: tensor(1.8315)\n",
      "14542 Traning Loss: tensor(1.8304)\n",
      "14543 Traning Loss: tensor(1.8293)\n",
      "14544 Traning Loss: tensor(1.8282)\n",
      "14545 Traning Loss: tensor(1.8271)\n",
      "14546 Traning Loss: tensor(1.8260)\n",
      "14547 Traning Loss: tensor(1.8249)\n",
      "14548 Traning Loss: tensor(1.8238)\n",
      "14549 Traning Loss: tensor(1.8227)\n",
      "14550 Traning Loss: tensor(1.8216)\n",
      "14551 Traning Loss: tensor(1.8205)\n",
      "14552 Traning Loss: tensor(1.8194)\n",
      "14553 Traning Loss: tensor(1.8184)\n",
      "14554 Traning Loss: tensor(1.8173)\n",
      "14555 Traning Loss: tensor(1.8162)\n",
      "14556 Traning Loss: tensor(1.8151)\n",
      "14557 Traning Loss: tensor(1.8140)\n",
      "14558 Traning Loss: tensor(1.8130)\n",
      "14559 Traning Loss: tensor(1.8119)\n",
      "14560 Traning Loss: tensor(1.8108)\n",
      "14561 Traning Loss: tensor(1.8097)\n",
      "14562 Traning Loss: tensor(1.8087)\n",
      "14563 Traning Loss: tensor(1.8076)\n",
      "14564 Traning Loss: tensor(1.8065)\n",
      "14565 Traning Loss: tensor(1.8054)\n",
      "14566 Traning Loss: tensor(1.8044)\n",
      "14567 Traning Loss: tensor(1.8033)\n",
      "14568 Traning Loss: tensor(1.8022)\n",
      "14569 Traning Loss: tensor(1.8012)\n",
      "14570 Traning Loss: tensor(1.8001)\n",
      "14571 Traning Loss: tensor(1.7991)\n",
      "14572 Traning Loss: tensor(1.7980)\n",
      "14573 Traning Loss: tensor(1.7969)\n",
      "14574 Traning Loss: tensor(1.7959)\n",
      "14575 Traning Loss: tensor(1.7948)\n",
      "14576 Traning Loss: tensor(1.7938)\n",
      "14577 Traning Loss: tensor(1.7927)\n",
      "14578 Traning Loss: tensor(1.7917)\n",
      "14579 Traning Loss: tensor(1.7906)\n",
      "14580 Traning Loss: tensor(1.7896)\n",
      "14581 Traning Loss: tensor(1.7885)\n",
      "14582 Traning Loss: tensor(1.7875)\n",
      "14583 Traning Loss: tensor(1.7864)\n",
      "14584 Traning Loss: tensor(1.7854)\n",
      "14585 Traning Loss: tensor(1.7843)\n",
      "14586 Traning Loss: tensor(1.7833)\n",
      "14587 Traning Loss: tensor(1.7823)\n",
      "14588 Traning Loss: tensor(1.7812)\n",
      "14589 Traning Loss: tensor(1.7802)\n",
      "14590 Traning Loss: tensor(1.7791)\n",
      "14591 Traning Loss: tensor(1.7781)\n",
      "14592 Traning Loss: tensor(1.7771)\n",
      "14593 Traning Loss: tensor(1.7760)\n",
      "14594 Traning Loss: tensor(1.7750)\n",
      "14595 Traning Loss: tensor(1.7740)\n",
      "14596 Traning Loss: tensor(1.7729)\n",
      "14597 Traning Loss: tensor(1.7719)\n",
      "14598 Traning Loss: tensor(1.7709)\n",
      "14599 Traning Loss: tensor(1.7699)\n",
      "14600 Traning Loss: tensor(1.7688)\n",
      "14601 Traning Loss: tensor(1.7678)\n",
      "14602 Traning Loss: tensor(1.7668)\n",
      "14603 Traning Loss: tensor(1.7658)\n",
      "14604 Traning Loss: tensor(1.7648)\n",
      "14605 Traning Loss: tensor(1.7637)\n",
      "14606 Traning Loss: tensor(1.7627)\n",
      "14607 Traning Loss: tensor(1.7617)\n",
      "14608 Traning Loss: tensor(1.7607)\n",
      "14609 Traning Loss: tensor(1.7597)\n",
      "14610 Traning Loss: tensor(1.7587)\n",
      "14611 Traning Loss: tensor(1.7576)\n",
      "14612 Traning Loss: tensor(1.7566)\n",
      "14613 Traning Loss: tensor(1.7556)\n",
      "14614 Traning Loss: tensor(1.7546)\n",
      "14615 Traning Loss: tensor(1.7536)\n",
      "14616 Traning Loss: tensor(1.7526)\n",
      "14617 Traning Loss: tensor(1.7516)\n",
      "14618 Traning Loss: tensor(1.7506)\n",
      "14619 Traning Loss: tensor(1.7496)\n",
      "14620 Traning Loss: tensor(1.7486)\n",
      "14621 Traning Loss: tensor(1.7476)\n",
      "14622 Traning Loss: tensor(1.7466)\n",
      "14623 Traning Loss: tensor(1.7456)\n",
      "14624 Traning Loss: tensor(1.7446)\n",
      "14625 Traning Loss: tensor(1.7436)\n",
      "14626 Traning Loss: tensor(1.7426)\n",
      "14627 Traning Loss: tensor(1.7416)\n",
      "14628 Traning Loss: tensor(1.7407)\n",
      "14629 Traning Loss: tensor(1.7397)\n",
      "14630 Traning Loss: tensor(1.7387)\n",
      "14631 Traning Loss: tensor(1.7377)\n",
      "14632 Traning Loss: tensor(1.7367)\n",
      "14633 Traning Loss: tensor(1.7357)\n",
      "14634 Traning Loss: tensor(1.7347)\n",
      "14635 Traning Loss: tensor(1.7338)\n",
      "14636 Traning Loss: tensor(1.7328)\n",
      "14637 Traning Loss: tensor(1.7318)\n",
      "14638 Traning Loss: tensor(1.7308)\n",
      "14639 Traning Loss: tensor(1.7298)\n",
      "14640 Traning Loss: tensor(1.7289)\n",
      "14641 Traning Loss: tensor(1.7279)\n",
      "14642 Traning Loss: tensor(1.7269)\n",
      "14643 Traning Loss: tensor(1.7259)\n",
      "14644 Traning Loss: tensor(1.7250)\n",
      "14645 Traning Loss: tensor(1.7240)\n",
      "14646 Traning Loss: tensor(1.7230)\n",
      "14647 Traning Loss: tensor(1.7221)\n",
      "14648 Traning Loss: tensor(1.7211)\n",
      "14649 Traning Loss: tensor(1.7201)\n",
      "14650 Traning Loss: tensor(1.7192)\n",
      "14651 Traning Loss: tensor(1.7182)\n",
      "14652 Traning Loss: tensor(1.7173)\n",
      "14653 Traning Loss: tensor(1.7163)\n",
      "14654 Traning Loss: tensor(1.7153)\n",
      "14655 Traning Loss: tensor(1.7144)\n",
      "14656 Traning Loss: tensor(1.7134)\n",
      "14657 Traning Loss: tensor(1.7125)\n",
      "14658 Traning Loss: tensor(1.7115)\n",
      "14659 Traning Loss: tensor(1.7106)\n",
      "14660 Traning Loss: tensor(1.7096)\n",
      "14661 Traning Loss: tensor(1.7087)\n",
      "14662 Traning Loss: tensor(1.7077)\n",
      "14663 Traning Loss: tensor(1.7068)\n",
      "14664 Traning Loss: tensor(1.7058)\n",
      "14665 Traning Loss: tensor(1.7049)\n",
      "14666 Traning Loss: tensor(1.7039)\n",
      "14667 Traning Loss: tensor(1.7030)\n",
      "14668 Traning Loss: tensor(1.7020)\n",
      "14669 Traning Loss: tensor(1.7011)\n",
      "14670 Traning Loss: tensor(1.7002)\n",
      "14671 Traning Loss: tensor(1.6992)\n",
      "14672 Traning Loss: tensor(1.6983)\n",
      "14673 Traning Loss: tensor(1.6973)\n",
      "14674 Traning Loss: tensor(1.6964)\n",
      "14675 Traning Loss: tensor(1.6955)\n",
      "14676 Traning Loss: tensor(1.6945)\n",
      "14677 Traning Loss: tensor(1.6936)\n",
      "14678 Traning Loss: tensor(1.6927)\n",
      "14679 Traning Loss: tensor(1.6918)\n",
      "14680 Traning Loss: tensor(1.6908)\n",
      "14681 Traning Loss: tensor(1.6899)\n",
      "14682 Traning Loss: tensor(1.6890)\n",
      "14683 Traning Loss: tensor(1.6880)\n",
      "14684 Traning Loss: tensor(1.6871)\n",
      "14685 Traning Loss: tensor(1.6862)\n",
      "14686 Traning Loss: tensor(1.6853)\n",
      "14687 Traning Loss: tensor(1.6844)\n",
      "14688 Traning Loss: tensor(1.6834)\n",
      "14689 Traning Loss: tensor(1.6825)\n",
      "14690 Traning Loss: tensor(1.6816)\n",
      "14691 Traning Loss: tensor(1.6807)\n",
      "14692 Traning Loss: tensor(1.6798)\n",
      "14693 Traning Loss: tensor(1.6789)\n",
      "14694 Traning Loss: tensor(1.6780)\n",
      "14695 Traning Loss: tensor(1.6770)\n",
      "14696 Traning Loss: tensor(1.6761)\n",
      "14697 Traning Loss: tensor(1.6752)\n",
      "14698 Traning Loss: tensor(1.6743)\n",
      "14699 Traning Loss: tensor(1.6734)\n",
      "14700 Traning Loss: tensor(1.6725)\n",
      "14701 Traning Loss: tensor(1.6716)\n",
      "14702 Traning Loss: tensor(1.6707)\n",
      "14703 Traning Loss: tensor(1.6698)\n",
      "14704 Traning Loss: tensor(1.6689)\n",
      "14705 Traning Loss: tensor(1.6680)\n",
      "14706 Traning Loss: tensor(1.6671)\n",
      "14707 Traning Loss: tensor(1.6662)\n",
      "14708 Traning Loss: tensor(1.6653)\n",
      "14709 Traning Loss: tensor(1.6644)\n",
      "14710 Traning Loss: tensor(1.6635)\n",
      "14711 Traning Loss: tensor(1.6626)\n",
      "14712 Traning Loss: tensor(1.6617)\n",
      "14713 Traning Loss: tensor(1.6609)\n",
      "14714 Traning Loss: tensor(1.6600)\n",
      "14715 Traning Loss: tensor(1.6591)\n",
      "14716 Traning Loss: tensor(1.6582)\n",
      "14717 Traning Loss: tensor(1.6573)\n",
      "14718 Traning Loss: tensor(1.6564)\n",
      "14719 Traning Loss: tensor(1.6555)\n",
      "14720 Traning Loss: tensor(1.6547)\n",
      "14721 Traning Loss: tensor(1.6538)\n",
      "14722 Traning Loss: tensor(1.6529)\n",
      "14723 Traning Loss: tensor(1.6520)\n",
      "14724 Traning Loss: tensor(1.6511)\n",
      "14725 Traning Loss: tensor(1.6503)\n",
      "14726 Traning Loss: tensor(1.6494)\n",
      "14727 Traning Loss: tensor(1.6485)\n",
      "14728 Traning Loss: tensor(1.6476)\n",
      "14729 Traning Loss: tensor(1.6468)\n",
      "14730 Traning Loss: tensor(1.6459)\n",
      "14731 Traning Loss: tensor(1.6450)\n",
      "14732 Traning Loss: tensor(1.6442)\n",
      "14733 Traning Loss: tensor(1.6433)\n",
      "14734 Traning Loss: tensor(1.6424)\n",
      "14735 Traning Loss: tensor(1.6416)\n",
      "14736 Traning Loss: tensor(1.6407)\n",
      "14737 Traning Loss: tensor(1.6398)\n",
      "14738 Traning Loss: tensor(1.6390)\n",
      "14739 Traning Loss: tensor(1.6381)\n",
      "14740 Traning Loss: tensor(1.6372)\n",
      "14741 Traning Loss: tensor(1.6364)\n",
      "14742 Traning Loss: tensor(1.6355)\n",
      "14743 Traning Loss: tensor(1.6347)\n",
      "14744 Traning Loss: tensor(1.6338)\n",
      "14745 Traning Loss: tensor(1.6330)\n",
      "14746 Traning Loss: tensor(1.6321)\n",
      "14747 Traning Loss: tensor(1.6313)\n",
      "14748 Traning Loss: tensor(1.6304)\n",
      "14749 Traning Loss: tensor(1.6296)\n",
      "14750 Traning Loss: tensor(1.6287)\n",
      "14751 Traning Loss: tensor(1.6279)\n",
      "14752 Traning Loss: tensor(1.6270)\n",
      "14753 Traning Loss: tensor(1.6262)\n",
      "14754 Traning Loss: tensor(1.6253)\n",
      "14755 Traning Loss: tensor(1.6245)\n",
      "14756 Traning Loss: tensor(1.6236)\n",
      "14757 Traning Loss: tensor(1.6228)\n",
      "14758 Traning Loss: tensor(1.6220)\n",
      "14759 Traning Loss: tensor(1.6211)\n",
      "14760 Traning Loss: tensor(1.6203)\n",
      "14761 Traning Loss: tensor(1.6195)\n",
      "14762 Traning Loss: tensor(1.6186)\n",
      "14763 Traning Loss: tensor(1.6178)\n",
      "14764 Traning Loss: tensor(1.6169)\n",
      "14765 Traning Loss: tensor(1.6161)\n",
      "14766 Traning Loss: tensor(1.6153)\n",
      "14767 Traning Loss: tensor(1.6145)\n",
      "14768 Traning Loss: tensor(1.6136)\n",
      "14769 Traning Loss: tensor(1.6128)\n",
      "14770 Traning Loss: tensor(1.6120)\n",
      "14771 Traning Loss: tensor(1.6111)\n",
      "14772 Traning Loss: tensor(1.6103)\n",
      "14773 Traning Loss: tensor(1.6095)\n",
      "14774 Traning Loss: tensor(1.6087)\n",
      "14775 Traning Loss: tensor(1.6079)\n",
      "14776 Traning Loss: tensor(1.6070)\n",
      "14777 Traning Loss: tensor(1.6062)\n",
      "14778 Traning Loss: tensor(1.6054)\n",
      "14779 Traning Loss: tensor(1.6046)\n",
      "14780 Traning Loss: tensor(1.6038)\n",
      "14781 Traning Loss: tensor(1.6029)\n",
      "14782 Traning Loss: tensor(1.6021)\n",
      "14783 Traning Loss: tensor(1.6013)\n",
      "14784 Traning Loss: tensor(1.6005)\n",
      "14785 Traning Loss: tensor(1.5997)\n",
      "14786 Traning Loss: tensor(1.5989)\n",
      "14787 Traning Loss: tensor(1.5981)\n",
      "14788 Traning Loss: tensor(1.5973)\n",
      "14789 Traning Loss: tensor(1.5965)\n",
      "14790 Traning Loss: tensor(1.5957)\n",
      "14791 Traning Loss: tensor(1.5949)\n",
      "14792 Traning Loss: tensor(1.5941)\n",
      "14793 Traning Loss: tensor(1.5933)\n",
      "14794 Traning Loss: tensor(1.5925)\n",
      "14795 Traning Loss: tensor(1.5917)\n",
      "14796 Traning Loss: tensor(1.5909)\n",
      "14797 Traning Loss: tensor(1.5901)\n",
      "14798 Traning Loss: tensor(1.5893)\n",
      "14799 Traning Loss: tensor(1.5885)\n",
      "14800 Traning Loss: tensor(1.5877)\n",
      "14801 Traning Loss: tensor(1.5869)\n",
      "14802 Traning Loss: tensor(1.5861)\n",
      "14803 Traning Loss: tensor(1.5853)\n",
      "14804 Traning Loss: tensor(1.5845)\n",
      "14805 Traning Loss: tensor(1.5837)\n",
      "14806 Traning Loss: tensor(1.5829)\n",
      "14807 Traning Loss: tensor(1.5821)\n",
      "14808 Traning Loss: tensor(1.5813)\n",
      "14809 Traning Loss: tensor(1.5806)\n",
      "14810 Traning Loss: tensor(1.5798)\n",
      "14811 Traning Loss: tensor(1.5790)\n",
      "14812 Traning Loss: tensor(1.5782)\n",
      "14813 Traning Loss: tensor(1.5774)\n",
      "14814 Traning Loss: tensor(1.5766)\n",
      "14815 Traning Loss: tensor(1.5759)\n",
      "14816 Traning Loss: tensor(1.5751)\n",
      "14817 Traning Loss: tensor(1.5743)\n",
      "14818 Traning Loss: tensor(1.5735)\n",
      "14819 Traning Loss: tensor(1.5728)\n",
      "14820 Traning Loss: tensor(1.5720)\n",
      "14821 Traning Loss: tensor(1.5712)\n",
      "14822 Traning Loss: tensor(1.5704)\n",
      "14823 Traning Loss: tensor(1.5697)\n",
      "14824 Traning Loss: tensor(1.5689)\n",
      "14825 Traning Loss: tensor(1.5681)\n",
      "14826 Traning Loss: tensor(1.5674)\n",
      "14827 Traning Loss: tensor(1.5666)\n",
      "14828 Traning Loss: tensor(1.5658)\n",
      "14829 Traning Loss: tensor(1.5651)\n",
      "14830 Traning Loss: tensor(1.5643)\n",
      "14831 Traning Loss: tensor(1.5635)\n",
      "14832 Traning Loss: tensor(1.5628)\n",
      "14833 Traning Loss: tensor(1.5620)\n",
      "14834 Traning Loss: tensor(1.5613)\n",
      "14835 Traning Loss: tensor(1.5605)\n",
      "14836 Traning Loss: tensor(1.5597)\n",
      "14837 Traning Loss: tensor(1.5590)\n",
      "14838 Traning Loss: tensor(1.5582)\n",
      "14839 Traning Loss: tensor(1.5575)\n",
      "14840 Traning Loss: tensor(1.5567)\n",
      "14841 Traning Loss: tensor(1.5560)\n",
      "14842 Traning Loss: tensor(1.5552)\n",
      "14843 Traning Loss: tensor(1.5545)\n",
      "14844 Traning Loss: tensor(1.5537)\n",
      "14845 Traning Loss: tensor(1.5530)\n",
      "14846 Traning Loss: tensor(1.5522)\n",
      "14847 Traning Loss: tensor(1.5515)\n",
      "14848 Traning Loss: tensor(1.5507)\n",
      "14849 Traning Loss: tensor(1.5500)\n",
      "14850 Traning Loss: tensor(1.5492)\n",
      "14851 Traning Loss: tensor(1.5485)\n",
      "14852 Traning Loss: tensor(1.5478)\n",
      "14853 Traning Loss: tensor(1.5470)\n",
      "14854 Traning Loss: tensor(1.5400)\n",
      "14855 Traning Loss: tensor(1.5393)\n",
      "14856 Traning Loss: tensor(1.5385)\n",
      "14857 Traning Loss: tensor(1.5378)\n",
      "14858 Traning Loss: tensor(1.5371)\n",
      "14859 Traning Loss: tensor(1.5364)\n",
      "14860 Traning Loss: tensor(1.5357)\n",
      "14861 Traning Loss: tensor(1.5349)\n",
      "14862 Traning Loss: tensor(1.5342)\n",
      "14863 Traning Loss: tensor(1.5335)\n",
      "14864 Traning Loss: tensor(1.5328)\n",
      "14865 Traning Loss: tensor(1.5321)\n",
      "14866 Traning Loss: tensor(1.5314)\n",
      "14867 Traning Loss: tensor(1.5307)\n",
      "14868 Traning Loss: tensor(1.5300)\n",
      "14869 Traning Loss: tensor(1.5292)\n",
      "14870 Traning Loss: tensor(1.5285)\n",
      "14871 Traning Loss: tensor(1.5278)\n",
      "14872 Traning Loss: tensor(1.5271)\n",
      "14873 Traning Loss: tensor(1.5264)\n",
      "14874 Traning Loss: tensor(1.5257)\n",
      "14875 Traning Loss: tensor(1.5250)\n",
      "14876 Traning Loss: tensor(1.5243)\n",
      "14877 Traning Loss: tensor(1.5236)\n",
      "14878 Traning Loss: tensor(1.5229)\n",
      "14879 Traning Loss: tensor(1.5222)\n",
      "14880 Traning Loss: tensor(1.5215)\n",
      "14881 Traning Loss: tensor(1.5208)\n",
      "14882 Traning Loss: tensor(1.5201)\n",
      "14883 Traning Loss: tensor(1.5195)\n",
      "14884 Traning Loss: tensor(1.5188)\n",
      "14885 Traning Loss: tensor(1.5181)\n",
      "14886 Traning Loss: tensor(1.5174)\n",
      "14887 Traning Loss: tensor(1.5167)\n",
      "14888 Traning Loss: tensor(1.5160)\n",
      "14889 Traning Loss: tensor(1.5153)\n",
      "14890 Traning Loss: tensor(1.5146)\n",
      "14891 Traning Loss: tensor(1.5140)\n",
      "14892 Traning Loss: tensor(1.5133)\n",
      "14893 Traning Loss: tensor(1.5126)\n",
      "14894 Traning Loss: tensor(1.5119)\n",
      "14895 Traning Loss: tensor(1.5112)\n",
      "14896 Traning Loss: tensor(1.5105)\n",
      "14897 Traning Loss: tensor(1.5099)\n",
      "14898 Traning Loss: tensor(1.5092)\n",
      "14899 Traning Loss: tensor(1.5085)\n",
      "14900 Traning Loss: tensor(1.5078)\n",
      "14901 Traning Loss: tensor(1.5072)\n",
      "14902 Traning Loss: tensor(1.5065)\n",
      "14903 Traning Loss: tensor(1.5058)\n",
      "14904 Traning Loss: tensor(1.5051)\n",
      "14905 Traning Loss: tensor(1.5045)\n",
      "14906 Traning Loss: tensor(1.5038)\n",
      "14907 Traning Loss: tensor(1.5031)\n",
      "14908 Traning Loss: tensor(1.5025)\n",
      "14909 Traning Loss: tensor(1.5018)\n",
      "14910 Traning Loss: tensor(1.5011)\n",
      "14911 Traning Loss: tensor(1.5005)\n",
      "14912 Traning Loss: tensor(1.4998)\n",
      "14913 Traning Loss: tensor(1.4991)\n",
      "14914 Traning Loss: tensor(1.4985)\n",
      "14915 Traning Loss: tensor(1.4978)\n",
      "14916 Traning Loss: tensor(1.4972)\n",
      "14917 Traning Loss: tensor(1.4965)\n",
      "14918 Traning Loss: tensor(1.4958)\n",
      "14919 Traning Loss: tensor(1.4952)\n",
      "14920 Traning Loss: tensor(1.4945)\n",
      "14921 Traning Loss: tensor(1.4939)\n",
      "14922 Traning Loss: tensor(1.4932)\n",
      "14923 Traning Loss: tensor(1.4926)\n",
      "14924 Traning Loss: tensor(1.4919)\n",
      "14925 Traning Loss: tensor(1.4913)\n",
      "14926 Traning Loss: tensor(1.4906)\n",
      "14927 Traning Loss: tensor(1.4900)\n",
      "14928 Traning Loss: tensor(1.4893)\n",
      "14929 Traning Loss: tensor(1.4887)\n",
      "14930 Traning Loss: tensor(1.4880)\n",
      "14931 Traning Loss: tensor(1.4874)\n",
      "14932 Traning Loss: tensor(1.4867)\n",
      "14933 Traning Loss: tensor(1.4861)\n",
      "14934 Traning Loss: tensor(1.4854)\n",
      "14935 Traning Loss: tensor(1.4848)\n",
      "14936 Traning Loss: tensor(1.4841)\n",
      "14937 Traning Loss: tensor(1.4835)\n",
      "14938 Traning Loss: tensor(1.4829)\n",
      "14939 Traning Loss: tensor(1.4822)\n",
      "14940 Traning Loss: tensor(1.4816)\n",
      "14941 Traning Loss: tensor(1.4809)\n",
      "14942 Traning Loss: tensor(1.4803)\n",
      "14943 Traning Loss: tensor(1.4797)\n",
      "14944 Traning Loss: tensor(1.4790)\n",
      "14945 Traning Loss: tensor(1.4784)\n",
      "14946 Traning Loss: tensor(1.4778)\n",
      "14947 Traning Loss: tensor(1.4771)\n",
      "14948 Traning Loss: tensor(1.4765)\n",
      "14949 Traning Loss: tensor(1.4759)\n",
      "14950 Traning Loss: tensor(1.4753)\n",
      "14951 Traning Loss: tensor(1.4746)\n",
      "14952 Traning Loss: tensor(1.4740)\n",
      "14953 Traning Loss: tensor(1.4734)\n",
      "14954 Traning Loss: tensor(1.4727)\n",
      "14955 Traning Loss: tensor(1.4721)\n",
      "14956 Traning Loss: tensor(1.4715)\n",
      "14957 Traning Loss: tensor(1.4709)\n",
      "14958 Traning Loss: tensor(1.4703)\n",
      "14959 Traning Loss: tensor(1.4696)\n",
      "14960 Traning Loss: tensor(1.4690)\n",
      "14961 Traning Loss: tensor(1.4684)\n",
      "14962 Traning Loss: tensor(1.4678)\n",
      "14963 Traning Loss: tensor(1.4672)\n",
      "14964 Traning Loss: tensor(1.4665)\n",
      "14965 Traning Loss: tensor(1.4659)\n",
      "14966 Traning Loss: tensor(1.4653)\n",
      "14967 Traning Loss: tensor(1.4647)\n",
      "14968 Traning Loss: tensor(1.4641)\n",
      "14969 Traning Loss: tensor(1.4635)\n",
      "14970 Traning Loss: tensor(1.4629)\n",
      "14971 Traning Loss: tensor(1.4622)\n",
      "14972 Traning Loss: tensor(1.4616)\n",
      "14973 Traning Loss: tensor(1.4610)\n",
      "14974 Traning Loss: tensor(1.4604)\n",
      "14975 Traning Loss: tensor(1.4598)\n",
      "14976 Traning Loss: tensor(1.4592)\n",
      "14977 Traning Loss: tensor(1.4586)\n",
      "14978 Traning Loss: tensor(1.4580)\n",
      "14979 Traning Loss: tensor(1.4574)\n",
      "14980 Traning Loss: tensor(1.4568)\n",
      "14981 Traning Loss: tensor(1.4562)\n",
      "14982 Traning Loss: tensor(1.4556)\n",
      "14983 Traning Loss: tensor(1.4550)\n",
      "14984 Traning Loss: tensor(1.4544)\n",
      "14985 Traning Loss: tensor(1.4538)\n",
      "14986 Traning Loss: tensor(1.4532)\n",
      "14987 Traning Loss: tensor(1.4526)\n",
      "14988 Traning Loss: tensor(1.4520)\n",
      "14989 Traning Loss: tensor(1.4514)\n",
      "14990 Traning Loss: tensor(1.4508)\n",
      "14991 Traning Loss: tensor(1.4502)\n",
      "14992 Traning Loss: tensor(1.4496)\n",
      "14993 Traning Loss: tensor(1.4490)\n",
      "14994 Traning Loss: tensor(1.4485)\n",
      "14995 Traning Loss: tensor(1.4479)\n",
      "14996 Traning Loss: tensor(1.4473)\n",
      "14997 Traning Loss: tensor(1.4467)\n",
      "14998 Traning Loss: tensor(1.4461)\n",
      "14999 Traning Loss: tensor(1.4455)\n",
      "15000 Traning Loss: tensor(1.4449)\n",
      "15001 Traning Loss: tensor(1.4443)\n",
      "15002 Traning Loss: tensor(1.4438)\n",
      "15003 Traning Loss: tensor(1.4432)\n",
      "15004 Traning Loss: tensor(1.4426)\n",
      "15005 Traning Loss: tensor(1.4420)\n",
      "15006 Traning Loss: tensor(1.4414)\n",
      "15007 Traning Loss: tensor(1.4409)\n",
      "15008 Traning Loss: tensor(1.4403)\n",
      "15009 Traning Loss: tensor(1.4397)\n",
      "15010 Traning Loss: tensor(1.4391)\n",
      "15011 Traning Loss: tensor(1.4385)\n",
      "15012 Traning Loss: tensor(1.4380)\n",
      "15013 Traning Loss: tensor(1.4374)\n",
      "15014 Traning Loss: tensor(1.4368)\n",
      "15015 Traning Loss: tensor(1.4363)\n",
      "15016 Traning Loss: tensor(1.4357)\n",
      "15017 Traning Loss: tensor(1.4351)\n",
      "15018 Traning Loss: tensor(1.4345)\n",
      "15019 Traning Loss: tensor(1.4340)\n",
      "15020 Traning Loss: tensor(1.4334)\n",
      "15021 Traning Loss: tensor(1.4328)\n",
      "15022 Traning Loss: tensor(1.4323)\n",
      "15023 Traning Loss: tensor(1.4317)\n",
      "15024 Traning Loss: tensor(1.4311)\n",
      "15025 Traning Loss: tensor(1.4306)\n",
      "15026 Traning Loss: tensor(1.4300)\n",
      "15027 Traning Loss: tensor(1.4294)\n",
      "15028 Traning Loss: tensor(1.4289)\n",
      "15029 Traning Loss: tensor(1.4283)\n",
      "15030 Traning Loss: tensor(1.4278)\n",
      "15031 Traning Loss: tensor(1.4272)\n",
      "15032 Traning Loss: tensor(1.4266)\n",
      "15033 Traning Loss: tensor(1.4261)\n",
      "15034 Traning Loss: tensor(1.4255)\n",
      "15035 Traning Loss: tensor(1.4250)\n",
      "15036 Traning Loss: tensor(1.4244)\n",
      "15037 Traning Loss: tensor(1.4239)\n",
      "15038 Traning Loss: tensor(1.4233)\n",
      "15039 Traning Loss: tensor(1.4228)\n",
      "15040 Traning Loss: tensor(1.4222)\n",
      "15041 Traning Loss: tensor(1.4217)\n",
      "15042 Traning Loss: tensor(1.4211)\n",
      "15043 Traning Loss: tensor(1.4206)\n",
      "15044 Traning Loss: tensor(1.4200)\n",
      "15045 Traning Loss: tensor(1.4195)\n",
      "15046 Traning Loss: tensor(1.4189)\n",
      "15047 Traning Loss: tensor(1.4184)\n",
      "15048 Traning Loss: tensor(1.4178)\n",
      "15049 Traning Loss: tensor(1.4173)\n",
      "15050 Traning Loss: tensor(1.4167)\n",
      "15051 Traning Loss: tensor(1.4162)\n",
      "15052 Traning Loss: tensor(1.4156)\n",
      "15053 Traning Loss: tensor(1.4151)\n",
      "15054 Traning Loss: tensor(1.4146)\n",
      "15055 Traning Loss: tensor(1.4140)\n",
      "15056 Traning Loss: tensor(1.4135)\n",
      "15057 Traning Loss: tensor(1.4129)\n",
      "15058 Traning Loss: tensor(1.4124)\n",
      "15059 Traning Loss: tensor(1.4119)\n",
      "15060 Traning Loss: tensor(1.4113)\n",
      "15061 Traning Loss: tensor(1.4108)\n",
      "15062 Traning Loss: tensor(1.4103)\n",
      "15063 Traning Loss: tensor(1.4097)\n",
      "15064 Traning Loss: tensor(1.4092)\n",
      "15065 Traning Loss: tensor(1.4087)\n",
      "15066 Traning Loss: tensor(1.4081)\n",
      "15067 Traning Loss: tensor(1.4076)\n",
      "15068 Traning Loss: tensor(1.4071)\n",
      "15069 Traning Loss: tensor(1.4065)\n",
      "15070 Traning Loss: tensor(1.4060)\n",
      "15071 Traning Loss: tensor(1.4055)\n",
      "15072 Traning Loss: tensor(1.4050)\n",
      "15073 Traning Loss: tensor(1.4044)\n",
      "15074 Traning Loss: tensor(1.4039)\n",
      "15075 Traning Loss: tensor(1.4034)\n",
      "15076 Traning Loss: tensor(1.4029)\n",
      "15077 Traning Loss: tensor(1.4023)\n",
      "15078 Traning Loss: tensor(1.4018)\n",
      "15079 Traning Loss: tensor(1.4013)\n",
      "15080 Traning Loss: tensor(1.4008)\n",
      "15081 Traning Loss: tensor(1.4003)\n",
      "15082 Traning Loss: tensor(1.3997)\n",
      "15083 Traning Loss: tensor(1.3992)\n",
      "15084 Traning Loss: tensor(1.3987)\n",
      "15085 Traning Loss: tensor(1.3982)\n",
      "15086 Traning Loss: tensor(1.3977)\n",
      "15087 Traning Loss: tensor(1.3972)\n",
      "15088 Traning Loss: tensor(1.3966)\n",
      "15089 Traning Loss: tensor(1.3961)\n",
      "15090 Traning Loss: tensor(1.3956)\n",
      "15091 Traning Loss: tensor(1.3951)\n",
      "15092 Traning Loss: tensor(1.3946)\n",
      "15093 Traning Loss: tensor(1.3941)\n",
      "15094 Traning Loss: tensor(1.3936)\n",
      "15095 Traning Loss: tensor(1.3931)\n",
      "15096 Traning Loss: tensor(1.3926)\n",
      "15097 Traning Loss: tensor(1.3921)\n",
      "15098 Traning Loss: tensor(1.3916)\n",
      "15099 Traning Loss: tensor(1.3910)\n",
      "15100 Traning Loss: tensor(1.3905)\n",
      "15101 Traning Loss: tensor(1.3900)\n",
      "15102 Traning Loss: tensor(1.3895)\n",
      "15103 Traning Loss: tensor(1.3890)\n",
      "15104 Traning Loss: tensor(1.3885)\n",
      "15105 Traning Loss: tensor(1.3880)\n",
      "15106 Traning Loss: tensor(1.3875)\n",
      "15107 Traning Loss: tensor(1.3870)\n",
      "15108 Traning Loss: tensor(1.3865)\n",
      "15109 Traning Loss: tensor(1.3860)\n",
      "15110 Traning Loss: tensor(1.3855)\n",
      "15111 Traning Loss: tensor(1.3850)\n",
      "15112 Traning Loss: tensor(1.3845)\n",
      "15113 Traning Loss: tensor(1.3840)\n",
      "15114 Traning Loss: tensor(1.3835)\n",
      "15115 Traning Loss: tensor(1.3831)\n",
      "15116 Traning Loss: tensor(1.3826)\n",
      "15117 Traning Loss: tensor(1.3821)\n",
      "15118 Traning Loss: tensor(1.3816)\n",
      "15119 Traning Loss: tensor(1.3811)\n",
      "15120 Traning Loss: tensor(1.3806)\n",
      "15121 Traning Loss: tensor(1.3801)\n",
      "15122 Traning Loss: tensor(1.3796)\n",
      "15123 Traning Loss: tensor(1.3791)\n",
      "15124 Traning Loss: tensor(1.3786)\n",
      "15125 Traning Loss: tensor(1.3782)\n",
      "15126 Traning Loss: tensor(1.3777)\n",
      "15127 Traning Loss: tensor(1.3772)\n",
      "15128 Traning Loss: tensor(1.3767)\n",
      "15129 Traning Loss: tensor(1.3762)\n",
      "15130 Traning Loss: tensor(1.3757)\n",
      "15131 Traning Loss: tensor(1.3753)\n",
      "15132 Traning Loss: tensor(1.3748)\n",
      "15133 Traning Loss: tensor(1.3743)\n",
      "15134 Traning Loss: tensor(1.3738)\n",
      "15135 Traning Loss: tensor(1.3733)\n",
      "15136 Traning Loss: tensor(1.3729)\n",
      "15137 Traning Loss: tensor(1.3724)\n",
      "15138 Traning Loss: tensor(1.3719)\n",
      "15139 Traning Loss: tensor(1.3714)\n",
      "15140 Traning Loss: tensor(1.3709)\n",
      "15141 Traning Loss: tensor(1.3705)\n",
      "15142 Traning Loss: tensor(1.3700)\n",
      "15143 Traning Loss: tensor(1.3695)\n",
      "15144 Traning Loss: tensor(1.3690)\n",
      "15145 Traning Loss: tensor(1.3686)\n",
      "15146 Traning Loss: tensor(1.3681)\n",
      "15147 Traning Loss: tensor(1.3676)\n",
      "15148 Traning Loss: tensor(1.3672)\n",
      "15149 Traning Loss: tensor(1.3667)\n",
      "15150 Traning Loss: tensor(1.3662)\n",
      "15151 Traning Loss: tensor(1.3658)\n",
      "15152 Traning Loss: tensor(1.3653)\n",
      "15153 Traning Loss: tensor(1.3648)\n",
      "15154 Traning Loss: tensor(1.3644)\n",
      "15155 Traning Loss: tensor(1.3639)\n",
      "15156 Traning Loss: tensor(1.3634)\n",
      "15157 Traning Loss: tensor(1.3630)\n",
      "15158 Traning Loss: tensor(1.3625)\n",
      "15159 Traning Loss: tensor(1.3620)\n",
      "15160 Traning Loss: tensor(1.3616)\n",
      "15161 Traning Loss: tensor(1.3611)\n",
      "15162 Traning Loss: tensor(1.3607)\n",
      "15163 Traning Loss: tensor(1.3602)\n",
      "15164 Traning Loss: tensor(1.3597)\n",
      "15165 Traning Loss: tensor(1.3593)\n",
      "15166 Traning Loss: tensor(1.3588)\n",
      "15167 Traning Loss: tensor(1.3584)\n",
      "15168 Traning Loss: tensor(1.3579)\n",
      "15169 Traning Loss: tensor(1.3575)\n",
      "15170 Traning Loss: tensor(1.3570)\n",
      "15171 Traning Loss: tensor(1.3565)\n",
      "15172 Traning Loss: tensor(1.3561)\n",
      "15173 Traning Loss: tensor(1.3556)\n",
      "15174 Traning Loss: tensor(1.3552)\n",
      "15175 Traning Loss: tensor(1.3547)\n",
      "15176 Traning Loss: tensor(1.3543)\n",
      "15177 Traning Loss: tensor(1.3538)\n",
      "15178 Traning Loss: tensor(1.3534)\n",
      "15179 Traning Loss: tensor(1.3529)\n",
      "15180 Traning Loss: tensor(1.3525)\n",
      "15181 Traning Loss: tensor(1.3520)\n",
      "15182 Traning Loss: tensor(1.3516)\n",
      "15183 Traning Loss: tensor(1.3511)\n",
      "15184 Traning Loss: tensor(1.3507)\n",
      "15185 Traning Loss: tensor(1.3503)\n",
      "15186 Traning Loss: tensor(1.3498)\n",
      "15187 Traning Loss: tensor(1.3494)\n",
      "15188 Traning Loss: tensor(1.3489)\n",
      "15189 Traning Loss: tensor(1.3485)\n",
      "15190 Traning Loss: tensor(1.3480)\n",
      "15191 Traning Loss: tensor(1.3476)\n",
      "15192 Traning Loss: tensor(1.3472)\n",
      "15193 Traning Loss: tensor(1.3467)\n",
      "15194 Traning Loss: tensor(1.3463)\n",
      "15195 Traning Loss: tensor(1.3458)\n",
      "15196 Traning Loss: tensor(1.3454)\n",
      "15197 Traning Loss: tensor(1.3450)\n",
      "15198 Traning Loss: tensor(1.3445)\n",
      "15199 Traning Loss: tensor(1.3441)\n",
      "15200 Traning Loss: tensor(1.3437)\n",
      "15201 Traning Loss: tensor(1.3432)\n",
      "15202 Traning Loss: tensor(1.3428)\n",
      "15203 Traning Loss: tensor(1.3424)\n",
      "15204 Traning Loss: tensor(1.3419)\n",
      "15205 Traning Loss: tensor(1.3415)\n",
      "15206 Traning Loss: tensor(1.3411)\n",
      "15207 Traning Loss: tensor(1.3406)\n",
      "15208 Traning Loss: tensor(1.3402)\n",
      "15209 Traning Loss: tensor(1.3398)\n",
      "15210 Traning Loss: tensor(1.3394)\n",
      "15211 Traning Loss: tensor(1.3389)\n",
      "15212 Traning Loss: tensor(1.3385)\n",
      "15213 Traning Loss: tensor(1.3381)\n",
      "15214 Traning Loss: tensor(1.3377)\n",
      "15215 Traning Loss: tensor(1.3372)\n",
      "15216 Traning Loss: tensor(1.3368)\n",
      "15217 Traning Loss: tensor(1.3364)\n",
      "15218 Traning Loss: tensor(1.3360)\n",
      "15219 Traning Loss: tensor(1.3355)\n",
      "15220 Traning Loss: tensor(1.3351)\n",
      "15221 Traning Loss: tensor(1.3347)\n",
      "15222 Traning Loss: tensor(1.3343)\n",
      "15223 Traning Loss: tensor(1.3338)\n",
      "15224 Traning Loss: tensor(1.3334)\n",
      "15225 Traning Loss: tensor(1.3330)\n",
      "15226 Traning Loss: tensor(1.3326)\n",
      "15227 Traning Loss: tensor(1.3322)\n",
      "15228 Traning Loss: tensor(1.3318)\n",
      "15229 Traning Loss: tensor(1.3313)\n",
      "15230 Traning Loss: tensor(1.3309)\n",
      "15231 Traning Loss: tensor(1.3305)\n",
      "15232 Traning Loss: tensor(1.3301)\n",
      "15233 Traning Loss: tensor(1.3297)\n",
      "15234 Traning Loss: tensor(1.3293)\n",
      "15235 Traning Loss: tensor(1.3289)\n",
      "15236 Traning Loss: tensor(1.3285)\n",
      "15237 Traning Loss: tensor(1.3280)\n",
      "15238 Traning Loss: tensor(1.3276)\n",
      "15239 Traning Loss: tensor(1.3272)\n",
      "15240 Traning Loss: tensor(1.3268)\n",
      "15241 Traning Loss: tensor(1.3264)\n",
      "15242 Traning Loss: tensor(1.3260)\n",
      "15243 Traning Loss: tensor(1.3256)\n",
      "15244 Traning Loss: tensor(1.3252)\n",
      "15245 Traning Loss: tensor(1.3248)\n",
      "15246 Traning Loss: tensor(1.3244)\n",
      "15247 Traning Loss: tensor(1.3240)\n",
      "15248 Traning Loss: tensor(1.3236)\n",
      "15249 Traning Loss: tensor(1.3232)\n",
      "15250 Traning Loss: tensor(1.3523)\n",
      "15251 Traning Loss: tensor(1.3519)\n",
      "15252 Traning Loss: tensor(1.3515)\n",
      "15253 Traning Loss: tensor(1.3511)\n",
      "15254 Traning Loss: tensor(1.3507)\n",
      "15255 Traning Loss: tensor(1.3425)\n",
      "15256 Traning Loss: tensor(1.3421)\n",
      "15257 Traning Loss: tensor(1.3417)\n",
      "15258 Traning Loss: tensor(1.3413)\n",
      "15259 Traning Loss: tensor(1.3409)\n",
      "15260 Traning Loss: tensor(1.3405)\n",
      "15261 Traning Loss: tensor(1.3401)\n",
      "15262 Traning Loss: tensor(1.3397)\n",
      "15263 Traning Loss: tensor(1.3393)\n",
      "15264 Traning Loss: tensor(1.3389)\n",
      "15265 Traning Loss: tensor(1.3385)\n",
      "15266 Traning Loss: tensor(1.3381)\n",
      "15267 Traning Loss: tensor(1.3378)\n",
      "15268 Traning Loss: tensor(1.3374)\n",
      "15269 Traning Loss: tensor(1.3370)\n",
      "15270 Traning Loss: tensor(1.3366)\n",
      "15271 Traning Loss: tensor(1.3362)\n",
      "15272 Traning Loss: tensor(1.3358)\n",
      "15273 Traning Loss: tensor(1.3354)\n",
      "15274 Traning Loss: tensor(1.3350)\n",
      "15275 Traning Loss: tensor(1.3347)\n",
      "15276 Traning Loss: tensor(1.3343)\n",
      "15277 Traning Loss: tensor(1.3339)\n",
      "15278 Traning Loss: tensor(1.3335)\n",
      "15279 Traning Loss: tensor(1.3331)\n",
      "15280 Traning Loss: tensor(1.3327)\n",
      "15281 Traning Loss: tensor(1.3323)\n",
      "15282 Traning Loss: tensor(1.3320)\n",
      "15283 Traning Loss: tensor(1.3316)\n",
      "15284 Traning Loss: tensor(1.3312)\n",
      "15285 Traning Loss: tensor(1.3308)\n",
      "15286 Traning Loss: tensor(1.3304)\n",
      "15287 Traning Loss: tensor(1.3301)\n",
      "15288 Traning Loss: tensor(1.3297)\n",
      "15289 Traning Loss: tensor(1.3293)\n",
      "15290 Traning Loss: tensor(1.3289)\n",
      "15291 Traning Loss: tensor(1.3286)\n",
      "15292 Traning Loss: tensor(1.3282)\n",
      "15293 Traning Loss: tensor(1.3278)\n",
      "15294 Traning Loss: tensor(1.3274)\n",
      "15295 Traning Loss: tensor(1.3271)\n",
      "15296 Traning Loss: tensor(1.3267)\n",
      "15297 Traning Loss: tensor(1.3263)\n",
      "15298 Traning Loss: tensor(1.3259)\n",
      "15299 Traning Loss: tensor(1.3256)\n",
      "15300 Traning Loss: tensor(1.3252)\n",
      "15301 Traning Loss: tensor(1.3248)\n",
      "15302 Traning Loss: tensor(1.3245)\n",
      "15303 Traning Loss: tensor(1.3241)\n",
      "15304 Traning Loss: tensor(1.3237)\n",
      "15305 Traning Loss: tensor(1.3233)\n",
      "15306 Traning Loss: tensor(1.3230)\n",
      "15307 Traning Loss: tensor(1.3226)\n",
      "15308 Traning Loss: tensor(1.3222)\n",
      "15309 Traning Loss: tensor(1.3219)\n",
      "15310 Traning Loss: tensor(1.3215)\n",
      "15311 Traning Loss: tensor(1.3211)\n",
      "15312 Traning Loss: tensor(1.3208)\n",
      "15313 Traning Loss: tensor(1.3204)\n",
      "15314 Traning Loss: tensor(1.3200)\n",
      "15315 Traning Loss: tensor(1.3197)\n",
      "15316 Traning Loss: tensor(1.3193)\n",
      "15317 Traning Loss: tensor(1.3190)\n",
      "15318 Traning Loss: tensor(1.3186)\n",
      "15319 Traning Loss: tensor(1.3182)\n",
      "15320 Traning Loss: tensor(1.3179)\n",
      "15321 Traning Loss: tensor(1.3175)\n",
      "15322 Traning Loss: tensor(1.3171)\n",
      "15323 Traning Loss: tensor(1.3168)\n",
      "15324 Traning Loss: tensor(1.3164)\n",
      "15325 Traning Loss: tensor(1.3161)\n",
      "15326 Traning Loss: tensor(1.3157)\n",
      "15327 Traning Loss: tensor(1.3153)\n",
      "15328 Traning Loss: tensor(1.3150)\n",
      "15329 Traning Loss: tensor(1.3146)\n",
      "15330 Traning Loss: tensor(1.3143)\n",
      "15331 Traning Loss: tensor(1.3139)\n",
      "15332 Traning Loss: tensor(1.3136)\n",
      "15333 Traning Loss: tensor(1.3132)\n",
      "15334 Traning Loss: tensor(1.3129)\n",
      "15335 Traning Loss: tensor(1.3125)\n",
      "15336 Traning Loss: tensor(1.3121)\n",
      "15337 Traning Loss: tensor(1.3118)\n",
      "15338 Traning Loss: tensor(1.3114)\n",
      "15339 Traning Loss: tensor(1.3111)\n",
      "15340 Traning Loss: tensor(1.3107)\n",
      "15341 Traning Loss: tensor(1.3104)\n",
      "15342 Traning Loss: tensor(1.3100)\n",
      "15343 Traning Loss: tensor(1.3097)\n",
      "15344 Traning Loss: tensor(1.3093)\n",
      "15345 Traning Loss: tensor(1.3090)\n",
      "15346 Traning Loss: tensor(1.3086)\n",
      "15347 Traning Loss: tensor(1.3083)\n",
      "15348 Traning Loss: tensor(1.3079)\n",
      "15349 Traning Loss: tensor(1.3076)\n",
      "15350 Traning Loss: tensor(1.3072)\n",
      "15351 Traning Loss: tensor(1.3069)\n",
      "15352 Traning Loss: tensor(1.3065)\n",
      "15353 Traning Loss: tensor(1.3062)\n",
      "15354 Traning Loss: tensor(1.3058)\n",
      "15355 Traning Loss: tensor(1.3055)\n",
      "15356 Traning Loss: tensor(1.3052)\n",
      "15357 Traning Loss: tensor(1.3048)\n",
      "15358 Traning Loss: tensor(1.3045)\n",
      "15359 Traning Loss: tensor(1.3041)\n",
      "15360 Traning Loss: tensor(1.3038)\n",
      "15361 Traning Loss: tensor(1.3034)\n",
      "15362 Traning Loss: tensor(1.3031)\n",
      "15363 Traning Loss: tensor(1.3028)\n",
      "15364 Traning Loss: tensor(1.3024)\n",
      "15365 Traning Loss: tensor(1.3021)\n",
      "15366 Traning Loss: tensor(1.3017)\n",
      "15367 Traning Loss: tensor(1.3014)\n",
      "15368 Traning Loss: tensor(1.3011)\n",
      "15369 Traning Loss: tensor(1.3007)\n",
      "15370 Traning Loss: tensor(1.3004)\n",
      "15371 Traning Loss: tensor(1.3000)\n",
      "15372 Traning Loss: tensor(1.2997)\n",
      "15373 Traning Loss: tensor(1.2994)\n",
      "15374 Traning Loss: tensor(1.2990)\n",
      "15375 Traning Loss: tensor(1.2987)\n",
      "15376 Traning Loss: tensor(1.2984)\n",
      "15377 Traning Loss: tensor(1.2980)\n",
      "15378 Traning Loss: tensor(1.2977)\n",
      "15379 Traning Loss: tensor(1.2973)\n",
      "15380 Traning Loss: tensor(1.2970)\n",
      "15381 Traning Loss: tensor(1.2967)\n",
      "15382 Traning Loss: tensor(1.2963)\n",
      "15383 Traning Loss: tensor(1.2960)\n",
      "15384 Traning Loss: tensor(1.2957)\n",
      "15385 Traning Loss: tensor(1.2953)\n",
      "15386 Traning Loss: tensor(1.2950)\n",
      "15387 Traning Loss: tensor(1.2947)\n",
      "15388 Traning Loss: tensor(1.2944)\n",
      "15389 Traning Loss: tensor(1.2940)\n",
      "15390 Traning Loss: tensor(1.2937)\n",
      "15391 Traning Loss: tensor(1.2934)\n",
      "15392 Traning Loss: tensor(1.2930)\n",
      "15393 Traning Loss: tensor(1.2927)\n",
      "15394 Traning Loss: tensor(1.2924)\n",
      "15395 Traning Loss: tensor(1.2920)\n",
      "15396 Traning Loss: tensor(1.2917)\n",
      "15397 Traning Loss: tensor(1.2914)\n",
      "15398 Traning Loss: tensor(1.2911)\n",
      "15399 Traning Loss: tensor(1.2907)\n",
      "15400 Traning Loss: tensor(1.2904)\n",
      "15401 Traning Loss: tensor(1.2901)\n",
      "15402 Traning Loss: tensor(1.2898)\n",
      "15403 Traning Loss: tensor(1.2894)\n",
      "15404 Traning Loss: tensor(1.2891)\n",
      "15405 Traning Loss: tensor(1.2888)\n",
      "15406 Traning Loss: tensor(1.2885)\n",
      "15407 Traning Loss: tensor(1.2881)\n",
      "15408 Traning Loss: tensor(1.2878)\n",
      "15409 Traning Loss: tensor(1.2875)\n",
      "15410 Traning Loss: tensor(1.2872)\n",
      "15411 Traning Loss: tensor(1.2869)\n",
      "15412 Traning Loss: tensor(1.2865)\n",
      "15413 Traning Loss: tensor(1.2862)\n",
      "15414 Traning Loss: tensor(1.2859)\n",
      "15415 Traning Loss: tensor(1.2856)\n",
      "15416 Traning Loss: tensor(1.2853)\n",
      "15417 Traning Loss: tensor(1.2849)\n",
      "15418 Traning Loss: tensor(1.2846)\n",
      "15419 Traning Loss: tensor(1.2843)\n",
      "15420 Traning Loss: tensor(1.2840)\n",
      "15421 Traning Loss: tensor(1.2837)\n",
      "15422 Traning Loss: tensor(1.2834)\n",
      "15423 Traning Loss: tensor(1.2830)\n",
      "15424 Traning Loss: tensor(1.2827)\n",
      "15425 Traning Loss: tensor(1.2824)\n",
      "15426 Traning Loss: tensor(1.2821)\n",
      "15427 Traning Loss: tensor(1.2818)\n",
      "15428 Traning Loss: tensor(1.2815)\n",
      "15429 Traning Loss: tensor(1.2811)\n",
      "15430 Traning Loss: tensor(1.2808)\n",
      "15431 Traning Loss: tensor(1.2805)\n",
      "15432 Traning Loss: tensor(1.2802)\n",
      "15433 Traning Loss: tensor(1.2799)\n",
      "15434 Traning Loss: tensor(1.2796)\n",
      "15435 Traning Loss: tensor(1.2793)\n",
      "15436 Traning Loss: tensor(1.2790)\n",
      "15437 Traning Loss: tensor(1.2787)\n",
      "15438 Traning Loss: tensor(1.2783)\n",
      "15439 Traning Loss: tensor(1.2780)\n",
      "15440 Traning Loss: tensor(1.2777)\n",
      "15441 Traning Loss: tensor(1.2774)\n",
      "15442 Traning Loss: tensor(1.2771)\n",
      "15443 Traning Loss: tensor(1.2768)\n",
      "15444 Traning Loss: tensor(1.2765)\n",
      "15445 Traning Loss: tensor(1.2762)\n",
      "15446 Traning Loss: tensor(1.2759)\n",
      "15447 Traning Loss: tensor(1.2756)\n",
      "15448 Traning Loss: tensor(1.2753)\n",
      "15449 Traning Loss: tensor(1.2750)\n",
      "15450 Traning Loss: tensor(1.2746)\n",
      "15451 Traning Loss: tensor(1.2743)\n",
      "15452 Traning Loss: tensor(1.2740)\n",
      "15453 Traning Loss: tensor(1.2737)\n",
      "15454 Traning Loss: tensor(1.2734)\n",
      "15455 Traning Loss: tensor(1.2731)\n",
      "15456 Traning Loss: tensor(1.2728)\n",
      "15457 Traning Loss: tensor(1.2725)\n",
      "15458 Traning Loss: tensor(1.2722)\n",
      "15459 Traning Loss: tensor(1.2719)\n",
      "15460 Traning Loss: tensor(1.2716)\n",
      "15461 Traning Loss: tensor(1.2713)\n",
      "15462 Traning Loss: tensor(1.2710)\n",
      "15463 Traning Loss: tensor(1.2707)\n",
      "15464 Traning Loss: tensor(1.2704)\n",
      "15465 Traning Loss: tensor(1.2701)\n",
      "15466 Traning Loss: tensor(1.2698)\n",
      "15467 Traning Loss: tensor(1.2695)\n",
      "15468 Traning Loss: tensor(1.2692)\n",
      "15469 Traning Loss: tensor(1.2689)\n",
      "15470 Traning Loss: tensor(1.2686)\n",
      "15471 Traning Loss: tensor(1.2683)\n",
      "15472 Traning Loss: tensor(1.2680)\n",
      "15473 Traning Loss: tensor(1.2677)\n",
      "15474 Traning Loss: tensor(1.2674)\n",
      "15475 Traning Loss: tensor(1.2671)\n",
      "15476 Traning Loss: tensor(1.2668)\n",
      "15477 Traning Loss: tensor(1.2665)\n",
      "15478 Traning Loss: tensor(1.2662)\n",
      "15479 Traning Loss: tensor(1.2659)\n",
      "15480 Traning Loss: tensor(1.2656)\n",
      "15481 Traning Loss: tensor(1.2654)\n",
      "15482 Traning Loss: tensor(1.2651)\n",
      "15483 Traning Loss: tensor(1.2648)\n",
      "15484 Traning Loss: tensor(1.2645)\n",
      "15485 Traning Loss: tensor(1.2642)\n",
      "15486 Traning Loss: tensor(1.2639)\n",
      "15487 Traning Loss: tensor(1.2636)\n",
      "15488 Traning Loss: tensor(1.2633)\n",
      "15489 Traning Loss: tensor(1.2630)\n",
      "15490 Traning Loss: tensor(1.2627)\n",
      "15491 Traning Loss: tensor(1.2624)\n",
      "15492 Traning Loss: tensor(1.2621)\n",
      "15493 Traning Loss: tensor(1.2619)\n",
      "15494 Traning Loss: tensor(1.2616)\n",
      "15495 Traning Loss: tensor(1.2613)\n",
      "15496 Traning Loss: tensor(1.2610)\n",
      "15497 Traning Loss: tensor(1.2607)\n",
      "15498 Traning Loss: tensor(1.2604)\n",
      "15499 Traning Loss: tensor(1.2601)\n",
      "15500 Traning Loss: tensor(1.2598)\n",
      "15501 Traning Loss: tensor(1.2595)\n",
      "15502 Traning Loss: tensor(1.2593)\n",
      "15503 Traning Loss: tensor(1.2590)\n",
      "15504 Traning Loss: tensor(1.2587)\n",
      "15505 Traning Loss: tensor(1.2584)\n",
      "15506 Traning Loss: tensor(1.2581)\n",
      "15507 Traning Loss: tensor(1.2578)\n",
      "15508 Traning Loss: tensor(1.2575)\n",
      "15509 Traning Loss: tensor(1.2573)\n",
      "15510 Traning Loss: tensor(1.2570)\n",
      "15511 Traning Loss: tensor(1.2567)\n",
      "15512 Traning Loss: tensor(1.2564)\n",
      "15513 Traning Loss: tensor(1.2561)\n",
      "15514 Traning Loss: tensor(1.2558)\n",
      "15515 Traning Loss: tensor(1.2556)\n",
      "15516 Traning Loss: tensor(1.2553)\n",
      "15517 Traning Loss: tensor(1.2550)\n",
      "15518 Traning Loss: tensor(1.2547)\n",
      "15519 Traning Loss: tensor(1.2544)\n",
      "15520 Traning Loss: tensor(1.2542)\n",
      "15521 Traning Loss: tensor(1.2539)\n",
      "15522 Traning Loss: tensor(1.2536)\n",
      "15523 Traning Loss: tensor(1.2533)\n",
      "15524 Traning Loss: tensor(1.2530)\n",
      "15525 Traning Loss: tensor(1.2528)\n",
      "15526 Traning Loss: tensor(1.2525)\n",
      "15527 Traning Loss: tensor(1.2522)\n",
      "15528 Traning Loss: tensor(1.2519)\n",
      "15529 Traning Loss: tensor(1.2516)\n",
      "15530 Traning Loss: tensor(1.2514)\n",
      "15531 Traning Loss: tensor(1.2511)\n",
      "15532 Traning Loss: tensor(1.2508)\n",
      "15533 Traning Loss: tensor(1.2505)\n",
      "15534 Traning Loss: tensor(1.2503)\n",
      "15535 Traning Loss: tensor(1.2500)\n",
      "15536 Traning Loss: tensor(1.2497)\n",
      "15537 Traning Loss: tensor(1.2494)\n",
      "15538 Traning Loss: tensor(1.2492)\n",
      "15539 Traning Loss: tensor(1.2489)\n",
      "15540 Traning Loss: tensor(1.2486)\n",
      "15541 Traning Loss: tensor(1.2483)\n",
      "15542 Traning Loss: tensor(1.2481)\n",
      "15543 Traning Loss: tensor(1.2478)\n",
      "15544 Traning Loss: tensor(1.2475)\n",
      "15545 Traning Loss: tensor(1.2473)\n",
      "15546 Traning Loss: tensor(1.2470)\n",
      "15547 Traning Loss: tensor(1.2467)\n",
      "15548 Traning Loss: tensor(1.2464)\n",
      "15549 Traning Loss: tensor(1.2462)\n",
      "15550 Traning Loss: tensor(1.2459)\n",
      "15551 Traning Loss: tensor(1.2456)\n",
      "15552 Traning Loss: tensor(1.2454)\n",
      "15553 Traning Loss: tensor(1.2451)\n",
      "15554 Traning Loss: tensor(1.2448)\n",
      "15555 Traning Loss: tensor(1.2445)\n",
      "15556 Traning Loss: tensor(1.2443)\n",
      "15557 Traning Loss: tensor(1.2440)\n",
      "15558 Traning Loss: tensor(1.2437)\n",
      "15559 Traning Loss: tensor(1.2435)\n",
      "15560 Traning Loss: tensor(1.2432)\n",
      "15561 Traning Loss: tensor(1.2429)\n",
      "15562 Traning Loss: tensor(1.2427)\n",
      "15563 Traning Loss: tensor(1.2424)\n",
      "15564 Traning Loss: tensor(1.2421)\n",
      "15565 Traning Loss: tensor(1.2419)\n",
      "15566 Traning Loss: tensor(1.2416)\n",
      "15567 Traning Loss: tensor(1.2413)\n",
      "15568 Traning Loss: tensor(1.2411)\n",
      "15569 Traning Loss: tensor(1.2408)\n",
      "15570 Traning Loss: tensor(1.2406)\n",
      "15571 Traning Loss: tensor(1.2403)\n",
      "15572 Traning Loss: tensor(1.2400)\n",
      "15573 Traning Loss: tensor(1.2398)\n",
      "15574 Traning Loss: tensor(1.2395)\n",
      "15575 Traning Loss: tensor(1.2392)\n",
      "15576 Traning Loss: tensor(1.2390)\n",
      "15577 Traning Loss: tensor(1.2387)\n",
      "15578 Traning Loss: tensor(1.2385)\n",
      "15579 Traning Loss: tensor(1.2382)\n",
      "15580 Traning Loss: tensor(1.2379)\n",
      "15581 Traning Loss: tensor(1.2377)\n",
      "15582 Traning Loss: tensor(1.2374)\n",
      "15583 Traning Loss: tensor(1.2371)\n",
      "15584 Traning Loss: tensor(1.2369)\n",
      "15585 Traning Loss: tensor(1.2366)\n",
      "15586 Traning Loss: tensor(1.2364)\n",
      "15587 Traning Loss: tensor(1.2361)\n",
      "15588 Traning Loss: tensor(1.2358)\n",
      "15589 Traning Loss: tensor(1.2356)\n",
      "15590 Traning Loss: tensor(1.2353)\n",
      "15591 Traning Loss: tensor(1.2351)\n",
      "15592 Traning Loss: tensor(1.2348)\n",
      "15593 Traning Loss: tensor(1.2346)\n",
      "15594 Traning Loss: tensor(1.2343)\n",
      "15595 Traning Loss: tensor(1.2340)\n",
      "15596 Traning Loss: tensor(1.2338)\n",
      "15597 Traning Loss: tensor(1.2335)\n",
      "15598 Traning Loss: tensor(1.2333)\n",
      "15599 Traning Loss: tensor(1.2330)\n",
      "15600 Traning Loss: tensor(1.2328)\n",
      "15601 Traning Loss: tensor(1.2325)\n",
      "15602 Traning Loss: tensor(1.2323)\n",
      "15603 Traning Loss: tensor(1.2320)\n",
      "15604 Traning Loss: tensor(1.2317)\n",
      "15605 Traning Loss: tensor(1.2315)\n",
      "15606 Traning Loss: tensor(1.2312)\n",
      "15607 Traning Loss: tensor(1.2310)\n",
      "15608 Traning Loss: tensor(1.2307)\n",
      "15609 Traning Loss: tensor(1.2305)\n",
      "15610 Traning Loss: tensor(1.2302)\n",
      "15611 Traning Loss: tensor(1.2300)\n",
      "15612 Traning Loss: tensor(1.2297)\n",
      "15613 Traning Loss: tensor(1.2295)\n",
      "15614 Traning Loss: tensor(1.2292)\n",
      "15615 Traning Loss: tensor(1.2290)\n",
      "15616 Traning Loss: tensor(1.2287)\n",
      "15617 Traning Loss: tensor(1.2285)\n",
      "15618 Traning Loss: tensor(1.2282)\n",
      "15619 Traning Loss: tensor(1.2280)\n",
      "15620 Traning Loss: tensor(1.2277)\n",
      "15621 Traning Loss: tensor(1.2275)\n",
      "15622 Traning Loss: tensor(1.2272)\n",
      "15623 Traning Loss: tensor(1.2270)\n",
      "15624 Traning Loss: tensor(1.2267)\n",
      "15625 Traning Loss: tensor(1.2171)\n",
      "15626 Traning Loss: tensor(1.2168)\n",
      "15627 Traning Loss: tensor(1.2166)\n",
      "15628 Traning Loss: tensor(1.2164)\n",
      "15629 Traning Loss: tensor(1.2162)\n",
      "15630 Traning Loss: tensor(1.2159)\n",
      "15631 Traning Loss: tensor(1.2157)\n",
      "15632 Traning Loss: tensor(1.2155)\n",
      "15633 Traning Loss: tensor(1.2153)\n",
      "15634 Traning Loss: tensor(1.2150)\n",
      "15635 Traning Loss: tensor(1.2148)\n",
      "15636 Traning Loss: tensor(1.2146)\n",
      "15637 Traning Loss: tensor(1.2144)\n",
      "15638 Traning Loss: tensor(1.2142)\n",
      "15639 Traning Loss: tensor(1.2140)\n",
      "15640 Traning Loss: tensor(1.2137)\n",
      "15641 Traning Loss: tensor(1.2135)\n",
      "15642 Traning Loss: tensor(1.2133)\n",
      "15643 Traning Loss: tensor(1.2131)\n",
      "15644 Traning Loss: tensor(1.2129)\n",
      "15645 Traning Loss: tensor(1.2127)\n",
      "15646 Traning Loss: tensor(1.2124)\n",
      "15647 Traning Loss: tensor(1.2122)\n",
      "15648 Traning Loss: tensor(1.2120)\n",
      "15649 Traning Loss: tensor(1.2118)\n",
      "15650 Traning Loss: tensor(1.2116)\n",
      "15651 Traning Loss: tensor(1.2114)\n",
      "15652 Traning Loss: tensor(1.2112)\n",
      "15653 Traning Loss: tensor(1.2110)\n",
      "15654 Traning Loss: tensor(1.2108)\n",
      "15655 Traning Loss: tensor(1.2105)\n",
      "15656 Traning Loss: tensor(1.2103)\n",
      "15657 Traning Loss: tensor(1.2101)\n",
      "15658 Traning Loss: tensor(1.2099)\n",
      "15659 Traning Loss: tensor(1.2097)\n",
      "15660 Traning Loss: tensor(1.2095)\n",
      "15661 Traning Loss: tensor(1.2093)\n",
      "15662 Traning Loss: tensor(1.2091)\n",
      "15663 Traning Loss: tensor(1.2089)\n",
      "15664 Traning Loss: tensor(1.2087)\n",
      "15665 Traning Loss: tensor(1.2085)\n",
      "15666 Traning Loss: tensor(1.2082)\n",
      "15667 Traning Loss: tensor(1.2080)\n",
      "15668 Traning Loss: tensor(1.2078)\n",
      "15669 Traning Loss: tensor(1.2076)\n",
      "15670 Traning Loss: tensor(1.2074)\n",
      "15671 Traning Loss: tensor(1.2072)\n",
      "15672 Traning Loss: tensor(1.2070)\n",
      "15673 Traning Loss: tensor(1.2068)\n",
      "15674 Traning Loss: tensor(1.2066)\n",
      "15675 Traning Loss: tensor(1.2064)\n",
      "15676 Traning Loss: tensor(1.2062)\n",
      "15677 Traning Loss: tensor(1.2060)\n",
      "15678 Traning Loss: tensor(1.2058)\n",
      "15679 Traning Loss: tensor(1.2056)\n",
      "15680 Traning Loss: tensor(1.2054)\n",
      "15681 Traning Loss: tensor(1.2052)\n",
      "15682 Traning Loss: tensor(1.2050)\n",
      "15683 Traning Loss: tensor(1.2048)\n",
      "15684 Traning Loss: tensor(1.2046)\n",
      "15685 Traning Loss: tensor(1.2044)\n",
      "15686 Traning Loss: tensor(1.2042)\n",
      "15687 Traning Loss: tensor(1.2040)\n",
      "15688 Traning Loss: tensor(1.2038)\n",
      "15689 Traning Loss: tensor(1.2036)\n",
      "15690 Traning Loss: tensor(1.2034)\n",
      "15691 Traning Loss: tensor(1.2031)\n",
      "15692 Traning Loss: tensor(1.2029)\n",
      "15693 Traning Loss: tensor(1.2027)\n",
      "15694 Traning Loss: tensor(1.2025)\n",
      "15695 Traning Loss: tensor(1.2023)\n",
      "15696 Traning Loss: tensor(1.2021)\n",
      "15697 Traning Loss: tensor(1.2019)\n",
      "15698 Traning Loss: tensor(1.2017)\n",
      "15699 Traning Loss: tensor(1.2016)\n",
      "15700 Traning Loss: tensor(1.2014)\n",
      "15701 Traning Loss: tensor(1.2012)\n",
      "15702 Traning Loss: tensor(1.2010)\n",
      "15703 Traning Loss: tensor(1.2008)\n",
      "15704 Traning Loss: tensor(1.2006)\n",
      "15705 Traning Loss: tensor(1.2004)\n",
      "15706 Traning Loss: tensor(1.2002)\n",
      "15707 Traning Loss: tensor(1.2000)\n",
      "15708 Traning Loss: tensor(1.1998)\n",
      "15709 Traning Loss: tensor(1.1996)\n",
      "15710 Traning Loss: tensor(1.1994)\n",
      "15711 Traning Loss: tensor(1.1992)\n",
      "15712 Traning Loss: tensor(1.1990)\n",
      "15713 Traning Loss: tensor(1.1988)\n",
      "15714 Traning Loss: tensor(1.1986)\n",
      "15715 Traning Loss: tensor(1.1984)\n",
      "15716 Traning Loss: tensor(1.1982)\n",
      "15717 Traning Loss: tensor(1.1980)\n",
      "15718 Traning Loss: tensor(1.1978)\n",
      "15719 Traning Loss: tensor(1.1976)\n",
      "15720 Traning Loss: tensor(1.1974)\n",
      "15721 Traning Loss: tensor(1.1972)\n",
      "15722 Traning Loss: tensor(1.1970)\n",
      "15723 Traning Loss: tensor(1.1968)\n",
      "15724 Traning Loss: tensor(1.1967)\n",
      "15725 Traning Loss: tensor(1.1965)\n",
      "15726 Traning Loss: tensor(1.1963)\n",
      "15727 Traning Loss: tensor(1.1961)\n",
      "15728 Traning Loss: tensor(1.1959)\n",
      "15729 Traning Loss: tensor(1.1957)\n",
      "15730 Traning Loss: tensor(1.1955)\n",
      "15731 Traning Loss: tensor(1.1953)\n",
      "15732 Traning Loss: tensor(1.1951)\n",
      "15733 Traning Loss: tensor(1.1949)\n",
      "15734 Traning Loss: tensor(1.1947)\n",
      "15735 Traning Loss: tensor(1.1945)\n",
      "15736 Traning Loss: tensor(1.1944)\n",
      "15737 Traning Loss: tensor(1.1942)\n",
      "15738 Traning Loss: tensor(1.1940)\n",
      "15739 Traning Loss: tensor(1.1938)\n",
      "15740 Traning Loss: tensor(1.1936)\n",
      "15741 Traning Loss: tensor(1.1934)\n",
      "15742 Traning Loss: tensor(1.1932)\n",
      "15743 Traning Loss: tensor(1.1930)\n",
      "15744 Traning Loss: tensor(1.1928)\n",
      "15745 Traning Loss: tensor(1.1926)\n",
      "15746 Traning Loss: tensor(1.1925)\n",
      "15747 Traning Loss: tensor(1.1923)\n",
      "15748 Traning Loss: tensor(1.1921)\n",
      "15749 Traning Loss: tensor(1.1919)\n",
      "15750 Traning Loss: tensor(1.1917)\n",
      "15751 Traning Loss: tensor(1.1915)\n",
      "15752 Traning Loss: tensor(1.1913)\n",
      "15753 Traning Loss: tensor(1.1911)\n",
      "15754 Traning Loss: tensor(1.1910)\n",
      "15755 Traning Loss: tensor(1.1908)\n",
      "15756 Traning Loss: tensor(1.1906)\n",
      "15757 Traning Loss: tensor(1.1904)\n",
      "15758 Traning Loss: tensor(1.1902)\n",
      "15759 Traning Loss: tensor(1.1900)\n",
      "15760 Traning Loss: tensor(1.1898)\n",
      "15761 Traning Loss: tensor(1.1897)\n",
      "15762 Traning Loss: tensor(1.1895)\n",
      "15763 Traning Loss: tensor(1.1893)\n",
      "15764 Traning Loss: tensor(1.1891)\n",
      "15765 Traning Loss: tensor(1.1889)\n",
      "15766 Traning Loss: tensor(1.1887)\n",
      "15767 Traning Loss: tensor(1.1886)\n",
      "15768 Traning Loss: tensor(1.1884)\n",
      "15769 Traning Loss: tensor(1.1882)\n",
      "15770 Traning Loss: tensor(1.1880)\n",
      "15771 Traning Loss: tensor(1.1878)\n",
      "15772 Traning Loss: tensor(1.1876)\n",
      "15773 Traning Loss: tensor(1.1875)\n",
      "15774 Traning Loss: tensor(1.1873)\n",
      "15775 Traning Loss: tensor(1.1871)\n",
      "15776 Traning Loss: tensor(1.1869)\n",
      "15777 Traning Loss: tensor(1.1867)\n",
      "15778 Traning Loss: tensor(1.1865)\n",
      "15779 Traning Loss: tensor(1.1864)\n",
      "15780 Traning Loss: tensor(1.1862)\n",
      "15781 Traning Loss: tensor(1.1860)\n",
      "15782 Traning Loss: tensor(1.1858)\n",
      "15783 Traning Loss: tensor(1.1856)\n",
      "15784 Traning Loss: tensor(1.1855)\n",
      "15785 Traning Loss: tensor(1.1853)\n",
      "15786 Traning Loss: tensor(1.1851)\n",
      "15787 Traning Loss: tensor(1.1849)\n",
      "15788 Traning Loss: tensor(1.1847)\n",
      "15789 Traning Loss: tensor(1.1846)\n",
      "15790 Traning Loss: tensor(1.1844)\n",
      "15791 Traning Loss: tensor(1.1842)\n",
      "15792 Traning Loss: tensor(1.1840)\n",
      "15793 Traning Loss: tensor(1.1838)\n",
      "15794 Traning Loss: tensor(1.1837)\n",
      "15795 Traning Loss: tensor(1.1835)\n",
      "15796 Traning Loss: tensor(1.1833)\n",
      "15797 Traning Loss: tensor(1.1831)\n",
      "15798 Traning Loss: tensor(1.1829)\n",
      "15799 Traning Loss: tensor(1.1828)\n",
      "15800 Traning Loss: tensor(1.1826)\n",
      "15801 Traning Loss: tensor(1.1824)\n",
      "15802 Traning Loss: tensor(1.1822)\n",
      "15803 Traning Loss: tensor(1.1821)\n",
      "15804 Traning Loss: tensor(1.1819)\n",
      "15805 Traning Loss: tensor(1.1817)\n",
      "15806 Traning Loss: tensor(1.1815)\n",
      "15807 Traning Loss: tensor(1.1813)\n",
      "15808 Traning Loss: tensor(1.1812)\n",
      "15809 Traning Loss: tensor(1.1810)\n",
      "15810 Traning Loss: tensor(1.1808)\n",
      "15811 Traning Loss: tensor(1.1806)\n",
      "15812 Traning Loss: tensor(1.1805)\n",
      "15813 Traning Loss: tensor(1.1803)\n",
      "15814 Traning Loss: tensor(1.1801)\n",
      "15815 Traning Loss: tensor(1.1799)\n",
      "15816 Traning Loss: tensor(1.1798)\n",
      "15817 Traning Loss: tensor(1.1796)\n",
      "15818 Traning Loss: tensor(1.1794)\n",
      "15819 Traning Loss: tensor(1.1792)\n",
      "15820 Traning Loss: tensor(1.1791)\n",
      "15821 Traning Loss: tensor(1.1789)\n",
      "15822 Traning Loss: tensor(1.1787)\n",
      "15823 Traning Loss: tensor(1.1786)\n",
      "15824 Traning Loss: tensor(1.1784)\n",
      "15825 Traning Loss: tensor(1.1782)\n",
      "15826 Traning Loss: tensor(1.1780)\n",
      "15827 Traning Loss: tensor(1.1779)\n",
      "15828 Traning Loss: tensor(1.1777)\n",
      "15829 Traning Loss: tensor(1.1775)\n",
      "15830 Traning Loss: tensor(1.1773)\n",
      "15831 Traning Loss: tensor(1.1772)\n",
      "15832 Traning Loss: tensor(1.1770)\n",
      "15833 Traning Loss: tensor(1.1768)\n",
      "15834 Traning Loss: tensor(1.1767)\n",
      "15835 Traning Loss: tensor(1.1765)\n",
      "15836 Traning Loss: tensor(1.1763)\n",
      "15837 Traning Loss: tensor(1.1761)\n",
      "15838 Traning Loss: tensor(1.1760)\n",
      "15839 Traning Loss: tensor(1.1758)\n",
      "15840 Traning Loss: tensor(1.1756)\n",
      "15841 Traning Loss: tensor(1.1755)\n",
      "15842 Traning Loss: tensor(1.1753)\n",
      "15843 Traning Loss: tensor(1.1751)\n",
      "15844 Traning Loss: tensor(1.1749)\n",
      "15845 Traning Loss: tensor(1.1748)\n",
      "15846 Traning Loss: tensor(1.1746)\n",
      "15847 Traning Loss: tensor(1.1744)\n",
      "15848 Traning Loss: tensor(1.1743)\n",
      "15849 Traning Loss: tensor(1.1741)\n",
      "15850 Traning Loss: tensor(1.1739)\n",
      "15851 Traning Loss: tensor(1.1738)\n",
      "15852 Traning Loss: tensor(1.1736)\n",
      "15853 Traning Loss: tensor(1.1734)\n",
      "15854 Traning Loss: tensor(1.1733)\n",
      "15855 Traning Loss: tensor(1.1731)\n",
      "15856 Traning Loss: tensor(1.1729)\n",
      "15857 Traning Loss: tensor(1.1728)\n",
      "15858 Traning Loss: tensor(1.1726)\n",
      "15859 Traning Loss: tensor(1.1724)\n",
      "15860 Traning Loss: tensor(1.1723)\n",
      "15861 Traning Loss: tensor(1.1721)\n",
      "15862 Traning Loss: tensor(1.1719)\n",
      "15863 Traning Loss: tensor(1.1718)\n",
      "15864 Traning Loss: tensor(1.1716)\n",
      "15865 Traning Loss: tensor(1.1714)\n",
      "15866 Traning Loss: tensor(1.1713)\n",
      "15867 Traning Loss: tensor(1.1711)\n",
      "15868 Traning Loss: tensor(1.1709)\n",
      "15869 Traning Loss: tensor(1.1708)\n",
      "15870 Traning Loss: tensor(1.1706)\n",
      "15871 Traning Loss: tensor(1.1704)\n",
      "15872 Traning Loss: tensor(1.1703)\n",
      "15873 Traning Loss: tensor(1.1701)\n",
      "15874 Traning Loss: tensor(1.1699)\n",
      "15875 Traning Loss: tensor(1.1698)\n",
      "15876 Traning Loss: tensor(1.1696)\n",
      "15877 Traning Loss: tensor(1.1694)\n",
      "15878 Traning Loss: tensor(1.1693)\n",
      "15879 Traning Loss: tensor(1.1691)\n",
      "15880 Traning Loss: tensor(1.1689)\n",
      "15881 Traning Loss: tensor(1.1688)\n",
      "15882 Traning Loss: tensor(1.1686)\n",
      "15883 Traning Loss: tensor(1.1685)\n",
      "15884 Traning Loss: tensor(1.1683)\n",
      "15885 Traning Loss: tensor(1.1681)\n",
      "15886 Traning Loss: tensor(1.1680)\n",
      "15887 Traning Loss: tensor(1.1678)\n",
      "15888 Traning Loss: tensor(1.1676)\n",
      "15889 Traning Loss: tensor(1.1675)\n",
      "15890 Traning Loss: tensor(1.1673)\n",
      "15891 Traning Loss: tensor(1.1672)\n",
      "15892 Traning Loss: tensor(1.1670)\n",
      "15893 Traning Loss: tensor(1.1668)\n",
      "15894 Traning Loss: tensor(1.1667)\n",
      "15895 Traning Loss: tensor(1.1665)\n",
      "15896 Traning Loss: tensor(1.1663)\n",
      "15897 Traning Loss: tensor(1.1662)\n",
      "15898 Traning Loss: tensor(1.1660)\n",
      "15899 Traning Loss: tensor(1.1659)\n",
      "15900 Traning Loss: tensor(1.1657)\n",
      "15901 Traning Loss: tensor(1.1655)\n",
      "15902 Traning Loss: tensor(1.1654)\n",
      "15903 Traning Loss: tensor(1.1652)\n",
      "15904 Traning Loss: tensor(1.1651)\n",
      "15905 Traning Loss: tensor(1.1649)\n",
      "15906 Traning Loss: tensor(1.1647)\n",
      "15907 Traning Loss: tensor(1.1646)\n",
      "15908 Traning Loss: tensor(1.1644)\n",
      "15909 Traning Loss: tensor(1.1643)\n",
      "15910 Traning Loss: tensor(1.1641)\n",
      "15911 Traning Loss: tensor(1.1639)\n",
      "15912 Traning Loss: tensor(1.1638)\n",
      "15913 Traning Loss: tensor(1.1636)\n",
      "15914 Traning Loss: tensor(1.1635)\n",
      "15915 Traning Loss: tensor(1.1633)\n",
      "15916 Traning Loss: tensor(1.1631)\n",
      "15917 Traning Loss: tensor(1.1630)\n",
      "15918 Traning Loss: tensor(1.1628)\n",
      "15919 Traning Loss: tensor(1.1627)\n",
      "15920 Traning Loss: tensor(1.1625)\n",
      "15921 Traning Loss: tensor(1.1623)\n",
      "15922 Traning Loss: tensor(1.1622)\n",
      "15923 Traning Loss: tensor(1.1620)\n",
      "15924 Traning Loss: tensor(1.1619)\n",
      "15925 Traning Loss: tensor(1.1617)\n",
      "15926 Traning Loss: tensor(1.1616)\n",
      "15927 Traning Loss: tensor(1.1614)\n",
      "15928 Traning Loss: tensor(1.1612)\n",
      "15929 Traning Loss: tensor(1.1611)\n",
      "15930 Traning Loss: tensor(1.1609)\n",
      "15931 Traning Loss: tensor(1.1608)\n",
      "15932 Traning Loss: tensor(1.1606)\n",
      "15933 Traning Loss: tensor(1.1605)\n",
      "15934 Traning Loss: tensor(1.1603)\n",
      "15935 Traning Loss: tensor(1.1602)\n",
      "15936 Traning Loss: tensor(1.1600)\n",
      "15937 Traning Loss: tensor(1.1598)\n",
      "15938 Traning Loss: tensor(1.1597)\n",
      "15939 Traning Loss: tensor(1.1595)\n",
      "15940 Traning Loss: tensor(1.1594)\n",
      "15941 Traning Loss: tensor(1.1592)\n",
      "15942 Traning Loss: tensor(1.1591)\n",
      "15943 Traning Loss: tensor(1.1589)\n",
      "15944 Traning Loss: tensor(1.1588)\n",
      "15945 Traning Loss: tensor(1.1586)\n",
      "15946 Traning Loss: tensor(1.1584)\n",
      "15947 Traning Loss: tensor(1.1583)\n",
      "15948 Traning Loss: tensor(1.1581)\n",
      "15949 Traning Loss: tensor(1.1580)\n",
      "15950 Traning Loss: tensor(1.1578)\n",
      "15951 Traning Loss: tensor(1.1577)\n",
      "15952 Traning Loss: tensor(1.1575)\n",
      "15953 Traning Loss: tensor(1.1574)\n",
      "15954 Traning Loss: tensor(1.1572)\n",
      "15955 Traning Loss: tensor(1.1571)\n",
      "15956 Traning Loss: tensor(1.1569)\n",
      "15957 Traning Loss: tensor(1.1568)\n",
      "15958 Traning Loss: tensor(1.1566)\n",
      "15959 Traning Loss: tensor(1.1564)\n",
      "15960 Traning Loss: tensor(1.1563)\n",
      "15961 Traning Loss: tensor(1.1561)\n",
      "15962 Traning Loss: tensor(1.1560)\n",
      "15963 Traning Loss: tensor(1.1558)\n",
      "15964 Traning Loss: tensor(1.1557)\n",
      "15965 Traning Loss: tensor(1.1555)\n",
      "15966 Traning Loss: tensor(1.1554)\n",
      "15967 Traning Loss: tensor(1.1552)\n",
      "15968 Traning Loss: tensor(1.1551)\n",
      "15969 Traning Loss: tensor(1.1549)\n",
      "15970 Traning Loss: tensor(1.1548)\n",
      "15971 Traning Loss: tensor(1.1546)\n",
      "15972 Traning Loss: tensor(1.1545)\n",
      "15973 Traning Loss: tensor(1.1543)\n",
      "15974 Traning Loss: tensor(1.1542)\n",
      "15975 Traning Loss: tensor(1.1540)\n",
      "15976 Traning Loss: tensor(1.1539)\n",
      "15977 Traning Loss: tensor(1.1537)\n",
      "15978 Traning Loss: tensor(1.1536)\n",
      "15979 Traning Loss: tensor(1.1534)\n",
      "15980 Traning Loss: tensor(1.1533)\n",
      "15981 Traning Loss: tensor(1.1531)\n",
      "15982 Traning Loss: tensor(1.1530)\n",
      "15983 Traning Loss: tensor(1.1528)\n",
      "15984 Traning Loss: tensor(1.1527)\n",
      "15985 Traning Loss: tensor(1.1525)\n",
      "15986 Traning Loss: tensor(1.1524)\n",
      "15987 Traning Loss: tensor(1.1522)\n",
      "15988 Traning Loss: tensor(1.1521)\n",
      "15989 Traning Loss: tensor(1.1519)\n",
      "15990 Traning Loss: tensor(1.1518)\n",
      "15991 Traning Loss: tensor(1.1516)\n",
      "15992 Traning Loss: tensor(1.1515)\n",
      "15993 Traning Loss: tensor(1.1513)\n",
      "15994 Traning Loss: tensor(1.1512)\n",
      "15995 Traning Loss: tensor(1.1510)\n",
      "15996 Traning Loss: tensor(1.1509)\n",
      "15997 Traning Loss: tensor(1.1507)\n",
      "15998 Traning Loss: tensor(1.1506)\n",
      "15999 Traning Loss: tensor(1.1504)\n",
      "16000 Traning Loss: tensor(1.1503)\n",
      "16001 Traning Loss: tensor(1.1501)\n",
      "16002 Traning Loss: tensor(1.1500)\n",
      "16003 Traning Loss: tensor(1.1499)\n",
      "16004 Traning Loss: tensor(1.1497)\n",
      "16005 Traning Loss: tensor(1.1496)\n",
      "16006 Traning Loss: tensor(1.1494)\n",
      "16007 Traning Loss: tensor(1.1493)\n",
      "16008 Traning Loss: tensor(1.1491)\n",
      "16009 Traning Loss: tensor(1.1490)\n",
      "16010 Traning Loss: tensor(1.1488)\n",
      "16011 Traning Loss: tensor(1.1487)\n",
      "16012 Traning Loss: tensor(1.1485)\n",
      "16013 Traning Loss: tensor(1.1484)\n",
      "16014 Traning Loss: tensor(1.1482)\n",
      "16015 Traning Loss: tensor(1.1481)\n",
      "16016 Traning Loss: tensor(1.1479)\n",
      "16017 Traning Loss: tensor(1.1478)\n",
      "16018 Traning Loss: tensor(1.1477)\n",
      "16019 Traning Loss: tensor(1.1475)\n",
      "16020 Traning Loss: tensor(1.1474)\n",
      "16021 Traning Loss: tensor(1.1472)\n",
      "16022 Traning Loss: tensor(1.1471)\n",
      "16023 Traning Loss: tensor(1.1469)\n",
      "16024 Traning Loss: tensor(1.1468)\n",
      "16025 Traning Loss: tensor(1.1466)\n",
      "16026 Traning Loss: tensor(1.1465)\n",
      "16027 Traning Loss: tensor(1.1464)\n",
      "16028 Traning Loss: tensor(1.1462)\n",
      "16029 Traning Loss: tensor(1.1461)\n",
      "16030 Traning Loss: tensor(1.1459)\n",
      "16031 Traning Loss: tensor(1.1856)\n",
      "16032 Traning Loss: tensor(1.1854)\n",
      "16033 Traning Loss: tensor(1.1853)\n",
      "16034 Traning Loss: tensor(1.1851)\n",
      "16035 Traning Loss: tensor(1.1849)\n",
      "16036 Traning Loss: tensor(1.1847)\n",
      "16037 Traning Loss: tensor(1.1845)\n",
      "16038 Traning Loss: tensor(1.1844)\n",
      "16039 Traning Loss: tensor(1.1842)\n",
      "16040 Traning Loss: tensor(1.1840)\n",
      "16041 Traning Loss: tensor(1.1838)\n",
      "16042 Traning Loss: tensor(1.1836)\n",
      "16043 Traning Loss: tensor(1.1834)\n",
      "16044 Traning Loss: tensor(1.1832)\n",
      "16045 Traning Loss: tensor(1.1831)\n",
      "16046 Traning Loss: tensor(1.1829)\n",
      "16047 Traning Loss: tensor(1.1827)\n",
      "16048 Traning Loss: tensor(1.1825)\n",
      "16049 Traning Loss: tensor(1.1823)\n",
      "16050 Traning Loss: tensor(1.1821)\n",
      "16051 Traning Loss: tensor(1.1819)\n",
      "16052 Traning Loss: tensor(1.1817)\n",
      "16053 Traning Loss: tensor(1.1815)\n",
      "16054 Traning Loss: tensor(1.1813)\n",
      "16055 Traning Loss: tensor(1.1697)\n",
      "16056 Traning Loss: tensor(1.1695)\n",
      "16057 Traning Loss: tensor(1.1694)\n",
      "16058 Traning Loss: tensor(1.1692)\n",
      "16059 Traning Loss: tensor(1.1690)\n",
      "16060 Traning Loss: tensor(1.1689)\n",
      "16061 Traning Loss: tensor(1.1687)\n",
      "16062 Traning Loss: tensor(1.1686)\n",
      "16063 Traning Loss: tensor(1.1684)\n",
      "16064 Traning Loss: tensor(1.1682)\n",
      "16065 Traning Loss: tensor(1.1681)\n",
      "16066 Traning Loss: tensor(1.1679)\n",
      "16067 Traning Loss: tensor(1.1678)\n",
      "16068 Traning Loss: tensor(1.1676)\n",
      "16069 Traning Loss: tensor(1.1675)\n",
      "16070 Traning Loss: tensor(1.1673)\n",
      "16071 Traning Loss: tensor(1.1672)\n",
      "16072 Traning Loss: tensor(1.1670)\n",
      "16073 Traning Loss: tensor(1.1668)\n",
      "16074 Traning Loss: tensor(1.1667)\n",
      "16075 Traning Loss: tensor(1.1665)\n",
      "16076 Traning Loss: tensor(1.1664)\n",
      "16077 Traning Loss: tensor(1.1662)\n",
      "16078 Traning Loss: tensor(1.1661)\n",
      "16079 Traning Loss: tensor(1.1659)\n",
      "16080 Traning Loss: tensor(1.1658)\n",
      "16081 Traning Loss: tensor(1.1656)\n",
      "16082 Traning Loss: tensor(1.1655)\n",
      "16083 Traning Loss: tensor(1.1653)\n",
      "16084 Traning Loss: tensor(1.1652)\n",
      "16085 Traning Loss: tensor(1.1650)\n",
      "16086 Traning Loss: tensor(1.1649)\n",
      "16087 Traning Loss: tensor(1.1647)\n",
      "16088 Traning Loss: tensor(1.1646)\n",
      "16089 Traning Loss: tensor(1.1644)\n",
      "16090 Traning Loss: tensor(1.1643)\n",
      "16091 Traning Loss: tensor(1.1641)\n",
      "16092 Traning Loss: tensor(1.1640)\n",
      "16093 Traning Loss: tensor(1.1638)\n",
      "16094 Traning Loss: tensor(1.1637)\n",
      "16095 Traning Loss: tensor(1.1635)\n",
      "16096 Traning Loss: tensor(1.1634)\n",
      "16097 Traning Loss: tensor(1.1632)\n",
      "16098 Traning Loss: tensor(1.1631)\n",
      "16099 Traning Loss: tensor(1.1629)\n",
      "16100 Traning Loss: tensor(1.1628)\n",
      "16101 Traning Loss: tensor(1.1626)\n",
      "16102 Traning Loss: tensor(1.1625)\n",
      "16103 Traning Loss: tensor(1.1623)\n",
      "16104 Traning Loss: tensor(1.1622)\n",
      "16105 Traning Loss: tensor(1.1620)\n",
      "16106 Traning Loss: tensor(1.1619)\n",
      "16107 Traning Loss: tensor(1.1617)\n",
      "16108 Traning Loss: tensor(1.1616)\n",
      "16109 Traning Loss: tensor(1.1614)\n",
      "16110 Traning Loss: tensor(1.1613)\n",
      "16111 Traning Loss: tensor(1.1611)\n",
      "16112 Traning Loss: tensor(1.1610)\n",
      "16113 Traning Loss: tensor(1.1608)\n",
      "16114 Traning Loss: tensor(1.1607)\n",
      "16115 Traning Loss: tensor(1.1605)\n",
      "16116 Traning Loss: tensor(1.1604)\n",
      "16117 Traning Loss: tensor(1.1603)\n",
      "16118 Traning Loss: tensor(1.1601)\n",
      "16119 Traning Loss: tensor(1.1600)\n",
      "16120 Traning Loss: tensor(1.1598)\n",
      "16121 Traning Loss: tensor(1.1597)\n",
      "16122 Traning Loss: tensor(1.1595)\n",
      "16123 Traning Loss: tensor(1.1594)\n",
      "16124 Traning Loss: tensor(1.1592)\n",
      "16125 Traning Loss: tensor(1.1591)\n",
      "16126 Traning Loss: tensor(1.1589)\n",
      "16127 Traning Loss: tensor(1.1588)\n",
      "16128 Traning Loss: tensor(1.1586)\n",
      "16129 Traning Loss: tensor(1.1585)\n",
      "16130 Traning Loss: tensor(1.1583)\n",
      "16131 Traning Loss: tensor(1.1582)\n",
      "16132 Traning Loss: tensor(1.1580)\n",
      "16133 Traning Loss: tensor(1.1579)\n",
      "16134 Traning Loss: tensor(1.1577)\n",
      "16135 Traning Loss: tensor(1.1576)\n",
      "16136 Traning Loss: tensor(1.1574)\n",
      "16137 Traning Loss: tensor(1.1573)\n",
      "16138 Traning Loss: tensor(1.1571)\n",
      "16139 Traning Loss: tensor(1.1570)\n",
      "16140 Traning Loss: tensor(1.1569)\n",
      "16141 Traning Loss: tensor(1.1567)\n",
      "16142 Traning Loss: tensor(1.1566)\n",
      "16143 Traning Loss: tensor(1.1564)\n",
      "16144 Traning Loss: tensor(1.1563)\n",
      "16145 Traning Loss: tensor(1.1561)\n",
      "16146 Traning Loss: tensor(1.1560)\n",
      "16147 Traning Loss: tensor(1.1558)\n",
      "16148 Traning Loss: tensor(1.1557)\n",
      "16149 Traning Loss: tensor(1.1555)\n",
      "16150 Traning Loss: tensor(1.1554)\n",
      "16151 Traning Loss: tensor(1.1552)\n",
      "16152 Traning Loss: tensor(1.1551)\n",
      "16153 Traning Loss: tensor(1.1549)\n",
      "16154 Traning Loss: tensor(1.1548)\n",
      "16155 Traning Loss: tensor(1.1546)\n",
      "16156 Traning Loss: tensor(1.1545)\n",
      "16157 Traning Loss: tensor(1.1544)\n",
      "16158 Traning Loss: tensor(1.1542)\n",
      "16159 Traning Loss: tensor(1.1541)\n",
      "16160 Traning Loss: tensor(1.1539)\n",
      "16161 Traning Loss: tensor(1.1538)\n",
      "16162 Traning Loss: tensor(1.1536)\n",
      "16163 Traning Loss: tensor(1.1535)\n",
      "16164 Traning Loss: tensor(1.1533)\n",
      "16165 Traning Loss: tensor(1.1532)\n",
      "16166 Traning Loss: tensor(1.1530)\n",
      "16167 Traning Loss: tensor(1.1529)\n",
      "16168 Traning Loss: tensor(1.1527)\n",
      "16169 Traning Loss: tensor(1.1526)\n",
      "16170 Traning Loss: tensor(1.1525)\n",
      "16171 Traning Loss: tensor(1.1523)\n",
      "16172 Traning Loss: tensor(1.1522)\n",
      "16173 Traning Loss: tensor(1.1520)\n",
      "16174 Traning Loss: tensor(1.1519)\n",
      "16175 Traning Loss: tensor(1.1517)\n",
      "16176 Traning Loss: tensor(1.1516)\n",
      "16177 Traning Loss: tensor(1.1514)\n",
      "16178 Traning Loss: tensor(1.1513)\n",
      "16179 Traning Loss: tensor(1.1511)\n",
      "16180 Traning Loss: tensor(1.1510)\n",
      "16181 Traning Loss: tensor(1.1508)\n",
      "16182 Traning Loss: tensor(1.1507)\n",
      "16183 Traning Loss: tensor(1.1506)\n",
      "16184 Traning Loss: tensor(1.1504)\n",
      "16185 Traning Loss: tensor(1.1503)\n",
      "16186 Traning Loss: tensor(1.1501)\n",
      "16187 Traning Loss: tensor(1.1500)\n",
      "16188 Traning Loss: tensor(1.1498)\n",
      "16189 Traning Loss: tensor(1.1497)\n",
      "16190 Traning Loss: tensor(1.1495)\n",
      "16191 Traning Loss: tensor(1.1494)\n",
      "16192 Traning Loss: tensor(1.1492)\n",
      "16193 Traning Loss: tensor(1.1491)\n",
      "16194 Traning Loss: tensor(1.1490)\n",
      "16195 Traning Loss: tensor(1.1488)\n",
      "16196 Traning Loss: tensor(1.1487)\n",
      "16197 Traning Loss: tensor(1.1485)\n",
      "16198 Traning Loss: tensor(1.1484)\n",
      "16199 Traning Loss: tensor(1.1482)\n",
      "16200 Traning Loss: tensor(1.1481)\n",
      "16201 Traning Loss: tensor(1.1479)\n",
      "16202 Traning Loss: tensor(1.1478)\n",
      "16203 Traning Loss: tensor(1.1476)\n",
      "16204 Traning Loss: tensor(1.1475)\n",
      "16205 Traning Loss: tensor(1.1474)\n",
      "16206 Traning Loss: tensor(1.1472)\n",
      "16207 Traning Loss: tensor(1.1471)\n",
      "16208 Traning Loss: tensor(1.1469)\n",
      "16209 Traning Loss: tensor(1.1468)\n",
      "16210 Traning Loss: tensor(1.1466)\n",
      "16211 Traning Loss: tensor(1.1465)\n",
      "16212 Traning Loss: tensor(1.1463)\n",
      "16213 Traning Loss: tensor(1.1462)\n",
      "16214 Traning Loss: tensor(1.1461)\n",
      "16215 Traning Loss: tensor(1.1459)\n",
      "16216 Traning Loss: tensor(1.1458)\n",
      "16217 Traning Loss: tensor(1.1456)\n",
      "16218 Traning Loss: tensor(1.1455)\n",
      "16219 Traning Loss: tensor(1.1453)\n",
      "16220 Traning Loss: tensor(1.1452)\n",
      "16221 Traning Loss: tensor(1.1450)\n",
      "16222 Traning Loss: tensor(1.1449)\n",
      "16223 Traning Loss: tensor(1.1448)\n",
      "16224 Traning Loss: tensor(1.1446)\n",
      "16225 Traning Loss: tensor(1.1445)\n",
      "16226 Traning Loss: tensor(1.1443)\n",
      "16227 Traning Loss: tensor(1.1442)\n",
      "16228 Traning Loss: tensor(1.1440)\n",
      "16229 Traning Loss: tensor(1.1439)\n",
      "16230 Traning Loss: tensor(1.1437)\n",
      "16231 Traning Loss: tensor(1.1436)\n",
      "16232 Traning Loss: tensor(1.1435)\n",
      "16233 Traning Loss: tensor(1.1433)\n",
      "16234 Traning Loss: tensor(1.1432)\n",
      "16235 Traning Loss: tensor(1.1430)\n",
      "16236 Traning Loss: tensor(1.1429)\n",
      "16237 Traning Loss: tensor(1.1427)\n",
      "16238 Traning Loss: tensor(1.1426)\n",
      "16239 Traning Loss: tensor(1.1424)\n",
      "16240 Traning Loss: tensor(1.1423)\n",
      "16241 Traning Loss: tensor(1.1422)\n",
      "16242 Traning Loss: tensor(1.1420)\n",
      "16243 Traning Loss: tensor(1.1419)\n",
      "16244 Traning Loss: tensor(1.1417)\n",
      "16245 Traning Loss: tensor(1.1416)\n",
      "16246 Traning Loss: tensor(1.1414)\n",
      "16247 Traning Loss: tensor(1.1413)\n",
      "16248 Traning Loss: tensor(1.1412)\n",
      "16249 Traning Loss: tensor(1.1410)\n",
      "16250 Traning Loss: tensor(1.1409)\n",
      "16251 Traning Loss: tensor(1.1407)\n",
      "16252 Traning Loss: tensor(1.1406)\n",
      "16253 Traning Loss: tensor(1.1404)\n",
      "16254 Traning Loss: tensor(1.1403)\n",
      "16255 Traning Loss: tensor(1.1402)\n",
      "16256 Traning Loss: tensor(1.1400)\n",
      "16257 Traning Loss: tensor(1.1399)\n",
      "16258 Traning Loss: tensor(1.1397)\n",
      "16259 Traning Loss: tensor(1.1396)\n",
      "16260 Traning Loss: tensor(1.1394)\n",
      "16261 Traning Loss: tensor(1.1393)\n",
      "16262 Traning Loss: tensor(1.1392)\n",
      "16263 Traning Loss: tensor(1.1390)\n",
      "16264 Traning Loss: tensor(1.1389)\n",
      "16265 Traning Loss: tensor(1.1387)\n",
      "16266 Traning Loss: tensor(1.1386)\n",
      "16267 Traning Loss: tensor(1.1384)\n",
      "16268 Traning Loss: tensor(1.1383)\n",
      "16269 Traning Loss: tensor(1.1382)\n",
      "16270 Traning Loss: tensor(1.1380)\n",
      "16271 Traning Loss: tensor(1.1379)\n",
      "16272 Traning Loss: tensor(1.1377)\n",
      "16273 Traning Loss: tensor(1.1376)\n",
      "16274 Traning Loss: tensor(1.1374)\n",
      "16275 Traning Loss: tensor(1.1373)\n",
      "16276 Traning Loss: tensor(1.1372)\n",
      "16277 Traning Loss: tensor(1.1370)\n",
      "16278 Traning Loss: tensor(1.1369)\n",
      "16279 Traning Loss: tensor(1.1367)\n",
      "16280 Traning Loss: tensor(1.1366)\n",
      "16281 Traning Loss: tensor(1.1364)\n",
      "16282 Traning Loss: tensor(1.1363)\n",
      "16283 Traning Loss: tensor(1.1362)\n",
      "16284 Traning Loss: tensor(1.1360)\n",
      "16285 Traning Loss: tensor(1.1359)\n",
      "16286 Traning Loss: tensor(1.1357)\n",
      "16287 Traning Loss: tensor(1.1356)\n",
      "16288 Traning Loss: tensor(1.1354)\n",
      "16289 Traning Loss: tensor(1.1353)\n",
      "16290 Traning Loss: tensor(1.1352)\n",
      "16291 Traning Loss: tensor(1.1350)\n",
      "16292 Traning Loss: tensor(1.1349)\n",
      "16293 Traning Loss: tensor(1.1347)\n",
      "16294 Traning Loss: tensor(1.1346)\n",
      "16295 Traning Loss: tensor(1.1344)\n",
      "16296 Traning Loss: tensor(1.1343)\n",
      "16297 Traning Loss: tensor(1.1342)\n",
      "16298 Traning Loss: tensor(1.1340)\n",
      "16299 Traning Loss: tensor(1.1339)\n",
      "16300 Traning Loss: tensor(1.1337)\n",
      "16301 Traning Loss: tensor(1.1336)\n",
      "16302 Traning Loss: tensor(1.1335)\n",
      "16303 Traning Loss: tensor(1.1333)\n",
      "16304 Traning Loss: tensor(1.1332)\n",
      "16305 Traning Loss: tensor(1.1330)\n",
      "16306 Traning Loss: tensor(1.1329)\n",
      "16307 Traning Loss: tensor(1.1327)\n",
      "16308 Traning Loss: tensor(1.1326)\n",
      "16309 Traning Loss: tensor(1.1325)\n",
      "16310 Traning Loss: tensor(1.1323)\n",
      "16311 Traning Loss: tensor(1.1322)\n",
      "16312 Traning Loss: tensor(1.1320)\n",
      "16313 Traning Loss: tensor(1.1319)\n",
      "16314 Traning Loss: tensor(1.1318)\n",
      "16315 Traning Loss: tensor(1.1316)\n",
      "16316 Traning Loss: tensor(1.1315)\n",
      "16317 Traning Loss: tensor(1.1313)\n",
      "16318 Traning Loss: tensor(1.1312)\n",
      "16319 Traning Loss: tensor(1.1311)\n",
      "16320 Traning Loss: tensor(1.1309)\n",
      "16321 Traning Loss: tensor(1.1308)\n",
      "16322 Traning Loss: tensor(1.1306)\n",
      "16323 Traning Loss: tensor(1.1305)\n",
      "16324 Traning Loss: tensor(1.1303)\n",
      "16325 Traning Loss: tensor(1.1302)\n",
      "16326 Traning Loss: tensor(1.1301)\n",
      "16327 Traning Loss: tensor(1.1299)\n",
      "16328 Traning Loss: tensor(1.1298)\n",
      "16329 Traning Loss: tensor(1.1296)\n",
      "16330 Traning Loss: tensor(1.1295)\n",
      "16331 Traning Loss: tensor(1.1294)\n",
      "16332 Traning Loss: tensor(1.1292)\n",
      "16333 Traning Loss: tensor(1.1291)\n",
      "16334 Traning Loss: tensor(1.1289)\n",
      "16335 Traning Loss: tensor(1.1288)\n",
      "16336 Traning Loss: tensor(1.1287)\n",
      "16337 Traning Loss: tensor(1.1285)\n",
      "16338 Traning Loss: tensor(1.1284)\n",
      "16339 Traning Loss: tensor(1.1282)\n",
      "16340 Traning Loss: tensor(1.1281)\n",
      "16341 Traning Loss: tensor(1.1280)\n",
      "16342 Traning Loss: tensor(1.1278)\n",
      "16343 Traning Loss: tensor(1.1277)\n",
      "16344 Traning Loss: tensor(1.1275)\n",
      "16345 Traning Loss: tensor(1.1274)\n",
      "16346 Traning Loss: tensor(1.1273)\n",
      "16347 Traning Loss: tensor(1.1271)\n",
      "16348 Traning Loss: tensor(1.1270)\n",
      "16349 Traning Loss: tensor(1.1268)\n",
      "16350 Traning Loss: tensor(1.1267)\n",
      "16351 Traning Loss: tensor(1.1265)\n",
      "16352 Traning Loss: tensor(1.1264)\n",
      "16353 Traning Loss: tensor(1.1263)\n",
      "16354 Traning Loss: tensor(1.1261)\n",
      "16355 Traning Loss: tensor(1.1260)\n",
      "16356 Traning Loss: tensor(1.1258)\n",
      "16357 Traning Loss: tensor(1.1257)\n",
      "16358 Traning Loss: tensor(1.1256)\n",
      "16359 Traning Loss: tensor(1.1254)\n",
      "16360 Traning Loss: tensor(1.1253)\n",
      "16361 Traning Loss: tensor(1.1251)\n",
      "16362 Traning Loss: tensor(1.1250)\n",
      "16363 Traning Loss: tensor(1.1249)\n",
      "16364 Traning Loss: tensor(1.1247)\n",
      "16365 Traning Loss: tensor(1.1246)\n",
      "16366 Traning Loss: tensor(1.1245)\n",
      "16367 Traning Loss: tensor(1.1243)\n",
      "16368 Traning Loss: tensor(1.1242)\n",
      "16369 Traning Loss: tensor(1.1240)\n",
      "16370 Traning Loss: tensor(1.1239)\n",
      "16371 Traning Loss: tensor(1.1238)\n",
      "16372 Traning Loss: tensor(1.1236)\n",
      "16373 Traning Loss: tensor(1.1235)\n",
      "16374 Traning Loss: tensor(1.1233)\n",
      "16375 Traning Loss: tensor(1.1232)\n",
      "16376 Traning Loss: tensor(1.1231)\n",
      "16377 Traning Loss: tensor(1.1229)\n",
      "16378 Traning Loss: tensor(1.1228)\n",
      "16379 Traning Loss: tensor(1.1226)\n",
      "16380 Traning Loss: tensor(1.1225)\n",
      "16381 Traning Loss: tensor(1.1224)\n",
      "16382 Traning Loss: tensor(1.1222)\n",
      "16383 Traning Loss: tensor(1.1221)\n",
      "16384 Traning Loss: tensor(1.1219)\n",
      "16385 Traning Loss: tensor(1.1218)\n",
      "16386 Traning Loss: tensor(1.1217)\n",
      "16387 Traning Loss: tensor(1.1215)\n",
      "16388 Traning Loss: tensor(1.1214)\n",
      "16389 Traning Loss: tensor(1.1212)\n",
      "16390 Traning Loss: tensor(1.1211)\n",
      "16391 Traning Loss: tensor(1.1210)\n",
      "16392 Traning Loss: tensor(1.1208)\n",
      "16393 Traning Loss: tensor(1.1207)\n",
      "16394 Traning Loss: tensor(1.1206)\n",
      "16395 Traning Loss: tensor(1.1204)\n",
      "16396 Traning Loss: tensor(1.1203)\n",
      "16397 Traning Loss: tensor(1.1201)\n",
      "16398 Traning Loss: tensor(1.1200)\n",
      "16399 Traning Loss: tensor(1.1199)\n",
      "16400 Traning Loss: tensor(1.1197)\n",
      "16401 Traning Loss: tensor(1.1196)\n",
      "16402 Traning Loss: tensor(1.1194)\n",
      "16403 Traning Loss: tensor(1.1193)\n",
      "16404 Traning Loss: tensor(1.1192)\n",
      "16405 Traning Loss: tensor(1.1190)\n",
      "16406 Traning Loss: tensor(1.1189)\n",
      "16407 Traning Loss: tensor(1.1188)\n",
      "16408 Traning Loss: tensor(1.1186)\n",
      "16409 Traning Loss: tensor(1.1185)\n",
      "16410 Traning Loss: tensor(1.1183)\n",
      "16411 Traning Loss: tensor(1.1182)\n",
      "16412 Traning Loss: tensor(1.1181)\n",
      "16413 Traning Loss: tensor(1.1179)\n",
      "16414 Traning Loss: tensor(1.1178)\n",
      "16415 Traning Loss: tensor(1.1176)\n",
      "16416 Traning Loss: tensor(1.1175)\n",
      "16417 Traning Loss: tensor(1.1174)\n",
      "16418 Traning Loss: tensor(1.1172)\n",
      "16419 Traning Loss: tensor(1.1171)\n",
      "16420 Traning Loss: tensor(1.1170)\n",
      "16421 Traning Loss: tensor(1.1168)\n",
      "16422 Traning Loss: tensor(1.1167)\n",
      "16423 Traning Loss: tensor(1.1165)\n",
      "16424 Traning Loss: tensor(1.1164)\n",
      "16425 Traning Loss: tensor(1.1163)\n",
      "16426 Traning Loss: tensor(1.1161)\n",
      "16427 Traning Loss: tensor(1.1160)\n",
      "16428 Traning Loss: tensor(1.1159)\n",
      "16429 Traning Loss: tensor(1.1157)\n",
      "16430 Traning Loss: tensor(1.1156)\n",
      "16431 Traning Loss: tensor(1.1154)\n",
      "16432 Traning Loss: tensor(1.1153)\n",
      "16433 Traning Loss: tensor(1.1152)\n",
      "16434 Traning Loss: tensor(1.1150)\n",
      "16435 Traning Loss: tensor(1.1149)\n",
      "16436 Traning Loss: tensor(1.1148)\n",
      "16437 Traning Loss: tensor(1.1146)\n",
      "16438 Traning Loss: tensor(1.1145)\n",
      "16439 Traning Loss: tensor(1.1143)\n",
      "16440 Traning Loss: tensor(1.1142)\n",
      "16441 Traning Loss: tensor(1.1141)\n",
      "16442 Traning Loss: tensor(1.1139)\n",
      "16443 Traning Loss: tensor(1.1138)\n",
      "16444 Traning Loss: tensor(1.1137)\n",
      "16445 Traning Loss: tensor(1.1135)\n",
      "16446 Traning Loss: tensor(1.1134)\n",
      "16447 Traning Loss: tensor(1.1132)\n",
      "16448 Traning Loss: tensor(1.1131)\n",
      "16449 Traning Loss: tensor(1.1130)\n",
      "16450 Traning Loss: tensor(1.1128)\n",
      "16451 Traning Loss: tensor(1.1127)\n",
      "16452 Traning Loss: tensor(1.1126)\n",
      "16453 Traning Loss: tensor(1.1124)\n",
      "16454 Traning Loss: tensor(1.1123)\n",
      "16455 Traning Loss: tensor(1.1122)\n",
      "16456 Traning Loss: tensor(1.1120)\n",
      "16457 Traning Loss: tensor(1.1119)\n",
      "16458 Traning Loss: tensor(1.1117)\n",
      "16459 Traning Loss: tensor(1.1116)\n",
      "16460 Traning Loss: tensor(1.1115)\n",
      "16461 Traning Loss: tensor(1.1113)\n",
      "16462 Traning Loss: tensor(1.1112)\n",
      "16463 Traning Loss: tensor(1.1111)\n",
      "16464 Traning Loss: tensor(1.1109)\n",
      "16465 Traning Loss: tensor(1.1108)\n",
      "16466 Traning Loss: tensor(1.1106)\n",
      "16467 Traning Loss: tensor(1.1105)\n",
      "16468 Traning Loss: tensor(1.1104)\n",
      "16469 Traning Loss: tensor(1.1102)\n",
      "16470 Traning Loss: tensor(1.1101)\n",
      "16471 Traning Loss: tensor(1.1100)\n",
      "16472 Traning Loss: tensor(1.1098)\n",
      "16473 Traning Loss: tensor(1.0960)\n",
      "16474 Traning Loss: tensor(1.0959)\n",
      "16475 Traning Loss: tensor(1.0958)\n",
      "16476 Traning Loss: tensor(1.0957)\n",
      "16477 Traning Loss: tensor(1.0956)\n",
      "16478 Traning Loss: tensor(1.0955)\n",
      "16479 Traning Loss: tensor(1.0954)\n",
      "16480 Traning Loss: tensor(1.0953)\n",
      "16481 Traning Loss: tensor(1.0951)\n",
      "16482 Traning Loss: tensor(1.0950)\n",
      "16483 Traning Loss: tensor(1.0949)\n",
      "16484 Traning Loss: tensor(1.0948)\n",
      "16485 Traning Loss: tensor(1.0947)\n",
      "16486 Traning Loss: tensor(1.0946)\n",
      "16487 Traning Loss: tensor(1.0945)\n",
      "16488 Traning Loss: tensor(1.0944)\n",
      "16489 Traning Loss: tensor(1.0943)\n",
      "16490 Traning Loss: tensor(1.0942)\n",
      "16491 Traning Loss: tensor(1.0941)\n",
      "16492 Traning Loss: tensor(1.0940)\n",
      "16493 Traning Loss: tensor(1.0940)\n",
      "16494 Traning Loss: tensor(1.0939)\n",
      "16495 Traning Loss: tensor(1.0938)\n",
      "16496 Traning Loss: tensor(1.0937)\n",
      "16497 Traning Loss: tensor(1.0936)\n",
      "16498 Traning Loss: tensor(1.0935)\n",
      "16499 Traning Loss: tensor(1.0934)\n",
      "16500 Traning Loss: tensor(1.0933)\n",
      "16501 Traning Loss: tensor(1.0932)\n",
      "16502 Traning Loss: tensor(1.0931)\n",
      "16503 Traning Loss: tensor(1.0930)\n",
      "16504 Traning Loss: tensor(1.0929)\n",
      "16505 Traning Loss: tensor(1.0928)\n",
      "16506 Traning Loss: tensor(1.0927)\n",
      "16507 Traning Loss: tensor(1.0926)\n",
      "16508 Traning Loss: tensor(1.0925)\n",
      "16509 Traning Loss: tensor(1.0924)\n",
      "16510 Traning Loss: tensor(1.0923)\n",
      "16511 Traning Loss: tensor(1.0922)\n",
      "16512 Traning Loss: tensor(1.0921)\n",
      "16513 Traning Loss: tensor(1.0920)\n",
      "16514 Traning Loss: tensor(1.0919)\n",
      "16515 Traning Loss: tensor(1.0918)\n",
      "16516 Traning Loss: tensor(1.0917)\n",
      "16517 Traning Loss: tensor(1.0916)\n",
      "16518 Traning Loss: tensor(1.0916)\n",
      "16519 Traning Loss: tensor(1.0915)\n",
      "16520 Traning Loss: tensor(1.0914)\n",
      "16521 Traning Loss: tensor(1.0913)\n",
      "16522 Traning Loss: tensor(1.0912)\n",
      "16523 Traning Loss: tensor(1.0911)\n",
      "16524 Traning Loss: tensor(1.0910)\n",
      "16525 Traning Loss: tensor(1.0909)\n",
      "16526 Traning Loss: tensor(1.0908)\n",
      "16527 Traning Loss: tensor(1.0907)\n",
      "16528 Traning Loss: tensor(1.0906)\n",
      "16529 Traning Loss: tensor(1.0905)\n",
      "16530 Traning Loss: tensor(1.0904)\n",
      "16531 Traning Loss: tensor(1.0903)\n",
      "16532 Traning Loss: tensor(1.0902)\n",
      "16533 Traning Loss: tensor(1.0901)\n",
      "16534 Traning Loss: tensor(1.0900)\n",
      "16535 Traning Loss: tensor(1.0899)\n",
      "16536 Traning Loss: tensor(1.0898)\n",
      "16537 Traning Loss: tensor(1.0898)\n",
      "16538 Traning Loss: tensor(1.0897)\n",
      "16539 Traning Loss: tensor(1.0896)\n",
      "16540 Traning Loss: tensor(1.0895)\n",
      "16541 Traning Loss: tensor(1.0894)\n",
      "16542 Traning Loss: tensor(1.0893)\n",
      "16543 Traning Loss: tensor(1.0892)\n",
      "16544 Traning Loss: tensor(1.0891)\n",
      "16545 Traning Loss: tensor(1.0890)\n",
      "16546 Traning Loss: tensor(1.0889)\n",
      "16547 Traning Loss: tensor(1.0888)\n",
      "16548 Traning Loss: tensor(1.0887)\n",
      "16549 Traning Loss: tensor(1.0886)\n",
      "16550 Traning Loss: tensor(1.0885)\n",
      "16551 Traning Loss: tensor(1.0884)\n",
      "16552 Traning Loss: tensor(1.0883)\n",
      "16553 Traning Loss: tensor(1.0882)\n",
      "16554 Traning Loss: tensor(1.0881)\n",
      "16555 Traning Loss: tensor(1.0881)\n",
      "16556 Traning Loss: tensor(1.0880)\n",
      "16557 Traning Loss: tensor(1.0879)\n",
      "16558 Traning Loss: tensor(1.0878)\n",
      "16559 Traning Loss: tensor(1.0877)\n",
      "16560 Traning Loss: tensor(1.0876)\n",
      "16561 Traning Loss: tensor(1.0875)\n",
      "16562 Traning Loss: tensor(1.0874)\n",
      "16563 Traning Loss: tensor(1.0873)\n",
      "16564 Traning Loss: tensor(1.0872)\n",
      "16565 Traning Loss: tensor(1.0871)\n",
      "16566 Traning Loss: tensor(1.0870)\n",
      "16567 Traning Loss: tensor(1.0869)\n",
      "16568 Traning Loss: tensor(1.0868)\n",
      "16569 Traning Loss: tensor(1.0867)\n",
      "16570 Traning Loss: tensor(1.0866)\n",
      "16571 Traning Loss: tensor(1.0865)\n",
      "16572 Traning Loss: tensor(1.0864)\n",
      "16573 Traning Loss: tensor(1.0864)\n",
      "16574 Traning Loss: tensor(1.0863)\n",
      "16575 Traning Loss: tensor(1.0862)\n",
      "16576 Traning Loss: tensor(1.0861)\n",
      "16577 Traning Loss: tensor(1.0860)\n",
      "16578 Traning Loss: tensor(1.0859)\n",
      "16579 Traning Loss: tensor(1.0858)\n",
      "16580 Traning Loss: tensor(1.0857)\n",
      "16581 Traning Loss: tensor(1.0856)\n",
      "16582 Traning Loss: tensor(1.0855)\n",
      "16583 Traning Loss: tensor(1.0854)\n",
      "16584 Traning Loss: tensor(1.0853)\n",
      "16585 Traning Loss: tensor(1.0852)\n",
      "16586 Traning Loss: tensor(1.0851)\n",
      "16587 Traning Loss: tensor(1.0850)\n",
      "16588 Traning Loss: tensor(1.0849)\n",
      "16589 Traning Loss: tensor(1.0848)\n",
      "16590 Traning Loss: tensor(1.0848)\n",
      "16591 Traning Loss: tensor(1.0847)\n",
      "16592 Traning Loss: tensor(1.0846)\n",
      "16593 Traning Loss: tensor(1.0845)\n",
      "16594 Traning Loss: tensor(1.0844)\n",
      "16595 Traning Loss: tensor(1.0843)\n",
      "16596 Traning Loss: tensor(1.0842)\n",
      "16597 Traning Loss: tensor(1.0841)\n",
      "16598 Traning Loss: tensor(1.0840)\n",
      "16599 Traning Loss: tensor(1.0839)\n",
      "16600 Traning Loss: tensor(1.0838)\n",
      "16601 Traning Loss: tensor(1.0837)\n",
      "16602 Traning Loss: tensor(1.0836)\n",
      "16603 Traning Loss: tensor(1.0835)\n",
      "16604 Traning Loss: tensor(1.0834)\n",
      "16605 Traning Loss: tensor(1.0833)\n",
      "16606 Traning Loss: tensor(1.0833)\n",
      "16607 Traning Loss: tensor(1.0832)\n",
      "16608 Traning Loss: tensor(1.0831)\n",
      "16609 Traning Loss: tensor(1.0830)\n",
      "16610 Traning Loss: tensor(1.0829)\n",
      "16611 Traning Loss: tensor(1.0828)\n",
      "16612 Traning Loss: tensor(1.0827)\n",
      "16613 Traning Loss: tensor(1.0826)\n",
      "16614 Traning Loss: tensor(1.0825)\n",
      "16615 Traning Loss: tensor(1.0824)\n",
      "16616 Traning Loss: tensor(1.0823)\n",
      "16617 Traning Loss: tensor(1.0822)\n",
      "16618 Traning Loss: tensor(1.0821)\n",
      "16619 Traning Loss: tensor(1.0820)\n",
      "16620 Traning Loss: tensor(1.0819)\n",
      "16621 Traning Loss: tensor(1.0818)\n",
      "16622 Traning Loss: tensor(1.0818)\n",
      "16623 Traning Loss: tensor(1.0817)\n",
      "16624 Traning Loss: tensor(1.0816)\n",
      "16625 Traning Loss: tensor(1.0815)\n",
      "16626 Traning Loss: tensor(1.0814)\n",
      "16627 Traning Loss: tensor(1.0813)\n",
      "16628 Traning Loss: tensor(1.0812)\n",
      "16629 Traning Loss: tensor(1.0811)\n",
      "16630 Traning Loss: tensor(1.0810)\n",
      "16631 Traning Loss: tensor(1.0809)\n",
      "16632 Traning Loss: tensor(1.0808)\n",
      "16633 Traning Loss: tensor(1.0807)\n",
      "16634 Traning Loss: tensor(1.0806)\n",
      "16635 Traning Loss: tensor(1.0805)\n",
      "16636 Traning Loss: tensor(1.0804)\n",
      "16637 Traning Loss: tensor(1.0803)\n",
      "16638 Traning Loss: tensor(1.0803)\n",
      "16639 Traning Loss: tensor(1.0802)\n",
      "16640 Traning Loss: tensor(1.0801)\n",
      "16641 Traning Loss: tensor(1.0800)\n",
      "16642 Traning Loss: tensor(1.0799)\n",
      "16643 Traning Loss: tensor(1.0798)\n",
      "16644 Traning Loss: tensor(1.0797)\n",
      "16645 Traning Loss: tensor(1.0796)\n",
      "16646 Traning Loss: tensor(1.0795)\n",
      "16647 Traning Loss: tensor(1.0794)\n",
      "16648 Traning Loss: tensor(1.0793)\n",
      "16649 Traning Loss: tensor(1.0792)\n",
      "16650 Traning Loss: tensor(1.0791)\n",
      "16651 Traning Loss: tensor(1.0790)\n",
      "16652 Traning Loss: tensor(1.0789)\n",
      "16653 Traning Loss: tensor(1.0789)\n",
      "16654 Traning Loss: tensor(1.0788)\n",
      "16655 Traning Loss: tensor(1.0787)\n",
      "16656 Traning Loss: tensor(1.0786)\n",
      "16657 Traning Loss: tensor(1.0785)\n",
      "16658 Traning Loss: tensor(1.0784)\n",
      "16659 Traning Loss: tensor(1.0783)\n",
      "16660 Traning Loss: tensor(1.0782)\n",
      "16661 Traning Loss: tensor(1.0781)\n",
      "16662 Traning Loss: tensor(1.0780)\n",
      "16663 Traning Loss: tensor(1.0779)\n",
      "16664 Traning Loss: tensor(1.0778)\n",
      "16665 Traning Loss: tensor(1.0777)\n",
      "16666 Traning Loss: tensor(1.0776)\n",
      "16667 Traning Loss: tensor(1.0775)\n",
      "16668 Traning Loss: tensor(1.0775)\n",
      "16669 Traning Loss: tensor(1.0774)\n",
      "16670 Traning Loss: tensor(1.0773)\n",
      "16671 Traning Loss: tensor(1.0772)\n",
      "16672 Traning Loss: tensor(1.0771)\n",
      "16673 Traning Loss: tensor(1.0770)\n",
      "16674 Traning Loss: tensor(1.0769)\n",
      "16675 Traning Loss: tensor(1.0768)\n",
      "16676 Traning Loss: tensor(1.0767)\n",
      "16677 Traning Loss: tensor(1.0766)\n",
      "16678 Traning Loss: tensor(1.0765)\n",
      "16679 Traning Loss: tensor(1.0764)\n",
      "16680 Traning Loss: tensor(1.0763)\n",
      "16681 Traning Loss: tensor(1.0762)\n",
      "16682 Traning Loss: tensor(1.0762)\n",
      "16683 Traning Loss: tensor(1.0761)\n",
      "16684 Traning Loss: tensor(1.0760)\n",
      "16685 Traning Loss: tensor(1.0759)\n",
      "16686 Traning Loss: tensor(1.0758)\n",
      "16687 Traning Loss: tensor(1.0757)\n",
      "16688 Traning Loss: tensor(1.0756)\n",
      "16689 Traning Loss: tensor(1.0755)\n",
      "16690 Traning Loss: tensor(1.0754)\n",
      "16691 Traning Loss: tensor(1.0753)\n",
      "16692 Traning Loss: tensor(1.0752)\n",
      "16693 Traning Loss: tensor(1.0751)\n",
      "16694 Traning Loss: tensor(1.0750)\n",
      "16695 Traning Loss: tensor(1.0749)\n",
      "16696 Traning Loss: tensor(1.0748)\n",
      "16697 Traning Loss: tensor(1.0748)\n",
      "16698 Traning Loss: tensor(1.0747)\n",
      "16699 Traning Loss: tensor(1.0746)\n",
      "16700 Traning Loss: tensor(1.0745)\n",
      "16701 Traning Loss: tensor(1.0744)\n",
      "16702 Traning Loss: tensor(1.0743)\n",
      "16703 Traning Loss: tensor(1.0742)\n",
      "16704 Traning Loss: tensor(1.0741)\n",
      "16705 Traning Loss: tensor(1.0740)\n",
      "16706 Traning Loss: tensor(1.0739)\n",
      "16707 Traning Loss: tensor(1.0738)\n",
      "16708 Traning Loss: tensor(1.0737)\n",
      "16709 Traning Loss: tensor(1.0736)\n",
      "16710 Traning Loss: tensor(1.0735)\n",
      "16711 Traning Loss: tensor(1.0735)\n",
      "16712 Traning Loss: tensor(1.0734)\n",
      "16713 Traning Loss: tensor(1.0733)\n",
      "16714 Traning Loss: tensor(1.0732)\n",
      "16715 Traning Loss: tensor(1.0731)\n",
      "16716 Traning Loss: tensor(1.0730)\n",
      "16717 Traning Loss: tensor(1.0729)\n",
      "16718 Traning Loss: tensor(1.0728)\n",
      "16719 Traning Loss: tensor(1.0727)\n",
      "16720 Traning Loss: tensor(1.0726)\n",
      "16721 Traning Loss: tensor(1.0725)\n",
      "16722 Traning Loss: tensor(1.0724)\n",
      "16723 Traning Loss: tensor(1.0723)\n",
      "16724 Traning Loss: tensor(1.0722)\n",
      "16725 Traning Loss: tensor(1.0722)\n",
      "16726 Traning Loss: tensor(1.0721)\n",
      "16727 Traning Loss: tensor(1.0720)\n",
      "16728 Traning Loss: tensor(1.0719)\n",
      "16729 Traning Loss: tensor(1.0718)\n",
      "16730 Traning Loss: tensor(1.0717)\n",
      "16731 Traning Loss: tensor(1.0716)\n",
      "16732 Traning Loss: tensor(1.0715)\n",
      "16733 Traning Loss: tensor(1.0714)\n",
      "16734 Traning Loss: tensor(1.0713)\n",
      "16735 Traning Loss: tensor(1.0712)\n",
      "16736 Traning Loss: tensor(1.0711)\n",
      "16737 Traning Loss: tensor(1.0710)\n",
      "16738 Traning Loss: tensor(1.0710)\n",
      "16739 Traning Loss: tensor(1.0709)\n",
      "16740 Traning Loss: tensor(1.0708)\n",
      "16741 Traning Loss: tensor(1.0707)\n",
      "16742 Traning Loss: tensor(1.0706)\n",
      "16743 Traning Loss: tensor(1.0705)\n",
      "16744 Traning Loss: tensor(1.0704)\n",
      "16745 Traning Loss: tensor(1.0703)\n",
      "16746 Traning Loss: tensor(1.0702)\n",
      "16747 Traning Loss: tensor(1.0701)\n",
      "16748 Traning Loss: tensor(1.0700)\n",
      "16749 Traning Loss: tensor(1.0699)\n",
      "16750 Traning Loss: tensor(1.0698)\n",
      "16751 Traning Loss: tensor(1.0697)\n",
      "16752 Traning Loss: tensor(1.0697)\n",
      "16753 Traning Loss: tensor(1.0696)\n",
      "16754 Traning Loss: tensor(1.0695)\n",
      "16755 Traning Loss: tensor(1.0694)\n",
      "16756 Traning Loss: tensor(1.0693)\n",
      "16757 Traning Loss: tensor(1.0692)\n",
      "16758 Traning Loss: tensor(1.0691)\n",
      "16759 Traning Loss: tensor(1.0690)\n",
      "16760 Traning Loss: tensor(1.0689)\n",
      "16761 Traning Loss: tensor(1.0688)\n",
      "16762 Traning Loss: tensor(1.0687)\n",
      "16763 Traning Loss: tensor(1.0686)\n",
      "16764 Traning Loss: tensor(1.0685)\n",
      "16765 Traning Loss: tensor(1.0685)\n",
      "16766 Traning Loss: tensor(1.0684)\n",
      "16767 Traning Loss: tensor(1.0683)\n",
      "16768 Traning Loss: tensor(1.0682)\n",
      "16769 Traning Loss: tensor(1.0681)\n",
      "16770 Traning Loss: tensor(1.0680)\n",
      "16771 Traning Loss: tensor(1.0679)\n",
      "16772 Traning Loss: tensor(1.0678)\n",
      "16773 Traning Loss: tensor(1.0677)\n",
      "16774 Traning Loss: tensor(1.0676)\n",
      "16775 Traning Loss: tensor(1.0675)\n",
      "16776 Traning Loss: tensor(1.1181)\n",
      "16777 Traning Loss: tensor(1.1179)\n",
      "16778 Traning Loss: tensor(1.1178)\n",
      "16779 Traning Loss: tensor(1.1177)\n",
      "16780 Traning Loss: tensor(1.1175)\n",
      "16781 Traning Loss: tensor(1.1174)\n",
      "16782 Traning Loss: tensor(1.1172)\n",
      "16783 Traning Loss: tensor(1.1171)\n",
      "16784 Traning Loss: tensor(1.1170)\n",
      "16785 Traning Loss: tensor(1.1168)\n",
      "16786 Traning Loss: tensor(1.1167)\n",
      "16787 Traning Loss: tensor(1.1165)\n",
      "16788 Traning Loss: tensor(1.1164)\n",
      "16789 Traning Loss: tensor(1.1162)\n",
      "16790 Traning Loss: tensor(1.1160)\n",
      "16791 Traning Loss: tensor(1.1159)\n",
      "16792 Traning Loss: tensor(1.1157)\n",
      "16793 Traning Loss: tensor(1.1156)\n",
      "16794 Traning Loss: tensor(1.1154)\n",
      "16795 Traning Loss: tensor(1.1153)\n",
      "16796 Traning Loss: tensor(1.1151)\n",
      "16797 Traning Loss: tensor(1.1149)\n",
      "16798 Traning Loss: tensor(1.1148)\n",
      "16799 Traning Loss: tensor(1.1146)\n",
      "16800 Traning Loss: tensor(1.1145)\n",
      "16801 Traning Loss: tensor(1.1143)\n",
      "16802 Traning Loss: tensor(1.1141)\n",
      "16803 Traning Loss: tensor(1.1140)\n",
      "16804 Traning Loss: tensor(1.1138)\n",
      "16805 Traning Loss: tensor(1.1137)\n",
      "16806 Traning Loss: tensor(1.1135)\n",
      "16807 Traning Loss: tensor(1.1133)\n",
      "16808 Traning Loss: tensor(1.1132)\n",
      "16809 Traning Loss: tensor(1.1130)\n",
      "16810 Traning Loss: tensor(1.1129)\n",
      "16811 Traning Loss: tensor(1.1127)\n",
      "16812 Traning Loss: tensor(1.1125)\n",
      "16813 Traning Loss: tensor(1.1124)\n",
      "16814 Traning Loss: tensor(1.1122)\n",
      "16815 Traning Loss: tensor(1.1121)\n",
      "16816 Traning Loss: tensor(1.1119)\n",
      "16817 Traning Loss: tensor(1.1118)\n",
      "16818 Traning Loss: tensor(1.1116)\n",
      "16819 Traning Loss: tensor(1.1114)\n",
      "16820 Traning Loss: tensor(1.1113)\n",
      "16821 Traning Loss: tensor(1.1111)\n",
      "16822 Traning Loss: tensor(1.1110)\n",
      "16823 Traning Loss: tensor(1.1108)\n",
      "16824 Traning Loss: tensor(1.1106)\n",
      "16825 Traning Loss: tensor(1.1105)\n",
      "16826 Traning Loss: tensor(1.1103)\n",
      "16827 Traning Loss: tensor(1.1102)\n",
      "16828 Traning Loss: tensor(1.1100)\n",
      "16829 Traning Loss: tensor(1.1099)\n",
      "16830 Traning Loss: tensor(1.1097)\n",
      "16831 Traning Loss: tensor(1.1095)\n",
      "16832 Traning Loss: tensor(1.1094)\n",
      "16833 Traning Loss: tensor(1.1092)\n",
      "16834 Traning Loss: tensor(1.1091)\n",
      "16835 Traning Loss: tensor(1.1089)\n",
      "16836 Traning Loss: tensor(1.1087)\n",
      "16837 Traning Loss: tensor(1.1086)\n",
      "16838 Traning Loss: tensor(1.1084)\n",
      "16839 Traning Loss: tensor(1.1083)\n",
      "16840 Traning Loss: tensor(1.1081)\n",
      "16841 Traning Loss: tensor(1.1080)\n",
      "16842 Traning Loss: tensor(1.1078)\n",
      "16843 Traning Loss: tensor(1.1076)\n",
      "16844 Traning Loss: tensor(1.1075)\n",
      "16845 Traning Loss: tensor(1.1073)\n",
      "16846 Traning Loss: tensor(1.1072)\n",
      "16847 Traning Loss: tensor(1.1070)\n",
      "16848 Traning Loss: tensor(1.1069)\n",
      "16849 Traning Loss: tensor(1.1067)\n",
      "16850 Traning Loss: tensor(1.1065)\n",
      "16851 Traning Loss: tensor(1.1064)\n",
      "16852 Traning Loss: tensor(1.1062)\n",
      "16853 Traning Loss: tensor(1.1061)\n",
      "16854 Traning Loss: tensor(1.1059)\n",
      "16855 Traning Loss: tensor(1.1058)\n",
      "16856 Traning Loss: tensor(1.1056)\n",
      "16857 Traning Loss: tensor(1.1055)\n",
      "16858 Traning Loss: tensor(1.1053)\n",
      "16859 Traning Loss: tensor(1.1051)\n",
      "16860 Traning Loss: tensor(1.1050)\n",
      "16861 Traning Loss: tensor(1.1048)\n",
      "16862 Traning Loss: tensor(1.1047)\n",
      "16863 Traning Loss: tensor(1.1045)\n",
      "16864 Traning Loss: tensor(1.1044)\n",
      "16865 Traning Loss: tensor(1.1042)\n",
      "16866 Traning Loss: tensor(1.1040)\n",
      "16867 Traning Loss: tensor(1.1039)\n",
      "16868 Traning Loss: tensor(1.1037)\n",
      "16869 Traning Loss: tensor(1.1036)\n",
      "16870 Traning Loss: tensor(1.1034)\n",
      "16871 Traning Loss: tensor(1.1033)\n",
      "16872 Traning Loss: tensor(1.1031)\n",
      "16873 Traning Loss: tensor(1.1030)\n",
      "16874 Traning Loss: tensor(1.1028)\n",
      "16875 Traning Loss: tensor(1.1026)\n",
      "16876 Traning Loss: tensor(1.1025)\n",
      "16877 Traning Loss: tensor(1.1023)\n",
      "16878 Traning Loss: tensor(1.1022)\n",
      "16879 Traning Loss: tensor(1.1020)\n",
      "16880 Traning Loss: tensor(1.1019)\n",
      "16881 Traning Loss: tensor(1.1017)\n",
      "16882 Traning Loss: tensor(1.1015)\n",
      "16883 Traning Loss: tensor(1.1014)\n",
      "16884 Traning Loss: tensor(1.1012)\n",
      "16885 Traning Loss: tensor(1.1011)\n",
      "16886 Traning Loss: tensor(1.1009)\n",
      "16887 Traning Loss: tensor(1.1008)\n",
      "16888 Traning Loss: tensor(1.1006)\n",
      "16889 Traning Loss: tensor(1.1005)\n",
      "16890 Traning Loss: tensor(1.1003)\n",
      "16891 Traning Loss: tensor(1.1001)\n",
      "16892 Traning Loss: tensor(1.1000)\n",
      "16893 Traning Loss: tensor(1.0998)\n",
      "16894 Traning Loss: tensor(1.0997)\n",
      "16895 Traning Loss: tensor(1.0995)\n",
      "16896 Traning Loss: tensor(1.0994)\n",
      "16897 Traning Loss: tensor(1.0992)\n",
      "16898 Traning Loss: tensor(1.0991)\n",
      "16899 Traning Loss: tensor(1.0989)\n",
      "16900 Traning Loss: tensor(1.0987)\n",
      "16901 Traning Loss: tensor(1.0986)\n",
      "16902 Traning Loss: tensor(1.0984)\n",
      "16903 Traning Loss: tensor(1.0983)\n",
      "16904 Traning Loss: tensor(1.0981)\n",
      "16905 Traning Loss: tensor(1.0980)\n",
      "16906 Traning Loss: tensor(1.0978)\n",
      "16907 Traning Loss: tensor(1.0977)\n",
      "16908 Traning Loss: tensor(1.0975)\n",
      "16909 Traning Loss: tensor(1.0974)\n",
      "16910 Traning Loss: tensor(1.0972)\n",
      "16911 Traning Loss: tensor(1.0970)\n",
      "16912 Traning Loss: tensor(1.0969)\n",
      "16913 Traning Loss: tensor(1.0967)\n",
      "16914 Traning Loss: tensor(1.0966)\n",
      "16915 Traning Loss: tensor(1.0964)\n",
      "16916 Traning Loss: tensor(1.0963)\n",
      "16917 Traning Loss: tensor(1.0961)\n",
      "16918 Traning Loss: tensor(1.0960)\n",
      "16919 Traning Loss: tensor(1.0958)\n",
      "16920 Traning Loss: tensor(1.0956)\n",
      "16921 Traning Loss: tensor(1.0955)\n",
      "16922 Traning Loss: tensor(1.0953)\n",
      "16923 Traning Loss: tensor(1.0952)\n",
      "16924 Traning Loss: tensor(1.0950)\n",
      "16925 Traning Loss: tensor(1.0949)\n",
      "16926 Traning Loss: tensor(1.0947)\n",
      "16927 Traning Loss: tensor(1.0946)\n",
      "16928 Traning Loss: tensor(1.0944)\n",
      "16929 Traning Loss: tensor(1.0943)\n",
      "16930 Traning Loss: tensor(1.0941)\n",
      "16931 Traning Loss: tensor(1.0939)\n",
      "16932 Traning Loss: tensor(1.0938)\n",
      "16933 Traning Loss: tensor(1.0936)\n",
      "16934 Traning Loss: tensor(1.0935)\n",
      "16935 Traning Loss: tensor(1.0933)\n",
      "16936 Traning Loss: tensor(1.0932)\n",
      "16937 Traning Loss: tensor(1.0930)\n",
      "16938 Traning Loss: tensor(1.0929)\n",
      "16939 Traning Loss: tensor(1.0927)\n",
      "16940 Traning Loss: tensor(1.0926)\n",
      "16941 Traning Loss: tensor(1.0924)\n",
      "16942 Traning Loss: tensor(1.0923)\n",
      "16943 Traning Loss: tensor(1.0921)\n",
      "16944 Traning Loss: tensor(1.0919)\n",
      "16945 Traning Loss: tensor(1.0918)\n",
      "16946 Traning Loss: tensor(1.0916)\n",
      "16947 Traning Loss: tensor(1.0915)\n",
      "16948 Traning Loss: tensor(1.0913)\n",
      "16949 Traning Loss: tensor(1.0912)\n",
      "16950 Traning Loss: tensor(1.0910)\n",
      "16951 Traning Loss: tensor(1.0909)\n",
      "16952 Traning Loss: tensor(1.0907)\n",
      "16953 Traning Loss: tensor(1.0906)\n",
      "16954 Traning Loss: tensor(1.0904)\n",
      "16955 Traning Loss: tensor(1.0903)\n",
      "16956 Traning Loss: tensor(1.0901)\n",
      "16957 Traning Loss: tensor(1.0734)\n",
      "16958 Traning Loss: tensor(1.0733)\n",
      "16959 Traning Loss: tensor(1.0732)\n",
      "16960 Traning Loss: tensor(1.0731)\n",
      "16961 Traning Loss: tensor(1.0729)\n",
      "16962 Traning Loss: tensor(1.0728)\n",
      "16963 Traning Loss: tensor(1.0727)\n",
      "16964 Traning Loss: tensor(1.0726)\n",
      "16965 Traning Loss: tensor(1.0725)\n",
      "16966 Traning Loss: tensor(1.0724)\n",
      "16967 Traning Loss: tensor(1.0723)\n",
      "16968 Traning Loss: tensor(1.0721)\n",
      "16969 Traning Loss: tensor(1.0720)\n",
      "16970 Traning Loss: tensor(1.0719)\n",
      "16971 Traning Loss: tensor(1.0718)\n",
      "16972 Traning Loss: tensor(1.0717)\n",
      "16973 Traning Loss: tensor(1.0716)\n",
      "16974 Traning Loss: tensor(1.0715)\n",
      "16975 Traning Loss: tensor(1.0714)\n",
      "16976 Traning Loss: tensor(1.0713)\n",
      "16977 Traning Loss: tensor(1.0712)\n",
      "16978 Traning Loss: tensor(1.0711)\n",
      "16979 Traning Loss: tensor(1.0710)\n",
      "16980 Traning Loss: tensor(1.0709)\n",
      "16981 Traning Loss: tensor(1.0708)\n",
      "16982 Traning Loss: tensor(1.0707)\n",
      "16983 Traning Loss: tensor(1.0705)\n",
      "16984 Traning Loss: tensor(1.0704)\n",
      "16985 Traning Loss: tensor(1.0703)\n",
      "16986 Traning Loss: tensor(1.0702)\n",
      "16987 Traning Loss: tensor(1.0701)\n",
      "16988 Traning Loss: tensor(1.0700)\n",
      "16989 Traning Loss: tensor(1.0699)\n",
      "16990 Traning Loss: tensor(1.0698)\n",
      "16991 Traning Loss: tensor(1.0697)\n",
      "16992 Traning Loss: tensor(1.0696)\n",
      "16993 Traning Loss: tensor(1.0695)\n",
      "16994 Traning Loss: tensor(1.0694)\n",
      "16995 Traning Loss: tensor(1.0693)\n",
      "16996 Traning Loss: tensor(1.0692)\n",
      "16997 Traning Loss: tensor(1.0691)\n",
      "16998 Traning Loss: tensor(1.0690)\n",
      "16999 Traning Loss: tensor(1.0689)\n",
      "17000 Traning Loss: tensor(1.0688)\n",
      "17001 Traning Loss: tensor(1.0687)\n",
      "17002 Traning Loss: tensor(1.0686)\n",
      "17003 Traning Loss: tensor(1.0685)\n",
      "17004 Traning Loss: tensor(1.0684)\n",
      "17005 Traning Loss: tensor(1.0683)\n",
      "17006 Traning Loss: tensor(1.0682)\n",
      "17007 Traning Loss: tensor(1.0681)\n",
      "17008 Traning Loss: tensor(1.0680)\n",
      "17009 Traning Loss: tensor(1.0679)\n",
      "17010 Traning Loss: tensor(1.0678)\n",
      "17011 Traning Loss: tensor(1.0677)\n",
      "17012 Traning Loss: tensor(1.0675)\n",
      "17013 Traning Loss: tensor(1.0674)\n",
      "17014 Traning Loss: tensor(1.0673)\n",
      "17015 Traning Loss: tensor(1.0672)\n",
      "17016 Traning Loss: tensor(1.0671)\n",
      "17017 Traning Loss: tensor(1.0670)\n",
      "17018 Traning Loss: tensor(1.0669)\n",
      "17019 Traning Loss: tensor(1.0668)\n",
      "17020 Traning Loss: tensor(1.0667)\n",
      "17021 Traning Loss: tensor(1.0666)\n",
      "17022 Traning Loss: tensor(1.0665)\n",
      "17023 Traning Loss: tensor(1.0664)\n",
      "17024 Traning Loss: tensor(1.0663)\n",
      "17025 Traning Loss: tensor(1.0662)\n",
      "17026 Traning Loss: tensor(1.0661)\n",
      "17027 Traning Loss: tensor(1.0660)\n",
      "17028 Traning Loss: tensor(1.0659)\n",
      "17029 Traning Loss: tensor(1.0658)\n",
      "17030 Traning Loss: tensor(1.0657)\n",
      "17031 Traning Loss: tensor(1.0656)\n",
      "17032 Traning Loss: tensor(1.0655)\n",
      "17033 Traning Loss: tensor(1.0654)\n",
      "17034 Traning Loss: tensor(1.0653)\n",
      "17035 Traning Loss: tensor(1.0652)\n",
      "17036 Traning Loss: tensor(1.0651)\n",
      "17037 Traning Loss: tensor(1.0650)\n",
      "17038 Traning Loss: tensor(1.0649)\n",
      "17039 Traning Loss: tensor(1.0648)\n",
      "17040 Traning Loss: tensor(1.0647)\n",
      "17041 Traning Loss: tensor(1.0646)\n",
      "17042 Traning Loss: tensor(1.0645)\n",
      "17043 Traning Loss: tensor(1.0644)\n",
      "17044 Traning Loss: tensor(1.0642)\n",
      "17045 Traning Loss: tensor(1.0641)\n",
      "17046 Traning Loss: tensor(1.0640)\n",
      "17047 Traning Loss: tensor(1.0639)\n",
      "17048 Traning Loss: tensor(1.0638)\n",
      "17049 Traning Loss: tensor(1.0637)\n",
      "17050 Traning Loss: tensor(1.0636)\n",
      "17051 Traning Loss: tensor(1.0635)\n",
      "17052 Traning Loss: tensor(1.0634)\n",
      "17053 Traning Loss: tensor(1.0633)\n",
      "17054 Traning Loss: tensor(1.0632)\n",
      "17055 Traning Loss: tensor(1.0631)\n",
      "17056 Traning Loss: tensor(1.0630)\n",
      "17057 Traning Loss: tensor(1.0629)\n",
      "17058 Traning Loss: tensor(1.0628)\n",
      "17059 Traning Loss: tensor(1.0627)\n",
      "17060 Traning Loss: tensor(1.0626)\n",
      "17061 Traning Loss: tensor(1.0625)\n",
      "17062 Traning Loss: tensor(1.0624)\n",
      "17063 Traning Loss: tensor(1.0623)\n",
      "17064 Traning Loss: tensor(1.0622)\n",
      "17065 Traning Loss: tensor(1.0621)\n",
      "17066 Traning Loss: tensor(1.0620)\n",
      "17067 Traning Loss: tensor(1.0619)\n",
      "17068 Traning Loss: tensor(1.0618)\n",
      "17069 Traning Loss: tensor(1.0617)\n",
      "17070 Traning Loss: tensor(1.0616)\n",
      "17071 Traning Loss: tensor(1.0615)\n",
      "17072 Traning Loss: tensor(1.0614)\n",
      "17073 Traning Loss: tensor(1.0613)\n",
      "17074 Traning Loss: tensor(1.0611)\n",
      "17075 Traning Loss: tensor(1.0610)\n",
      "17076 Traning Loss: tensor(1.0609)\n",
      "17077 Traning Loss: tensor(1.0608)\n",
      "17078 Traning Loss: tensor(1.0607)\n",
      "17079 Traning Loss: tensor(1.0606)\n",
      "17080 Traning Loss: tensor(1.0605)\n",
      "17081 Traning Loss: tensor(1.0604)\n",
      "17082 Traning Loss: tensor(1.0603)\n",
      "17083 Traning Loss: tensor(1.0602)\n",
      "17084 Traning Loss: tensor(1.0601)\n",
      "17085 Traning Loss: tensor(1.0600)\n",
      "17086 Traning Loss: tensor(1.0599)\n",
      "17087 Traning Loss: tensor(1.0598)\n",
      "17088 Traning Loss: tensor(1.0597)\n",
      "17089 Traning Loss: tensor(1.0596)\n",
      "17090 Traning Loss: tensor(1.0595)\n",
      "17091 Traning Loss: tensor(1.0594)\n",
      "17092 Traning Loss: tensor(1.0593)\n",
      "17093 Traning Loss: tensor(1.0592)\n",
      "17094 Traning Loss: tensor(1.0591)\n",
      "17095 Traning Loss: tensor(1.0590)\n",
      "17096 Traning Loss: tensor(1.0589)\n",
      "17097 Traning Loss: tensor(1.0588)\n",
      "17098 Traning Loss: tensor(1.0587)\n",
      "17099 Traning Loss: tensor(1.0586)\n",
      "17100 Traning Loss: tensor(1.0585)\n",
      "17101 Traning Loss: tensor(1.0584)\n",
      "17102 Traning Loss: tensor(1.0583)\n",
      "17103 Traning Loss: tensor(1.0581)\n",
      "17104 Traning Loss: tensor(1.0580)\n",
      "17105 Traning Loss: tensor(1.0579)\n",
      "17106 Traning Loss: tensor(1.0578)\n",
      "17107 Traning Loss: tensor(1.0577)\n",
      "17108 Traning Loss: tensor(1.0576)\n",
      "17109 Traning Loss: tensor(1.0575)\n",
      "17110 Traning Loss: tensor(1.0574)\n",
      "17111 Traning Loss: tensor(1.0573)\n",
      "17112 Traning Loss: tensor(1.0572)\n",
      "17113 Traning Loss: tensor(1.0571)\n",
      "17114 Traning Loss: tensor(1.0570)\n",
      "17115 Traning Loss: tensor(1.0569)\n",
      "17116 Traning Loss: tensor(1.0568)\n",
      "17117 Traning Loss: tensor(1.0567)\n",
      "17118 Traning Loss: tensor(1.0566)\n",
      "17119 Traning Loss: tensor(1.0565)\n",
      "17120 Traning Loss: tensor(1.0564)\n",
      "17121 Traning Loss: tensor(1.0563)\n",
      "17122 Traning Loss: tensor(1.0562)\n",
      "17123 Traning Loss: tensor(1.0561)\n",
      "17124 Traning Loss: tensor(1.0560)\n",
      "17125 Traning Loss: tensor(1.0559)\n",
      "17126 Traning Loss: tensor(1.0558)\n",
      "17127 Traning Loss: tensor(1.0557)\n",
      "17128 Traning Loss: tensor(1.0556)\n",
      "17129 Traning Loss: tensor(1.0555)\n",
      "17130 Traning Loss: tensor(1.0554)\n",
      "17131 Traning Loss: tensor(1.0553)\n",
      "17132 Traning Loss: tensor(1.0551)\n",
      "17133 Traning Loss: tensor(1.0550)\n",
      "17134 Traning Loss: tensor(1.0549)\n",
      "17135 Traning Loss: tensor(1.0548)\n",
      "17136 Traning Loss: tensor(1.0547)\n",
      "17137 Traning Loss: tensor(1.0546)\n",
      "17138 Traning Loss: tensor(1.0545)\n",
      "17139 Traning Loss: tensor(1.0544)\n",
      "17140 Traning Loss: tensor(1.0543)\n",
      "17141 Traning Loss: tensor(1.0542)\n",
      "17142 Traning Loss: tensor(1.0541)\n",
      "17143 Traning Loss: tensor(1.0540)\n",
      "17144 Traning Loss: tensor(1.0539)\n",
      "17145 Traning Loss: tensor(1.0538)\n",
      "17146 Traning Loss: tensor(1.0537)\n",
      "17147 Traning Loss: tensor(1.0536)\n",
      "17148 Traning Loss: tensor(1.0535)\n",
      "17149 Traning Loss: tensor(1.0534)\n",
      "17150 Traning Loss: tensor(1.0533)\n",
      "17151 Traning Loss: tensor(1.0532)\n",
      "17152 Traning Loss: tensor(1.0531)\n",
      "17153 Traning Loss: tensor(1.0530)\n",
      "17154 Traning Loss: tensor(1.0529)\n",
      "17155 Traning Loss: tensor(1.0528)\n",
      "17156 Traning Loss: tensor(1.0527)\n",
      "17157 Traning Loss: tensor(1.0526)\n",
      "17158 Traning Loss: tensor(1.0525)\n",
      "17159 Traning Loss: tensor(1.0523)\n",
      "17160 Traning Loss: tensor(1.0522)\n",
      "17161 Traning Loss: tensor(1.0521)\n",
      "17162 Traning Loss: tensor(1.0520)\n",
      "17163 Traning Loss: tensor(1.0519)\n",
      "17164 Traning Loss: tensor(1.0518)\n",
      "17165 Traning Loss: tensor(1.0517)\n",
      "17166 Traning Loss: tensor(1.0516)\n",
      "17167 Traning Loss: tensor(1.0515)\n",
      "17168 Traning Loss: tensor(1.0514)\n",
      "17169 Traning Loss: tensor(1.0513)\n",
      "17170 Traning Loss: tensor(1.0512)\n",
      "17171 Traning Loss: tensor(1.0511)\n",
      "17172 Traning Loss: tensor(1.0510)\n",
      "17173 Traning Loss: tensor(1.0509)\n",
      "17174 Traning Loss: tensor(1.0508)\n",
      "17175 Traning Loss: tensor(1.0507)\n",
      "17176 Traning Loss: tensor(1.0506)\n",
      "17177 Traning Loss: tensor(1.0505)\n",
      "17178 Traning Loss: tensor(1.0504)\n",
      "17179 Traning Loss: tensor(1.0503)\n",
      "17180 Traning Loss: tensor(1.0502)\n",
      "17181 Traning Loss: tensor(1.0501)\n",
      "17182 Traning Loss: tensor(1.0500)\n",
      "17183 Traning Loss: tensor(1.0499)\n",
      "17184 Traning Loss: tensor(1.0498)\n",
      "17185 Traning Loss: tensor(1.0497)\n",
      "17186 Traning Loss: tensor(1.0496)\n",
      "17187 Traning Loss: tensor(1.0494)\n",
      "17188 Traning Loss: tensor(1.0493)\n",
      "17189 Traning Loss: tensor(1.0492)\n",
      "17190 Traning Loss: tensor(1.0491)\n",
      "17191 Traning Loss: tensor(1.0490)\n",
      "17192 Traning Loss: tensor(1.0489)\n",
      "17193 Traning Loss: tensor(1.0488)\n",
      "17194 Traning Loss: tensor(1.0487)\n",
      "17195 Traning Loss: tensor(1.0486)\n",
      "17196 Traning Loss: tensor(1.0485)\n",
      "17197 Traning Loss: tensor(1.0484)\n",
      "17198 Traning Loss: tensor(1.0483)\n",
      "17199 Traning Loss: tensor(1.0482)\n",
      "17200 Traning Loss: tensor(1.0481)\n",
      "17201 Traning Loss: tensor(1.0480)\n",
      "17202 Traning Loss: tensor(1.0479)\n",
      "17203 Traning Loss: tensor(1.0478)\n",
      "17204 Traning Loss: tensor(1.0477)\n",
      "17205 Traning Loss: tensor(1.0476)\n",
      "17206 Traning Loss: tensor(1.0475)\n",
      "17207 Traning Loss: tensor(1.0474)\n",
      "17208 Traning Loss: tensor(1.0473)\n",
      "17209 Traning Loss: tensor(1.0472)\n",
      "17210 Traning Loss: tensor(1.0471)\n",
      "17211 Traning Loss: tensor(1.0470)\n",
      "17212 Traning Loss: tensor(1.0469)\n",
      "17213 Traning Loss: tensor(1.0468)\n",
      "17214 Traning Loss: tensor(1.0466)\n",
      "17215 Traning Loss: tensor(1.0465)\n",
      "17216 Traning Loss: tensor(1.0464)\n",
      "17217 Traning Loss: tensor(1.0463)\n",
      "17218 Traning Loss: tensor(1.0462)\n",
      "17219 Traning Loss: tensor(1.0461)\n",
      "17220 Traning Loss: tensor(1.0460)\n",
      "17221 Traning Loss: tensor(1.0459)\n",
      "17222 Traning Loss: tensor(1.0458)\n",
      "17223 Traning Loss: tensor(1.0457)\n",
      "17224 Traning Loss: tensor(1.0456)\n",
      "17225 Traning Loss: tensor(1.0455)\n",
      "17226 Traning Loss: tensor(1.0454)\n",
      "17227 Traning Loss: tensor(1.0453)\n",
      "17228 Traning Loss: tensor(1.0452)\n",
      "17229 Traning Loss: tensor(1.0451)\n",
      "17230 Traning Loss: tensor(1.0450)\n",
      "17231 Traning Loss: tensor(1.0449)\n",
      "17232 Traning Loss: tensor(1.0448)\n",
      "17233 Traning Loss: tensor(1.0447)\n",
      "17234 Traning Loss: tensor(1.0446)\n",
      "17235 Traning Loss: tensor(1.0445)\n",
      "17236 Traning Loss: tensor(1.0444)\n",
      "17237 Traning Loss: tensor(1.0443)\n",
      "17238 Traning Loss: tensor(1.0442)\n",
      "17239 Traning Loss: tensor(1.0441)\n",
      "17240 Traning Loss: tensor(1.0440)\n",
      "17241 Traning Loss: tensor(1.0439)\n",
      "17242 Traning Loss: tensor(1.0437)\n",
      "17243 Traning Loss: tensor(1.0436)\n",
      "17244 Traning Loss: tensor(1.0435)\n",
      "17245 Traning Loss: tensor(1.0434)\n",
      "17246 Traning Loss: tensor(1.0433)\n",
      "17247 Traning Loss: tensor(1.0432)\n",
      "17248 Traning Loss: tensor(1.0431)\n",
      "17249 Traning Loss: tensor(1.0430)\n",
      "17250 Traning Loss: tensor(1.0429)\n",
      "17251 Traning Loss: tensor(1.0428)\n",
      "17252 Traning Loss: tensor(1.0427)\n",
      "17253 Traning Loss: tensor(1.0426)\n",
      "17254 Traning Loss: tensor(1.0425)\n",
      "17255 Traning Loss: tensor(1.0424)\n",
      "17256 Traning Loss: tensor(1.0423)\n",
      "17257 Traning Loss: tensor(1.0422)\n",
      "17258 Traning Loss: tensor(1.0421)\n",
      "17259 Traning Loss: tensor(1.0420)\n",
      "17260 Traning Loss: tensor(1.0419)\n",
      "17261 Traning Loss: tensor(1.0418)\n",
      "17262 Traning Loss: tensor(1.0417)\n",
      "17263 Traning Loss: tensor(1.0416)\n",
      "17264 Traning Loss: tensor(1.0415)\n",
      "17265 Traning Loss: tensor(1.0414)\n",
      "17266 Traning Loss: tensor(1.0413)\n",
      "17267 Traning Loss: tensor(1.0412)\n",
      "17268 Traning Loss: tensor(1.0411)\n",
      "17269 Traning Loss: tensor(1.0410)\n",
      "17270 Traning Loss: tensor(1.0408)\n",
      "17271 Traning Loss: tensor(1.0407)\n",
      "17272 Traning Loss: tensor(1.0406)\n",
      "17273 Traning Loss: tensor(1.0405)\n",
      "17274 Traning Loss: tensor(1.0404)\n",
      "17275 Traning Loss: tensor(1.0403)\n",
      "17276 Traning Loss: tensor(1.0402)\n",
      "17277 Traning Loss: tensor(1.0401)\n",
      "17278 Traning Loss: tensor(1.0400)\n",
      "17279 Traning Loss: tensor(1.0399)\n",
      "17280 Traning Loss: tensor(1.0398)\n",
      "17281 Traning Loss: tensor(1.0397)\n",
      "17282 Traning Loss: tensor(1.0396)\n",
      "17283 Traning Loss: tensor(1.0395)\n",
      "17284 Traning Loss: tensor(1.0394)\n",
      "17285 Traning Loss: tensor(1.0393)\n",
      "17286 Traning Loss: tensor(1.0392)\n",
      "17287 Traning Loss: tensor(1.0391)\n",
      "17288 Traning Loss: tensor(1.0390)\n",
      "17289 Traning Loss: tensor(1.0389)\n",
      "17290 Traning Loss: tensor(1.0388)\n",
      "17291 Traning Loss: tensor(1.0387)\n",
      "17292 Traning Loss: tensor(1.0386)\n",
      "17293 Traning Loss: tensor(1.0385)\n",
      "17294 Traning Loss: tensor(1.0384)\n",
      "17295 Traning Loss: tensor(1.0383)\n",
      "17296 Traning Loss: tensor(1.0382)\n",
      "17297 Traning Loss: tensor(1.0381)\n",
      "17298 Traning Loss: tensor(1.0380)\n",
      "17299 Traning Loss: tensor(1.0378)\n",
      "17300 Traning Loss: tensor(1.0377)\n",
      "17301 Traning Loss: tensor(1.0376)\n",
      "17302 Traning Loss: tensor(1.0375)\n",
      "17303 Traning Loss: tensor(1.0374)\n",
      "17304 Traning Loss: tensor(1.0373)\n",
      "17305 Traning Loss: tensor(1.0372)\n",
      "17306 Traning Loss: tensor(1.0371)\n",
      "17307 Traning Loss: tensor(1.0370)\n",
      "17308 Traning Loss: tensor(1.0369)\n",
      "17309 Traning Loss: tensor(1.0368)\n",
      "17310 Traning Loss: tensor(1.0367)\n",
      "17311 Traning Loss: tensor(1.0366)\n",
      "17312 Traning Loss: tensor(1.0365)\n",
      "17313 Traning Loss: tensor(1.0364)\n",
      "17314 Traning Loss: tensor(1.0363)\n",
      "17315 Traning Loss: tensor(1.0362)\n",
      "17316 Traning Loss: tensor(1.0361)\n",
      "17317 Traning Loss: tensor(1.0360)\n",
      "17318 Traning Loss: tensor(1.0359)\n",
      "17319 Traning Loss: tensor(1.0358)\n",
      "17320 Traning Loss: tensor(1.0357)\n",
      "17321 Traning Loss: tensor(1.0356)\n",
      "17322 Traning Loss: tensor(1.0355)\n",
      "17323 Traning Loss: tensor(1.0354)\n",
      "17324 Traning Loss: tensor(1.0353)\n",
      "17325 Traning Loss: tensor(1.0352)\n",
      "17326 Traning Loss: tensor(1.0351)\n",
      "17327 Traning Loss: tensor(1.0350)\n",
      "17328 Traning Loss: tensor(1.0349)\n",
      "17329 Traning Loss: tensor(1.0347)\n",
      "17330 Traning Loss: tensor(1.0346)\n",
      "17331 Traning Loss: tensor(1.0345)\n",
      "17332 Traning Loss: tensor(1.0344)\n",
      "17333 Traning Loss: tensor(1.0343)\n",
      "17334 Traning Loss: tensor(1.0342)\n",
      "17335 Traning Loss: tensor(1.0341)\n",
      "17336 Traning Loss: tensor(1.0340)\n",
      "17337 Traning Loss: tensor(1.0339)\n",
      "17338 Traning Loss: tensor(1.0338)\n",
      "17339 Traning Loss: tensor(1.0337)\n",
      "17340 Traning Loss: tensor(1.0336)\n",
      "17341 Traning Loss: tensor(1.0335)\n",
      "17342 Traning Loss: tensor(1.0334)\n",
      "17343 Traning Loss: tensor(1.0333)\n",
      "17344 Traning Loss: tensor(1.0332)\n",
      "17345 Traning Loss: tensor(1.0331)\n",
      "17346 Traning Loss: tensor(1.0330)\n",
      "17347 Traning Loss: tensor(1.0329)\n",
      "17348 Traning Loss: tensor(1.0328)\n",
      "17349 Traning Loss: tensor(1.0327)\n",
      "17350 Traning Loss: tensor(1.0326)\n",
      "17351 Traning Loss: tensor(1.0325)\n",
      "17352 Traning Loss: tensor(1.0324)\n",
      "17353 Traning Loss: tensor(1.0323)\n",
      "17354 Traning Loss: tensor(1.0322)\n",
      "17355 Traning Loss: tensor(1.0321)\n",
      "17356 Traning Loss: tensor(1.0320)\n",
      "17357 Traning Loss: tensor(1.0319)\n",
      "17358 Traning Loss: tensor(1.0318)\n",
      "17359 Traning Loss: tensor(1.0317)\n",
      "17360 Traning Loss: tensor(1.0316)\n",
      "17361 Traning Loss: tensor(1.0314)\n",
      "17362 Traning Loss: tensor(1.0313)\n",
      "17363 Traning Loss: tensor(1.0312)\n",
      "17364 Traning Loss: tensor(1.0311)\n",
      "17365 Traning Loss: tensor(1.0310)\n",
      "17366 Traning Loss: tensor(1.0309)\n",
      "17367 Traning Loss: tensor(1.0308)\n",
      "17368 Traning Loss: tensor(1.0307)\n",
      "17369 Traning Loss: tensor(1.0306)\n",
      "17370 Traning Loss: tensor(1.0305)\n",
      "17371 Traning Loss: tensor(1.0304)\n",
      "17372 Traning Loss: tensor(1.0303)\n",
      "17373 Traning Loss: tensor(1.0302)\n",
      "17374 Traning Loss: tensor(1.0301)\n",
      "17375 Traning Loss: tensor(1.0300)\n",
      "17376 Traning Loss: tensor(1.0299)\n",
      "17377 Traning Loss: tensor(1.0298)\n",
      "17378 Traning Loss: tensor(1.0297)\n",
      "17379 Traning Loss: tensor(1.0296)\n",
      "17380 Traning Loss: tensor(1.0295)\n",
      "17381 Traning Loss: tensor(1.0294)\n",
      "17382 Traning Loss: tensor(1.0293)\n",
      "17383 Traning Loss: tensor(1.0292)\n",
      "17384 Traning Loss: tensor(1.0291)\n",
      "17385 Traning Loss: tensor(1.0290)\n",
      "17386 Traning Loss: tensor(1.0289)\n",
      "17387 Traning Loss: tensor(1.0288)\n",
      "17388 Traning Loss: tensor(1.0287)\n",
      "17389 Traning Loss: tensor(1.0286)\n",
      "17390 Traning Loss: tensor(1.0285)\n",
      "17391 Traning Loss: tensor(1.0284)\n",
      "17392 Traning Loss: tensor(1.0283)\n",
      "17393 Traning Loss: tensor(1.0282)\n",
      "17394 Traning Loss: tensor(1.0281)\n",
      "17395 Traning Loss: tensor(1.0280)\n",
      "17396 Traning Loss: tensor(1.0278)\n",
      "17397 Traning Loss: tensor(1.0277)\n",
      "17398 Traning Loss: tensor(1.0276)\n",
      "17399 Traning Loss: tensor(1.0275)\n",
      "17400 Traning Loss: tensor(1.0274)\n",
      "17401 Traning Loss: tensor(1.0273)\n",
      "17402 Traning Loss: tensor(1.0272)\n",
      "17403 Traning Loss: tensor(1.0271)\n",
      "17404 Traning Loss: tensor(1.0270)\n",
      "17405 Traning Loss: tensor(1.0269)\n",
      "17406 Traning Loss: tensor(1.0268)\n",
      "17407 Traning Loss: tensor(1.0267)\n",
      "17408 Traning Loss: tensor(1.0266)\n",
      "17409 Traning Loss: tensor(1.0265)\n",
      "17410 Traning Loss: tensor(1.0264)\n",
      "17411 Traning Loss: tensor(1.0263)\n",
      "17412 Traning Loss: tensor(1.0262)\n",
      "17413 Traning Loss: tensor(1.0261)\n",
      "17414 Traning Loss: tensor(1.0260)\n",
      "17415 Traning Loss: tensor(1.0259)\n",
      "17416 Traning Loss: tensor(1.0258)\n",
      "17417 Traning Loss: tensor(1.0257)\n",
      "17418 Traning Loss: tensor(1.0256)\n",
      "17419 Traning Loss: tensor(1.0255)\n",
      "17420 Traning Loss: tensor(1.0254)\n",
      "17421 Traning Loss: tensor(1.0253)\n",
      "17422 Traning Loss: tensor(1.0252)\n",
      "17423 Traning Loss: tensor(1.0251)\n",
      "17424 Traning Loss: tensor(1.0250)\n",
      "17425 Traning Loss: tensor(1.0249)\n",
      "17426 Traning Loss: tensor(1.0248)\n",
      "17427 Traning Loss: tensor(1.0247)\n",
      "17428 Traning Loss: tensor(1.0246)\n",
      "17429 Traning Loss: tensor(1.0245)\n",
      "17430 Traning Loss: tensor(1.0244)\n",
      "17431 Traning Loss: tensor(1.0243)\n",
      "17432 Traning Loss: tensor(1.0242)\n",
      "17433 Traning Loss: tensor(1.0241)\n",
      "17434 Traning Loss: tensor(1.0240)\n",
      "17435 Traning Loss: tensor(1.0239)\n",
      "17436 Traning Loss: tensor(1.0237)\n",
      "17437 Traning Loss: tensor(1.0236)\n",
      "17438 Traning Loss: tensor(1.0235)\n",
      "17439 Traning Loss: tensor(1.0234)\n",
      "17440 Traning Loss: tensor(1.0233)\n",
      "17441 Traning Loss: tensor(1.0232)\n",
      "17442 Traning Loss: tensor(1.0231)\n",
      "17443 Traning Loss: tensor(1.0230)\n",
      "17444 Traning Loss: tensor(1.0229)\n",
      "17445 Traning Loss: tensor(1.0228)\n",
      "17446 Traning Loss: tensor(1.0227)\n",
      "17447 Traning Loss: tensor(1.0226)\n",
      "17448 Traning Loss: tensor(1.0225)\n",
      "17449 Traning Loss: tensor(1.0224)\n",
      "17450 Traning Loss: tensor(1.0223)\n",
      "17451 Traning Loss: tensor(1.0222)\n",
      "17452 Traning Loss: tensor(1.0221)\n",
      "17453 Traning Loss: tensor(1.0220)\n",
      "17454 Traning Loss: tensor(1.0219)\n",
      "17455 Traning Loss: tensor(1.0218)\n",
      "17456 Traning Loss: tensor(1.0217)\n",
      "17457 Traning Loss: tensor(1.0216)\n",
      "17458 Traning Loss: tensor(1.0215)\n",
      "17459 Traning Loss: tensor(1.0214)\n",
      "17460 Traning Loss: tensor(1.0213)\n",
      "17461 Traning Loss: tensor(1.0212)\n",
      "17462 Traning Loss: tensor(1.0211)\n",
      "17463 Traning Loss: tensor(1.0210)\n",
      "17464 Traning Loss: tensor(1.0209)\n",
      "17465 Traning Loss: tensor(1.0208)\n",
      "17466 Traning Loss: tensor(1.0207)\n",
      "17467 Traning Loss: tensor(1.0206)\n",
      "17468 Traning Loss: tensor(1.0205)\n",
      "17469 Traning Loss: tensor(1.0204)\n",
      "17470 Traning Loss: tensor(1.0203)\n",
      "17471 Traning Loss: tensor(1.0202)\n",
      "17472 Traning Loss: tensor(1.0201)\n",
      "17473 Traning Loss: tensor(1.0200)\n",
      "17474 Traning Loss: tensor(1.0199)\n",
      "17475 Traning Loss: tensor(1.0198)\n",
      "17476 Traning Loss: tensor(1.0197)\n",
      "17477 Traning Loss: tensor(1.0196)\n",
      "17478 Traning Loss: tensor(1.0195)\n",
      "17479 Traning Loss: tensor(1.0194)\n",
      "17480 Traning Loss: tensor(1.0193)\n",
      "17481 Traning Loss: tensor(1.0192)\n",
      "17482 Traning Loss: tensor(1.0191)\n",
      "17483 Traning Loss: tensor(1.0190)\n",
      "17484 Traning Loss: tensor(1.0189)\n",
      "17485 Traning Loss: tensor(1.0188)\n",
      "17486 Traning Loss: tensor(1.0186)\n",
      "17487 Traning Loss: tensor(1.0185)\n",
      "17488 Traning Loss: tensor(1.0184)\n",
      "17489 Traning Loss: tensor(1.0183)\n",
      "17490 Traning Loss: tensor(1.0182)\n",
      "17491 Traning Loss: tensor(1.0181)\n",
      "17492 Traning Loss: tensor(1.0180)\n",
      "17493 Traning Loss: tensor(1.0179)\n",
      "17494 Traning Loss: tensor(1.0178)\n",
      "17495 Traning Loss: tensor(1.0177)\n",
      "17496 Traning Loss: tensor(1.0176)\n",
      "17497 Traning Loss: tensor(1.0175)\n",
      "17498 Traning Loss: tensor(1.0174)\n",
      "17499 Traning Loss: tensor(1.0173)\n",
      "17500 Traning Loss: tensor(1.0172)\n",
      "17501 Traning Loss: tensor(1.0171)\n",
      "17502 Traning Loss: tensor(1.0170)\n",
      "17503 Traning Loss: tensor(1.0169)\n",
      "17504 Traning Loss: tensor(1.0168)\n",
      "17505 Traning Loss: tensor(1.0167)\n",
      "17506 Traning Loss: tensor(0.9963)\n",
      "17507 Traning Loss: tensor(0.9962)\n",
      "17508 Traning Loss: tensor(0.9961)\n",
      "17509 Traning Loss: tensor(0.9961)\n",
      "17510 Traning Loss: tensor(0.9960)\n",
      "17511 Traning Loss: tensor(0.9959)\n",
      "17512 Traning Loss: tensor(0.9959)\n",
      "17513 Traning Loss: tensor(0.9958)\n",
      "17514 Traning Loss: tensor(0.9957)\n",
      "17515 Traning Loss: tensor(0.9957)\n",
      "17516 Traning Loss: tensor(0.9956)\n",
      "17517 Traning Loss: tensor(0.9956)\n",
      "17518 Traning Loss: tensor(0.9955)\n",
      "17519 Traning Loss: tensor(0.9954)\n",
      "17520 Traning Loss: tensor(0.9954)\n",
      "17521 Traning Loss: tensor(0.9953)\n",
      "17522 Traning Loss: tensor(0.9952)\n",
      "17523 Traning Loss: tensor(0.9952)\n",
      "17524 Traning Loss: tensor(0.9951)\n",
      "17525 Traning Loss: tensor(0.9951)\n",
      "17526 Traning Loss: tensor(0.9950)\n",
      "17527 Traning Loss: tensor(0.9950)\n",
      "17528 Traning Loss: tensor(0.9949)\n",
      "17529 Traning Loss: tensor(0.9948)\n",
      "17530 Traning Loss: tensor(0.9948)\n",
      "17531 Traning Loss: tensor(0.9947)\n",
      "17532 Traning Loss: tensor(0.9947)\n",
      "17533 Traning Loss: tensor(0.9946)\n",
      "17534 Traning Loss: tensor(0.9945)\n",
      "17535 Traning Loss: tensor(0.9945)\n",
      "17536 Traning Loss: tensor(0.9944)\n",
      "17537 Traning Loss: tensor(0.9944)\n",
      "17538 Traning Loss: tensor(0.9943)\n",
      "17539 Traning Loss: tensor(0.9943)\n",
      "17540 Traning Loss: tensor(0.9942)\n",
      "17541 Traning Loss: tensor(0.9941)\n",
      "17542 Traning Loss: tensor(0.9941)\n",
      "17543 Traning Loss: tensor(0.9940)\n",
      "17544 Traning Loss: tensor(0.9940)\n",
      "17545 Traning Loss: tensor(0.9939)\n",
      "17546 Traning Loss: tensor(0.9939)\n",
      "17547 Traning Loss: tensor(0.9938)\n",
      "17548 Traning Loss: tensor(0.9937)\n",
      "17549 Traning Loss: tensor(0.9937)\n",
      "17550 Traning Loss: tensor(0.9936)\n",
      "17551 Traning Loss: tensor(0.9936)\n",
      "17552 Traning Loss: tensor(0.9935)\n",
      "17553 Traning Loss: tensor(0.9935)\n",
      "17554 Traning Loss: tensor(0.9934)\n",
      "17555 Traning Loss: tensor(0.9933)\n",
      "17556 Traning Loss: tensor(0.9933)\n",
      "17557 Traning Loss: tensor(0.9932)\n",
      "17558 Traning Loss: tensor(0.9932)\n",
      "17559 Traning Loss: tensor(0.9931)\n",
      "17560 Traning Loss: tensor(0.9931)\n",
      "17561 Traning Loss: tensor(0.9930)\n",
      "17562 Traning Loss: tensor(0.9930)\n",
      "17563 Traning Loss: tensor(0.9929)\n",
      "17564 Traning Loss: tensor(0.9928)\n",
      "17565 Traning Loss: tensor(0.9928)\n",
      "17566 Traning Loss: tensor(0.9927)\n",
      "17567 Traning Loss: tensor(0.9927)\n",
      "17568 Traning Loss: tensor(0.9926)\n",
      "17569 Traning Loss: tensor(0.9926)\n",
      "17570 Traning Loss: tensor(0.9925)\n",
      "17571 Traning Loss: tensor(0.9924)\n",
      "17572 Traning Loss: tensor(0.9924)\n",
      "17573 Traning Loss: tensor(0.9923)\n",
      "17574 Traning Loss: tensor(0.9923)\n",
      "17575 Traning Loss: tensor(0.9922)\n",
      "17576 Traning Loss: tensor(0.9922)\n",
      "17577 Traning Loss: tensor(0.9921)\n",
      "17578 Traning Loss: tensor(0.9920)\n",
      "17579 Traning Loss: tensor(0.9920)\n",
      "17580 Traning Loss: tensor(0.9919)\n",
      "17581 Traning Loss: tensor(1.0563)\n",
      "17582 Traning Loss: tensor(1.0562)\n",
      "17583 Traning Loss: tensor(1.0561)\n",
      "17584 Traning Loss: tensor(1.0560)\n",
      "17585 Traning Loss: tensor(1.0559)\n",
      "17586 Traning Loss: tensor(1.0558)\n",
      "17587 Traning Loss: tensor(1.0557)\n",
      "17588 Traning Loss: tensor(1.0556)\n",
      "17589 Traning Loss: tensor(1.0555)\n",
      "17590 Traning Loss: tensor(1.0553)\n",
      "17591 Traning Loss: tensor(1.0552)\n",
      "17592 Traning Loss: tensor(1.0551)\n",
      "17593 Traning Loss: tensor(1.0550)\n",
      "17594 Traning Loss: tensor(1.0549)\n",
      "17595 Traning Loss: tensor(1.0547)\n",
      "17596 Traning Loss: tensor(1.0546)\n",
      "17597 Traning Loss: tensor(1.0545)\n",
      "17598 Traning Loss: tensor(1.0544)\n",
      "17599 Traning Loss: tensor(1.0542)\n",
      "17600 Traning Loss: tensor(1.0541)\n",
      "17601 Traning Loss: tensor(1.0540)\n",
      "17602 Traning Loss: tensor(1.0539)\n",
      "17603 Traning Loss: tensor(1.0537)\n",
      "17604 Traning Loss: tensor(1.0536)\n",
      "17605 Traning Loss: tensor(1.0535)\n",
      "17606 Traning Loss: tensor(1.0533)\n",
      "17607 Traning Loss: tensor(1.0532)\n",
      "17608 Traning Loss: tensor(1.0531)\n",
      "17609 Traning Loss: tensor(1.0530)\n",
      "17610 Traning Loss: tensor(1.0528)\n",
      "17611 Traning Loss: tensor(1.0527)\n",
      "17612 Traning Loss: tensor(1.0526)\n",
      "17613 Traning Loss: tensor(1.0525)\n",
      "17614 Traning Loss: tensor(1.0523)\n",
      "17615 Traning Loss: tensor(1.0522)\n",
      "17616 Traning Loss: tensor(1.0521)\n",
      "17617 Traning Loss: tensor(1.0520)\n",
      "17618 Traning Loss: tensor(1.0518)\n",
      "17619 Traning Loss: tensor(1.0517)\n",
      "17620 Traning Loss: tensor(1.0516)\n",
      "17621 Traning Loss: tensor(1.0515)\n",
      "17622 Traning Loss: tensor(1.0513)\n",
      "17623 Traning Loss: tensor(1.0512)\n",
      "17624 Traning Loss: tensor(1.0511)\n",
      "17625 Traning Loss: tensor(1.0510)\n",
      "17626 Traning Loss: tensor(1.0509)\n",
      "17627 Traning Loss: tensor(1.0507)\n",
      "17628 Traning Loss: tensor(1.0506)\n",
      "17629 Traning Loss: tensor(1.0505)\n",
      "17630 Traning Loss: tensor(1.0504)\n",
      "17631 Traning Loss: tensor(1.0502)\n",
      "17632 Traning Loss: tensor(1.0501)\n",
      "17633 Traning Loss: tensor(1.0500)\n",
      "17634 Traning Loss: tensor(1.0499)\n",
      "17635 Traning Loss: tensor(1.0497)\n",
      "17636 Traning Loss: tensor(1.0496)\n",
      "17637 Traning Loss: tensor(1.0495)\n",
      "17638 Traning Loss: tensor(1.0494)\n",
      "17639 Traning Loss: tensor(1.0493)\n",
      "17640 Traning Loss: tensor(1.0491)\n",
      "17641 Traning Loss: tensor(1.0490)\n",
      "17642 Traning Loss: tensor(1.0489)\n",
      "17643 Traning Loss: tensor(1.0488)\n",
      "17644 Traning Loss: tensor(1.0486)\n",
      "17645 Traning Loss: tensor(1.0485)\n",
      "17646 Traning Loss: tensor(1.0484)\n",
      "17647 Traning Loss: tensor(1.0483)\n",
      "17648 Traning Loss: tensor(1.0482)\n",
      "17649 Traning Loss: tensor(1.0480)\n",
      "17650 Traning Loss: tensor(1.0479)\n",
      "17651 Traning Loss: tensor(1.0478)\n",
      "17652 Traning Loss: tensor(1.0477)\n",
      "17653 Traning Loss: tensor(1.0475)\n",
      "17654 Traning Loss: tensor(1.0474)\n",
      "17655 Traning Loss: tensor(1.0473)\n",
      "17656 Traning Loss: tensor(1.0472)\n",
      "17657 Traning Loss: tensor(1.0471)\n",
      "17658 Traning Loss: tensor(1.0469)\n",
      "17659 Traning Loss: tensor(1.0468)\n",
      "17660 Traning Loss: tensor(1.0467)\n",
      "17661 Traning Loss: tensor(1.0466)\n",
      "17662 Traning Loss: tensor(1.0464)\n",
      "17663 Traning Loss: tensor(1.0463)\n",
      "17664 Traning Loss: tensor(1.0462)\n",
      "17665 Traning Loss: tensor(1.0461)\n",
      "17666 Traning Loss: tensor(1.0460)\n",
      "17667 Traning Loss: tensor(1.0458)\n",
      "17668 Traning Loss: tensor(1.0457)\n",
      "17669 Traning Loss: tensor(1.0456)\n",
      "17670 Traning Loss: tensor(1.0455)\n",
      "17671 Traning Loss: tensor(1.0454)\n",
      "17672 Traning Loss: tensor(1.0452)\n",
      "17673 Traning Loss: tensor(1.0451)\n",
      "17674 Traning Loss: tensor(1.0450)\n",
      "17675 Traning Loss: tensor(1.0449)\n",
      "17676 Traning Loss: tensor(1.0447)\n",
      "17677 Traning Loss: tensor(1.0446)\n",
      "17678 Traning Loss: tensor(1.0445)\n",
      "17679 Traning Loss: tensor(1.0444)\n",
      "17680 Traning Loss: tensor(1.0443)\n",
      "17681 Traning Loss: tensor(1.0441)\n",
      "17682 Traning Loss: tensor(1.0440)\n",
      "17683 Traning Loss: tensor(1.0439)\n",
      "17684 Traning Loss: tensor(1.0438)\n",
      "17685 Traning Loss: tensor(1.0437)\n",
      "17686 Traning Loss: tensor(1.0435)\n",
      "17687 Traning Loss: tensor(1.0434)\n",
      "17688 Traning Loss: tensor(1.0433)\n",
      "17689 Traning Loss: tensor(1.0432)\n",
      "17690 Traning Loss: tensor(1.0430)\n",
      "17691 Traning Loss: tensor(1.0429)\n",
      "17692 Traning Loss: tensor(1.0428)\n",
      "17693 Traning Loss: tensor(1.0427)\n",
      "17694 Traning Loss: tensor(1.0426)\n",
      "17695 Traning Loss: tensor(1.0424)\n",
      "17696 Traning Loss: tensor(1.0423)\n",
      "17697 Traning Loss: tensor(1.0422)\n",
      "17698 Traning Loss: tensor(1.0421)\n",
      "17699 Traning Loss: tensor(1.0420)\n",
      "17700 Traning Loss: tensor(1.0418)\n",
      "17701 Traning Loss: tensor(1.0417)\n",
      "17702 Traning Loss: tensor(1.0416)\n",
      "17703 Traning Loss: tensor(1.0415)\n",
      "17704 Traning Loss: tensor(1.0413)\n",
      "17705 Traning Loss: tensor(1.0412)\n",
      "17706 Traning Loss: tensor(1.0411)\n",
      "17707 Traning Loss: tensor(1.0410)\n",
      "17708 Traning Loss: tensor(1.0409)\n",
      "17709 Traning Loss: tensor(1.0407)\n",
      "17710 Traning Loss: tensor(1.0406)\n",
      "17711 Traning Loss: tensor(1.0405)\n",
      "17712 Traning Loss: tensor(1.0404)\n",
      "17713 Traning Loss: tensor(1.0403)\n",
      "17714 Traning Loss: tensor(1.0401)\n",
      "17715 Traning Loss: tensor(1.0400)\n",
      "17716 Traning Loss: tensor(1.0399)\n",
      "17717 Traning Loss: tensor(1.0398)\n",
      "17718 Traning Loss: tensor(1.0397)\n",
      "17719 Traning Loss: tensor(1.0395)\n",
      "17720 Traning Loss: tensor(1.0394)\n",
      "17721 Traning Loss: tensor(1.0393)\n",
      "17722 Traning Loss: tensor(1.0392)\n",
      "17723 Traning Loss: tensor(1.0390)\n",
      "17724 Traning Loss: tensor(1.0389)\n",
      "17725 Traning Loss: tensor(1.0388)\n",
      "17726 Traning Loss: tensor(1.0387)\n",
      "17727 Traning Loss: tensor(1.0386)\n",
      "17728 Traning Loss: tensor(1.0384)\n",
      "17729 Traning Loss: tensor(1.0383)\n",
      "17730 Traning Loss: tensor(1.0382)\n",
      "17731 Traning Loss: tensor(1.0381)\n",
      "17732 Traning Loss: tensor(1.0380)\n",
      "17733 Traning Loss: tensor(1.0378)\n",
      "17734 Traning Loss: tensor(1.0377)\n",
      "17735 Traning Loss: tensor(1.0376)\n",
      "17736 Traning Loss: tensor(1.0375)\n",
      "17737 Traning Loss: tensor(1.0374)\n",
      "17738 Traning Loss: tensor(1.0372)\n",
      "17739 Traning Loss: tensor(1.0371)\n",
      "17740 Traning Loss: tensor(1.0370)\n",
      "17741 Traning Loss: tensor(1.0369)\n",
      "17742 Traning Loss: tensor(1.0368)\n",
      "17743 Traning Loss: tensor(1.0366)\n",
      "17744 Traning Loss: tensor(1.0365)\n",
      "17745 Traning Loss: tensor(1.0364)\n",
      "17746 Traning Loss: tensor(1.0363)\n",
      "17747 Traning Loss: tensor(1.0362)\n",
      "17748 Traning Loss: tensor(1.0360)\n",
      "17749 Traning Loss: tensor(1.0359)\n",
      "17750 Traning Loss: tensor(1.0358)\n",
      "17751 Traning Loss: tensor(1.0357)\n",
      "17752 Traning Loss: tensor(1.0356)\n",
      "17753 Traning Loss: tensor(1.0354)\n",
      "17754 Traning Loss: tensor(1.0353)\n",
      "17755 Traning Loss: tensor(1.0352)\n",
      "17756 Traning Loss: tensor(1.0351)\n",
      "17757 Traning Loss: tensor(1.0349)\n",
      "17758 Traning Loss: tensor(1.0348)\n",
      "17759 Traning Loss: tensor(1.0347)\n",
      "17760 Traning Loss: tensor(1.0346)\n",
      "17761 Traning Loss: tensor(1.0345)\n",
      "17762 Traning Loss: tensor(1.0343)\n",
      "17763 Traning Loss: tensor(1.0342)\n",
      "17764 Traning Loss: tensor(1.0341)\n",
      "17765 Traning Loss: tensor(1.0340)\n",
      "17766 Traning Loss: tensor(1.0339)\n",
      "17767 Traning Loss: tensor(1.0337)\n",
      "17768 Traning Loss: tensor(1.0336)\n",
      "17769 Traning Loss: tensor(1.0335)\n",
      "17770 Traning Loss: tensor(1.0334)\n",
      "17771 Traning Loss: tensor(1.0333)\n",
      "17772 Traning Loss: tensor(1.0331)\n",
      "17773 Traning Loss: tensor(1.0330)\n",
      "17774 Traning Loss: tensor(1.0329)\n",
      "17775 Traning Loss: tensor(1.0328)\n",
      "17776 Traning Loss: tensor(1.0327)\n",
      "17777 Traning Loss: tensor(1.0325)\n",
      "17778 Traning Loss: tensor(1.0324)\n",
      "17779 Traning Loss: tensor(1.0323)\n",
      "17780 Traning Loss: tensor(1.0322)\n",
      "17781 Traning Loss: tensor(1.0321)\n",
      "17782 Traning Loss: tensor(1.0319)\n",
      "17783 Traning Loss: tensor(1.0318)\n",
      "17784 Traning Loss: tensor(1.0317)\n",
      "17785 Traning Loss: tensor(1.0316)\n",
      "17786 Traning Loss: tensor(1.0315)\n",
      "17787 Traning Loss: tensor(1.0313)\n",
      "17788 Traning Loss: tensor(1.0312)\n",
      "17789 Traning Loss: tensor(1.0311)\n",
      "17790 Traning Loss: tensor(1.0310)\n",
      "17791 Traning Loss: tensor(1.0309)\n",
      "17792 Traning Loss: tensor(1.0307)\n",
      "17793 Traning Loss: tensor(1.0306)\n",
      "17794 Traning Loss: tensor(1.0305)\n",
      "17795 Traning Loss: tensor(1.0304)\n",
      "17796 Traning Loss: tensor(1.0303)\n",
      "17797 Traning Loss: tensor(1.0301)\n",
      "17798 Traning Loss: tensor(1.0300)\n",
      "17799 Traning Loss: tensor(1.0299)\n",
      "17800 Traning Loss: tensor(1.0298)\n",
      "17801 Traning Loss: tensor(1.0297)\n",
      "17802 Traning Loss: tensor(1.0295)\n",
      "17803 Traning Loss: tensor(1.0294)\n",
      "17804 Traning Loss: tensor(1.0293)\n",
      "17805 Traning Loss: tensor(1.0292)\n",
      "17806 Traning Loss: tensor(1.0291)\n",
      "17807 Traning Loss: tensor(1.0289)\n",
      "17808 Traning Loss: tensor(1.0288)\n",
      "17809 Traning Loss: tensor(1.0287)\n",
      "17810 Traning Loss: tensor(1.0286)\n",
      "17811 Traning Loss: tensor(1.0285)\n",
      "17812 Traning Loss: tensor(1.0283)\n",
      "17813 Traning Loss: tensor(1.0282)\n",
      "17814 Traning Loss: tensor(1.0281)\n",
      "17815 Traning Loss: tensor(1.0280)\n",
      "17816 Traning Loss: tensor(1.0279)\n",
      "17817 Traning Loss: tensor(1.0277)\n",
      "17818 Traning Loss: tensor(1.0276)\n",
      "17819 Traning Loss: tensor(1.0275)\n",
      "17820 Traning Loss: tensor(1.0274)\n",
      "17821 Traning Loss: tensor(1.0273)\n",
      "17822 Traning Loss: tensor(1.0271)\n",
      "17823 Traning Loss: tensor(1.0270)\n",
      "17824 Traning Loss: tensor(1.0269)\n",
      "17825 Traning Loss: tensor(1.0268)\n",
      "17826 Traning Loss: tensor(1.0267)\n",
      "17827 Traning Loss: tensor(1.0266)\n",
      "17828 Traning Loss: tensor(1.0264)\n",
      "17829 Traning Loss: tensor(1.0263)\n",
      "17830 Traning Loss: tensor(1.0262)\n",
      "17831 Traning Loss: tensor(1.0261)\n",
      "17832 Traning Loss: tensor(1.0260)\n",
      "17833 Traning Loss: tensor(1.0258)\n",
      "17834 Traning Loss: tensor(1.0257)\n",
      "17835 Traning Loss: tensor(1.0256)\n",
      "17836 Traning Loss: tensor(1.0255)\n",
      "17837 Traning Loss: tensor(1.0254)\n",
      "17838 Traning Loss: tensor(1.0252)\n",
      "17839 Traning Loss: tensor(1.0251)\n",
      "17840 Traning Loss: tensor(1.0250)\n",
      "17841 Traning Loss: tensor(1.0249)\n",
      "17842 Traning Loss: tensor(1.0248)\n",
      "17843 Traning Loss: tensor(1.0246)\n",
      "17844 Traning Loss: tensor(1.0245)\n",
      "17845 Traning Loss: tensor(1.0244)\n",
      "17846 Traning Loss: tensor(1.0243)\n",
      "17847 Traning Loss: tensor(1.0242)\n",
      "17848 Traning Loss: tensor(1.0240)\n",
      "17849 Traning Loss: tensor(1.0239)\n",
      "17850 Traning Loss: tensor(1.0238)\n",
      "17851 Traning Loss: tensor(1.0237)\n",
      "17852 Traning Loss: tensor(1.0236)\n",
      "17853 Traning Loss: tensor(1.0234)\n",
      "17854 Traning Loss: tensor(1.0233)\n",
      "17855 Traning Loss: tensor(1.0232)\n",
      "17856 Traning Loss: tensor(1.0231)\n",
      "17857 Traning Loss: tensor(1.0230)\n",
      "17858 Traning Loss: tensor(1.0228)\n",
      "17859 Traning Loss: tensor(1.0227)\n",
      "17860 Traning Loss: tensor(1.0226)\n",
      "17861 Traning Loss: tensor(1.0225)\n",
      "17862 Traning Loss: tensor(1.0224)\n",
      "17863 Traning Loss: tensor(1.0223)\n",
      "17864 Traning Loss: tensor(1.0221)\n",
      "17865 Traning Loss: tensor(1.0220)\n",
      "17866 Traning Loss: tensor(1.0219)\n",
      "17867 Traning Loss: tensor(1.0218)\n",
      "17868 Traning Loss: tensor(1.0217)\n",
      "17869 Traning Loss: tensor(1.0215)\n",
      "17870 Traning Loss: tensor(1.0214)\n",
      "17871 Traning Loss: tensor(1.0213)\n",
      "17872 Traning Loss: tensor(1.0212)\n",
      "17873 Traning Loss: tensor(1.0211)\n",
      "17874 Traning Loss: tensor(1.0209)\n",
      "17875 Traning Loss: tensor(1.0208)\n",
      "17876 Traning Loss: tensor(1.0207)\n",
      "17877 Traning Loss: tensor(1.0206)\n",
      "17878 Traning Loss: tensor(1.0205)\n",
      "17879 Traning Loss: tensor(1.0203)\n",
      "17880 Traning Loss: tensor(1.0202)\n",
      "17881 Traning Loss: tensor(1.0201)\n",
      "17882 Traning Loss: tensor(1.0200)\n",
      "17883 Traning Loss: tensor(1.0199)\n",
      "17884 Traning Loss: tensor(1.0197)\n",
      "17885 Traning Loss: tensor(1.0196)\n",
      "17886 Traning Loss: tensor(1.0195)\n",
      "17887 Traning Loss: tensor(1.0194)\n",
      "17888 Traning Loss: tensor(1.0193)\n",
      "17889 Traning Loss: tensor(1.0192)\n",
      "17890 Traning Loss: tensor(1.0190)\n",
      "17891 Traning Loss: tensor(1.0189)\n",
      "17892 Traning Loss: tensor(1.0188)\n",
      "17893 Traning Loss: tensor(1.0187)\n",
      "17894 Traning Loss: tensor(1.0186)\n",
      "17895 Traning Loss: tensor(1.0184)\n",
      "17896 Traning Loss: tensor(1.0183)\n",
      "17897 Traning Loss: tensor(1.0182)\n",
      "17898 Traning Loss: tensor(1.0181)\n",
      "17899 Traning Loss: tensor(1.0180)\n",
      "17900 Traning Loss: tensor(1.0178)\n",
      "17901 Traning Loss: tensor(1.0177)\n",
      "17902 Traning Loss: tensor(1.0176)\n",
      "17903 Traning Loss: tensor(1.0175)\n",
      "17904 Traning Loss: tensor(1.0174)\n",
      "17905 Traning Loss: tensor(1.0173)\n",
      "17906 Traning Loss: tensor(1.0171)\n",
      "17907 Traning Loss: tensor(1.0170)\n",
      "17908 Traning Loss: tensor(1.0169)\n",
      "17909 Traning Loss: tensor(1.0168)\n",
      "17910 Traning Loss: tensor(1.0167)\n",
      "17911 Traning Loss: tensor(1.0165)\n",
      "17912 Traning Loss: tensor(1.0164)\n",
      "17913 Traning Loss: tensor(1.0163)\n",
      "17914 Traning Loss: tensor(1.0162)\n",
      "17915 Traning Loss: tensor(1.0161)\n",
      "17916 Traning Loss: tensor(1.0159)\n",
      "17917 Traning Loss: tensor(1.0158)\n",
      "17918 Traning Loss: tensor(1.0157)\n",
      "17919 Traning Loss: tensor(1.0156)\n",
      "17920 Traning Loss: tensor(1.0155)\n",
      "17921 Traning Loss: tensor(1.0154)\n",
      "17922 Traning Loss: tensor(1.0152)\n",
      "17923 Traning Loss: tensor(1.0151)\n",
      "17924 Traning Loss: tensor(1.0150)\n",
      "17925 Traning Loss: tensor(1.0149)\n",
      "17926 Traning Loss: tensor(1.0148)\n",
      "17927 Traning Loss: tensor(1.0146)\n",
      "17928 Traning Loss: tensor(1.0145)\n",
      "17929 Traning Loss: tensor(1.0144)\n",
      "17930 Traning Loss: tensor(1.0143)\n",
      "17931 Traning Loss: tensor(1.0142)\n",
      "17932 Traning Loss: tensor(1.0140)\n",
      "17933 Traning Loss: tensor(1.0139)\n",
      "17934 Traning Loss: tensor(1.0138)\n",
      "17935 Traning Loss: tensor(1.0137)\n",
      "17936 Traning Loss: tensor(1.0136)\n",
      "17937 Traning Loss: tensor(1.0135)\n",
      "17938 Traning Loss: tensor(1.0133)\n",
      "17939 Traning Loss: tensor(1.0132)\n",
      "17940 Traning Loss: tensor(1.0131)\n",
      "17941 Traning Loss: tensor(1.0130)\n",
      "17942 Traning Loss: tensor(1.0129)\n",
      "17943 Traning Loss: tensor(1.0127)\n",
      "17944 Traning Loss: tensor(1.0126)\n",
      "17945 Traning Loss: tensor(1.0125)\n",
      "17946 Traning Loss: tensor(1.0124)\n",
      "17947 Traning Loss: tensor(1.0123)\n",
      "17948 Traning Loss: tensor(1.0122)\n",
      "17949 Traning Loss: tensor(1.0120)\n",
      "17950 Traning Loss: tensor(1.0119)\n",
      "17951 Traning Loss: tensor(1.0118)\n",
      "17952 Traning Loss: tensor(1.0117)\n",
      "17953 Traning Loss: tensor(1.0116)\n",
      "17954 Traning Loss: tensor(1.0114)\n",
      "17955 Traning Loss: tensor(1.0113)\n",
      "17956 Traning Loss: tensor(1.0112)\n",
      "17957 Traning Loss: tensor(1.0111)\n",
      "17958 Traning Loss: tensor(1.0110)\n",
      "17959 Traning Loss: tensor(1.0109)\n",
      "17960 Traning Loss: tensor(1.0107)\n",
      "17961 Traning Loss: tensor(1.0106)\n",
      "17962 Traning Loss: tensor(1.0105)\n",
      "17963 Traning Loss: tensor(1.0104)\n",
      "17964 Traning Loss: tensor(1.0103)\n",
      "17965 Traning Loss: tensor(1.0101)\n",
      "17966 Traning Loss: tensor(1.0100)\n",
      "17967 Traning Loss: tensor(1.0099)\n",
      "17968 Traning Loss: tensor(1.0098)\n",
      "17969 Traning Loss: tensor(1.0097)\n",
      "17970 Traning Loss: tensor(1.0096)\n",
      "17971 Traning Loss: tensor(1.0094)\n",
      "17972 Traning Loss: tensor(1.0093)\n",
      "17973 Traning Loss: tensor(1.0092)\n",
      "17974 Traning Loss: tensor(1.0091)\n",
      "17975 Traning Loss: tensor(1.0090)\n",
      "17976 Traning Loss: tensor(1.0088)\n",
      "17977 Traning Loss: tensor(1.0087)\n",
      "17978 Traning Loss: tensor(1.0086)\n",
      "17979 Traning Loss: tensor(1.0085)\n",
      "17980 Traning Loss: tensor(1.0084)\n",
      "17981 Traning Loss: tensor(1.0083)\n",
      "17982 Traning Loss: tensor(1.0081)\n",
      "17983 Traning Loss: tensor(1.0080)\n",
      "17984 Traning Loss: tensor(1.0079)\n",
      "17985 Traning Loss: tensor(1.0078)\n",
      "17986 Traning Loss: tensor(1.0077)\n",
      "17987 Traning Loss: tensor(1.0076)\n",
      "17988 Traning Loss: tensor(1.0074)\n",
      "17989 Traning Loss: tensor(1.0073)\n",
      "17990 Traning Loss: tensor(1.0072)\n",
      "17991 Traning Loss: tensor(1.0071)\n",
      "17992 Traning Loss: tensor(1.0070)\n",
      "17993 Traning Loss: tensor(1.0068)\n",
      "17994 Traning Loss: tensor(1.0067)\n",
      "17995 Traning Loss: tensor(1.0066)\n",
      "17996 Traning Loss: tensor(1.0065)\n",
      "17997 Traning Loss: tensor(1.0064)\n",
      "17998 Traning Loss: tensor(1.0063)\n",
      "17999 Traning Loss: tensor(1.0061)\n",
      "18000 Traning Loss: tensor(1.0060)\n",
      "18001 Traning Loss: tensor(1.0059)\n",
      "18002 Traning Loss: tensor(1.0058)\n",
      "18003 Traning Loss: tensor(1.0057)\n",
      "18004 Traning Loss: tensor(1.0056)\n",
      "18005 Traning Loss: tensor(1.0054)\n",
      "18006 Traning Loss: tensor(1.0053)\n",
      "18007 Traning Loss: tensor(1.0052)\n",
      "18008 Traning Loss: tensor(1.0051)\n",
      "18009 Traning Loss: tensor(1.0050)\n",
      "18010 Traning Loss: tensor(1.0048)\n",
      "18011 Traning Loss: tensor(1.0047)\n",
      "18012 Traning Loss: tensor(1.0046)\n",
      "18013 Traning Loss: tensor(1.0045)\n",
      "18014 Traning Loss: tensor(1.0044)\n",
      "18015 Traning Loss: tensor(1.0043)\n",
      "18016 Traning Loss: tensor(1.0041)\n",
      "18017 Traning Loss: tensor(1.0040)\n",
      "18018 Traning Loss: tensor(1.0039)\n",
      "18019 Traning Loss: tensor(1.0038)\n",
      "18020 Traning Loss: tensor(1.0037)\n",
      "18021 Traning Loss: tensor(1.0036)\n",
      "18022 Traning Loss: tensor(1.0034)\n",
      "18023 Traning Loss: tensor(1.0033)\n",
      "18024 Traning Loss: tensor(1.0032)\n",
      "18025 Traning Loss: tensor(1.0031)\n",
      "18026 Traning Loss: tensor(1.0030)\n",
      "18027 Traning Loss: tensor(1.0029)\n",
      "18028 Traning Loss: tensor(1.0027)\n",
      "18029 Traning Loss: tensor(1.0026)\n",
      "18030 Traning Loss: tensor(1.0025)\n",
      "18031 Traning Loss: tensor(1.0024)\n",
      "18032 Traning Loss: tensor(1.0023)\n",
      "18033 Traning Loss: tensor(1.0021)\n",
      "18034 Traning Loss: tensor(1.0020)\n",
      "18035 Traning Loss: tensor(1.0019)\n",
      "18036 Traning Loss: tensor(1.0018)\n",
      "18037 Traning Loss: tensor(1.0017)\n",
      "18038 Traning Loss: tensor(1.0016)\n",
      "18039 Traning Loss: tensor(1.0014)\n",
      "18040 Traning Loss: tensor(1.0013)\n",
      "18041 Traning Loss: tensor(1.0012)\n",
      "18042 Traning Loss: tensor(1.0011)\n",
      "18043 Traning Loss: tensor(1.0010)\n",
      "18044 Traning Loss: tensor(1.0009)\n",
      "18045 Traning Loss: tensor(1.0007)\n",
      "18046 Traning Loss: tensor(1.0006)\n",
      "18047 Traning Loss: tensor(1.0005)\n",
      "18048 Traning Loss: tensor(1.0004)\n",
      "18049 Traning Loss: tensor(1.0003)\n",
      "18050 Traning Loss: tensor(1.0002)\n",
      "18051 Traning Loss: tensor(1.0000)\n",
      "18052 Traning Loss: tensor(0.9999)\n",
      "18053 Traning Loss: tensor(0.9998)\n",
      "18054 Traning Loss: tensor(0.9997)\n",
      "18055 Traning Loss: tensor(0.9996)\n",
      "18056 Traning Loss: tensor(0.9995)\n",
      "18057 Traning Loss: tensor(0.9993)\n",
      "18058 Traning Loss: tensor(0.9992)\n",
      "18059 Traning Loss: tensor(0.9991)\n",
      "18060 Traning Loss: tensor(0.9990)\n",
      "18061 Traning Loss: tensor(0.9989)\n",
      "18062 Traning Loss: tensor(0.9988)\n",
      "18063 Traning Loss: tensor(0.9986)\n",
      "18064 Traning Loss: tensor(0.9985)\n",
      "18065 Traning Loss: tensor(0.9984)\n",
      "18066 Traning Loss: tensor(0.9983)\n",
      "18067 Traning Loss: tensor(0.9982)\n",
      "18068 Traning Loss: tensor(0.9981)\n",
      "18069 Traning Loss: tensor(0.9979)\n",
      "18070 Traning Loss: tensor(0.9978)\n",
      "18071 Traning Loss: tensor(0.9977)\n",
      "18072 Traning Loss: tensor(0.9976)\n",
      "18073 Traning Loss: tensor(0.9975)\n",
      "18074 Traning Loss: tensor(0.9974)\n",
      "18075 Traning Loss: tensor(0.9972)\n",
      "18076 Traning Loss: tensor(0.9971)\n",
      "18077 Traning Loss: tensor(0.9970)\n",
      "18078 Traning Loss: tensor(0.9969)\n",
      "18079 Traning Loss: tensor(0.9968)\n",
      "18080 Traning Loss: tensor(0.9967)\n",
      "18081 Traning Loss: tensor(0.9965)\n",
      "18082 Traning Loss: tensor(0.9964)\n",
      "18083 Traning Loss: tensor(0.9963)\n",
      "18084 Traning Loss: tensor(0.9962)\n",
      "18085 Traning Loss: tensor(0.9961)\n",
      "18086 Traning Loss: tensor(0.9960)\n",
      "18087 Traning Loss: tensor(0.9958)\n",
      "18088 Traning Loss: tensor(0.9957)\n",
      "18089 Traning Loss: tensor(0.9956)\n",
      "18090 Traning Loss: tensor(0.9955)\n",
      "18091 Traning Loss: tensor(0.9954)\n",
      "18092 Traning Loss: tensor(0.9953)\n",
      "18093 Traning Loss: tensor(0.9951)\n",
      "18094 Traning Loss: tensor(0.9950)\n",
      "18095 Traning Loss: tensor(0.9949)\n",
      "18096 Traning Loss: tensor(0.9948)\n",
      "18097 Traning Loss: tensor(0.9947)\n",
      "18098 Traning Loss: tensor(0.9946)\n",
      "18099 Traning Loss: tensor(0.9945)\n",
      "18100 Traning Loss: tensor(0.9943)\n",
      "18101 Traning Loss: tensor(0.9942)\n",
      "18102 Traning Loss: tensor(0.9941)\n",
      "18103 Traning Loss: tensor(0.9940)\n",
      "18104 Traning Loss: tensor(0.9939)\n",
      "18105 Traning Loss: tensor(0.9686)\n",
      "18106 Traning Loss: tensor(0.9686)\n",
      "18107 Traning Loss: tensor(0.9685)\n",
      "18108 Traning Loss: tensor(0.9684)\n",
      "18109 Traning Loss: tensor(0.9683)\n",
      "18110 Traning Loss: tensor(0.9682)\n",
      "18111 Traning Loss: tensor(0.9682)\n",
      "18112 Traning Loss: tensor(0.9681)\n",
      "18113 Traning Loss: tensor(0.9680)\n",
      "18114 Traning Loss: tensor(0.9680)\n",
      "18115 Traning Loss: tensor(0.9679)\n",
      "18116 Traning Loss: tensor(0.9678)\n",
      "18117 Traning Loss: tensor(0.9677)\n",
      "18118 Traning Loss: tensor(0.9677)\n",
      "18119 Traning Loss: tensor(0.9676)\n",
      "18120 Traning Loss: tensor(0.9675)\n",
      "18121 Traning Loss: tensor(0.9675)\n",
      "18122 Traning Loss: tensor(0.9674)\n",
      "18123 Traning Loss: tensor(0.9673)\n",
      "18124 Traning Loss: tensor(0.9673)\n",
      "18125 Traning Loss: tensor(0.9672)\n",
      "18126 Traning Loss: tensor(0.9671)\n",
      "18127 Traning Loss: tensor(0.9671)\n",
      "18128 Traning Loss: tensor(0.9670)\n",
      "18129 Traning Loss: tensor(0.9669)\n",
      "18130 Traning Loss: tensor(0.9669)\n",
      "18131 Traning Loss: tensor(0.9668)\n",
      "18132 Traning Loss: tensor(0.9667)\n",
      "18133 Traning Loss: tensor(0.9667)\n",
      "18134 Traning Loss: tensor(0.9666)\n",
      "18135 Traning Loss: tensor(0.9665)\n",
      "18136 Traning Loss: tensor(0.9665)\n",
      "18137 Traning Loss: tensor(0.9664)\n",
      "18138 Traning Loss: tensor(0.9664)\n",
      "18139 Traning Loss: tensor(0.9663)\n",
      "18140 Traning Loss: tensor(0.9662)\n",
      "18141 Traning Loss: tensor(0.9662)\n",
      "18142 Traning Loss: tensor(0.9661)\n",
      "18143 Traning Loss: tensor(0.9660)\n",
      "18144 Traning Loss: tensor(0.9660)\n",
      "18145 Traning Loss: tensor(0.9659)\n",
      "18146 Traning Loss: tensor(0.9658)\n",
      "18147 Traning Loss: tensor(0.9658)\n",
      "18148 Traning Loss: tensor(0.9657)\n",
      "18149 Traning Loss: tensor(0.9656)\n",
      "18150 Traning Loss: tensor(0.9656)\n",
      "18151 Traning Loss: tensor(0.9655)\n",
      "18152 Traning Loss: tensor(0.9655)\n",
      "18153 Traning Loss: tensor(0.9654)\n",
      "18154 Traning Loss: tensor(0.9653)\n",
      "18155 Traning Loss: tensor(0.9653)\n",
      "18156 Traning Loss: tensor(0.9652)\n",
      "18157 Traning Loss: tensor(0.9651)\n",
      "18158 Traning Loss: tensor(0.9651)\n",
      "18159 Traning Loss: tensor(0.9650)\n",
      "18160 Traning Loss: tensor(0.9650)\n",
      "18161 Traning Loss: tensor(0.9649)\n",
      "18162 Traning Loss: tensor(0.9648)\n",
      "18163 Traning Loss: tensor(0.9648)\n",
      "18164 Traning Loss: tensor(0.9647)\n",
      "18165 Traning Loss: tensor(0.9646)\n",
      "18166 Traning Loss: tensor(0.9646)\n",
      "18167 Traning Loss: tensor(0.9645)\n",
      "18168 Traning Loss: tensor(0.9644)\n",
      "18169 Traning Loss: tensor(0.9644)\n",
      "18170 Traning Loss: tensor(0.9643)\n",
      "18171 Traning Loss: tensor(0.9643)\n",
      "18172 Traning Loss: tensor(0.9642)\n",
      "18173 Traning Loss: tensor(0.9641)\n",
      "18174 Traning Loss: tensor(0.9641)\n",
      "18175 Traning Loss: tensor(0.9640)\n",
      "18176 Traning Loss: tensor(0.9639)\n",
      "18177 Traning Loss: tensor(0.9639)\n",
      "18178 Traning Loss: tensor(0.9638)\n",
      "18179 Traning Loss: tensor(0.9637)\n",
      "18180 Traning Loss: tensor(0.9637)\n",
      "18181 Traning Loss: tensor(0.9636)\n",
      "18182 Traning Loss: tensor(0.9636)\n",
      "18183 Traning Loss: tensor(0.9635)\n",
      "18184 Traning Loss: tensor(0.9634)\n",
      "18185 Traning Loss: tensor(0.9634)\n",
      "18186 Traning Loss: tensor(0.9633)\n",
      "18187 Traning Loss: tensor(0.9632)\n",
      "18188 Traning Loss: tensor(0.9632)\n",
      "18189 Traning Loss: tensor(0.9631)\n",
      "18190 Traning Loss: tensor(0.9630)\n",
      "18191 Traning Loss: tensor(0.9630)\n",
      "18192 Traning Loss: tensor(0.9629)\n",
      "18193 Traning Loss: tensor(0.9629)\n",
      "18194 Traning Loss: tensor(0.9628)\n",
      "18195 Traning Loss: tensor(0.9627)\n",
      "18196 Traning Loss: tensor(0.9627)\n",
      "18197 Traning Loss: tensor(0.9626)\n",
      "18198 Traning Loss: tensor(0.9625)\n",
      "18199 Traning Loss: tensor(0.9625)\n",
      "18200 Traning Loss: tensor(0.9624)\n",
      "18201 Traning Loss: tensor(0.9623)\n",
      "18202 Traning Loss: tensor(0.9623)\n",
      "18203 Traning Loss: tensor(0.9622)\n",
      "18204 Traning Loss: tensor(0.9622)\n",
      "18205 Traning Loss: tensor(0.9621)\n",
      "18206 Traning Loss: tensor(0.9620)\n",
      "18207 Traning Loss: tensor(0.9620)\n",
      "18208 Traning Loss: tensor(0.9619)\n",
      "18209 Traning Loss: tensor(0.9618)\n",
      "18210 Traning Loss: tensor(0.9618)\n",
      "18211 Traning Loss: tensor(0.9617)\n",
      "18212 Traning Loss: tensor(0.9616)\n",
      "18213 Traning Loss: tensor(0.9616)\n",
      "18214 Traning Loss: tensor(0.9615)\n",
      "18215 Traning Loss: tensor(0.9615)\n",
      "18216 Traning Loss: tensor(0.9614)\n",
      "18217 Traning Loss: tensor(0.9613)\n",
      "18218 Traning Loss: tensor(0.9613)\n",
      "18219 Traning Loss: tensor(0.9612)\n",
      "18220 Traning Loss: tensor(0.9611)\n",
      "18221 Traning Loss: tensor(0.9611)\n",
      "18222 Traning Loss: tensor(0.9610)\n",
      "18223 Traning Loss: tensor(0.9610)\n",
      "18224 Traning Loss: tensor(0.9609)\n",
      "18225 Traning Loss: tensor(0.9608)\n",
      "18226 Traning Loss: tensor(0.9608)\n",
      "18227 Traning Loss: tensor(0.9607)\n",
      "18228 Traning Loss: tensor(0.9606)\n",
      "18229 Traning Loss: tensor(0.9606)\n",
      "18230 Traning Loss: tensor(0.9605)\n",
      "18231 Traning Loss: tensor(0.9604)\n",
      "18232 Traning Loss: tensor(0.9604)\n",
      "18233 Traning Loss: tensor(0.9603)\n",
      "18234 Traning Loss: tensor(0.9603)\n",
      "18235 Traning Loss: tensor(0.9602)\n",
      "18236 Traning Loss: tensor(0.9601)\n",
      "18237 Traning Loss: tensor(0.9601)\n",
      "18238 Traning Loss: tensor(0.9600)\n",
      "18239 Traning Loss: tensor(0.9599)\n",
      "18240 Traning Loss: tensor(0.9599)\n",
      "18241 Traning Loss: tensor(0.9598)\n",
      "18242 Traning Loss: tensor(0.9597)\n",
      "18243 Traning Loss: tensor(0.9597)\n",
      "18244 Traning Loss: tensor(0.9596)\n",
      "18245 Traning Loss: tensor(0.9596)\n",
      "18246 Traning Loss: tensor(0.9595)\n",
      "18247 Traning Loss: tensor(0.9594)\n",
      "18248 Traning Loss: tensor(0.9594)\n",
      "18249 Traning Loss: tensor(0.9593)\n",
      "18250 Traning Loss: tensor(0.9592)\n",
      "18251 Traning Loss: tensor(0.9592)\n",
      "18252 Traning Loss: tensor(0.9591)\n",
      "18253 Traning Loss: tensor(0.9590)\n",
      "18254 Traning Loss: tensor(0.9590)\n",
      "18255 Traning Loss: tensor(0.9589)\n",
      "18256 Traning Loss: tensor(0.9589)\n",
      "18257 Traning Loss: tensor(0.9588)\n",
      "18258 Traning Loss: tensor(0.9587)\n",
      "18259 Traning Loss: tensor(0.9587)\n",
      "18260 Traning Loss: tensor(0.9586)\n",
      "18261 Traning Loss: tensor(0.9585)\n",
      "18262 Traning Loss: tensor(0.9585)\n",
      "18263 Traning Loss: tensor(0.9584)\n",
      "18264 Traning Loss: tensor(0.9583)\n",
      "18265 Traning Loss: tensor(0.9583)\n",
      "18266 Traning Loss: tensor(0.9582)\n",
      "18267 Traning Loss: tensor(0.9582)\n",
      "18268 Traning Loss: tensor(0.9581)\n",
      "18269 Traning Loss: tensor(0.9580)\n",
      "18270 Traning Loss: tensor(0.9580)\n",
      "18271 Traning Loss: tensor(0.9579)\n",
      "18272 Traning Loss: tensor(0.9578)\n",
      "18273 Traning Loss: tensor(0.9578)\n",
      "18274 Traning Loss: tensor(0.9577)\n",
      "18275 Traning Loss: tensor(0.9576)\n",
      "18276 Traning Loss: tensor(0.9576)\n",
      "18277 Traning Loss: tensor(0.9575)\n",
      "18278 Traning Loss: tensor(0.9575)\n",
      "18279 Traning Loss: tensor(0.9574)\n",
      "18280 Traning Loss: tensor(0.9573)\n",
      "18281 Traning Loss: tensor(0.9573)\n",
      "18282 Traning Loss: tensor(0.9572)\n",
      "18283 Traning Loss: tensor(0.9571)\n",
      "18284 Traning Loss: tensor(0.9571)\n",
      "18285 Traning Loss: tensor(0.9570)\n",
      "18286 Traning Loss: tensor(0.9569)\n",
      "18287 Traning Loss: tensor(0.9569)\n",
      "18288 Traning Loss: tensor(0.9568)\n",
      "18289 Traning Loss: tensor(0.9568)\n",
      "18290 Traning Loss: tensor(0.9567)\n",
      "18291 Traning Loss: tensor(0.9566)\n",
      "18292 Traning Loss: tensor(0.9566)\n",
      "18293 Traning Loss: tensor(0.9565)\n",
      "18294 Traning Loss: tensor(0.9564)\n",
      "18295 Traning Loss: tensor(0.9564)\n",
      "18296 Traning Loss: tensor(0.9563)\n",
      "18297 Traning Loss: tensor(0.9562)\n",
      "18298 Traning Loss: tensor(0.9562)\n",
      "18299 Traning Loss: tensor(0.9561)\n",
      "18300 Traning Loss: tensor(0.9560)\n",
      "18301 Traning Loss: tensor(0.9560)\n",
      "18302 Traning Loss: tensor(0.9559)\n",
      "18303 Traning Loss: tensor(0.9559)\n",
      "18304 Traning Loss: tensor(0.9558)\n",
      "18305 Traning Loss: tensor(0.9557)\n",
      "18306 Traning Loss: tensor(0.9557)\n",
      "18307 Traning Loss: tensor(0.9556)\n",
      "18308 Traning Loss: tensor(0.9555)\n",
      "18309 Traning Loss: tensor(0.9555)\n",
      "18310 Traning Loss: tensor(0.9554)\n",
      "18311 Traning Loss: tensor(0.9553)\n",
      "18312 Traning Loss: tensor(0.9553)\n",
      "18313 Traning Loss: tensor(0.9552)\n",
      "18314 Traning Loss: tensor(0.9552)\n",
      "18315 Traning Loss: tensor(0.9551)\n",
      "18316 Traning Loss: tensor(0.9550)\n",
      "18317 Traning Loss: tensor(0.9550)\n",
      "18318 Traning Loss: tensor(0.9549)\n",
      "18319 Traning Loss: tensor(0.9548)\n",
      "18320 Traning Loss: tensor(0.9548)\n",
      "18321 Traning Loss: tensor(0.9547)\n",
      "18322 Traning Loss: tensor(0.9546)\n",
      "18323 Traning Loss: tensor(0.9546)\n",
      "18324 Traning Loss: tensor(0.9545)\n",
      "18325 Traning Loss: tensor(0.9545)\n",
      "18326 Traning Loss: tensor(0.9544)\n",
      "18327 Traning Loss: tensor(0.9543)\n",
      "18328 Traning Loss: tensor(0.9543)\n",
      "18329 Traning Loss: tensor(0.9542)\n",
      "18330 Traning Loss: tensor(0.9541)\n",
      "18331 Traning Loss: tensor(0.9541)\n",
      "18332 Traning Loss: tensor(0.9540)\n",
      "18333 Traning Loss: tensor(0.9539)\n",
      "18334 Traning Loss: tensor(0.9539)\n",
      "18335 Traning Loss: tensor(0.9538)\n",
      "18336 Traning Loss: tensor(0.9538)\n",
      "18337 Traning Loss: tensor(0.9537)\n",
      "18338 Traning Loss: tensor(0.9536)\n",
      "18339 Traning Loss: tensor(0.9536)\n",
      "18340 Traning Loss: tensor(0.9535)\n",
      "18341 Traning Loss: tensor(0.9534)\n",
      "18342 Traning Loss: tensor(0.9534)\n",
      "18343 Traning Loss: tensor(0.9533)\n",
      "18344 Traning Loss: tensor(0.9532)\n",
      "18345 Traning Loss: tensor(0.9532)\n",
      "18346 Traning Loss: tensor(0.9531)\n",
      "18347 Traning Loss: tensor(0.9530)\n",
      "18348 Traning Loss: tensor(0.9530)\n",
      "18349 Traning Loss: tensor(0.9529)\n",
      "18350 Traning Loss: tensor(0.9529)\n",
      "18351 Traning Loss: tensor(0.9528)\n",
      "18352 Traning Loss: tensor(0.9527)\n",
      "18353 Traning Loss: tensor(0.9527)\n",
      "18354 Traning Loss: tensor(0.9526)\n",
      "18355 Traning Loss: tensor(0.9525)\n",
      "18356 Traning Loss: tensor(0.9525)\n",
      "18357 Traning Loss: tensor(0.9524)\n",
      "18358 Traning Loss: tensor(0.9523)\n",
      "18359 Traning Loss: tensor(0.9523)\n",
      "18360 Traning Loss: tensor(0.9522)\n",
      "18361 Traning Loss: tensor(0.9522)\n",
      "18362 Traning Loss: tensor(0.9521)\n",
      "18363 Traning Loss: tensor(0.9520)\n",
      "18364 Traning Loss: tensor(0.9520)\n",
      "18365 Traning Loss: tensor(0.9519)\n",
      "18366 Traning Loss: tensor(0.9518)\n",
      "18367 Traning Loss: tensor(0.9518)\n",
      "18368 Traning Loss: tensor(0.9517)\n",
      "18369 Traning Loss: tensor(0.9516)\n",
      "18370 Traning Loss: tensor(0.9516)\n",
      "18371 Traning Loss: tensor(0.9515)\n",
      "18372 Traning Loss: tensor(0.9514)\n",
      "18373 Traning Loss: tensor(0.9514)\n",
      "18374 Traning Loss: tensor(0.9513)\n",
      "18375 Traning Loss: tensor(0.9513)\n",
      "18376 Traning Loss: tensor(0.9512)\n",
      "18377 Traning Loss: tensor(0.9511)\n",
      "18378 Traning Loss: tensor(0.9511)\n",
      "18379 Traning Loss: tensor(0.9510)\n",
      "18380 Traning Loss: tensor(0.9509)\n",
      "18381 Traning Loss: tensor(0.9509)\n",
      "18382 Traning Loss: tensor(0.9508)\n",
      "18383 Traning Loss: tensor(0.9507)\n",
      "18384 Traning Loss: tensor(0.9507)\n",
      "18385 Traning Loss: tensor(0.9506)\n",
      "18386 Traning Loss: tensor(0.9505)\n",
      "18387 Traning Loss: tensor(0.9505)\n",
      "18388 Traning Loss: tensor(0.9504)\n",
      "18389 Traning Loss: tensor(0.9504)\n",
      "18390 Traning Loss: tensor(0.9503)\n",
      "18391 Traning Loss: tensor(0.9502)\n",
      "18392 Traning Loss: tensor(0.9502)\n",
      "18393 Traning Loss: tensor(0.9501)\n",
      "18394 Traning Loss: tensor(0.9500)\n",
      "18395 Traning Loss: tensor(0.9500)\n",
      "18396 Traning Loss: tensor(0.9499)\n",
      "18397 Traning Loss: tensor(0.9498)\n",
      "18398 Traning Loss: tensor(0.9498)\n",
      "18399 Traning Loss: tensor(0.9497)\n",
      "18400 Traning Loss: tensor(0.9497)\n",
      "18401 Traning Loss: tensor(0.9496)\n",
      "18402 Traning Loss: tensor(0.9495)\n",
      "18403 Traning Loss: tensor(0.9495)\n",
      "18404 Traning Loss: tensor(0.9494)\n",
      "18405 Traning Loss: tensor(0.9493)\n",
      "18406 Traning Loss: tensor(0.9493)\n",
      "18407 Traning Loss: tensor(0.9492)\n",
      "18408 Traning Loss: tensor(0.9491)\n",
      "18409 Traning Loss: tensor(0.9491)\n",
      "18410 Traning Loss: tensor(0.9490)\n",
      "18411 Traning Loss: tensor(0.9489)\n",
      "18412 Traning Loss: tensor(0.9489)\n",
      "18413 Traning Loss: tensor(0.9488)\n",
      "18414 Traning Loss: tensor(0.9488)\n",
      "18415 Traning Loss: tensor(0.9487)\n",
      "18416 Traning Loss: tensor(0.9486)\n",
      "18417 Traning Loss: tensor(0.9486)\n",
      "18418 Traning Loss: tensor(0.9485)\n",
      "18419 Traning Loss: tensor(0.9484)\n",
      "18420 Traning Loss: tensor(0.9484)\n",
      "18421 Traning Loss: tensor(0.9483)\n",
      "18422 Traning Loss: tensor(0.9482)\n",
      "18423 Traning Loss: tensor(0.9482)\n",
      "18424 Traning Loss: tensor(0.9481)\n",
      "18425 Traning Loss: tensor(0.9480)\n",
      "18426 Traning Loss: tensor(0.9480)\n",
      "18427 Traning Loss: tensor(0.9479)\n",
      "18428 Traning Loss: tensor(0.9479)\n",
      "18429 Traning Loss: tensor(0.9478)\n",
      "18430 Traning Loss: tensor(0.9477)\n",
      "18431 Traning Loss: tensor(0.9477)\n",
      "18432 Traning Loss: tensor(0.9476)\n",
      "18433 Traning Loss: tensor(0.9475)\n",
      "18434 Traning Loss: tensor(0.9475)\n",
      "18435 Traning Loss: tensor(0.9474)\n",
      "18436 Traning Loss: tensor(0.9473)\n",
      "18437 Traning Loss: tensor(0.9473)\n",
      "18438 Traning Loss: tensor(0.9472)\n",
      "18439 Traning Loss: tensor(0.9471)\n",
      "18440 Traning Loss: tensor(0.9471)\n",
      "18441 Traning Loss: tensor(0.9470)\n",
      "18442 Traning Loss: tensor(0.9470)\n",
      "18443 Traning Loss: tensor(0.9469)\n",
      "18444 Traning Loss: tensor(0.9468)\n",
      "18445 Traning Loss: tensor(0.9468)\n",
      "18446 Traning Loss: tensor(0.9467)\n",
      "18447 Traning Loss: tensor(0.9466)\n",
      "18448 Traning Loss: tensor(0.9466)\n",
      "18449 Traning Loss: tensor(0.9465)\n",
      "18450 Traning Loss: tensor(0.9464)\n",
      "18451 Traning Loss: tensor(0.9464)\n",
      "18452 Traning Loss: tensor(0.9463)\n",
      "18453 Traning Loss: tensor(0.9462)\n",
      "18454 Traning Loss: tensor(0.9462)\n",
      "18455 Traning Loss: tensor(0.9461)\n",
      "18456 Traning Loss: tensor(0.9461)\n",
      "18457 Traning Loss: tensor(0.9460)\n",
      "18458 Traning Loss: tensor(0.9459)\n",
      "18459 Traning Loss: tensor(0.9459)\n",
      "18460 Traning Loss: tensor(0.9458)\n",
      "18461 Traning Loss: tensor(0.9457)\n",
      "18462 Traning Loss: tensor(0.9457)\n",
      "18463 Traning Loss: tensor(0.9456)\n",
      "18464 Traning Loss: tensor(0.9455)\n",
      "18465 Traning Loss: tensor(0.9455)\n",
      "18466 Traning Loss: tensor(0.9454)\n",
      "18467 Traning Loss: tensor(0.9453)\n",
      "18468 Traning Loss: tensor(0.9453)\n",
      "18469 Traning Loss: tensor(0.9452)\n",
      "18470 Traning Loss: tensor(0.9451)\n",
      "18471 Traning Loss: tensor(0.9451)\n",
      "18472 Traning Loss: tensor(0.9450)\n",
      "18473 Traning Loss: tensor(0.9450)\n",
      "18474 Traning Loss: tensor(0.9449)\n",
      "18475 Traning Loss: tensor(0.9448)\n",
      "18476 Traning Loss: tensor(0.9448)\n",
      "18477 Traning Loss: tensor(0.9447)\n",
      "18478 Traning Loss: tensor(0.9446)\n",
      "18479 Traning Loss: tensor(0.9446)\n",
      "18480 Traning Loss: tensor(0.9445)\n",
      "18481 Traning Loss: tensor(0.9444)\n",
      "18482 Traning Loss: tensor(0.9444)\n",
      "18483 Traning Loss: tensor(0.9443)\n",
      "18484 Traning Loss: tensor(0.9442)\n",
      "18485 Traning Loss: tensor(0.9442)\n",
      "18486 Traning Loss: tensor(0.9441)\n",
      "18487 Traning Loss: tensor(0.9441)\n",
      "18488 Traning Loss: tensor(0.9440)\n",
      "18489 Traning Loss: tensor(0.9439)\n",
      "18490 Traning Loss: tensor(0.9439)\n",
      "18491 Traning Loss: tensor(0.9438)\n",
      "18492 Traning Loss: tensor(0.9437)\n",
      "18493 Traning Loss: tensor(0.9437)\n",
      "18494 Traning Loss: tensor(0.9436)\n",
      "18495 Traning Loss: tensor(0.9435)\n",
      "18496 Traning Loss: tensor(0.9435)\n",
      "18497 Traning Loss: tensor(0.9434)\n",
      "18498 Traning Loss: tensor(0.9433)\n",
      "18499 Traning Loss: tensor(0.9433)\n",
      "18500 Traning Loss: tensor(0.9432)\n",
      "18501 Traning Loss: tensor(0.9432)\n",
      "18502 Traning Loss: tensor(0.9431)\n",
      "18503 Traning Loss: tensor(0.9430)\n",
      "18504 Traning Loss: tensor(0.9430)\n",
      "18505 Traning Loss: tensor(0.9429)\n",
      "18506 Traning Loss: tensor(0.9428)\n",
      "18507 Traning Loss: tensor(0.9428)\n",
      "18508 Traning Loss: tensor(0.9427)\n",
      "18509 Traning Loss: tensor(0.9426)\n",
      "18510 Traning Loss: tensor(0.9426)\n",
      "18511 Traning Loss: tensor(0.9425)\n",
      "18512 Traning Loss: tensor(0.9424)\n",
      "18513 Traning Loss: tensor(0.9424)\n",
      "18514 Traning Loss: tensor(0.9423)\n",
      "18515 Traning Loss: tensor(0.9422)\n",
      "18516 Traning Loss: tensor(0.9422)\n",
      "18517 Traning Loss: tensor(0.9421)\n",
      "18518 Traning Loss: tensor(0.9421)\n",
      "18519 Traning Loss: tensor(0.9420)\n",
      "18520 Traning Loss: tensor(0.9419)\n",
      "18521 Traning Loss: tensor(0.9419)\n",
      "18522 Traning Loss: tensor(0.9418)\n",
      "18523 Traning Loss: tensor(0.9417)\n",
      "18524 Traning Loss: tensor(0.9417)\n",
      "18525 Traning Loss: tensor(0.9416)\n",
      "18526 Traning Loss: tensor(0.9415)\n",
      "18527 Traning Loss: tensor(0.9415)\n",
      "18528 Traning Loss: tensor(0.9414)\n",
      "18529 Traning Loss: tensor(0.9413)\n",
      "18530 Traning Loss: tensor(0.9413)\n",
      "18531 Traning Loss: tensor(0.9412)\n",
      "18532 Traning Loss: tensor(0.9412)\n",
      "18533 Traning Loss: tensor(0.9411)\n",
      "18534 Traning Loss: tensor(0.9410)\n",
      "18535 Traning Loss: tensor(0.9410)\n",
      "18536 Traning Loss: tensor(0.9409)\n",
      "18537 Traning Loss: tensor(0.9408)\n",
      "18538 Traning Loss: tensor(0.9408)\n",
      "18539 Traning Loss: tensor(0.9407)\n",
      "18540 Traning Loss: tensor(0.9406)\n",
      "18541 Traning Loss: tensor(0.9406)\n",
      "18542 Traning Loss: tensor(0.9405)\n",
      "18543 Traning Loss: tensor(0.9404)\n",
      "18544 Traning Loss: tensor(0.9404)\n",
      "18545 Traning Loss: tensor(0.9403)\n",
      "18546 Traning Loss: tensor(0.9402)\n",
      "18547 Traning Loss: tensor(0.9402)\n",
      "18548 Traning Loss: tensor(0.9401)\n",
      "18549 Traning Loss: tensor(0.9401)\n",
      "18550 Traning Loss: tensor(0.9400)\n",
      "18551 Traning Loss: tensor(0.9399)\n",
      "18552 Traning Loss: tensor(0.9399)\n",
      "18553 Traning Loss: tensor(0.9398)\n",
      "18554 Traning Loss: tensor(0.9397)\n",
      "18555 Traning Loss: tensor(0.9397)\n",
      "18556 Traning Loss: tensor(0.9396)\n",
      "18557 Traning Loss: tensor(0.9395)\n",
      "18558 Traning Loss: tensor(0.9395)\n",
      "18559 Traning Loss: tensor(0.9394)\n",
      "18560 Traning Loss: tensor(0.9393)\n",
      "18561 Traning Loss: tensor(0.9393)\n",
      "18562 Traning Loss: tensor(0.9392)\n",
      "18563 Traning Loss: tensor(0.9391)\n",
      "18564 Traning Loss: tensor(0.9391)\n",
      "18565 Traning Loss: tensor(0.9390)\n",
      "18566 Traning Loss: tensor(0.9390)\n",
      "18567 Traning Loss: tensor(0.9389)\n",
      "18568 Traning Loss: tensor(0.9388)\n",
      "18569 Traning Loss: tensor(0.9388)\n",
      "18570 Traning Loss: tensor(0.9387)\n",
      "18571 Traning Loss: tensor(0.9386)\n",
      "18572 Traning Loss: tensor(0.9386)\n",
      "18573 Traning Loss: tensor(0.9385)\n",
      "18574 Traning Loss: tensor(0.9384)\n",
      "18575 Traning Loss: tensor(0.9384)\n",
      "18576 Traning Loss: tensor(0.9383)\n",
      "18577 Traning Loss: tensor(1.0216)\n",
      "18578 Traning Loss: tensor(1.0215)\n",
      "18579 Traning Loss: tensor(1.0214)\n",
      "18580 Traning Loss: tensor(1.0213)\n",
      "18581 Traning Loss: tensor(1.0212)\n",
      "18582 Traning Loss: tensor(1.0210)\n",
      "18583 Traning Loss: tensor(1.0209)\n",
      "18584 Traning Loss: tensor(1.0207)\n",
      "18585 Traning Loss: tensor(1.0206)\n",
      "18586 Traning Loss: tensor(1.0204)\n",
      "18587 Traning Loss: tensor(1.0203)\n",
      "18588 Traning Loss: tensor(1.0201)\n",
      "18589 Traning Loss: tensor(1.0200)\n",
      "18590 Traning Loss: tensor(1.0198)\n",
      "18591 Traning Loss: tensor(1.0196)\n",
      "18592 Traning Loss: tensor(1.0195)\n",
      "18593 Traning Loss: tensor(1.0193)\n",
      "18594 Traning Loss: tensor(1.0191)\n",
      "18595 Traning Loss: tensor(1.0190)\n",
      "18596 Traning Loss: tensor(1.0188)\n",
      "18597 Traning Loss: tensor(1.0187)\n",
      "18598 Traning Loss: tensor(1.0185)\n",
      "18599 Traning Loss: tensor(1.0184)\n",
      "18600 Traning Loss: tensor(1.0182)\n",
      "18601 Traning Loss: tensor(1.0180)\n",
      "18602 Traning Loss: tensor(1.0179)\n",
      "18603 Traning Loss: tensor(1.0177)\n",
      "18604 Traning Loss: tensor(1.0176)\n",
      "18605 Traning Loss: tensor(1.0174)\n",
      "18606 Traning Loss: tensor(1.0173)\n",
      "18607 Traning Loss: tensor(1.0171)\n",
      "18608 Traning Loss: tensor(1.0170)\n",
      "18609 Traning Loss: tensor(1.0168)\n",
      "18610 Traning Loss: tensor(1.0167)\n",
      "18611 Traning Loss: tensor(1.0165)\n",
      "18612 Traning Loss: tensor(1.0164)\n",
      "18613 Traning Loss: tensor(1.0162)\n",
      "18614 Traning Loss: tensor(1.0161)\n",
      "18615 Traning Loss: tensor(1.0159)\n",
      "18616 Traning Loss: tensor(1.0158)\n",
      "18617 Traning Loss: tensor(1.0156)\n",
      "18618 Traning Loss: tensor(1.0155)\n",
      "18619 Traning Loss: tensor(1.0153)\n",
      "18620 Traning Loss: tensor(1.0152)\n",
      "18621 Traning Loss: tensor(1.0150)\n",
      "18622 Traning Loss: tensor(1.0149)\n",
      "18623 Traning Loss: tensor(1.0147)\n",
      "18624 Traning Loss: tensor(1.0146)\n",
      "18625 Traning Loss: tensor(1.0144)\n",
      "18626 Traning Loss: tensor(1.0143)\n",
      "18627 Traning Loss: tensor(1.0141)\n",
      "18628 Traning Loss: tensor(1.0140)\n",
      "18629 Traning Loss: tensor(1.0138)\n",
      "18630 Traning Loss: tensor(1.0137)\n",
      "18631 Traning Loss: tensor(1.0135)\n",
      "18632 Traning Loss: tensor(1.0134)\n",
      "18633 Traning Loss: tensor(1.0132)\n",
      "18634 Traning Loss: tensor(1.0131)\n",
      "18635 Traning Loss: tensor(1.0129)\n",
      "18636 Traning Loss: tensor(1.0128)\n",
      "18637 Traning Loss: tensor(1.0126)\n",
      "18638 Traning Loss: tensor(1.0125)\n",
      "18639 Traning Loss: tensor(1.0123)\n",
      "18640 Traning Loss: tensor(1.0122)\n",
      "18641 Traning Loss: tensor(1.0120)\n",
      "18642 Traning Loss: tensor(1.0119)\n",
      "18643 Traning Loss: tensor(1.0117)\n",
      "18644 Traning Loss: tensor(1.0116)\n",
      "18645 Traning Loss: tensor(1.0114)\n",
      "18646 Traning Loss: tensor(1.0113)\n",
      "18647 Traning Loss: tensor(1.0112)\n",
      "18648 Traning Loss: tensor(1.0110)\n",
      "18649 Traning Loss: tensor(1.0109)\n",
      "18650 Traning Loss: tensor(1.0107)\n",
      "18651 Traning Loss: tensor(1.0106)\n",
      "18652 Traning Loss: tensor(1.0104)\n",
      "18653 Traning Loss: tensor(1.0103)\n",
      "18654 Traning Loss: tensor(1.0101)\n",
      "18655 Traning Loss: tensor(1.0100)\n",
      "18656 Traning Loss: tensor(1.0098)\n",
      "18657 Traning Loss: tensor(1.0097)\n",
      "18658 Traning Loss: tensor(1.0095)\n",
      "18659 Traning Loss: tensor(1.0094)\n",
      "18660 Traning Loss: tensor(1.0093)\n",
      "18661 Traning Loss: tensor(1.0091)\n",
      "18662 Traning Loss: tensor(1.0090)\n",
      "18663 Traning Loss: tensor(1.0088)\n",
      "18664 Traning Loss: tensor(1.0087)\n",
      "18665 Traning Loss: tensor(1.0085)\n",
      "18666 Traning Loss: tensor(1.0084)\n",
      "18667 Traning Loss: tensor(1.0082)\n",
      "18668 Traning Loss: tensor(1.0081)\n",
      "18669 Traning Loss: tensor(1.0079)\n",
      "18670 Traning Loss: tensor(1.0078)\n",
      "18671 Traning Loss: tensor(1.0077)\n",
      "18672 Traning Loss: tensor(1.0075)\n",
      "18673 Traning Loss: tensor(1.0074)\n",
      "18674 Traning Loss: tensor(1.0072)\n",
      "18675 Traning Loss: tensor(1.0071)\n",
      "18676 Traning Loss: tensor(1.0069)\n",
      "18677 Traning Loss: tensor(1.0068)\n",
      "18678 Traning Loss: tensor(1.0067)\n",
      "18679 Traning Loss: tensor(1.0065)\n",
      "18680 Traning Loss: tensor(1.0064)\n",
      "18681 Traning Loss: tensor(1.0062)\n",
      "18682 Traning Loss: tensor(1.0061)\n",
      "18683 Traning Loss: tensor(1.0059)\n",
      "18684 Traning Loss: tensor(1.0058)\n",
      "18685 Traning Loss: tensor(1.0057)\n",
      "18686 Traning Loss: tensor(1.0055)\n",
      "18687 Traning Loss: tensor(1.0054)\n",
      "18688 Traning Loss: tensor(1.0052)\n",
      "18689 Traning Loss: tensor(1.0051)\n",
      "18690 Traning Loss: tensor(1.0049)\n",
      "18691 Traning Loss: tensor(1.0048)\n",
      "18692 Traning Loss: tensor(1.0047)\n",
      "18693 Traning Loss: tensor(1.0045)\n",
      "18694 Traning Loss: tensor(1.0044)\n",
      "18695 Traning Loss: tensor(1.0042)\n",
      "18696 Traning Loss: tensor(1.0041)\n",
      "18697 Traning Loss: tensor(1.0039)\n",
      "18698 Traning Loss: tensor(1.0038)\n",
      "18699 Traning Loss: tensor(1.0037)\n",
      "18700 Traning Loss: tensor(1.0035)\n",
      "18701 Traning Loss: tensor(1.0034)\n",
      "18702 Traning Loss: tensor(1.0032)\n",
      "18703 Traning Loss: tensor(1.0031)\n",
      "18704 Traning Loss: tensor(1.0029)\n",
      "18705 Traning Loss: tensor(1.0028)\n",
      "18706 Traning Loss: tensor(1.0027)\n",
      "18707 Traning Loss: tensor(1.0025)\n",
      "18708 Traning Loss: tensor(1.0024)\n",
      "18709 Traning Loss: tensor(1.0022)\n",
      "18710 Traning Loss: tensor(1.0021)\n",
      "18711 Traning Loss: tensor(1.0020)\n",
      "18712 Traning Loss: tensor(1.0018)\n",
      "18713 Traning Loss: tensor(1.0017)\n",
      "18714 Traning Loss: tensor(1.0015)\n",
      "18715 Traning Loss: tensor(1.0014)\n",
      "18716 Traning Loss: tensor(1.0013)\n",
      "18717 Traning Loss: tensor(1.0011)\n",
      "18718 Traning Loss: tensor(1.0010)\n",
      "18719 Traning Loss: tensor(1.0008)\n",
      "18720 Traning Loss: tensor(1.0007)\n",
      "18721 Traning Loss: tensor(1.0006)\n",
      "18722 Traning Loss: tensor(1.0004)\n",
      "18723 Traning Loss: tensor(1.0003)\n",
      "18724 Traning Loss: tensor(1.0001)\n",
      "18725 Traning Loss: tensor(1.0000)\n",
      "18726 Traning Loss: tensor(0.9999)\n",
      "18727 Traning Loss: tensor(0.9997)\n",
      "18728 Traning Loss: tensor(0.9996)\n",
      "18729 Traning Loss: tensor(0.9994)\n",
      "18730 Traning Loss: tensor(0.9993)\n",
      "18731 Traning Loss: tensor(0.9992)\n",
      "18732 Traning Loss: tensor(0.9990)\n",
      "18733 Traning Loss: tensor(0.9989)\n",
      "18734 Traning Loss: tensor(0.9987)\n",
      "18735 Traning Loss: tensor(0.9986)\n",
      "18736 Traning Loss: tensor(0.9985)\n",
      "18737 Traning Loss: tensor(0.9983)\n",
      "18738 Traning Loss: tensor(0.9982)\n",
      "18739 Traning Loss: tensor(0.9980)\n",
      "18740 Traning Loss: tensor(0.9979)\n",
      "18741 Traning Loss: tensor(0.9978)\n",
      "18742 Traning Loss: tensor(0.9976)\n",
      "18743 Traning Loss: tensor(0.9975)\n",
      "18744 Traning Loss: tensor(0.9973)\n",
      "18745 Traning Loss: tensor(0.9972)\n",
      "18746 Traning Loss: tensor(0.9971)\n",
      "18747 Traning Loss: tensor(0.9969)\n",
      "18748 Traning Loss: tensor(0.9968)\n",
      "18749 Traning Loss: tensor(0.9967)\n",
      "18750 Traning Loss: tensor(0.9965)\n",
      "18751 Traning Loss: tensor(0.9964)\n",
      "18752 Traning Loss: tensor(0.9962)\n",
      "18753 Traning Loss: tensor(0.9961)\n",
      "18754 Traning Loss: tensor(0.9960)\n",
      "18755 Traning Loss: tensor(0.9958)\n",
      "18756 Traning Loss: tensor(0.9957)\n",
      "18757 Traning Loss: tensor(0.9955)\n",
      "18758 Traning Loss: tensor(0.9954)\n",
      "18759 Traning Loss: tensor(0.9953)\n",
      "18760 Traning Loss: tensor(0.9951)\n",
      "18761 Traning Loss: tensor(0.9950)\n",
      "18762 Traning Loss: tensor(0.9949)\n",
      "18763 Traning Loss: tensor(0.9947)\n",
      "18764 Traning Loss: tensor(0.9946)\n",
      "18765 Traning Loss: tensor(0.9944)\n",
      "18766 Traning Loss: tensor(0.9943)\n",
      "18767 Traning Loss: tensor(0.9942)\n",
      "18768 Traning Loss: tensor(0.9940)\n",
      "18769 Traning Loss: tensor(0.9939)\n",
      "18770 Traning Loss: tensor(0.9938)\n",
      "18771 Traning Loss: tensor(0.9936)\n",
      "18772 Traning Loss: tensor(0.9935)\n",
      "18773 Traning Loss: tensor(0.9933)\n",
      "18774 Traning Loss: tensor(0.9932)\n",
      "18775 Traning Loss: tensor(0.9931)\n",
      "18776 Traning Loss: tensor(0.9929)\n",
      "18777 Traning Loss: tensor(0.9928)\n",
      "18778 Traning Loss: tensor(0.9927)\n",
      "18779 Traning Loss: tensor(0.9925)\n",
      "18780 Traning Loss: tensor(0.9924)\n",
      "18781 Traning Loss: tensor(0.9922)\n",
      "18782 Traning Loss: tensor(0.9921)\n",
      "18783 Traning Loss: tensor(0.9920)\n",
      "18784 Traning Loss: tensor(0.9918)\n",
      "18785 Traning Loss: tensor(0.9917)\n",
      "18786 Traning Loss: tensor(0.9916)\n",
      "18787 Traning Loss: tensor(0.9914)\n",
      "18788 Traning Loss: tensor(0.9913)\n",
      "18789 Traning Loss: tensor(0.9911)\n",
      "18790 Traning Loss: tensor(0.9910)\n",
      "18791 Traning Loss: tensor(0.9909)\n",
      "18792 Traning Loss: tensor(0.9907)\n",
      "18793 Traning Loss: tensor(0.9906)\n",
      "18794 Traning Loss: tensor(0.9905)\n",
      "18795 Traning Loss: tensor(0.9903)\n",
      "18796 Traning Loss: tensor(0.9902)\n",
      "18797 Traning Loss: tensor(0.9901)\n",
      "18798 Traning Loss: tensor(0.9899)\n",
      "18799 Traning Loss: tensor(0.9898)\n",
      "18800 Traning Loss: tensor(0.9896)\n",
      "18801 Traning Loss: tensor(0.9895)\n",
      "18802 Traning Loss: tensor(0.9894)\n",
      "18803 Traning Loss: tensor(0.9892)\n",
      "18804 Traning Loss: tensor(0.9891)\n",
      "18805 Traning Loss: tensor(0.9890)\n",
      "18806 Traning Loss: tensor(0.9888)\n",
      "18807 Traning Loss: tensor(0.9887)\n",
      "18808 Traning Loss: tensor(0.9886)\n",
      "18809 Traning Loss: tensor(0.9884)\n",
      "18810 Traning Loss: tensor(0.9883)\n",
      "18811 Traning Loss: tensor(0.9882)\n",
      "18812 Traning Loss: tensor(0.9880)\n",
      "18813 Traning Loss: tensor(0.9879)\n",
      "18814 Traning Loss: tensor(0.9877)\n",
      "18815 Traning Loss: tensor(0.9876)\n",
      "18816 Traning Loss: tensor(0.9875)\n",
      "18817 Traning Loss: tensor(0.9873)\n",
      "18818 Traning Loss: tensor(0.9872)\n",
      "18819 Traning Loss: tensor(0.9871)\n",
      "18820 Traning Loss: tensor(0.9869)\n",
      "18821 Traning Loss: tensor(0.9868)\n",
      "18822 Traning Loss: tensor(0.9867)\n",
      "18823 Traning Loss: tensor(0.9865)\n",
      "18824 Traning Loss: tensor(0.9864)\n",
      "18825 Traning Loss: tensor(0.9863)\n",
      "18826 Traning Loss: tensor(0.9861)\n",
      "18827 Traning Loss: tensor(0.9860)\n",
      "18828 Traning Loss: tensor(0.9859)\n",
      "18829 Traning Loss: tensor(0.9857)\n",
      "18830 Traning Loss: tensor(0.9856)\n",
      "18831 Traning Loss: tensor(0.9854)\n",
      "18832 Traning Loss: tensor(0.9853)\n",
      "18833 Traning Loss: tensor(0.9852)\n",
      "18834 Traning Loss: tensor(0.9850)\n",
      "18835 Traning Loss: tensor(0.9849)\n",
      "18836 Traning Loss: tensor(0.9848)\n",
      "18837 Traning Loss: tensor(0.9846)\n",
      "18838 Traning Loss: tensor(0.9845)\n",
      "18839 Traning Loss: tensor(0.9844)\n",
      "18840 Traning Loss: tensor(0.9842)\n",
      "18841 Traning Loss: tensor(0.9841)\n",
      "18842 Traning Loss: tensor(0.9840)\n",
      "18843 Traning Loss: tensor(0.9838)\n",
      "18844 Traning Loss: tensor(0.9837)\n",
      "18845 Traning Loss: tensor(0.9836)\n",
      "18846 Traning Loss: tensor(0.9834)\n",
      "18847 Traning Loss: tensor(0.9833)\n",
      "18848 Traning Loss: tensor(0.9832)\n",
      "18849 Traning Loss: tensor(0.9830)\n",
      "18850 Traning Loss: tensor(0.9829)\n",
      "18851 Traning Loss: tensor(0.9828)\n",
      "18852 Traning Loss: tensor(0.9826)\n",
      "18853 Traning Loss: tensor(0.9825)\n",
      "18854 Traning Loss: tensor(0.9824)\n",
      "18855 Traning Loss: tensor(0.9822)\n",
      "18856 Traning Loss: tensor(0.9821)\n",
      "18857 Traning Loss: tensor(0.9820)\n",
      "18858 Traning Loss: tensor(0.9818)\n",
      "18859 Traning Loss: tensor(0.9817)\n",
      "18860 Traning Loss: tensor(0.9816)\n",
      "18861 Traning Loss: tensor(0.9814)\n",
      "18862 Traning Loss: tensor(0.9813)\n",
      "18863 Traning Loss: tensor(0.9812)\n",
      "18864 Traning Loss: tensor(0.9810)\n",
      "18865 Traning Loss: tensor(0.9809)\n",
      "18866 Traning Loss: tensor(0.9808)\n",
      "18867 Traning Loss: tensor(0.9806)\n",
      "18868 Traning Loss: tensor(0.9805)\n",
      "18869 Traning Loss: tensor(0.9804)\n",
      "18870 Traning Loss: tensor(0.9487)\n",
      "18871 Traning Loss: tensor(0.9486)\n",
      "18872 Traning Loss: tensor(0.9485)\n",
      "18873 Traning Loss: tensor(0.9484)\n",
      "18874 Traning Loss: tensor(0.9483)\n",
      "18875 Traning Loss: tensor(0.9482)\n",
      "18876 Traning Loss: tensor(0.9482)\n",
      "18877 Traning Loss: tensor(0.9481)\n",
      "18878 Traning Loss: tensor(0.9480)\n",
      "18879 Traning Loss: tensor(0.9479)\n",
      "18880 Traning Loss: tensor(0.9478)\n",
      "18881 Traning Loss: tensor(0.9477)\n",
      "18882 Traning Loss: tensor(0.9477)\n",
      "18883 Traning Loss: tensor(0.9476)\n",
      "18884 Traning Loss: tensor(0.9475)\n",
      "18885 Traning Loss: tensor(0.9474)\n",
      "18886 Traning Loss: tensor(0.9473)\n",
      "18887 Traning Loss: tensor(0.9473)\n",
      "18888 Traning Loss: tensor(0.9472)\n",
      "18889 Traning Loss: tensor(0.9471)\n",
      "18890 Traning Loss: tensor(0.9470)\n",
      "18891 Traning Loss: tensor(0.9470)\n",
      "18892 Traning Loss: tensor(0.9469)\n",
      "18893 Traning Loss: tensor(0.9468)\n",
      "18894 Traning Loss: tensor(0.9467)\n",
      "18895 Traning Loss: tensor(0.9467)\n",
      "18896 Traning Loss: tensor(0.9466)\n",
      "18897 Traning Loss: tensor(0.9465)\n",
      "18898 Traning Loss: tensor(0.9464)\n",
      "18899 Traning Loss: tensor(0.9464)\n",
      "18900 Traning Loss: tensor(0.9463)\n",
      "18901 Traning Loss: tensor(0.9462)\n",
      "18902 Traning Loss: tensor(0.9461)\n",
      "18903 Traning Loss: tensor(0.9461)\n",
      "18904 Traning Loss: tensor(0.9460)\n",
      "18905 Traning Loss: tensor(0.9459)\n",
      "18906 Traning Loss: tensor(0.9458)\n",
      "18907 Traning Loss: tensor(0.9458)\n",
      "18908 Traning Loss: tensor(0.9457)\n",
      "18909 Traning Loss: tensor(0.9456)\n",
      "18910 Traning Loss: tensor(0.9455)\n",
      "18911 Traning Loss: tensor(0.9455)\n",
      "18912 Traning Loss: tensor(0.9454)\n",
      "18913 Traning Loss: tensor(0.9453)\n",
      "18914 Traning Loss: tensor(0.9453)\n",
      "18915 Traning Loss: tensor(0.9452)\n",
      "18916 Traning Loss: tensor(0.9451)\n",
      "18917 Traning Loss: tensor(0.9450)\n",
      "18918 Traning Loss: tensor(0.9450)\n",
      "18919 Traning Loss: tensor(0.9449)\n",
      "18920 Traning Loss: tensor(0.9448)\n",
      "18921 Traning Loss: tensor(0.9447)\n",
      "18922 Traning Loss: tensor(0.9447)\n",
      "18923 Traning Loss: tensor(0.9446)\n",
      "18924 Traning Loss: tensor(0.9445)\n",
      "18925 Traning Loss: tensor(0.9444)\n",
      "18926 Traning Loss: tensor(0.9444)\n",
      "18927 Traning Loss: tensor(0.9443)\n",
      "18928 Traning Loss: tensor(0.9442)\n",
      "18929 Traning Loss: tensor(0.9442)\n",
      "18930 Traning Loss: tensor(0.9441)\n",
      "18931 Traning Loss: tensor(0.9440)\n",
      "18932 Traning Loss: tensor(0.9439)\n",
      "18933 Traning Loss: tensor(0.9439)\n",
      "18934 Traning Loss: tensor(0.9438)\n",
      "18935 Traning Loss: tensor(0.9437)\n",
      "18936 Traning Loss: tensor(0.9436)\n",
      "18937 Traning Loss: tensor(0.9436)\n",
      "18938 Traning Loss: tensor(0.9435)\n",
      "18939 Traning Loss: tensor(0.9434)\n",
      "18940 Traning Loss: tensor(0.9433)\n",
      "18941 Traning Loss: tensor(0.9433)\n",
      "18942 Traning Loss: tensor(0.9432)\n",
      "18943 Traning Loss: tensor(0.9431)\n",
      "18944 Traning Loss: tensor(0.9431)\n",
      "18945 Traning Loss: tensor(0.9430)\n",
      "18946 Traning Loss: tensor(0.9429)\n",
      "18947 Traning Loss: tensor(0.9428)\n",
      "18948 Traning Loss: tensor(0.9428)\n",
      "18949 Traning Loss: tensor(0.9427)\n",
      "18950 Traning Loss: tensor(0.9426)\n",
      "18951 Traning Loss: tensor(0.9425)\n",
      "18952 Traning Loss: tensor(0.9425)\n",
      "18953 Traning Loss: tensor(0.9424)\n",
      "18954 Traning Loss: tensor(0.9423)\n",
      "18955 Traning Loss: tensor(0.9423)\n",
      "18956 Traning Loss: tensor(0.9422)\n",
      "18957 Traning Loss: tensor(0.9421)\n",
      "18958 Traning Loss: tensor(0.9420)\n",
      "18959 Traning Loss: tensor(0.9420)\n",
      "18960 Traning Loss: tensor(0.9419)\n",
      "18961 Traning Loss: tensor(0.9418)\n",
      "18962 Traning Loss: tensor(0.9417)\n",
      "18963 Traning Loss: tensor(0.9417)\n",
      "18964 Traning Loss: tensor(0.9416)\n",
      "18965 Traning Loss: tensor(0.9415)\n",
      "18966 Traning Loss: tensor(0.9415)\n",
      "18967 Traning Loss: tensor(0.9414)\n",
      "18968 Traning Loss: tensor(0.9413)\n",
      "18969 Traning Loss: tensor(0.9412)\n",
      "18970 Traning Loss: tensor(0.9412)\n",
      "18971 Traning Loss: tensor(0.9411)\n",
      "18972 Traning Loss: tensor(0.9410)\n",
      "18973 Traning Loss: tensor(0.9409)\n",
      "18974 Traning Loss: tensor(0.9409)\n",
      "18975 Traning Loss: tensor(0.9408)\n",
      "18976 Traning Loss: tensor(0.9407)\n",
      "18977 Traning Loss: tensor(0.9407)\n",
      "18978 Traning Loss: tensor(0.9406)\n",
      "18979 Traning Loss: tensor(0.9405)\n",
      "18980 Traning Loss: tensor(0.9404)\n",
      "18981 Traning Loss: tensor(0.9404)\n",
      "18982 Traning Loss: tensor(0.9403)\n",
      "18983 Traning Loss: tensor(0.9402)\n",
      "18984 Traning Loss: tensor(0.9401)\n",
      "18985 Traning Loss: tensor(0.9401)\n",
      "18986 Traning Loss: tensor(0.9400)\n",
      "18987 Traning Loss: tensor(0.9399)\n",
      "18988 Traning Loss: tensor(0.9399)\n",
      "18989 Traning Loss: tensor(0.9398)\n",
      "18990 Traning Loss: tensor(0.9397)\n",
      "18991 Traning Loss: tensor(0.9396)\n",
      "18992 Traning Loss: tensor(0.9396)\n",
      "18993 Traning Loss: tensor(0.9395)\n",
      "18994 Traning Loss: tensor(0.9394)\n",
      "18995 Traning Loss: tensor(0.9393)\n",
      "18996 Traning Loss: tensor(0.9393)\n",
      "18997 Traning Loss: tensor(0.9392)\n",
      "18998 Traning Loss: tensor(0.9391)\n",
      "18999 Traning Loss: tensor(0.9391)\n",
      "19000 Traning Loss: tensor(0.9390)\n",
      "19001 Traning Loss: tensor(0.9389)\n",
      "19002 Traning Loss: tensor(0.9388)\n",
      "19003 Traning Loss: tensor(0.9388)\n",
      "19004 Traning Loss: tensor(0.9387)\n",
      "19005 Traning Loss: tensor(0.9386)\n",
      "19006 Traning Loss: tensor(0.9385)\n",
      "19007 Traning Loss: tensor(0.9385)\n",
      "19008 Traning Loss: tensor(0.9384)\n",
      "19009 Traning Loss: tensor(0.9383)\n",
      "19010 Traning Loss: tensor(0.9383)\n",
      "19011 Traning Loss: tensor(0.9382)\n",
      "19012 Traning Loss: tensor(0.9381)\n",
      "19013 Traning Loss: tensor(0.9380)\n",
      "19014 Traning Loss: tensor(0.9380)\n",
      "19015 Traning Loss: tensor(0.9379)\n",
      "19016 Traning Loss: tensor(0.9378)\n",
      "19017 Traning Loss: tensor(0.9378)\n",
      "19018 Traning Loss: tensor(0.9377)\n",
      "19019 Traning Loss: tensor(0.9376)\n",
      "19020 Traning Loss: tensor(0.9375)\n",
      "19021 Traning Loss: tensor(0.9375)\n",
      "19022 Traning Loss: tensor(0.9374)\n",
      "19023 Traning Loss: tensor(0.9373)\n",
      "19024 Traning Loss: tensor(0.9372)\n",
      "19025 Traning Loss: tensor(0.9372)\n",
      "19026 Traning Loss: tensor(0.9371)\n",
      "19027 Traning Loss: tensor(0.9370)\n",
      "19028 Traning Loss: tensor(0.9370)\n",
      "19029 Traning Loss: tensor(0.9369)\n",
      "19030 Traning Loss: tensor(0.9368)\n",
      "19031 Traning Loss: tensor(0.9367)\n",
      "19032 Traning Loss: tensor(0.9367)\n",
      "19033 Traning Loss: tensor(0.9366)\n",
      "19034 Traning Loss: tensor(0.9365)\n",
      "19035 Traning Loss: tensor(0.9364)\n",
      "19036 Traning Loss: tensor(0.9364)\n",
      "19037 Traning Loss: tensor(0.9363)\n",
      "19038 Traning Loss: tensor(0.9362)\n",
      "19039 Traning Loss: tensor(0.9362)\n",
      "19040 Traning Loss: tensor(0.9361)\n",
      "19041 Traning Loss: tensor(0.9360)\n",
      "19042 Traning Loss: tensor(0.9359)\n",
      "19043 Traning Loss: tensor(0.9359)\n",
      "19044 Traning Loss: tensor(0.9358)\n",
      "19045 Traning Loss: tensor(0.9357)\n",
      "19046 Traning Loss: tensor(0.9357)\n",
      "19047 Traning Loss: tensor(0.9356)\n",
      "19048 Traning Loss: tensor(0.9355)\n",
      "19049 Traning Loss: tensor(0.9354)\n",
      "19050 Traning Loss: tensor(0.9354)\n",
      "19051 Traning Loss: tensor(0.9353)\n",
      "19052 Traning Loss: tensor(0.9352)\n",
      "19053 Traning Loss: tensor(0.9351)\n",
      "19054 Traning Loss: tensor(0.9351)\n",
      "19055 Traning Loss: tensor(0.9350)\n",
      "19056 Traning Loss: tensor(0.9349)\n",
      "19057 Traning Loss: tensor(0.9349)\n",
      "19058 Traning Loss: tensor(0.9348)\n",
      "19059 Traning Loss: tensor(0.9347)\n",
      "19060 Traning Loss: tensor(0.9346)\n",
      "19061 Traning Loss: tensor(0.9346)\n",
      "19062 Traning Loss: tensor(0.9345)\n",
      "19063 Traning Loss: tensor(0.9344)\n",
      "19064 Traning Loss: tensor(0.9343)\n",
      "19065 Traning Loss: tensor(0.9343)\n",
      "19066 Traning Loss: tensor(0.9342)\n",
      "19067 Traning Loss: tensor(0.9341)\n",
      "19068 Traning Loss: tensor(0.9341)\n",
      "19069 Traning Loss: tensor(0.9340)\n",
      "19070 Traning Loss: tensor(0.9339)\n",
      "19071 Traning Loss: tensor(0.9338)\n",
      "19072 Traning Loss: tensor(0.9338)\n",
      "19073 Traning Loss: tensor(0.9337)\n",
      "19074 Traning Loss: tensor(0.9336)\n",
      "19075 Traning Loss: tensor(0.9336)\n",
      "19076 Traning Loss: tensor(0.9335)\n",
      "19077 Traning Loss: tensor(0.9334)\n",
      "19078 Traning Loss: tensor(0.9333)\n",
      "19079 Traning Loss: tensor(0.9333)\n",
      "19080 Traning Loss: tensor(0.9332)\n",
      "19081 Traning Loss: tensor(0.9331)\n",
      "19082 Traning Loss: tensor(0.9330)\n",
      "19083 Traning Loss: tensor(0.9330)\n",
      "19084 Traning Loss: tensor(0.9329)\n",
      "19085 Traning Loss: tensor(0.9328)\n",
      "19086 Traning Loss: tensor(0.9328)\n",
      "19087 Traning Loss: tensor(0.9327)\n",
      "19088 Traning Loss: tensor(0.9326)\n",
      "19089 Traning Loss: tensor(0.9325)\n",
      "19090 Traning Loss: tensor(0.9325)\n",
      "19091 Traning Loss: tensor(0.9324)\n",
      "19092 Traning Loss: tensor(0.9323)\n",
      "19093 Traning Loss: tensor(0.9323)\n",
      "19094 Traning Loss: tensor(0.9322)\n",
      "19095 Traning Loss: tensor(0.9321)\n",
      "19096 Traning Loss: tensor(0.9320)\n",
      "19097 Traning Loss: tensor(0.9320)\n",
      "19098 Traning Loss: tensor(0.9319)\n",
      "19099 Traning Loss: tensor(0.9318)\n",
      "19100 Traning Loss: tensor(0.9317)\n",
      "19101 Traning Loss: tensor(0.9317)\n",
      "19102 Traning Loss: tensor(0.9316)\n",
      "19103 Traning Loss: tensor(0.9315)\n",
      "19104 Traning Loss: tensor(0.9315)\n",
      "19105 Traning Loss: tensor(0.9314)\n",
      "19106 Traning Loss: tensor(0.9313)\n",
      "19107 Traning Loss: tensor(0.9312)\n",
      "19108 Traning Loss: tensor(0.9312)\n",
      "19109 Traning Loss: tensor(0.9311)\n",
      "19110 Traning Loss: tensor(0.9310)\n",
      "19111 Traning Loss: tensor(0.9310)\n",
      "19112 Traning Loss: tensor(0.9309)\n",
      "19113 Traning Loss: tensor(0.9308)\n",
      "19114 Traning Loss: tensor(0.9307)\n",
      "19115 Traning Loss: tensor(0.9307)\n",
      "19116 Traning Loss: tensor(0.9306)\n",
      "19117 Traning Loss: tensor(0.9305)\n",
      "19118 Traning Loss: tensor(0.9304)\n",
      "19119 Traning Loss: tensor(0.9304)\n",
      "19120 Traning Loss: tensor(0.9303)\n",
      "19121 Traning Loss: tensor(0.9302)\n",
      "19122 Traning Loss: tensor(0.9302)\n",
      "19123 Traning Loss: tensor(0.9301)\n",
      "19124 Traning Loss: tensor(0.9300)\n",
      "19125 Traning Loss: tensor(0.9299)\n",
      "19126 Traning Loss: tensor(0.9299)\n",
      "19127 Traning Loss: tensor(0.9298)\n",
      "19128 Traning Loss: tensor(0.9297)\n",
      "19129 Traning Loss: tensor(0.9297)\n",
      "19130 Traning Loss: tensor(0.9296)\n",
      "19131 Traning Loss: tensor(0.9295)\n",
      "19132 Traning Loss: tensor(0.9294)\n",
      "19133 Traning Loss: tensor(0.9294)\n",
      "19134 Traning Loss: tensor(0.9293)\n",
      "19135 Traning Loss: tensor(0.9292)\n",
      "19136 Traning Loss: tensor(0.9292)\n",
      "19137 Traning Loss: tensor(0.9291)\n",
      "19138 Traning Loss: tensor(0.9290)\n",
      "19139 Traning Loss: tensor(0.9289)\n",
      "19140 Traning Loss: tensor(0.9289)\n",
      "19141 Traning Loss: tensor(0.9288)\n",
      "19142 Traning Loss: tensor(0.9287)\n",
      "19143 Traning Loss: tensor(0.9286)\n",
      "19144 Traning Loss: tensor(0.9286)\n",
      "19145 Traning Loss: tensor(0.9285)\n",
      "19146 Traning Loss: tensor(0.9284)\n",
      "19147 Traning Loss: tensor(0.9284)\n",
      "19148 Traning Loss: tensor(0.9283)\n",
      "19149 Traning Loss: tensor(0.9282)\n",
      "19150 Traning Loss: tensor(0.9281)\n",
      "19151 Traning Loss: tensor(0.9281)\n",
      "19152 Traning Loss: tensor(0.9280)\n",
      "19153 Traning Loss: tensor(0.9279)\n",
      "19154 Traning Loss: tensor(0.9279)\n",
      "19155 Traning Loss: tensor(0.9278)\n",
      "19156 Traning Loss: tensor(0.9277)\n",
      "19157 Traning Loss: tensor(0.9276)\n",
      "19158 Traning Loss: tensor(0.9276)\n",
      "19159 Traning Loss: tensor(0.9275)\n",
      "19160 Traning Loss: tensor(0.9274)\n",
      "19161 Traning Loss: tensor(0.9273)\n",
      "19162 Traning Loss: tensor(0.9273)\n",
      "19163 Traning Loss: tensor(0.9272)\n",
      "19164 Traning Loss: tensor(0.9271)\n",
      "19165 Traning Loss: tensor(0.9271)\n",
      "19166 Traning Loss: tensor(0.9270)\n",
      "19167 Traning Loss: tensor(0.9269)\n",
      "19168 Traning Loss: tensor(0.9268)\n",
      "19169 Traning Loss: tensor(0.9268)\n",
      "19170 Traning Loss: tensor(0.9267)\n",
      "19171 Traning Loss: tensor(0.9266)\n",
      "19172 Traning Loss: tensor(0.9266)\n",
      "19173 Traning Loss: tensor(0.9265)\n",
      "19174 Traning Loss: tensor(0.9264)\n",
      "19175 Traning Loss: tensor(0.9263)\n",
      "19176 Traning Loss: tensor(0.9263)\n",
      "19177 Traning Loss: tensor(0.9262)\n",
      "19178 Traning Loss: tensor(0.9261)\n",
      "19179 Traning Loss: tensor(0.9261)\n",
      "19180 Traning Loss: tensor(0.9260)\n",
      "19181 Traning Loss: tensor(0.9259)\n",
      "19182 Traning Loss: tensor(0.9258)\n",
      "19183 Traning Loss: tensor(0.9258)\n",
      "19184 Traning Loss: tensor(0.9257)\n",
      "19185 Traning Loss: tensor(0.9256)\n",
      "19186 Traning Loss: tensor(0.9256)\n",
      "19187 Traning Loss: tensor(0.9255)\n",
      "19188 Traning Loss: tensor(0.9254)\n",
      "19189 Traning Loss: tensor(0.9253)\n",
      "19190 Traning Loss: tensor(0.9253)\n",
      "19191 Traning Loss: tensor(0.9252)\n",
      "19192 Traning Loss: tensor(0.9251)\n",
      "19193 Traning Loss: tensor(0.9250)\n",
      "19194 Traning Loss: tensor(0.9250)\n",
      "19195 Traning Loss: tensor(0.9249)\n",
      "19196 Traning Loss: tensor(0.9248)\n",
      "19197 Traning Loss: tensor(0.9248)\n",
      "19198 Traning Loss: tensor(0.9247)\n",
      "19199 Traning Loss: tensor(0.9246)\n",
      "19200 Traning Loss: tensor(0.9245)\n",
      "19201 Traning Loss: tensor(0.9245)\n",
      "19202 Traning Loss: tensor(0.9244)\n",
      "19203 Traning Loss: tensor(0.9243)\n",
      "19204 Traning Loss: tensor(0.9243)\n",
      "19205 Traning Loss: tensor(0.9242)\n",
      "19206 Traning Loss: tensor(0.9241)\n",
      "19207 Traning Loss: tensor(0.9240)\n",
      "19208 Traning Loss: tensor(0.9240)\n",
      "19209 Traning Loss: tensor(0.9239)\n",
      "19210 Traning Loss: tensor(0.9238)\n",
      "19211 Traning Loss: tensor(0.9238)\n",
      "19212 Traning Loss: tensor(0.9237)\n",
      "19213 Traning Loss: tensor(0.9236)\n",
      "19214 Traning Loss: tensor(0.9235)\n",
      "19215 Traning Loss: tensor(0.9235)\n",
      "19216 Traning Loss: tensor(0.9234)\n",
      "19217 Traning Loss: tensor(0.9233)\n",
      "19218 Traning Loss: tensor(0.9233)\n",
      "19219 Traning Loss: tensor(0.9232)\n",
      "19220 Traning Loss: tensor(0.9231)\n",
      "19221 Traning Loss: tensor(0.9230)\n",
      "19222 Traning Loss: tensor(0.9230)\n",
      "19223 Traning Loss: tensor(0.9229)\n",
      "19224 Traning Loss: tensor(0.9228)\n",
      "19225 Traning Loss: tensor(0.9228)\n",
      "19226 Traning Loss: tensor(0.9227)\n",
      "19227 Traning Loss: tensor(0.9226)\n",
      "19228 Traning Loss: tensor(0.9225)\n",
      "19229 Traning Loss: tensor(0.9225)\n",
      "19230 Traning Loss: tensor(0.9224)\n",
      "19231 Traning Loss: tensor(0.9223)\n",
      "19232 Traning Loss: tensor(0.9222)\n",
      "19233 Traning Loss: tensor(0.9222)\n",
      "19234 Traning Loss: tensor(0.9221)\n",
      "19235 Traning Loss: tensor(0.9220)\n",
      "19236 Traning Loss: tensor(0.9220)\n",
      "19237 Traning Loss: tensor(0.9219)\n",
      "19238 Traning Loss: tensor(0.9218)\n",
      "19239 Traning Loss: tensor(0.9217)\n",
      "19240 Traning Loss: tensor(0.9217)\n",
      "19241 Traning Loss: tensor(0.9216)\n",
      "19242 Traning Loss: tensor(0.9215)\n",
      "19243 Traning Loss: tensor(0.9215)\n",
      "19244 Traning Loss: tensor(0.9214)\n",
      "19245 Traning Loss: tensor(0.9213)\n",
      "19246 Traning Loss: tensor(0.9212)\n",
      "19247 Traning Loss: tensor(0.9212)\n",
      "19248 Traning Loss: tensor(0.9211)\n",
      "19249 Traning Loss: tensor(0.9210)\n",
      "19250 Traning Loss: tensor(0.9210)\n",
      "19251 Traning Loss: tensor(0.9209)\n",
      "19252 Traning Loss: tensor(0.9208)\n",
      "19253 Traning Loss: tensor(0.9207)\n",
      "19254 Traning Loss: tensor(0.9207)\n",
      "19255 Traning Loss: tensor(0.9206)\n",
      "19256 Traning Loss: tensor(0.9205)\n",
      "19257 Traning Loss: tensor(0.9205)\n",
      "19258 Traning Loss: tensor(0.9204)\n",
      "19259 Traning Loss: tensor(0.9203)\n",
      "19260 Traning Loss: tensor(0.9202)\n",
      "19261 Traning Loss: tensor(0.9202)\n",
      "19262 Traning Loss: tensor(0.9201)\n",
      "19263 Traning Loss: tensor(0.9200)\n",
      "19264 Traning Loss: tensor(0.9200)\n",
      "19265 Traning Loss: tensor(0.9199)\n",
      "19266 Traning Loss: tensor(0.9198)\n",
      "19267 Traning Loss: tensor(0.9197)\n",
      "19268 Traning Loss: tensor(0.9197)\n",
      "19269 Traning Loss: tensor(0.9196)\n",
      "19270 Traning Loss: tensor(0.9195)\n",
      "19271 Traning Loss: tensor(0.9195)\n",
      "19272 Traning Loss: tensor(0.9194)\n",
      "19273 Traning Loss: tensor(0.9193)\n",
      "19274 Traning Loss: tensor(0.9192)\n",
      "19275 Traning Loss: tensor(0.9192)\n",
      "19276 Traning Loss: tensor(0.9191)\n",
      "19277 Traning Loss: tensor(0.9190)\n",
      "19278 Traning Loss: tensor(0.9190)\n",
      "19279 Traning Loss: tensor(0.9189)\n",
      "19280 Traning Loss: tensor(0.9188)\n",
      "19281 Traning Loss: tensor(0.9187)\n",
      "19282 Traning Loss: tensor(0.9187)\n",
      "19283 Traning Loss: tensor(0.9186)\n",
      "19284 Traning Loss: tensor(0.9185)\n",
      "19285 Traning Loss: tensor(0.9185)\n",
      "19286 Traning Loss: tensor(0.9184)\n",
      "19287 Traning Loss: tensor(0.9183)\n",
      "19288 Traning Loss: tensor(0.9182)\n",
      "19289 Traning Loss: tensor(0.9182)\n",
      "19290 Traning Loss: tensor(0.9181)\n",
      "19291 Traning Loss: tensor(0.9180)\n",
      "19292 Traning Loss: tensor(0.9180)\n",
      "19293 Traning Loss: tensor(0.9179)\n",
      "19294 Traning Loss: tensor(0.9178)\n",
      "19295 Traning Loss: tensor(0.9177)\n",
      "19296 Traning Loss: tensor(0.9177)\n",
      "19297 Traning Loss: tensor(0.9176)\n",
      "19298 Traning Loss: tensor(0.9175)\n",
      "19299 Traning Loss: tensor(0.9175)\n",
      "19300 Traning Loss: tensor(0.9174)\n",
      "19301 Traning Loss: tensor(0.9173)\n",
      "19302 Traning Loss: tensor(0.9172)\n",
      "19303 Traning Loss: tensor(0.9172)\n",
      "19304 Traning Loss: tensor(0.9171)\n",
      "19305 Traning Loss: tensor(0.9170)\n",
      "19306 Traning Loss: tensor(0.9170)\n",
      "19307 Traning Loss: tensor(0.9169)\n",
      "19308 Traning Loss: tensor(0.9168)\n",
      "19309 Traning Loss: tensor(0.9167)\n",
      "19310 Traning Loss: tensor(0.9167)\n",
      "19311 Traning Loss: tensor(0.9166)\n",
      "19312 Traning Loss: tensor(0.9165)\n",
      "19313 Traning Loss: tensor(0.9165)\n",
      "19314 Traning Loss: tensor(0.9164)\n",
      "19315 Traning Loss: tensor(0.9163)\n",
      "19316 Traning Loss: tensor(0.9162)\n",
      "19317 Traning Loss: tensor(0.9162)\n",
      "19318 Traning Loss: tensor(0.9161)\n",
      "19319 Traning Loss: tensor(0.9160)\n",
      "19320 Traning Loss: tensor(0.9160)\n",
      "19321 Traning Loss: tensor(0.9159)\n",
      "19322 Traning Loss: tensor(0.9158)\n",
      "19323 Traning Loss: tensor(0.9157)\n",
      "19324 Traning Loss: tensor(0.9157)\n",
      "19325 Traning Loss: tensor(0.9156)\n",
      "19326 Traning Loss: tensor(0.9155)\n",
      "19327 Traning Loss: tensor(0.9155)\n",
      "19328 Traning Loss: tensor(0.9154)\n",
      "19329 Traning Loss: tensor(0.9153)\n",
      "19330 Traning Loss: tensor(0.9152)\n",
      "19331 Traning Loss: tensor(0.9152)\n",
      "19332 Traning Loss: tensor(0.9151)\n",
      "19333 Traning Loss: tensor(0.9150)\n",
      "19334 Traning Loss: tensor(0.9150)\n",
      "19335 Traning Loss: tensor(0.9149)\n",
      "19336 Traning Loss: tensor(0.9148)\n",
      "19337 Traning Loss: tensor(0.9147)\n",
      "19338 Traning Loss: tensor(0.9147)\n",
      "19339 Traning Loss: tensor(0.9146)\n",
      "19340 Traning Loss: tensor(0.9145)\n",
      "19341 Traning Loss: tensor(0.9145)\n",
      "19342 Traning Loss: tensor(0.9144)\n",
      "19343 Traning Loss: tensor(0.9143)\n",
      "19344 Traning Loss: tensor(0.9142)\n",
      "19345 Traning Loss: tensor(0.9142)\n",
      "19346 Traning Loss: tensor(0.9141)\n",
      "19347 Traning Loss: tensor(0.9140)\n",
      "19348 Traning Loss: tensor(0.9140)\n",
      "19349 Traning Loss: tensor(0.9139)\n",
      "19350 Traning Loss: tensor(0.9138)\n",
      "19351 Traning Loss: tensor(0.9137)\n",
      "19352 Traning Loss: tensor(0.9137)\n",
      "19353 Traning Loss: tensor(0.9136)\n",
      "19354 Traning Loss: tensor(0.9135)\n",
      "19355 Traning Loss: tensor(0.9135)\n",
      "19356 Traning Loss: tensor(0.9134)\n",
      "19357 Traning Loss: tensor(0.9133)\n",
      "19358 Traning Loss: tensor(0.9133)\n",
      "19359 Traning Loss: tensor(0.9132)\n",
      "19360 Traning Loss: tensor(0.9131)\n",
      "19361 Traning Loss: tensor(0.9130)\n",
      "19362 Traning Loss: tensor(0.9130)\n",
      "19363 Traning Loss: tensor(0.9129)\n",
      "19364 Traning Loss: tensor(0.9128)\n",
      "19365 Traning Loss: tensor(0.9128)\n",
      "19366 Traning Loss: tensor(0.9127)\n",
      "19367 Traning Loss: tensor(0.9126)\n",
      "19368 Traning Loss: tensor(0.9125)\n",
      "19369 Traning Loss: tensor(0.9125)\n",
      "19370 Traning Loss: tensor(0.9124)\n",
      "19371 Traning Loss: tensor(0.9123)\n",
      "19372 Traning Loss: tensor(0.9123)\n",
      "19373 Traning Loss: tensor(0.9122)\n",
      "19374 Traning Loss: tensor(0.9121)\n",
      "19375 Traning Loss: tensor(0.9120)\n",
      "19376 Traning Loss: tensor(0.9120)\n",
      "19377 Traning Loss: tensor(0.9119)\n",
      "19378 Traning Loss: tensor(0.9118)\n",
      "19379 Traning Loss: tensor(0.9118)\n",
      "19380 Traning Loss: tensor(0.9117)\n",
      "19381 Traning Loss: tensor(0.9116)\n",
      "19382 Traning Loss: tensor(0.9115)\n",
      "19383 Traning Loss: tensor(0.9115)\n",
      "19384 Traning Loss: tensor(0.9114)\n",
      "19385 Traning Loss: tensor(0.9113)\n",
      "19386 Traning Loss: tensor(0.9113)\n",
      "19387 Traning Loss: tensor(0.9112)\n",
      "19388 Traning Loss: tensor(0.9111)\n",
      "19389 Traning Loss: tensor(0.9110)\n",
      "19390 Traning Loss: tensor(0.9110)\n",
      "19391 Traning Loss: tensor(0.9109)\n",
      "19392 Traning Loss: tensor(0.9108)\n",
      "19393 Traning Loss: tensor(0.9108)\n",
      "19394 Traning Loss: tensor(0.9107)\n",
      "19395 Traning Loss: tensor(0.9106)\n",
      "19396 Traning Loss: tensor(0.9106)\n",
      "19397 Traning Loss: tensor(0.9105)\n",
      "19398 Traning Loss: tensor(0.9104)\n",
      "19399 Traning Loss: tensor(0.9103)\n",
      "19400 Traning Loss: tensor(0.9103)\n",
      "19401 Traning Loss: tensor(0.9102)\n",
      "19402 Traning Loss: tensor(0.9101)\n",
      "19403 Traning Loss: tensor(0.9101)\n",
      "19404 Traning Loss: tensor(0.9100)\n",
      "19405 Traning Loss: tensor(0.9099)\n",
      "19406 Traning Loss: tensor(0.9098)\n",
      "19407 Traning Loss: tensor(0.9098)\n",
      "19408 Traning Loss: tensor(0.9097)\n",
      "19409 Traning Loss: tensor(0.9096)\n",
      "19410 Traning Loss: tensor(0.9096)\n",
      "19411 Traning Loss: tensor(0.9095)\n",
      "19412 Traning Loss: tensor(0.9094)\n",
      "19413 Traning Loss: tensor(0.9093)\n",
      "19414 Traning Loss: tensor(0.9093)\n",
      "19415 Traning Loss: tensor(0.9092)\n",
      "19416 Traning Loss: tensor(0.9091)\n",
      "19417 Traning Loss: tensor(0.9091)\n",
      "19418 Traning Loss: tensor(0.9090)\n",
      "19419 Traning Loss: tensor(0.9089)\n",
      "19420 Traning Loss: tensor(0.9089)\n",
      "19421 Traning Loss: tensor(0.9088)\n",
      "19422 Traning Loss: tensor(0.9087)\n",
      "19423 Traning Loss: tensor(0.9086)\n",
      "19424 Traning Loss: tensor(0.9086)\n",
      "19425 Traning Loss: tensor(0.9085)\n",
      "19426 Traning Loss: tensor(0.9084)\n",
      "19427 Traning Loss: tensor(0.9084)\n",
      "19428 Traning Loss: tensor(0.9083)\n",
      "19429 Traning Loss: tensor(0.9082)\n",
      "19430 Traning Loss: tensor(0.9081)\n",
      "19431 Traning Loss: tensor(0.9081)\n",
      "19432 Traning Loss: tensor(0.9080)\n",
      "19433 Traning Loss: tensor(0.9079)\n",
      "19434 Traning Loss: tensor(0.9079)\n",
      "19435 Traning Loss: tensor(0.9078)\n",
      "19436 Traning Loss: tensor(0.9077)\n",
      "19437 Traning Loss: tensor(0.9077)\n",
      "19438 Traning Loss: tensor(0.9076)\n",
      "19439 Traning Loss: tensor(0.9075)\n",
      "19440 Traning Loss: tensor(0.9074)\n",
      "19441 Traning Loss: tensor(0.9074)\n",
      "19442 Traning Loss: tensor(0.9073)\n",
      "19443 Traning Loss: tensor(0.9072)\n",
      "19444 Traning Loss: tensor(0.9072)\n",
      "19445 Traning Loss: tensor(0.9071)\n",
      "19446 Traning Loss: tensor(0.9070)\n",
      "19447 Traning Loss: tensor(0.9069)\n",
      "19448 Traning Loss: tensor(0.9069)\n",
      "19449 Traning Loss: tensor(0.9068)\n",
      "19450 Traning Loss: tensor(0.9067)\n",
      "19451 Traning Loss: tensor(0.9067)\n",
      "19452 Traning Loss: tensor(0.9066)\n",
      "19453 Traning Loss: tensor(0.9065)\n",
      "19454 Traning Loss: tensor(0.9065)\n",
      "19455 Traning Loss: tensor(0.9064)\n",
      "19456 Traning Loss: tensor(0.9063)\n",
      "19457 Traning Loss: tensor(0.9062)\n",
      "19458 Traning Loss: tensor(0.9062)\n",
      "19459 Traning Loss: tensor(0.9061)\n",
      "19460 Traning Loss: tensor(0.9060)\n",
      "19461 Traning Loss: tensor(0.9060)\n",
      "19462 Traning Loss: tensor(0.9059)\n",
      "19463 Traning Loss: tensor(0.9058)\n",
      "19464 Traning Loss: tensor(0.9057)\n",
      "19465 Traning Loss: tensor(0.9057)\n",
      "19466 Traning Loss: tensor(0.9056)\n",
      "19467 Traning Loss: tensor(0.9055)\n",
      "19468 Traning Loss: tensor(0.9055)\n",
      "19469 Traning Loss: tensor(0.9054)\n",
      "19470 Traning Loss: tensor(0.9053)\n",
      "19471 Traning Loss: tensor(0.9053)\n",
      "19472 Traning Loss: tensor(0.9052)\n",
      "19473 Traning Loss: tensor(0.9051)\n",
      "19474 Traning Loss: tensor(0.9050)\n",
      "19475 Traning Loss: tensor(0.9050)\n",
      "19476 Traning Loss: tensor(0.9049)\n",
      "19477 Traning Loss: tensor(0.9048)\n",
      "19478 Traning Loss: tensor(0.9048)\n",
      "19479 Traning Loss: tensor(0.9047)\n",
      "19480 Traning Loss: tensor(0.9046)\n",
      "19481 Traning Loss: tensor(0.9045)\n",
      "19482 Traning Loss: tensor(0.9045)\n",
      "19483 Traning Loss: tensor(0.9044)\n",
      "19484 Traning Loss: tensor(0.9043)\n",
      "19485 Traning Loss: tensor(0.9043)\n",
      "19486 Traning Loss: tensor(0.9042)\n",
      "19487 Traning Loss: tensor(0.9041)\n",
      "19488 Traning Loss: tensor(0.9041)\n",
      "19489 Traning Loss: tensor(0.9040)\n",
      "19490 Traning Loss: tensor(0.9039)\n",
      "19491 Traning Loss: tensor(0.9038)\n",
      "19492 Traning Loss: tensor(0.9038)\n",
      "19493 Traning Loss: tensor(0.9037)\n",
      "19494 Traning Loss: tensor(0.9036)\n",
      "19495 Traning Loss: tensor(0.9036)\n",
      "19496 Traning Loss: tensor(0.9035)\n",
      "19497 Traning Loss: tensor(0.9034)\n",
      "19498 Traning Loss: tensor(0.9034)\n",
      "19499 Traning Loss: tensor(0.9033)\n",
      "19500 Traning Loss: tensor(0.9032)\n",
      "19501 Traning Loss: tensor(0.9031)\n",
      "19502 Traning Loss: tensor(0.9031)\n",
      "19503 Traning Loss: tensor(0.9030)\n",
      "19504 Traning Loss: tensor(0.9029)\n",
      "19505 Traning Loss: tensor(0.9029)\n",
      "19506 Traning Loss: tensor(0.9028)\n",
      "19507 Traning Loss: tensor(0.9027)\n",
      "19508 Traning Loss: tensor(0.9027)\n",
      "19509 Traning Loss: tensor(0.9026)\n",
      "19510 Traning Loss: tensor(0.9025)\n",
      "19511 Traning Loss: tensor(0.9024)\n",
      "19512 Traning Loss: tensor(0.9024)\n",
      "19513 Traning Loss: tensor(0.9023)\n",
      "19514 Traning Loss: tensor(0.9022)\n",
      "19515 Traning Loss: tensor(0.9022)\n",
      "19516 Traning Loss: tensor(0.9021)\n",
      "19517 Traning Loss: tensor(0.9020)\n",
      "19518 Traning Loss: tensor(0.9019)\n",
      "19519 Traning Loss: tensor(0.9019)\n",
      "19520 Traning Loss: tensor(0.9018)\n",
      "19521 Traning Loss: tensor(0.9017)\n",
      "19522 Traning Loss: tensor(0.9017)\n",
      "19523 Traning Loss: tensor(0.9016)\n",
      "19524 Traning Loss: tensor(0.9015)\n",
      "19525 Traning Loss: tensor(0.9015)\n",
      "19526 Traning Loss: tensor(0.9014)\n",
      "19527 Traning Loss: tensor(0.9013)\n",
      "19528 Traning Loss: tensor(0.9013)\n",
      "19529 Traning Loss: tensor(0.9012)\n",
      "19530 Traning Loss: tensor(0.9011)\n",
      "19531 Traning Loss: tensor(0.9010)\n",
      "19532 Traning Loss: tensor(0.9010)\n",
      "19533 Traning Loss: tensor(0.9009)\n",
      "19534 Traning Loss: tensor(0.9008)\n",
      "19535 Traning Loss: tensor(0.9008)\n",
      "19536 Traning Loss: tensor(0.9007)\n",
      "19537 Traning Loss: tensor(0.9006)\n",
      "19538 Traning Loss: tensor(0.9005)\n",
      "19539 Traning Loss: tensor(0.9005)\n",
      "19540 Traning Loss: tensor(0.9004)\n",
      "19541 Traning Loss: tensor(0.9003)\n",
      "19542 Traning Loss: tensor(0.9003)\n",
      "19543 Traning Loss: tensor(0.9002)\n",
      "19544 Traning Loss: tensor(0.9001)\n",
      "19545 Traning Loss: tensor(0.9001)\n",
      "19546 Traning Loss: tensor(0.9000)\n",
      "19547 Traning Loss: tensor(0.8999)\n",
      "19548 Traning Loss: tensor(0.8998)\n",
      "19549 Traning Loss: tensor(0.8998)\n",
      "19550 Traning Loss: tensor(0.8997)\n",
      "19551 Traning Loss: tensor(0.8996)\n",
      "19552 Traning Loss: tensor(0.8996)\n",
      "19553 Traning Loss: tensor(0.8995)\n",
      "19554 Traning Loss: tensor(0.8994)\n",
      "19555 Traning Loss: tensor(0.8994)\n",
      "19556 Traning Loss: tensor(0.8993)\n",
      "19557 Traning Loss: tensor(0.8992)\n",
      "19558 Traning Loss: tensor(0.8992)\n",
      "19559 Traning Loss: tensor(0.8991)\n",
      "19560 Traning Loss: tensor(0.8990)\n",
      "19561 Traning Loss: tensor(0.8989)\n",
      "19562 Traning Loss: tensor(0.8989)\n",
      "19563 Traning Loss: tensor(0.8988)\n",
      "19564 Traning Loss: tensor(0.8987)\n",
      "19565 Traning Loss: tensor(0.8987)\n",
      "19566 Traning Loss: tensor(0.8986)\n",
      "19567 Traning Loss: tensor(0.8985)\n",
      "19568 Traning Loss: tensor(0.8985)\n",
      "19569 Traning Loss: tensor(0.8984)\n",
      "19570 Traning Loss: tensor(0.8983)\n",
      "19571 Traning Loss: tensor(0.8982)\n",
      "19572 Traning Loss: tensor(0.8982)\n",
      "19573 Traning Loss: tensor(0.8981)\n",
      "19574 Traning Loss: tensor(0.8980)\n",
      "19575 Traning Loss: tensor(0.8980)\n",
      "19576 Traning Loss: tensor(0.8979)\n",
      "19577 Traning Loss: tensor(0.8978)\n",
      "19578 Traning Loss: tensor(0.8978)\n",
      "19579 Traning Loss: tensor(0.8977)\n",
      "19580 Traning Loss: tensor(0.8976)\n",
      "19581 Traning Loss: tensor(0.8975)\n",
      "19582 Traning Loss: tensor(0.8975)\n",
      "19583 Traning Loss: tensor(0.8974)\n",
      "19584 Traning Loss: tensor(0.8973)\n",
      "19585 Traning Loss: tensor(0.8973)\n",
      "19586 Traning Loss: tensor(0.8972)\n",
      "19587 Traning Loss: tensor(0.8971)\n",
      "19588 Traning Loss: tensor(0.8971)\n",
      "19589 Traning Loss: tensor(0.8970)\n",
      "19590 Traning Loss: tensor(0.8969)\n",
      "19591 Traning Loss: tensor(0.8968)\n",
      "19592 Traning Loss: tensor(0.8968)\n",
      "19593 Traning Loss: tensor(0.8967)\n",
      "19594 Traning Loss: tensor(0.8966)\n",
      "19595 Traning Loss: tensor(0.8966)\n",
      "19596 Traning Loss: tensor(0.8965)\n",
      "19597 Traning Loss: tensor(0.8964)\n",
      "19598 Traning Loss: tensor(0.8964)\n",
      "19599 Traning Loss: tensor(0.8963)\n",
      "19600 Traning Loss: tensor(0.8962)\n",
      "19601 Traning Loss: tensor(0.8962)\n",
      "19602 Traning Loss: tensor(0.8961)\n",
      "19603 Traning Loss: tensor(0.8960)\n",
      "19604 Traning Loss: tensor(0.8959)\n",
      "19605 Traning Loss: tensor(0.8959)\n",
      "19606 Traning Loss: tensor(0.8958)\n",
      "19607 Traning Loss: tensor(0.8957)\n",
      "19608 Traning Loss: tensor(0.8957)\n",
      "19609 Traning Loss: tensor(0.8956)\n",
      "19610 Traning Loss: tensor(0.8955)\n",
      "19611 Traning Loss: tensor(0.8955)\n",
      "19612 Traning Loss: tensor(0.8954)\n",
      "19613 Traning Loss: tensor(0.8953)\n",
      "19614 Traning Loss: tensor(0.8953)\n",
      "19615 Traning Loss: tensor(0.8952)\n",
      "19616 Traning Loss: tensor(0.8951)\n",
      "19617 Traning Loss: tensor(0.8950)\n",
      "19618 Traning Loss: tensor(0.8950)\n",
      "19619 Traning Loss: tensor(0.8949)\n",
      "19620 Traning Loss: tensor(0.8948)\n",
      "19621 Traning Loss: tensor(0.8948)\n",
      "19622 Traning Loss: tensor(0.8947)\n",
      "19623 Traning Loss: tensor(0.8946)\n",
      "19624 Traning Loss: tensor(0.8946)\n",
      "19625 Traning Loss: tensor(0.8945)\n",
      "19626 Traning Loss: tensor(0.8944)\n",
      "19627 Traning Loss: tensor(0.8943)\n",
      "19628 Traning Loss: tensor(0.8943)\n",
      "19629 Traning Loss: tensor(0.8942)\n",
      "19630 Traning Loss: tensor(0.8941)\n",
      "19631 Traning Loss: tensor(0.8941)\n",
      "19632 Traning Loss: tensor(0.8940)\n",
      "19633 Traning Loss: tensor(0.8939)\n",
      "19634 Traning Loss: tensor(0.8939)\n",
      "19635 Traning Loss: tensor(0.8938)\n",
      "19636 Traning Loss: tensor(0.8937)\n",
      "19637 Traning Loss: tensor(0.8937)\n",
      "19638 Traning Loss: tensor(0.8936)\n",
      "19639 Traning Loss: tensor(0.8935)\n",
      "19640 Traning Loss: tensor(0.8934)\n",
      "19641 Traning Loss: tensor(0.8934)\n",
      "19642 Traning Loss: tensor(0.8933)\n",
      "19643 Traning Loss: tensor(0.8932)\n",
      "19644 Traning Loss: tensor(0.8932)\n",
      "19645 Traning Loss: tensor(0.8931)\n",
      "19646 Traning Loss: tensor(0.8930)\n",
      "19647 Traning Loss: tensor(0.8930)\n",
      "19648 Traning Loss: tensor(0.8929)\n",
      "19649 Traning Loss: tensor(0.8928)\n",
      "19650 Traning Loss: tensor(0.8928)\n",
      "19651 Traning Loss: tensor(0.8927)\n",
      "19652 Traning Loss: tensor(0.8926)\n",
      "19653 Traning Loss: tensor(0.8925)\n",
      "19654 Traning Loss: tensor(0.8925)\n",
      "19655 Traning Loss: tensor(0.8924)\n",
      "19656 Traning Loss: tensor(0.8923)\n",
      "19657 Traning Loss: tensor(0.8923)\n",
      "19658 Traning Loss: tensor(0.8922)\n",
      "19659 Traning Loss: tensor(0.8921)\n",
      "19660 Traning Loss: tensor(0.8921)\n",
      "19661 Traning Loss: tensor(0.8920)\n",
      "19662 Traning Loss: tensor(0.8919)\n",
      "19663 Traning Loss: tensor(0.8919)\n",
      "19664 Traning Loss: tensor(0.8918)\n",
      "19665 Traning Loss: tensor(0.8917)\n",
      "19666 Traning Loss: tensor(0.8917)\n",
      "19667 Traning Loss: tensor(0.8916)\n",
      "19668 Traning Loss: tensor(0.8915)\n",
      "19669 Traning Loss: tensor(0.8914)\n",
      "19670 Traning Loss: tensor(0.8914)\n",
      "19671 Traning Loss: tensor(0.8913)\n",
      "19672 Traning Loss: tensor(0.8912)\n",
      "19673 Traning Loss: tensor(0.8912)\n",
      "19674 Traning Loss: tensor(0.8911)\n",
      "19675 Traning Loss: tensor(0.8910)\n",
      "19676 Traning Loss: tensor(0.8910)\n",
      "19677 Traning Loss: tensor(0.8909)\n",
      "19678 Traning Loss: tensor(0.8908)\n",
      "19679 Traning Loss: tensor(0.8908)\n",
      "19680 Traning Loss: tensor(0.8907)\n",
      "19681 Traning Loss: tensor(0.8906)\n",
      "19682 Traning Loss: tensor(0.8905)\n",
      "19683 Traning Loss: tensor(0.8905)\n",
      "19684 Traning Loss: tensor(0.8904)\n",
      "19685 Traning Loss: tensor(0.8903)\n",
      "19686 Traning Loss: tensor(0.8903)\n",
      "19687 Traning Loss: tensor(0.8902)\n",
      "19688 Traning Loss: tensor(0.8901)\n",
      "19689 Traning Loss: tensor(0.8901)\n",
      "19690 Traning Loss: tensor(0.8900)\n",
      "19691 Traning Loss: tensor(0.8899)\n",
      "19692 Traning Loss: tensor(0.8899)\n",
      "19693 Traning Loss: tensor(0.8898)\n",
      "19694 Traning Loss: tensor(0.8897)\n",
      "19695 Traning Loss: tensor(0.8897)\n",
      "19696 Traning Loss: tensor(0.8896)\n",
      "19697 Traning Loss: tensor(0.8895)\n",
      "19698 Traning Loss: tensor(0.8894)\n",
      "19699 Traning Loss: tensor(0.8894)\n",
      "19700 Traning Loss: tensor(0.8893)\n",
      "19701 Traning Loss: tensor(0.8892)\n",
      "19702 Traning Loss: tensor(0.8892)\n",
      "19703 Traning Loss: tensor(0.8891)\n",
      "19704 Traning Loss: tensor(0.8890)\n",
      "19705 Traning Loss: tensor(0.8890)\n",
      "19706 Traning Loss: tensor(0.8889)\n",
      "19707 Traning Loss: tensor(0.8888)\n",
      "19708 Traning Loss: tensor(0.8888)\n",
      "19709 Traning Loss: tensor(0.8887)\n",
      "19710 Traning Loss: tensor(0.8886)\n",
      "19711 Traning Loss: tensor(0.8886)\n",
      "19712 Traning Loss: tensor(0.8885)\n",
      "19713 Traning Loss: tensor(0.8884)\n",
      "19714 Traning Loss: tensor(0.8883)\n",
      "19715 Traning Loss: tensor(0.8883)\n",
      "19716 Traning Loss: tensor(0.8882)\n",
      "19717 Traning Loss: tensor(0.8881)\n",
      "19718 Traning Loss: tensor(0.8881)\n",
      "19719 Traning Loss: tensor(0.8880)\n",
      "19720 Traning Loss: tensor(0.8879)\n",
      "19721 Traning Loss: tensor(0.8879)\n",
      "19722 Traning Loss: tensor(0.8878)\n",
      "19723 Traning Loss: tensor(0.8877)\n",
      "19724 Traning Loss: tensor(0.8877)\n",
      "19725 Traning Loss: tensor(0.8876)\n",
      "19726 Traning Loss: tensor(0.8875)\n",
      "19727 Traning Loss: tensor(0.8875)\n",
      "19728 Traning Loss: tensor(0.8874)\n",
      "19729 Traning Loss: tensor(0.8873)\n",
      "19730 Traning Loss: tensor(0.8873)\n",
      "19731 Traning Loss: tensor(0.8872)\n",
      "19732 Traning Loss: tensor(0.8871)\n",
      "19733 Traning Loss: tensor(0.8870)\n",
      "19734 Traning Loss: tensor(0.8870)\n",
      "19735 Traning Loss: tensor(0.8869)\n",
      "19736 Traning Loss: tensor(0.8868)\n",
      "19737 Traning Loss: tensor(0.8868)\n",
      "19738 Traning Loss: tensor(0.8867)\n",
      "19739 Traning Loss: tensor(0.8866)\n",
      "19740 Traning Loss: tensor(0.8866)\n",
      "19741 Traning Loss: tensor(0.8865)\n",
      "19742 Traning Loss: tensor(0.8864)\n",
      "19743 Traning Loss: tensor(0.8864)\n",
      "19744 Traning Loss: tensor(0.8863)\n",
      "19745 Traning Loss: tensor(0.8862)\n",
      "19746 Traning Loss: tensor(0.8862)\n",
      "19747 Traning Loss: tensor(0.8861)\n",
      "19748 Traning Loss: tensor(0.8860)\n",
      "19749 Traning Loss: tensor(0.8860)\n",
      "19750 Traning Loss: tensor(0.8859)\n",
      "19751 Traning Loss: tensor(0.8858)\n",
      "19752 Traning Loss: tensor(0.8857)\n",
      "19753 Traning Loss: tensor(0.8857)\n",
      "19754 Traning Loss: tensor(0.8856)\n",
      "19755 Traning Loss: tensor(0.8855)\n",
      "19756 Traning Loss: tensor(0.8855)\n",
      "19757 Traning Loss: tensor(0.8854)\n",
      "19758 Traning Loss: tensor(0.8853)\n",
      "19759 Traning Loss: tensor(0.8853)\n",
      "19760 Traning Loss: tensor(0.8852)\n",
      "19761 Traning Loss: tensor(0.8851)\n",
      "19762 Traning Loss: tensor(0.8851)\n",
      "19763 Traning Loss: tensor(0.8850)\n",
      "19764 Traning Loss: tensor(0.8849)\n",
      "19765 Traning Loss: tensor(0.8849)\n",
      "19766 Traning Loss: tensor(0.8848)\n",
      "19767 Traning Loss: tensor(0.8847)\n",
      "19768 Traning Loss: tensor(0.8847)\n",
      "19769 Traning Loss: tensor(0.8846)\n",
      "19770 Traning Loss: tensor(0.8845)\n",
      "19771 Traning Loss: tensor(0.8845)\n",
      "19772 Traning Loss: tensor(0.8844)\n",
      "19773 Traning Loss: tensor(0.8843)\n",
      "19774 Traning Loss: tensor(0.8842)\n",
      "19775 Traning Loss: tensor(0.8842)\n",
      "19776 Traning Loss: tensor(0.8841)\n",
      "19777 Traning Loss: tensor(0.8840)\n",
      "19778 Traning Loss: tensor(0.8840)\n",
      "19779 Traning Loss: tensor(0.8839)\n",
      "19780 Traning Loss: tensor(0.8838)\n",
      "19781 Traning Loss: tensor(0.8838)\n",
      "19782 Traning Loss: tensor(0.8837)\n",
      "19783 Traning Loss: tensor(0.8836)\n",
      "19784 Traning Loss: tensor(0.9914)\n",
      "19785 Traning Loss: tensor(0.9913)\n",
      "19786 Traning Loss: tensor(0.9912)\n",
      "19787 Traning Loss: tensor(0.9910)\n",
      "19788 Traning Loss: tensor(0.9908)\n",
      "19789 Traning Loss: tensor(0.9907)\n",
      "19790 Traning Loss: tensor(0.9905)\n",
      "19791 Traning Loss: tensor(0.9903)\n",
      "19792 Traning Loss: tensor(0.9901)\n",
      "19793 Traning Loss: tensor(0.9899)\n",
      "19794 Traning Loss: tensor(0.9897)\n",
      "19795 Traning Loss: tensor(0.9895)\n",
      "19796 Traning Loss: tensor(0.9893)\n",
      "19797 Traning Loss: tensor(0.9891)\n",
      "19798 Traning Loss: tensor(0.9889)\n",
      "19799 Traning Loss: tensor(0.9887)\n",
      "19800 Traning Loss: tensor(0.9886)\n",
      "19801 Traning Loss: tensor(0.9884)\n",
      "19802 Traning Loss: tensor(0.9882)\n",
      "19803 Traning Loss: tensor(0.9880)\n",
      "19804 Traning Loss: tensor(0.9878)\n",
      "19805 Traning Loss: tensor(0.9877)\n",
      "19806 Traning Loss: tensor(0.9875)\n",
      "19807 Traning Loss: tensor(0.9873)\n",
      "19808 Traning Loss: tensor(0.9871)\n",
      "19809 Traning Loss: tensor(0.9870)\n",
      "19810 Traning Loss: tensor(0.9868)\n",
      "19811 Traning Loss: tensor(0.9866)\n",
      "19812 Traning Loss: tensor(0.9864)\n",
      "19813 Traning Loss: tensor(0.9863)\n",
      "19814 Traning Loss: tensor(0.9861)\n",
      "19815 Traning Loss: tensor(0.9859)\n",
      "19816 Traning Loss: tensor(0.9858)\n",
      "19817 Traning Loss: tensor(0.9856)\n",
      "19818 Traning Loss: tensor(0.9854)\n",
      "19819 Traning Loss: tensor(0.9852)\n",
      "19820 Traning Loss: tensor(0.9851)\n",
      "19821 Traning Loss: tensor(0.9849)\n",
      "19822 Traning Loss: tensor(0.9847)\n",
      "19823 Traning Loss: tensor(0.9845)\n",
      "19824 Traning Loss: tensor(0.9844)\n",
      "19825 Traning Loss: tensor(0.9842)\n",
      "19826 Traning Loss: tensor(0.9840)\n",
      "19827 Traning Loss: tensor(0.9839)\n",
      "19828 Traning Loss: tensor(0.9837)\n",
      "19829 Traning Loss: tensor(0.9835)\n",
      "19830 Traning Loss: tensor(0.9833)\n",
      "19831 Traning Loss: tensor(0.9832)\n",
      "19832 Traning Loss: tensor(0.9830)\n",
      "19833 Traning Loss: tensor(0.9828)\n",
      "19834 Traning Loss: tensor(0.9827)\n",
      "19835 Traning Loss: tensor(0.9825)\n",
      "19836 Traning Loss: tensor(0.9823)\n",
      "19837 Traning Loss: tensor(0.9822)\n",
      "19838 Traning Loss: tensor(0.9820)\n",
      "19839 Traning Loss: tensor(0.9818)\n",
      "19840 Traning Loss: tensor(0.9816)\n",
      "19841 Traning Loss: tensor(0.9815)\n",
      "19842 Traning Loss: tensor(0.9813)\n",
      "19843 Traning Loss: tensor(0.9811)\n",
      "19844 Traning Loss: tensor(0.9810)\n",
      "19845 Traning Loss: tensor(0.9808)\n",
      "19846 Traning Loss: tensor(0.9806)\n",
      "19847 Traning Loss: tensor(0.9805)\n",
      "19848 Traning Loss: tensor(0.9803)\n",
      "19849 Traning Loss: tensor(0.9802)\n",
      "19850 Traning Loss: tensor(0.9800)\n",
      "19851 Traning Loss: tensor(0.9798)\n",
      "19852 Traning Loss: tensor(0.9797)\n",
      "19853 Traning Loss: tensor(0.9795)\n",
      "19854 Traning Loss: tensor(0.9793)\n",
      "19855 Traning Loss: tensor(0.9792)\n",
      "19856 Traning Loss: tensor(0.9790)\n",
      "19857 Traning Loss: tensor(0.9788)\n",
      "19858 Traning Loss: tensor(0.9787)\n",
      "19859 Traning Loss: tensor(0.9785)\n",
      "19860 Traning Loss: tensor(0.9784)\n",
      "19861 Traning Loss: tensor(0.9782)\n",
      "19862 Traning Loss: tensor(0.9780)\n",
      "19863 Traning Loss: tensor(0.9779)\n",
      "19864 Traning Loss: tensor(0.9777)\n",
      "19865 Traning Loss: tensor(0.9775)\n",
      "19866 Traning Loss: tensor(0.9774)\n",
      "19867 Traning Loss: tensor(0.9772)\n",
      "19868 Traning Loss: tensor(0.9771)\n",
      "19869 Traning Loss: tensor(0.9769)\n",
      "19870 Traning Loss: tensor(0.9767)\n",
      "19871 Traning Loss: tensor(0.9766)\n",
      "19872 Traning Loss: tensor(0.9764)\n",
      "19873 Traning Loss: tensor(0.9763)\n",
      "19874 Traning Loss: tensor(0.9761)\n",
      "19875 Traning Loss: tensor(0.9759)\n",
      "19876 Traning Loss: tensor(0.9758)\n",
      "19877 Traning Loss: tensor(0.9756)\n",
      "19878 Traning Loss: tensor(0.9755)\n",
      "19879 Traning Loss: tensor(0.9753)\n",
      "19880 Traning Loss: tensor(0.9751)\n",
      "19881 Traning Loss: tensor(0.9750)\n",
      "19882 Traning Loss: tensor(0.9748)\n",
      "19883 Traning Loss: tensor(0.9747)\n",
      "19884 Traning Loss: tensor(0.9349)\n",
      "19885 Traning Loss: tensor(0.9347)\n",
      "19886 Traning Loss: tensor(0.9346)\n",
      "19887 Traning Loss: tensor(0.9345)\n",
      "19888 Traning Loss: tensor(0.9344)\n",
      "19889 Traning Loss: tensor(0.9343)\n",
      "19890 Traning Loss: tensor(0.9342)\n",
      "19891 Traning Loss: tensor(0.9341)\n",
      "19892 Traning Loss: tensor(0.9340)\n",
      "19893 Traning Loss: tensor(0.9339)\n",
      "19894 Traning Loss: tensor(0.9338)\n",
      "19895 Traning Loss: tensor(0.9336)\n",
      "19896 Traning Loss: tensor(0.9335)\n",
      "19897 Traning Loss: tensor(0.9334)\n",
      "19898 Traning Loss: tensor(0.9333)\n",
      "19899 Traning Loss: tensor(0.9332)\n",
      "19900 Traning Loss: tensor(0.9331)\n",
      "19901 Traning Loss: tensor(0.9330)\n",
      "19902 Traning Loss: tensor(0.9329)\n",
      "19903 Traning Loss: tensor(0.9328)\n",
      "19904 Traning Loss: tensor(0.9327)\n",
      "19905 Traning Loss: tensor(0.9326)\n",
      "19906 Traning Loss: tensor(0.9326)\n",
      "19907 Traning Loss: tensor(0.9325)\n",
      "19908 Traning Loss: tensor(0.9324)\n",
      "19909 Traning Loss: tensor(0.9323)\n",
      "19910 Traning Loss: tensor(0.9322)\n",
      "19911 Traning Loss: tensor(0.9321)\n",
      "19912 Traning Loss: tensor(0.9320)\n",
      "19913 Traning Loss: tensor(0.9319)\n",
      "19914 Traning Loss: tensor(0.9318)\n",
      "19915 Traning Loss: tensor(0.9317)\n",
      "19916 Traning Loss: tensor(0.9316)\n",
      "19917 Traning Loss: tensor(0.9315)\n",
      "19918 Traning Loss: tensor(0.9314)\n",
      "19919 Traning Loss: tensor(0.9313)\n",
      "19920 Traning Loss: tensor(0.9312)\n",
      "19921 Traning Loss: tensor(0.9311)\n",
      "19922 Traning Loss: tensor(0.9310)\n",
      "19923 Traning Loss: tensor(0.9309)\n",
      "19924 Traning Loss: tensor(0.9308)\n",
      "19925 Traning Loss: tensor(0.9307)\n",
      "19926 Traning Loss: tensor(0.9306)\n",
      "19927 Traning Loss: tensor(0.9305)\n",
      "19928 Traning Loss: tensor(0.9305)\n",
      "19929 Traning Loss: tensor(0.9304)\n",
      "19930 Traning Loss: tensor(0.9303)\n",
      "19931 Traning Loss: tensor(0.9302)\n",
      "19932 Traning Loss: tensor(0.9301)\n",
      "19933 Traning Loss: tensor(0.9300)\n",
      "19934 Traning Loss: tensor(0.9299)\n",
      "19935 Traning Loss: tensor(0.9298)\n",
      "19936 Traning Loss: tensor(0.9297)\n",
      "19937 Traning Loss: tensor(0.9296)\n",
      "19938 Traning Loss: tensor(0.9295)\n",
      "19939 Traning Loss: tensor(0.9294)\n",
      "19940 Traning Loss: tensor(0.9293)\n",
      "19941 Traning Loss: tensor(0.9292)\n",
      "19942 Traning Loss: tensor(0.9291)\n",
      "19943 Traning Loss: tensor(0.9290)\n",
      "19944 Traning Loss: tensor(0.9289)\n",
      "19945 Traning Loss: tensor(0.9289)\n",
      "19946 Traning Loss: tensor(0.9288)\n",
      "19947 Traning Loss: tensor(0.9287)\n",
      "19948 Traning Loss: tensor(0.9286)\n",
      "19949 Traning Loss: tensor(0.9285)\n",
      "19950 Traning Loss: tensor(0.9284)\n",
      "19951 Traning Loss: tensor(0.9283)\n",
      "19952 Traning Loss: tensor(0.9282)\n",
      "19953 Traning Loss: tensor(0.9281)\n",
      "19954 Traning Loss: tensor(0.9280)\n",
      "19955 Traning Loss: tensor(0.9279)\n",
      "19956 Traning Loss: tensor(0.9278)\n",
      "19957 Traning Loss: tensor(0.9277)\n",
      "19958 Traning Loss: tensor(0.9276)\n",
      "19959 Traning Loss: tensor(0.9275)\n",
      "19960 Traning Loss: tensor(0.9275)\n",
      "19961 Traning Loss: tensor(0.9274)\n",
      "19962 Traning Loss: tensor(0.9273)\n",
      "19963 Traning Loss: tensor(0.9272)\n",
      "19964 Traning Loss: tensor(0.9271)\n",
      "19965 Traning Loss: tensor(0.9270)\n",
      "19966 Traning Loss: tensor(0.9269)\n",
      "19967 Traning Loss: tensor(0.9268)\n",
      "19968 Traning Loss: tensor(0.9267)\n",
      "19969 Traning Loss: tensor(0.9266)\n",
      "19970 Traning Loss: tensor(0.9265)\n",
      "19971 Traning Loss: tensor(0.9264)\n",
      "19972 Traning Loss: tensor(0.9263)\n",
      "19973 Traning Loss: tensor(0.9262)\n",
      "19974 Traning Loss: tensor(0.9262)\n",
      "19975 Traning Loss: tensor(0.9261)\n",
      "19976 Traning Loss: tensor(0.9260)\n",
      "19977 Traning Loss: tensor(0.9259)\n",
      "19978 Traning Loss: tensor(0.9258)\n",
      "19979 Traning Loss: tensor(0.9257)\n",
      "19980 Traning Loss: tensor(0.9256)\n",
      "19981 Traning Loss: tensor(0.9255)\n",
      "19982 Traning Loss: tensor(0.9254)\n",
      "19983 Traning Loss: tensor(0.9253)\n",
      "19984 Traning Loss: tensor(0.9252)\n",
      "19985 Traning Loss: tensor(0.9251)\n",
      "19986 Traning Loss: tensor(0.9250)\n",
      "19987 Traning Loss: tensor(0.9250)\n",
      "19988 Traning Loss: tensor(0.9249)\n",
      "19989 Traning Loss: tensor(0.9248)\n",
      "19990 Traning Loss: tensor(0.9247)\n",
      "19991 Traning Loss: tensor(0.9246)\n",
      "19992 Traning Loss: tensor(0.9245)\n",
      "19993 Traning Loss: tensor(0.9244)\n",
      "19994 Traning Loss: tensor(0.9243)\n",
      "19995 Traning Loss: tensor(0.9242)\n",
      "19996 Traning Loss: tensor(0.9241)\n",
      "19997 Traning Loss: tensor(0.9240)\n",
      "19998 Traning Loss: tensor(0.9239)\n",
      "19999 Traning Loss: tensor(0.9238)\n",
      "20000 Traning Loss: tensor(0.9238)\n",
      "20001 Traning Loss: tensor(0.9237)\n",
      "20002 Traning Loss: tensor(0.9236)\n",
      "20003 Traning Loss: tensor(0.9235)\n",
      "20004 Traning Loss: tensor(0.9234)\n",
      "20005 Traning Loss: tensor(0.9233)\n",
      "20006 Traning Loss: tensor(0.9232)\n",
      "20007 Traning Loss: tensor(0.9231)\n",
      "20008 Traning Loss: tensor(0.9230)\n",
      "20009 Traning Loss: tensor(0.9229)\n",
      "20010 Traning Loss: tensor(0.9228)\n",
      "20011 Traning Loss: tensor(0.9228)\n",
      "20012 Traning Loss: tensor(0.9227)\n",
      "20013 Traning Loss: tensor(0.9226)\n",
      "20014 Traning Loss: tensor(0.9225)\n",
      "20015 Traning Loss: tensor(0.9224)\n",
      "20016 Traning Loss: tensor(0.9223)\n",
      "20017 Traning Loss: tensor(0.9222)\n",
      "20018 Traning Loss: tensor(0.9221)\n",
      "20019 Traning Loss: tensor(0.9220)\n",
      "20020 Traning Loss: tensor(0.9219)\n",
      "20021 Traning Loss: tensor(0.9218)\n",
      "20022 Traning Loss: tensor(0.9218)\n",
      "20023 Traning Loss: tensor(0.9217)\n",
      "20024 Traning Loss: tensor(0.9216)\n",
      "20025 Traning Loss: tensor(0.9215)\n",
      "20026 Traning Loss: tensor(0.9214)\n",
      "20027 Traning Loss: tensor(0.9213)\n",
      "20028 Traning Loss: tensor(0.9212)\n",
      "20029 Traning Loss: tensor(0.9211)\n",
      "20030 Traning Loss: tensor(0.9210)\n",
      "20031 Traning Loss: tensor(0.9209)\n",
      "20032 Traning Loss: tensor(0.9208)\n",
      "20033 Traning Loss: tensor(0.9208)\n",
      "20034 Traning Loss: tensor(0.9207)\n",
      "20035 Traning Loss: tensor(0.9206)\n",
      "20036 Traning Loss: tensor(0.9205)\n",
      "20037 Traning Loss: tensor(0.9204)\n",
      "20038 Traning Loss: tensor(0.9203)\n",
      "20039 Traning Loss: tensor(0.9202)\n",
      "20040 Traning Loss: tensor(0.9201)\n",
      "20041 Traning Loss: tensor(0.9200)\n",
      "20042 Traning Loss: tensor(0.9199)\n",
      "20043 Traning Loss: tensor(0.9199)\n",
      "20044 Traning Loss: tensor(0.9198)\n",
      "20045 Traning Loss: tensor(0.9197)\n",
      "20046 Traning Loss: tensor(0.9196)\n",
      "20047 Traning Loss: tensor(0.9195)\n",
      "20048 Traning Loss: tensor(0.9194)\n",
      "20049 Traning Loss: tensor(0.9193)\n",
      "20050 Traning Loss: tensor(0.9192)\n",
      "20051 Traning Loss: tensor(0.9191)\n",
      "20052 Traning Loss: tensor(0.9190)\n",
      "20053 Traning Loss: tensor(0.9190)\n",
      "20054 Traning Loss: tensor(0.9189)\n",
      "20055 Traning Loss: tensor(0.9188)\n",
      "20056 Traning Loss: tensor(0.9187)\n",
      "20057 Traning Loss: tensor(0.9186)\n",
      "20058 Traning Loss: tensor(0.9185)\n",
      "20059 Traning Loss: tensor(0.9184)\n",
      "20060 Traning Loss: tensor(0.9183)\n",
      "20061 Traning Loss: tensor(0.9182)\n",
      "20062 Traning Loss: tensor(0.9181)\n",
      "20063 Traning Loss: tensor(0.9181)\n",
      "20064 Traning Loss: tensor(0.9180)\n",
      "20065 Traning Loss: tensor(0.9179)\n",
      "20066 Traning Loss: tensor(0.9178)\n",
      "20067 Traning Loss: tensor(0.9177)\n",
      "20068 Traning Loss: tensor(0.9176)\n",
      "20069 Traning Loss: tensor(0.9175)\n",
      "20070 Traning Loss: tensor(0.9174)\n",
      "20071 Traning Loss: tensor(0.9173)\n",
      "20072 Traning Loss: tensor(0.9173)\n",
      "20073 Traning Loss: tensor(0.9172)\n",
      "20074 Traning Loss: tensor(0.9171)\n",
      "20075 Traning Loss: tensor(0.9170)\n",
      "20076 Traning Loss: tensor(0.9169)\n",
      "20077 Traning Loss: tensor(0.9168)\n",
      "20078 Traning Loss: tensor(0.9167)\n",
      "20079 Traning Loss: tensor(0.9166)\n",
      "20080 Traning Loss: tensor(0.9165)\n",
      "20081 Traning Loss: tensor(0.9165)\n",
      "20082 Traning Loss: tensor(0.9164)\n",
      "20083 Traning Loss: tensor(0.9163)\n",
      "20084 Traning Loss: tensor(0.9162)\n",
      "20085 Traning Loss: tensor(0.9161)\n",
      "20086 Traning Loss: tensor(0.9160)\n",
      "20087 Traning Loss: tensor(0.9159)\n",
      "20088 Traning Loss: tensor(0.9158)\n",
      "20089 Traning Loss: tensor(0.9157)\n",
      "20090 Traning Loss: tensor(0.9157)\n",
      "20091 Traning Loss: tensor(0.9156)\n",
      "20092 Traning Loss: tensor(0.9155)\n",
      "20093 Traning Loss: tensor(0.9154)\n",
      "20094 Traning Loss: tensor(0.9153)\n",
      "20095 Traning Loss: tensor(0.9152)\n",
      "20096 Traning Loss: tensor(0.9151)\n",
      "20097 Traning Loss: tensor(0.9150)\n",
      "20098 Traning Loss: tensor(0.9150)\n",
      "20099 Traning Loss: tensor(0.9149)\n",
      "20100 Traning Loss: tensor(0.9148)\n",
      "20101 Traning Loss: tensor(0.9147)\n",
      "20102 Traning Loss: tensor(0.9146)\n",
      "20103 Traning Loss: tensor(0.9145)\n",
      "20104 Traning Loss: tensor(0.9144)\n",
      "20105 Traning Loss: tensor(0.9143)\n",
      "20106 Traning Loss: tensor(0.9142)\n",
      "20107 Traning Loss: tensor(0.9142)\n",
      "20108 Traning Loss: tensor(0.9141)\n",
      "20109 Traning Loss: tensor(0.9140)\n",
      "20110 Traning Loss: tensor(0.9139)\n",
      "20111 Traning Loss: tensor(0.9138)\n",
      "20112 Traning Loss: tensor(0.9137)\n",
      "20113 Traning Loss: tensor(0.9136)\n",
      "20114 Traning Loss: tensor(0.9135)\n",
      "20115 Traning Loss: tensor(0.9135)\n",
      "20116 Traning Loss: tensor(0.9134)\n",
      "20117 Traning Loss: tensor(0.9133)\n",
      "20118 Traning Loss: tensor(0.9132)\n",
      "20119 Traning Loss: tensor(0.9131)\n",
      "20120 Traning Loss: tensor(0.9130)\n",
      "20121 Traning Loss: tensor(0.9129)\n",
      "20122 Traning Loss: tensor(0.9128)\n",
      "20123 Traning Loss: tensor(0.9128)\n",
      "20124 Traning Loss: tensor(0.9127)\n",
      "20125 Traning Loss: tensor(0.9126)\n",
      "20126 Traning Loss: tensor(0.9125)\n",
      "20127 Traning Loss: tensor(0.9124)\n",
      "20128 Traning Loss: tensor(0.9123)\n",
      "20129 Traning Loss: tensor(0.9122)\n",
      "20130 Traning Loss: tensor(0.9121)\n",
      "20131 Traning Loss: tensor(0.9121)\n",
      "20132 Traning Loss: tensor(0.9120)\n",
      "20133 Traning Loss: tensor(0.9119)\n",
      "20134 Traning Loss: tensor(0.9118)\n",
      "20135 Traning Loss: tensor(0.9117)\n",
      "20136 Traning Loss: tensor(0.9116)\n",
      "20137 Traning Loss: tensor(0.9115)\n",
      "20138 Traning Loss: tensor(0.9115)\n",
      "20139 Traning Loss: tensor(0.9114)\n",
      "20140 Traning Loss: tensor(0.9113)\n",
      "20141 Traning Loss: tensor(0.9112)\n",
      "20142 Traning Loss: tensor(0.9111)\n",
      "20143 Traning Loss: tensor(0.9110)\n",
      "20144 Traning Loss: tensor(0.9109)\n",
      "20145 Traning Loss: tensor(0.9108)\n",
      "20146 Traning Loss: tensor(0.9108)\n",
      "20147 Traning Loss: tensor(0.9107)\n",
      "20148 Traning Loss: tensor(0.9106)\n",
      "20149 Traning Loss: tensor(0.9105)\n",
      "20150 Traning Loss: tensor(0.9104)\n",
      "20151 Traning Loss: tensor(0.9103)\n",
      "20152 Traning Loss: tensor(0.9102)\n",
      "20153 Traning Loss: tensor(0.9102)\n",
      "20154 Traning Loss: tensor(0.9101)\n",
      "20155 Traning Loss: tensor(0.9100)\n",
      "20156 Traning Loss: tensor(0.9099)\n",
      "20157 Traning Loss: tensor(0.9098)\n",
      "20158 Traning Loss: tensor(0.9097)\n",
      "20159 Traning Loss: tensor(0.9096)\n",
      "20160 Traning Loss: tensor(0.9096)\n",
      "20161 Traning Loss: tensor(0.9095)\n",
      "20162 Traning Loss: tensor(0.9094)\n",
      "20163 Traning Loss: tensor(0.9093)\n",
      "20164 Traning Loss: tensor(0.9092)\n",
      "20165 Traning Loss: tensor(0.9091)\n",
      "20166 Traning Loss: tensor(0.9090)\n",
      "20167 Traning Loss: tensor(0.9090)\n",
      "20168 Traning Loss: tensor(0.9089)\n",
      "20169 Traning Loss: tensor(0.9088)\n",
      "20170 Traning Loss: tensor(0.9087)\n",
      "20171 Traning Loss: tensor(0.9086)\n",
      "20172 Traning Loss: tensor(0.9085)\n",
      "20173 Traning Loss: tensor(0.9084)\n",
      "20174 Traning Loss: tensor(0.9084)\n",
      "20175 Traning Loss: tensor(0.9083)\n",
      "20176 Traning Loss: tensor(0.9082)\n",
      "20177 Traning Loss: tensor(0.9081)\n",
      "20178 Traning Loss: tensor(0.9080)\n",
      "20179 Traning Loss: tensor(0.9079)\n",
      "20180 Traning Loss: tensor(0.9078)\n",
      "20181 Traning Loss: tensor(0.9078)\n",
      "20182 Traning Loss: tensor(0.9077)\n",
      "20183 Traning Loss: tensor(0.9076)\n",
      "20184 Traning Loss: tensor(0.9075)\n",
      "20185 Traning Loss: tensor(0.9074)\n",
      "20186 Traning Loss: tensor(0.9073)\n",
      "20187 Traning Loss: tensor(0.9072)\n",
      "20188 Traning Loss: tensor(0.9072)\n",
      "20189 Traning Loss: tensor(0.9071)\n",
      "20190 Traning Loss: tensor(0.9070)\n",
      "20191 Traning Loss: tensor(0.9069)\n",
      "20192 Traning Loss: tensor(0.9068)\n",
      "20193 Traning Loss: tensor(0.9067)\n",
      "20194 Traning Loss: tensor(0.9067)\n",
      "20195 Traning Loss: tensor(0.9066)\n",
      "20196 Traning Loss: tensor(0.9065)\n",
      "20197 Traning Loss: tensor(0.9064)\n",
      "20198 Traning Loss: tensor(0.9063)\n",
      "20199 Traning Loss: tensor(0.9062)\n",
      "20200 Traning Loss: tensor(0.9061)\n",
      "20201 Traning Loss: tensor(0.9061)\n",
      "20202 Traning Loss: tensor(0.9060)\n",
      "20203 Traning Loss: tensor(0.9059)\n",
      "20204 Traning Loss: tensor(0.9058)\n",
      "20205 Traning Loss: tensor(0.9057)\n",
      "20206 Traning Loss: tensor(0.9056)\n",
      "20207 Traning Loss: tensor(0.9056)\n",
      "20208 Traning Loss: tensor(0.9055)\n",
      "20209 Traning Loss: tensor(0.9054)\n",
      "20210 Traning Loss: tensor(0.9053)\n",
      "20211 Traning Loss: tensor(0.9052)\n",
      "20212 Traning Loss: tensor(0.9051)\n",
      "20213 Traning Loss: tensor(0.9050)\n",
      "20214 Traning Loss: tensor(0.9050)\n",
      "20215 Traning Loss: tensor(0.9049)\n",
      "20216 Traning Loss: tensor(0.9048)\n",
      "20217 Traning Loss: tensor(0.9047)\n",
      "20218 Traning Loss: tensor(0.9046)\n",
      "20219 Traning Loss: tensor(0.9045)\n",
      "20220 Traning Loss: tensor(0.9045)\n",
      "20221 Traning Loss: tensor(0.9044)\n",
      "20222 Traning Loss: tensor(0.9043)\n",
      "20223 Traning Loss: tensor(0.9042)\n",
      "20224 Traning Loss: tensor(0.9041)\n",
      "20225 Traning Loss: tensor(0.9040)\n",
      "20226 Traning Loss: tensor(0.9040)\n",
      "20227 Traning Loss: tensor(0.9039)\n",
      "20228 Traning Loss: tensor(0.9038)\n",
      "20229 Traning Loss: tensor(0.9037)\n",
      "20230 Traning Loss: tensor(0.9036)\n",
      "20231 Traning Loss: tensor(0.9035)\n",
      "20232 Traning Loss: tensor(0.9035)\n",
      "20233 Traning Loss: tensor(0.9034)\n",
      "20234 Traning Loss: tensor(0.9033)\n",
      "20235 Traning Loss: tensor(0.9032)\n",
      "20236 Traning Loss: tensor(0.9031)\n",
      "20237 Traning Loss: tensor(0.9030)\n",
      "20238 Traning Loss: tensor(0.9030)\n",
      "20239 Traning Loss: tensor(0.9029)\n",
      "20240 Traning Loss: tensor(0.9028)\n",
      "20241 Traning Loss: tensor(0.9027)\n",
      "20242 Traning Loss: tensor(0.9026)\n",
      "20243 Traning Loss: tensor(0.9025)\n",
      "20244 Traning Loss: tensor(0.9025)\n",
      "20245 Traning Loss: tensor(0.9024)\n",
      "20246 Traning Loss: tensor(0.9023)\n",
      "20247 Traning Loss: tensor(0.9022)\n",
      "20248 Traning Loss: tensor(0.9021)\n",
      "20249 Traning Loss: tensor(0.9020)\n",
      "20250 Traning Loss: tensor(0.9020)\n",
      "20251 Traning Loss: tensor(0.9019)\n",
      "20252 Traning Loss: tensor(0.9018)\n",
      "20253 Traning Loss: tensor(0.9017)\n",
      "20254 Traning Loss: tensor(0.9016)\n",
      "20255 Traning Loss: tensor(0.9015)\n",
      "20256 Traning Loss: tensor(0.9015)\n",
      "20257 Traning Loss: tensor(0.9014)\n",
      "20258 Traning Loss: tensor(0.9013)\n",
      "20259 Traning Loss: tensor(0.9012)\n",
      "20260 Traning Loss: tensor(0.9011)\n",
      "20261 Traning Loss: tensor(0.9010)\n",
      "20262 Traning Loss: tensor(0.9010)\n",
      "20263 Traning Loss: tensor(0.9009)\n",
      "20264 Traning Loss: tensor(0.9008)\n",
      "20265 Traning Loss: tensor(0.9007)\n",
      "20266 Traning Loss: tensor(0.9006)\n",
      "20267 Traning Loss: tensor(0.9006)\n",
      "20268 Traning Loss: tensor(0.9005)\n",
      "20269 Traning Loss: tensor(0.9004)\n",
      "20270 Traning Loss: tensor(0.9003)\n",
      "20271 Traning Loss: tensor(0.9002)\n",
      "20272 Traning Loss: tensor(0.9001)\n",
      "20273 Traning Loss: tensor(0.9001)\n",
      "20274 Traning Loss: tensor(0.9000)\n",
      "20275 Traning Loss: tensor(0.8999)\n",
      "20276 Traning Loss: tensor(0.8998)\n",
      "20277 Traning Loss: tensor(0.8997)\n",
      "20278 Traning Loss: tensor(0.8997)\n",
      "20279 Traning Loss: tensor(0.8996)\n",
      "20280 Traning Loss: tensor(0.8995)\n",
      "20281 Traning Loss: tensor(0.8994)\n",
      "20282 Traning Loss: tensor(0.8993)\n",
      "20283 Traning Loss: tensor(0.8992)\n",
      "20284 Traning Loss: tensor(0.8992)\n",
      "20285 Traning Loss: tensor(0.8991)\n",
      "20286 Traning Loss: tensor(0.8990)\n",
      "20287 Traning Loss: tensor(0.8989)\n",
      "20288 Traning Loss: tensor(0.8988)\n",
      "20289 Traning Loss: tensor(0.8988)\n",
      "20290 Traning Loss: tensor(0.8987)\n",
      "20291 Traning Loss: tensor(0.8986)\n",
      "20292 Traning Loss: tensor(0.8985)\n",
      "20293 Traning Loss: tensor(0.8984)\n",
      "20294 Traning Loss: tensor(0.8983)\n",
      "20295 Traning Loss: tensor(0.8983)\n",
      "20296 Traning Loss: tensor(0.8982)\n",
      "20297 Traning Loss: tensor(0.8981)\n",
      "20298 Traning Loss: tensor(0.8980)\n",
      "20299 Traning Loss: tensor(0.8979)\n",
      "20300 Traning Loss: tensor(0.8979)\n",
      "20301 Traning Loss: tensor(0.8978)\n",
      "20302 Traning Loss: tensor(0.8977)\n",
      "20303 Traning Loss: tensor(0.8976)\n",
      "20304 Traning Loss: tensor(0.8975)\n",
      "20305 Traning Loss: tensor(0.8975)\n",
      "20306 Traning Loss: tensor(0.8974)\n",
      "20307 Traning Loss: tensor(0.8973)\n",
      "20308 Traning Loss: tensor(0.8972)\n",
      "20309 Traning Loss: tensor(0.8971)\n",
      "20310 Traning Loss: tensor(0.8970)\n",
      "20311 Traning Loss: tensor(0.8970)\n",
      "20312 Traning Loss: tensor(0.8969)\n",
      "20313 Traning Loss: tensor(0.8968)\n",
      "20314 Traning Loss: tensor(0.8967)\n",
      "20315 Traning Loss: tensor(0.8966)\n",
      "20316 Traning Loss: tensor(0.8966)\n",
      "20317 Traning Loss: tensor(0.8965)\n",
      "20318 Traning Loss: tensor(0.8964)\n",
      "20319 Traning Loss: tensor(0.8963)\n",
      "20320 Traning Loss: tensor(0.8962)\n",
      "20321 Traning Loss: tensor(0.8962)\n",
      "20322 Traning Loss: tensor(0.8961)\n",
      "20323 Traning Loss: tensor(0.8960)\n",
      "20324 Traning Loss: tensor(0.8959)\n",
      "20325 Traning Loss: tensor(0.8958)\n",
      "20326 Traning Loss: tensor(0.8958)\n",
      "20327 Traning Loss: tensor(0.8957)\n",
      "20328 Traning Loss: tensor(0.8956)\n",
      "20329 Traning Loss: tensor(0.8955)\n",
      "20330 Traning Loss: tensor(0.8954)\n",
      "20331 Traning Loss: tensor(0.8954)\n",
      "20332 Traning Loss: tensor(0.8953)\n",
      "20333 Traning Loss: tensor(0.8952)\n",
      "20334 Traning Loss: tensor(0.8951)\n",
      "20335 Traning Loss: tensor(0.8950)\n",
      "20336 Traning Loss: tensor(0.8950)\n",
      "20337 Traning Loss: tensor(0.8949)\n",
      "20338 Traning Loss: tensor(0.8948)\n",
      "20339 Traning Loss: tensor(0.8947)\n",
      "20340 Traning Loss: tensor(0.8946)\n",
      "20341 Traning Loss: tensor(0.8946)\n",
      "20342 Traning Loss: tensor(0.8945)\n",
      "20343 Traning Loss: tensor(0.8944)\n",
      "20344 Traning Loss: tensor(0.8943)\n",
      "20345 Traning Loss: tensor(0.8942)\n",
      "20346 Traning Loss: tensor(0.8942)\n",
      "20347 Traning Loss: tensor(0.8941)\n",
      "20348 Traning Loss: tensor(0.8940)\n",
      "20349 Traning Loss: tensor(0.8939)\n",
      "20350 Traning Loss: tensor(0.8938)\n",
      "20351 Traning Loss: tensor(0.8938)\n",
      "20352 Traning Loss: tensor(0.8937)\n",
      "20353 Traning Loss: tensor(0.8936)\n",
      "20354 Traning Loss: tensor(0.8935)\n",
      "20355 Traning Loss: tensor(0.8934)\n",
      "20356 Traning Loss: tensor(0.8934)\n",
      "20357 Traning Loss: tensor(0.8933)\n",
      "20358 Traning Loss: tensor(0.8932)\n",
      "20359 Traning Loss: tensor(0.8931)\n",
      "20360 Traning Loss: tensor(0.8930)\n",
      "20361 Traning Loss: tensor(0.8930)\n",
      "20362 Traning Loss: tensor(0.8929)\n",
      "20363 Traning Loss: tensor(0.8928)\n",
      "20364 Traning Loss: tensor(0.8927)\n",
      "20365 Traning Loss: tensor(0.8926)\n",
      "20366 Traning Loss: tensor(0.8926)\n",
      "20367 Traning Loss: tensor(0.8925)\n",
      "20368 Traning Loss: tensor(0.8924)\n",
      "20369 Traning Loss: tensor(0.8923)\n",
      "20370 Traning Loss: tensor(0.8923)\n",
      "20371 Traning Loss: tensor(0.8922)\n",
      "20372 Traning Loss: tensor(0.8921)\n",
      "20373 Traning Loss: tensor(0.8920)\n",
      "20374 Traning Loss: tensor(0.8919)\n",
      "20375 Traning Loss: tensor(0.8919)\n",
      "20376 Traning Loss: tensor(0.8918)\n",
      "20377 Traning Loss: tensor(0.8917)\n",
      "20378 Traning Loss: tensor(0.8916)\n",
      "20379 Traning Loss: tensor(0.8915)\n",
      "20380 Traning Loss: tensor(0.8915)\n",
      "20381 Traning Loss: tensor(0.8914)\n",
      "20382 Traning Loss: tensor(0.8913)\n",
      "20383 Traning Loss: tensor(0.8912)\n",
      "20384 Traning Loss: tensor(0.8912)\n",
      "20385 Traning Loss: tensor(0.8911)\n",
      "20386 Traning Loss: tensor(0.8910)\n",
      "20387 Traning Loss: tensor(0.8909)\n",
      "20388 Traning Loss: tensor(0.8908)\n",
      "20389 Traning Loss: tensor(0.8908)\n",
      "20390 Traning Loss: tensor(0.8907)\n",
      "20391 Traning Loss: tensor(0.8906)\n",
      "20392 Traning Loss: tensor(0.8905)\n",
      "20393 Traning Loss: tensor(0.8904)\n",
      "20394 Traning Loss: tensor(0.8904)\n",
      "20395 Traning Loss: tensor(0.8903)\n",
      "20396 Traning Loss: tensor(0.8902)\n",
      "20397 Traning Loss: tensor(0.8901)\n",
      "20398 Traning Loss: tensor(0.8901)\n",
      "20399 Traning Loss: tensor(0.8900)\n",
      "20400 Traning Loss: tensor(0.8899)\n",
      "20401 Traning Loss: tensor(0.8898)\n",
      "20402 Traning Loss: tensor(0.8897)\n",
      "20403 Traning Loss: tensor(0.8897)\n",
      "20404 Traning Loss: tensor(0.8896)\n",
      "20405 Traning Loss: tensor(0.8895)\n",
      "20406 Traning Loss: tensor(0.8894)\n",
      "20407 Traning Loss: tensor(0.8894)\n",
      "20408 Traning Loss: tensor(0.8893)\n",
      "20409 Traning Loss: tensor(0.8892)\n",
      "20410 Traning Loss: tensor(0.8891)\n",
      "20411 Traning Loss: tensor(0.8890)\n",
      "20412 Traning Loss: tensor(0.8890)\n",
      "20413 Traning Loss: tensor(0.8889)\n",
      "20414 Traning Loss: tensor(0.8888)\n",
      "20415 Traning Loss: tensor(0.8887)\n",
      "20416 Traning Loss: tensor(0.8887)\n",
      "20417 Traning Loss: tensor(0.8886)\n",
      "20418 Traning Loss: tensor(0.8885)\n",
      "20419 Traning Loss: tensor(0.8884)\n",
      "20420 Traning Loss: tensor(0.8883)\n",
      "20421 Traning Loss: tensor(0.8883)\n",
      "20422 Traning Loss: tensor(0.8882)\n",
      "20423 Traning Loss: tensor(0.8881)\n",
      "20424 Traning Loss: tensor(0.8880)\n",
      "20425 Traning Loss: tensor(0.8880)\n",
      "20426 Traning Loss: tensor(0.8879)\n",
      "20427 Traning Loss: tensor(0.8878)\n",
      "20428 Traning Loss: tensor(0.8877)\n",
      "20429 Traning Loss: tensor(0.8877)\n",
      "20430 Traning Loss: tensor(0.8876)\n",
      "20431 Traning Loss: tensor(0.8875)\n",
      "20432 Traning Loss: tensor(0.8874)\n",
      "20433 Traning Loss: tensor(0.8873)\n",
      "20434 Traning Loss: tensor(0.8873)\n",
      "20435 Traning Loss: tensor(0.8872)\n",
      "20436 Traning Loss: tensor(0.8871)\n",
      "20437 Traning Loss: tensor(0.8870)\n",
      "20438 Traning Loss: tensor(0.8870)\n",
      "20439 Traning Loss: tensor(0.8869)\n",
      "20440 Traning Loss: tensor(0.8868)\n",
      "20441 Traning Loss: tensor(0.8867)\n",
      "20442 Traning Loss: tensor(0.8867)\n",
      "20443 Traning Loss: tensor(0.8866)\n",
      "20444 Traning Loss: tensor(0.8865)\n",
      "20445 Traning Loss: tensor(0.8864)\n",
      "20446 Traning Loss: tensor(0.8863)\n",
      "20447 Traning Loss: tensor(0.8863)\n",
      "20448 Traning Loss: tensor(0.8862)\n",
      "20449 Traning Loss: tensor(0.8861)\n",
      "20450 Traning Loss: tensor(0.8860)\n",
      "20451 Traning Loss: tensor(0.8860)\n",
      "20452 Traning Loss: tensor(0.8859)\n",
      "20453 Traning Loss: tensor(0.8858)\n",
      "20454 Traning Loss: tensor(0.8857)\n",
      "20455 Traning Loss: tensor(0.8857)\n",
      "20456 Traning Loss: tensor(0.8856)\n",
      "20457 Traning Loss: tensor(0.8855)\n",
      "20458 Traning Loss: tensor(0.8854)\n",
      "20459 Traning Loss: tensor(0.8854)\n",
      "20460 Traning Loss: tensor(0.8853)\n",
      "20461 Traning Loss: tensor(0.8852)\n",
      "20462 Traning Loss: tensor(0.8851)\n",
      "20463 Traning Loss: tensor(0.8851)\n",
      "20464 Traning Loss: tensor(0.8850)\n",
      "20465 Traning Loss: tensor(0.8849)\n",
      "20466 Traning Loss: tensor(0.8848)\n",
      "20467 Traning Loss: tensor(0.8848)\n",
      "20468 Traning Loss: tensor(0.8847)\n",
      "20469 Traning Loss: tensor(0.8846)\n",
      "20470 Traning Loss: tensor(0.8845)\n",
      "20471 Traning Loss: tensor(0.8844)\n",
      "20472 Traning Loss: tensor(0.8844)\n",
      "20473 Traning Loss: tensor(0.8843)\n",
      "20474 Traning Loss: tensor(0.8842)\n",
      "20475 Traning Loss: tensor(0.8841)\n",
      "20476 Traning Loss: tensor(0.8841)\n",
      "20477 Traning Loss: tensor(0.8840)\n",
      "20478 Traning Loss: tensor(0.8839)\n",
      "20479 Traning Loss: tensor(0.8838)\n",
      "20480 Traning Loss: tensor(0.8838)\n",
      "20481 Traning Loss: tensor(0.8837)\n",
      "20482 Traning Loss: tensor(0.8836)\n",
      "20483 Traning Loss: tensor(0.8835)\n",
      "20484 Traning Loss: tensor(0.8835)\n",
      "20485 Traning Loss: tensor(0.8834)\n",
      "20486 Traning Loss: tensor(0.8833)\n",
      "20487 Traning Loss: tensor(0.8832)\n",
      "20488 Traning Loss: tensor(0.8832)\n",
      "20489 Traning Loss: tensor(0.8831)\n",
      "20490 Traning Loss: tensor(0.8830)\n",
      "20491 Traning Loss: tensor(0.8829)\n",
      "20492 Traning Loss: tensor(0.8829)\n",
      "20493 Traning Loss: tensor(0.8828)\n",
      "20494 Traning Loss: tensor(0.8827)\n",
      "20495 Traning Loss: tensor(0.8826)\n",
      "20496 Traning Loss: tensor(0.8826)\n",
      "20497 Traning Loss: tensor(0.8825)\n",
      "20498 Traning Loss: tensor(0.8824)\n",
      "20499 Traning Loss: tensor(0.8823)\n",
      "20500 Traning Loss: tensor(0.8823)\n",
      "20501 Traning Loss: tensor(0.8822)\n",
      "20502 Traning Loss: tensor(0.8821)\n",
      "20503 Traning Loss: tensor(0.8820)\n",
      "20504 Traning Loss: tensor(0.8820)\n",
      "20505 Traning Loss: tensor(0.8819)\n",
      "20506 Traning Loss: tensor(0.8818)\n",
      "20507 Traning Loss: tensor(0.8817)\n",
      "20508 Traning Loss: tensor(0.8817)\n",
      "20509 Traning Loss: tensor(0.8816)\n",
      "20510 Traning Loss: tensor(0.8815)\n",
      "20511 Traning Loss: tensor(0.8814)\n",
      "20512 Traning Loss: tensor(0.8814)\n",
      "20513 Traning Loss: tensor(0.8813)\n",
      "20514 Traning Loss: tensor(0.8812)\n",
      "20515 Traning Loss: tensor(0.8811)\n",
      "20516 Traning Loss: tensor(0.8811)\n",
      "20517 Traning Loss: tensor(0.8810)\n",
      "20518 Traning Loss: tensor(0.8809)\n",
      "20519 Traning Loss: tensor(0.8809)\n",
      "20520 Traning Loss: tensor(0.8808)\n",
      "20521 Traning Loss: tensor(0.8807)\n",
      "20522 Traning Loss: tensor(0.8806)\n",
      "20523 Traning Loss: tensor(0.8806)\n",
      "20524 Traning Loss: tensor(0.8805)\n",
      "20525 Traning Loss: tensor(0.8804)\n",
      "20526 Traning Loss: tensor(0.8803)\n",
      "20527 Traning Loss: tensor(0.8803)\n",
      "20528 Traning Loss: tensor(0.8802)\n",
      "20529 Traning Loss: tensor(0.8801)\n",
      "20530 Traning Loss: tensor(0.8800)\n",
      "20531 Traning Loss: tensor(0.8800)\n",
      "20532 Traning Loss: tensor(0.8799)\n",
      "20533 Traning Loss: tensor(0.8798)\n",
      "20534 Traning Loss: tensor(0.8797)\n",
      "20535 Traning Loss: tensor(0.8797)\n",
      "20536 Traning Loss: tensor(0.8796)\n",
      "20537 Traning Loss: tensor(0.8795)\n",
      "20538 Traning Loss: tensor(0.8794)\n",
      "20539 Traning Loss: tensor(0.8794)\n",
      "20540 Traning Loss: tensor(0.8793)\n",
      "20541 Traning Loss: tensor(0.8792)\n",
      "20542 Traning Loss: tensor(0.8792)\n",
      "20543 Traning Loss: tensor(0.8791)\n",
      "20544 Traning Loss: tensor(0.8790)\n",
      "20545 Traning Loss: tensor(0.8789)\n",
      "20546 Traning Loss: tensor(0.8789)\n",
      "20547 Traning Loss: tensor(0.8788)\n",
      "20548 Traning Loss: tensor(0.8787)\n",
      "20549 Traning Loss: tensor(0.8786)\n",
      "20550 Traning Loss: tensor(0.8786)\n",
      "20551 Traning Loss: tensor(0.8785)\n",
      "20552 Traning Loss: tensor(0.8784)\n",
      "20553 Traning Loss: tensor(0.8783)\n",
      "20554 Traning Loss: tensor(0.8783)\n",
      "20555 Traning Loss: tensor(0.8782)\n",
      "20556 Traning Loss: tensor(0.8781)\n",
      "20557 Traning Loss: tensor(0.8781)\n",
      "20558 Traning Loss: tensor(0.8780)\n",
      "20559 Traning Loss: tensor(0.8779)\n",
      "20560 Traning Loss: tensor(0.8778)\n",
      "20561 Traning Loss: tensor(0.8778)\n",
      "20562 Traning Loss: tensor(0.8777)\n",
      "20563 Traning Loss: tensor(0.8776)\n",
      "20564 Traning Loss: tensor(0.8775)\n",
      "20565 Traning Loss: tensor(0.8775)\n",
      "20566 Traning Loss: tensor(0.8774)\n",
      "20567 Traning Loss: tensor(0.8773)\n",
      "20568 Traning Loss: tensor(0.8773)\n",
      "20569 Traning Loss: tensor(0.8772)\n",
      "20570 Traning Loss: tensor(0.8771)\n",
      "20571 Traning Loss: tensor(0.8770)\n",
      "20572 Traning Loss: tensor(0.8770)\n",
      "20573 Traning Loss: tensor(0.8769)\n",
      "20574 Traning Loss: tensor(0.8768)\n",
      "20575 Traning Loss: tensor(0.8767)\n",
      "20576 Traning Loss: tensor(0.8767)\n",
      "20577 Traning Loss: tensor(0.8766)\n",
      "20578 Traning Loss: tensor(0.8765)\n",
      "20579 Traning Loss: tensor(0.8765)\n",
      "20580 Traning Loss: tensor(0.8764)\n",
      "20581 Traning Loss: tensor(0.8763)\n",
      "20582 Traning Loss: tensor(0.8762)\n",
      "20583 Traning Loss: tensor(0.8762)\n",
      "20584 Traning Loss: tensor(0.8761)\n",
      "20585 Traning Loss: tensor(0.8760)\n",
      "20586 Traning Loss: tensor(0.8759)\n",
      "20587 Traning Loss: tensor(0.8759)\n",
      "20588 Traning Loss: tensor(0.8758)\n",
      "20589 Traning Loss: tensor(0.8757)\n",
      "20590 Traning Loss: tensor(0.8757)\n",
      "20591 Traning Loss: tensor(0.8756)\n",
      "20592 Traning Loss: tensor(0.8755)\n",
      "20593 Traning Loss: tensor(0.8754)\n",
      "20594 Traning Loss: tensor(0.8754)\n",
      "20595 Traning Loss: tensor(0.8753)\n",
      "20596 Traning Loss: tensor(0.8752)\n",
      "20597 Traning Loss: tensor(0.8752)\n",
      "20598 Traning Loss: tensor(0.8751)\n",
      "20599 Traning Loss: tensor(0.8750)\n",
      "20600 Traning Loss: tensor(0.8749)\n",
      "20601 Traning Loss: tensor(0.8749)\n",
      "20602 Traning Loss: tensor(0.8748)\n",
      "20603 Traning Loss: tensor(0.8747)\n",
      "20604 Traning Loss: tensor(0.8747)\n",
      "20605 Traning Loss: tensor(0.8746)\n",
      "20606 Traning Loss: tensor(0.8745)\n",
      "20607 Traning Loss: tensor(0.8744)\n",
      "20608 Traning Loss: tensor(0.8744)\n",
      "20609 Traning Loss: tensor(0.8743)\n",
      "20610 Traning Loss: tensor(0.8742)\n",
      "20611 Traning Loss: tensor(0.8742)\n",
      "20612 Traning Loss: tensor(0.8741)\n",
      "20613 Traning Loss: tensor(0.8740)\n",
      "20614 Traning Loss: tensor(0.8739)\n",
      "20615 Traning Loss: tensor(0.8739)\n",
      "20616 Traning Loss: tensor(0.8738)\n",
      "20617 Traning Loss: tensor(0.8737)\n",
      "20618 Traning Loss: tensor(0.8737)\n",
      "20619 Traning Loss: tensor(0.8736)\n",
      "20620 Traning Loss: tensor(0.8735)\n",
      "20621 Traning Loss: tensor(0.8734)\n",
      "20622 Traning Loss: tensor(0.8734)\n",
      "20623 Traning Loss: tensor(0.8733)\n",
      "20624 Traning Loss: tensor(0.8732)\n",
      "20625 Traning Loss: tensor(0.8732)\n",
      "20626 Traning Loss: tensor(0.8731)\n",
      "20627 Traning Loss: tensor(0.8730)\n",
      "20628 Traning Loss: tensor(0.8729)\n",
      "20629 Traning Loss: tensor(0.8729)\n",
      "20630 Traning Loss: tensor(0.8728)\n",
      "20631 Traning Loss: tensor(0.8727)\n",
      "20632 Traning Loss: tensor(0.8727)\n",
      "20633 Traning Loss: tensor(0.8726)\n",
      "20634 Traning Loss: tensor(0.8725)\n",
      "20635 Traning Loss: tensor(0.8725)\n",
      "20636 Traning Loss: tensor(0.8724)\n",
      "20637 Traning Loss: tensor(0.8723)\n",
      "20638 Traning Loss: tensor(0.8722)\n",
      "20639 Traning Loss: tensor(0.8722)\n",
      "20640 Traning Loss: tensor(0.8721)\n",
      "20641 Traning Loss: tensor(0.8720)\n",
      "20642 Traning Loss: tensor(0.8720)\n",
      "20643 Traning Loss: tensor(0.8719)\n",
      "20644 Traning Loss: tensor(0.8718)\n",
      "20645 Traning Loss: tensor(0.8717)\n",
      "20646 Traning Loss: tensor(0.8717)\n",
      "20647 Traning Loss: tensor(0.8716)\n",
      "20648 Traning Loss: tensor(0.8715)\n",
      "20649 Traning Loss: tensor(0.8715)\n",
      "20650 Traning Loss: tensor(0.8714)\n",
      "20651 Traning Loss: tensor(0.8713)\n",
      "20652 Traning Loss: tensor(0.8713)\n",
      "20653 Traning Loss: tensor(0.8712)\n",
      "20654 Traning Loss: tensor(0.8711)\n",
      "20655 Traning Loss: tensor(0.8710)\n",
      "20656 Traning Loss: tensor(0.8710)\n",
      "20657 Traning Loss: tensor(0.8709)\n",
      "20658 Traning Loss: tensor(0.8708)\n",
      "20659 Traning Loss: tensor(0.8708)\n",
      "20660 Traning Loss: tensor(0.8707)\n",
      "20661 Traning Loss: tensor(0.8706)\n",
      "20662 Traning Loss: tensor(0.8706)\n",
      "20663 Traning Loss: tensor(0.8705)\n",
      "20664 Traning Loss: tensor(0.8704)\n",
      "20665 Traning Loss: tensor(0.8703)\n",
      "20666 Traning Loss: tensor(0.8703)\n",
      "20667 Traning Loss: tensor(0.8702)\n",
      "20668 Traning Loss: tensor(0.8701)\n",
      "20669 Traning Loss: tensor(0.8701)\n",
      "20670 Traning Loss: tensor(0.8700)\n",
      "20671 Traning Loss: tensor(0.8699)\n",
      "20672 Traning Loss: tensor(0.8699)\n",
      "20673 Traning Loss: tensor(0.8698)\n",
      "20674 Traning Loss: tensor(0.8697)\n",
      "20675 Traning Loss: tensor(0.8696)\n",
      "20676 Traning Loss: tensor(0.8696)\n",
      "20677 Traning Loss: tensor(0.8695)\n",
      "20678 Traning Loss: tensor(0.8694)\n",
      "20679 Traning Loss: tensor(0.8694)\n",
      "20680 Traning Loss: tensor(0.8693)\n",
      "20681 Traning Loss: tensor(0.8692)\n",
      "20682 Traning Loss: tensor(0.8692)\n",
      "20683 Traning Loss: tensor(0.8691)\n",
      "20684 Traning Loss: tensor(0.8690)\n",
      "20685 Traning Loss: tensor(0.8690)\n",
      "20686 Traning Loss: tensor(0.8689)\n",
      "20687 Traning Loss: tensor(0.8688)\n",
      "20688 Traning Loss: tensor(0.8687)\n",
      "20689 Traning Loss: tensor(0.8687)\n",
      "20690 Traning Loss: tensor(0.8686)\n",
      "20691 Traning Loss: tensor(0.8685)\n",
      "20692 Traning Loss: tensor(0.8685)\n",
      "20693 Traning Loss: tensor(0.8684)\n",
      "20694 Traning Loss: tensor(0.8683)\n",
      "20695 Traning Loss: tensor(0.8683)\n",
      "20696 Traning Loss: tensor(0.8682)\n",
      "20697 Traning Loss: tensor(0.8681)\n",
      "20698 Traning Loss: tensor(0.8681)\n",
      "20699 Traning Loss: tensor(0.8680)\n",
      "20700 Traning Loss: tensor(0.8679)\n",
      "20701 Traning Loss: tensor(0.8678)\n",
      "20702 Traning Loss: tensor(0.8678)\n",
      "20703 Traning Loss: tensor(0.8677)\n",
      "20704 Traning Loss: tensor(0.8676)\n",
      "20705 Traning Loss: tensor(0.8676)\n",
      "20706 Traning Loss: tensor(0.8675)\n",
      "20707 Traning Loss: tensor(0.8674)\n",
      "20708 Traning Loss: tensor(0.8674)\n",
      "20709 Traning Loss: tensor(0.8673)\n",
      "20710 Traning Loss: tensor(0.8672)\n",
      "20711 Traning Loss: tensor(0.8672)\n",
      "20712 Traning Loss: tensor(0.8671)\n",
      "20713 Traning Loss: tensor(0.8670)\n",
      "20714 Traning Loss: tensor(0.8670)\n",
      "20715 Traning Loss: tensor(0.8669)\n",
      "20716 Traning Loss: tensor(0.8668)\n",
      "20717 Traning Loss: tensor(0.8668)\n",
      "20718 Traning Loss: tensor(0.8667)\n",
      "20719 Traning Loss: tensor(0.8666)\n",
      "20720 Traning Loss: tensor(0.8665)\n",
      "20721 Traning Loss: tensor(0.8665)\n",
      "20722 Traning Loss: tensor(0.8664)\n",
      "20723 Traning Loss: tensor(0.8663)\n",
      "20724 Traning Loss: tensor(0.8663)\n",
      "20725 Traning Loss: tensor(0.8662)\n",
      "20726 Traning Loss: tensor(0.8661)\n",
      "20727 Traning Loss: tensor(0.8661)\n",
      "20728 Traning Loss: tensor(0.8660)\n",
      "20729 Traning Loss: tensor(0.8659)\n",
      "20730 Traning Loss: tensor(0.8659)\n",
      "20731 Traning Loss: tensor(0.8658)\n",
      "20732 Traning Loss: tensor(0.8657)\n",
      "20733 Traning Loss: tensor(0.8657)\n",
      "20734 Traning Loss: tensor(0.8656)\n",
      "20735 Traning Loss: tensor(0.8655)\n",
      "20736 Traning Loss: tensor(0.8655)\n",
      "20737 Traning Loss: tensor(0.8654)\n",
      "20738 Traning Loss: tensor(0.8653)\n",
      "20739 Traning Loss: tensor(0.8653)\n",
      "20740 Traning Loss: tensor(0.8652)\n",
      "20741 Traning Loss: tensor(0.8651)\n",
      "20742 Traning Loss: tensor(0.8651)\n",
      "20743 Traning Loss: tensor(0.8650)\n",
      "20744 Traning Loss: tensor(0.8649)\n",
      "20745 Traning Loss: tensor(0.8649)\n",
      "20746 Traning Loss: tensor(0.8648)\n",
      "20747 Traning Loss: tensor(0.8647)\n",
      "20748 Traning Loss: tensor(0.8646)\n",
      "20749 Traning Loss: tensor(0.8646)\n",
      "20750 Traning Loss: tensor(0.8645)\n",
      "20751 Traning Loss: tensor(0.8644)\n",
      "20752 Traning Loss: tensor(0.8644)\n",
      "20753 Traning Loss: tensor(0.8643)\n",
      "20754 Traning Loss: tensor(0.8642)\n",
      "20755 Traning Loss: tensor(0.8642)\n",
      "20756 Traning Loss: tensor(0.8641)\n",
      "20757 Traning Loss: tensor(0.8640)\n",
      "20758 Traning Loss: tensor(0.8640)\n",
      "20759 Traning Loss: tensor(0.8639)\n",
      "20760 Traning Loss: tensor(0.8638)\n",
      "20761 Traning Loss: tensor(0.8638)\n",
      "20762 Traning Loss: tensor(0.8637)\n",
      "20763 Traning Loss: tensor(0.8636)\n",
      "20764 Traning Loss: tensor(0.8636)\n",
      "20765 Traning Loss: tensor(0.8635)\n",
      "20766 Traning Loss: tensor(0.8634)\n",
      "20767 Traning Loss: tensor(0.8634)\n",
      "20768 Traning Loss: tensor(0.8633)\n",
      "20769 Traning Loss: tensor(0.8632)\n",
      "20770 Traning Loss: tensor(0.8632)\n",
      "20771 Traning Loss: tensor(0.8631)\n",
      "20772 Traning Loss: tensor(0.8630)\n",
      "20773 Traning Loss: tensor(0.8630)\n",
      "20774 Traning Loss: tensor(0.8629)\n",
      "20775 Traning Loss: tensor(0.8628)\n",
      "20776 Traning Loss: tensor(0.8628)\n",
      "20777 Traning Loss: tensor(0.8627)\n",
      "20778 Traning Loss: tensor(0.8626)\n",
      "20779 Traning Loss: tensor(0.8626)\n",
      "20780 Traning Loss: tensor(0.8625)\n",
      "20781 Traning Loss: tensor(0.8624)\n",
      "20782 Traning Loss: tensor(0.8624)\n",
      "20783 Traning Loss: tensor(0.8623)\n",
      "20784 Traning Loss: tensor(0.8622)\n",
      "20785 Traning Loss: tensor(0.8622)\n",
      "20786 Traning Loss: tensor(0.8621)\n",
      "20787 Traning Loss: tensor(0.8620)\n",
      "20788 Traning Loss: tensor(0.8620)\n",
      "20789 Traning Loss: tensor(0.8619)\n",
      "20790 Traning Loss: tensor(0.8618)\n",
      "20791 Traning Loss: tensor(0.8618)\n",
      "20792 Traning Loss: tensor(0.8617)\n",
      "20793 Traning Loss: tensor(0.8616)\n",
      "20794 Traning Loss: tensor(0.8616)\n",
      "20795 Traning Loss: tensor(0.8615)\n",
      "20796 Traning Loss: tensor(0.8614)\n",
      "20797 Traning Loss: tensor(0.8614)\n",
      "20798 Traning Loss: tensor(0.8613)\n",
      "20799 Traning Loss: tensor(0.8612)\n",
      "20800 Traning Loss: tensor(0.8612)\n",
      "20801 Traning Loss: tensor(0.8611)\n",
      "20802 Traning Loss: tensor(0.8610)\n",
      "20803 Traning Loss: tensor(0.8610)\n",
      "20804 Traning Loss: tensor(0.8609)\n",
      "20805 Traning Loss: tensor(0.8608)\n",
      "20806 Traning Loss: tensor(0.8608)\n",
      "20807 Traning Loss: tensor(0.8607)\n",
      "20808 Traning Loss: tensor(0.8607)\n",
      "20809 Traning Loss: tensor(0.8606)\n",
      "20810 Traning Loss: tensor(0.8605)\n",
      "20811 Traning Loss: tensor(0.8605)\n",
      "20812 Traning Loss: tensor(0.8604)\n",
      "20813 Traning Loss: tensor(0.8603)\n",
      "20814 Traning Loss: tensor(0.8603)\n",
      "20815 Traning Loss: tensor(0.8602)\n",
      "20816 Traning Loss: tensor(0.8601)\n",
      "20817 Traning Loss: tensor(0.8601)\n",
      "20818 Traning Loss: tensor(0.8600)\n",
      "20819 Traning Loss: tensor(0.8599)\n",
      "20820 Traning Loss: tensor(0.8599)\n",
      "20821 Traning Loss: tensor(0.8598)\n",
      "20822 Traning Loss: tensor(0.8597)\n",
      "20823 Traning Loss: tensor(0.8597)\n",
      "20824 Traning Loss: tensor(0.8596)\n",
      "20825 Traning Loss: tensor(0.8595)\n",
      "20826 Traning Loss: tensor(0.8595)\n",
      "20827 Traning Loss: tensor(0.8594)\n",
      "20828 Traning Loss: tensor(0.8593)\n",
      "20829 Traning Loss: tensor(0.8593)\n",
      "20830 Traning Loss: tensor(0.8592)\n",
      "20831 Traning Loss: tensor(0.8591)\n",
      "20832 Traning Loss: tensor(0.8591)\n",
      "20833 Traning Loss: tensor(0.8590)\n",
      "20834 Traning Loss: tensor(0.8589)\n",
      "20835 Traning Loss: tensor(0.8589)\n",
      "20836 Traning Loss: tensor(0.8588)\n",
      "20837 Traning Loss: tensor(0.8588)\n",
      "20838 Traning Loss: tensor(0.8587)\n",
      "20839 Traning Loss: tensor(0.8586)\n",
      "20840 Traning Loss: tensor(0.8586)\n",
      "20841 Traning Loss: tensor(0.8585)\n",
      "20842 Traning Loss: tensor(0.8584)\n",
      "20843 Traning Loss: tensor(0.8584)\n",
      "20844 Traning Loss: tensor(0.8583)\n",
      "20845 Traning Loss: tensor(0.8582)\n",
      "20846 Traning Loss: tensor(0.8582)\n",
      "20847 Traning Loss: tensor(0.8581)\n",
      "20848 Traning Loss: tensor(0.8580)\n",
      "20849 Traning Loss: tensor(0.8580)\n",
      "20850 Traning Loss: tensor(0.8579)\n",
      "20851 Traning Loss: tensor(0.8578)\n",
      "20852 Traning Loss: tensor(0.8578)\n",
      "20853 Traning Loss: tensor(0.8577)\n",
      "20854 Traning Loss: tensor(0.8577)\n",
      "20855 Traning Loss: tensor(0.8576)\n",
      "20856 Traning Loss: tensor(0.8575)\n",
      "20857 Traning Loss: tensor(0.8575)\n",
      "20858 Traning Loss: tensor(0.8574)\n",
      "20859 Traning Loss: tensor(0.8573)\n",
      "20860 Traning Loss: tensor(0.8573)\n",
      "20861 Traning Loss: tensor(0.8572)\n",
      "20862 Traning Loss: tensor(0.8571)\n",
      "20863 Traning Loss: tensor(0.8571)\n",
      "20864 Traning Loss: tensor(0.8570)\n",
      "20865 Traning Loss: tensor(0.8569)\n",
      "20866 Traning Loss: tensor(0.8569)\n",
      "20867 Traning Loss: tensor(0.8568)\n",
      "20868 Traning Loss: tensor(0.8568)\n",
      "20869 Traning Loss: tensor(0.8567)\n",
      "20870 Traning Loss: tensor(0.8566)\n",
      "20871 Traning Loss: tensor(0.8566)\n",
      "20872 Traning Loss: tensor(0.8565)\n",
      "20873 Traning Loss: tensor(0.8564)\n",
      "20874 Traning Loss: tensor(0.8564)\n",
      "20875 Traning Loss: tensor(0.8563)\n",
      "20876 Traning Loss: tensor(0.8562)\n",
      "20877 Traning Loss: tensor(0.8562)\n",
      "20878 Traning Loss: tensor(0.8561)\n",
      "20879 Traning Loss: tensor(0.8560)\n",
      "20880 Traning Loss: tensor(0.8560)\n",
      "20881 Traning Loss: tensor(0.8559)\n",
      "20882 Traning Loss: tensor(0.8559)\n",
      "20883 Traning Loss: tensor(0.8558)\n",
      "20884 Traning Loss: tensor(0.8557)\n",
      "20885 Traning Loss: tensor(0.8557)\n",
      "20886 Traning Loss: tensor(0.8556)\n",
      "20887 Traning Loss: tensor(0.8555)\n",
      "20888 Traning Loss: tensor(0.8555)\n",
      "20889 Traning Loss: tensor(0.8554)\n",
      "20890 Traning Loss: tensor(0.8553)\n",
      "20891 Traning Loss: tensor(0.8553)\n",
      "20892 Traning Loss: tensor(0.8552)\n",
      "20893 Traning Loss: tensor(0.8552)\n",
      "20894 Traning Loss: tensor(0.8551)\n",
      "20895 Traning Loss: tensor(0.8550)\n",
      "20896 Traning Loss: tensor(0.8550)\n",
      "20897 Traning Loss: tensor(0.8549)\n",
      "20898 Traning Loss: tensor(0.8548)\n",
      "20899 Traning Loss: tensor(0.8548)\n",
      "20900 Traning Loss: tensor(0.8547)\n",
      "20901 Traning Loss: tensor(0.8546)\n",
      "20902 Traning Loss: tensor(0.8546)\n",
      "20903 Traning Loss: tensor(0.8545)\n",
      "20904 Traning Loss: tensor(0.8545)\n",
      "20905 Traning Loss: tensor(0.8544)\n",
      "20906 Traning Loss: tensor(0.8543)\n",
      "20907 Traning Loss: tensor(0.8543)\n",
      "20908 Traning Loss: tensor(0.8542)\n",
      "20909 Traning Loss: tensor(0.8541)\n",
      "20910 Traning Loss: tensor(0.8541)\n",
      "20911 Traning Loss: tensor(0.8540)\n",
      "20912 Traning Loss: tensor(0.8540)\n",
      "20913 Traning Loss: tensor(0.8539)\n",
      "20914 Traning Loss: tensor(0.8538)\n",
      "20915 Traning Loss: tensor(0.8538)\n",
      "20916 Traning Loss: tensor(0.8537)\n",
      "20917 Traning Loss: tensor(0.8536)\n",
      "20918 Traning Loss: tensor(0.8536)\n",
      "20919 Traning Loss: tensor(0.8535)\n",
      "20920 Traning Loss: tensor(0.8534)\n",
      "20921 Traning Loss: tensor(0.8534)\n",
      "20922 Traning Loss: tensor(0.8533)\n",
      "20923 Traning Loss: tensor(0.8533)\n",
      "20924 Traning Loss: tensor(0.8532)\n",
      "20925 Traning Loss: tensor(0.8531)\n",
      "20926 Traning Loss: tensor(0.8531)\n",
      "20927 Traning Loss: tensor(0.8530)\n",
      "20928 Traning Loss: tensor(0.8529)\n",
      "20929 Traning Loss: tensor(0.8529)\n",
      "20930 Traning Loss: tensor(0.8528)\n",
      "20931 Traning Loss: tensor(0.8528)\n",
      "20932 Traning Loss: tensor(0.8527)\n",
      "20933 Traning Loss: tensor(0.8526)\n",
      "20934 Traning Loss: tensor(0.8526)\n",
      "20935 Traning Loss: tensor(0.8525)\n",
      "20936 Traning Loss: tensor(0.8524)\n",
      "20937 Traning Loss: tensor(0.8524)\n",
      "20938 Traning Loss: tensor(0.8523)\n",
      "20939 Traning Loss: tensor(0.8523)\n",
      "20940 Traning Loss: tensor(0.8522)\n",
      "20941 Traning Loss: tensor(0.8521)\n",
      "20942 Traning Loss: tensor(0.8521)\n",
      "20943 Traning Loss: tensor(0.8520)\n",
      "20944 Traning Loss: tensor(0.8519)\n",
      "20945 Traning Loss: tensor(0.8519)\n",
      "20946 Traning Loss: tensor(0.8518)\n",
      "20947 Traning Loss: tensor(0.8518)\n",
      "20948 Traning Loss: tensor(0.8517)\n",
      "20949 Traning Loss: tensor(0.8516)\n",
      "20950 Traning Loss: tensor(0.8516)\n",
      "20951 Traning Loss: tensor(0.8515)\n",
      "20952 Traning Loss: tensor(0.8514)\n",
      "20953 Traning Loss: tensor(0.8514)\n",
      "20954 Traning Loss: tensor(0.8513)\n",
      "20955 Traning Loss: tensor(0.8513)\n",
      "20956 Traning Loss: tensor(0.8512)\n",
      "20957 Traning Loss: tensor(0.8511)\n",
      "20958 Traning Loss: tensor(0.8511)\n",
      "20959 Traning Loss: tensor(0.8510)\n",
      "20960 Traning Loss: tensor(0.8510)\n",
      "20961 Traning Loss: tensor(0.8509)\n",
      "20962 Traning Loss: tensor(0.8508)\n",
      "20963 Traning Loss: tensor(0.8508)\n",
      "20964 Traning Loss: tensor(0.8507)\n",
      "20965 Traning Loss: tensor(0.8506)\n",
      "20966 Traning Loss: tensor(0.8506)\n",
      "20967 Traning Loss: tensor(0.8505)\n",
      "20968 Traning Loss: tensor(0.8505)\n",
      "20969 Traning Loss: tensor(0.8504)\n",
      "20970 Traning Loss: tensor(0.8503)\n",
      "20971 Traning Loss: tensor(0.8503)\n",
      "20972 Traning Loss: tensor(0.8502)\n",
      "20973 Traning Loss: tensor(0.8502)\n",
      "20974 Traning Loss: tensor(0.8501)\n",
      "20975 Traning Loss: tensor(0.8500)\n",
      "20976 Traning Loss: tensor(0.8500)\n",
      "20977 Traning Loss: tensor(0.8499)\n",
      "20978 Traning Loss: tensor(0.8498)\n",
      "20979 Traning Loss: tensor(0.8498)\n",
      "20980 Traning Loss: tensor(0.8497)\n",
      "20981 Traning Loss: tensor(0.8497)\n",
      "20982 Traning Loss: tensor(0.8496)\n",
      "20983 Traning Loss: tensor(0.8495)\n",
      "20984 Traning Loss: tensor(0.8495)\n",
      "20985 Traning Loss: tensor(0.8494)\n",
      "20986 Traning Loss: tensor(0.8494)\n",
      "20987 Traning Loss: tensor(0.8493)\n",
      "20988 Traning Loss: tensor(0.8492)\n",
      "20989 Traning Loss: tensor(0.8492)\n",
      "20990 Traning Loss: tensor(0.8491)\n",
      "20991 Traning Loss: tensor(0.8490)\n",
      "20992 Traning Loss: tensor(0.8490)\n",
      "20993 Traning Loss: tensor(0.8489)\n",
      "20994 Traning Loss: tensor(0.8489)\n",
      "20995 Traning Loss: tensor(0.8488)\n",
      "20996 Traning Loss: tensor(0.8487)\n",
      "20997 Traning Loss: tensor(0.8487)\n",
      "20998 Traning Loss: tensor(0.8486)\n",
      "20999 Traning Loss: tensor(0.8486)\n",
      "21000 Traning Loss: tensor(0.8485)\n",
      "21001 Traning Loss: tensor(0.8484)\n",
      "21002 Traning Loss: tensor(0.8484)\n",
      "21003 Traning Loss: tensor(0.8483)\n",
      "21004 Traning Loss: tensor(0.8483)\n",
      "21005 Traning Loss: tensor(0.8482)\n",
      "21006 Traning Loss: tensor(0.8481)\n",
      "21007 Traning Loss: tensor(0.8481)\n",
      "21008 Traning Loss: tensor(0.8480)\n",
      "21009 Traning Loss: tensor(0.8480)\n",
      "21010 Traning Loss: tensor(0.8479)\n",
      "21011 Traning Loss: tensor(0.8478)\n",
      "21012 Traning Loss: tensor(0.8478)\n",
      "21013 Traning Loss: tensor(0.8477)\n",
      "21014 Traning Loss: tensor(0.8476)\n",
      "21015 Traning Loss: tensor(0.8476)\n",
      "21016 Traning Loss: tensor(0.8475)\n",
      "21017 Traning Loss: tensor(0.8475)\n",
      "21018 Traning Loss: tensor(0.8474)\n",
      "21019 Traning Loss: tensor(0.8473)\n",
      "21020 Traning Loss: tensor(0.8473)\n",
      "21021 Traning Loss: tensor(0.8472)\n",
      "21022 Traning Loss: tensor(0.8472)\n",
      "21023 Traning Loss: tensor(0.8471)\n",
      "21024 Traning Loss: tensor(0.8470)\n",
      "21025 Traning Loss: tensor(0.8470)\n",
      "21026 Traning Loss: tensor(0.8469)\n",
      "21027 Traning Loss: tensor(0.8469)\n",
      "21028 Traning Loss: tensor(0.8468)\n",
      "21029 Traning Loss: tensor(0.8467)\n",
      "21030 Traning Loss: tensor(0.8467)\n",
      "21031 Traning Loss: tensor(0.8466)\n",
      "21032 Traning Loss: tensor(0.8466)\n",
      "21033 Traning Loss: tensor(0.8465)\n",
      "21034 Traning Loss: tensor(0.8464)\n",
      "21035 Traning Loss: tensor(0.8464)\n",
      "21036 Traning Loss: tensor(0.8463)\n",
      "21037 Traning Loss: tensor(0.8463)\n",
      "21038 Traning Loss: tensor(0.8462)\n",
      "21039 Traning Loss: tensor(0.8461)\n",
      "21040 Traning Loss: tensor(0.8461)\n",
      "21041 Traning Loss: tensor(0.8460)\n",
      "21042 Traning Loss: tensor(0.8460)\n",
      "21043 Traning Loss: tensor(0.8459)\n",
      "21044 Traning Loss: tensor(0.8458)\n",
      "21045 Traning Loss: tensor(0.8458)\n",
      "21046 Traning Loss: tensor(0.8457)\n",
      "21047 Traning Loss: tensor(0.8457)\n",
      "21048 Traning Loss: tensor(0.8456)\n",
      "21049 Traning Loss: tensor(0.8455)\n",
      "21050 Traning Loss: tensor(0.8455)\n",
      "21051 Traning Loss: tensor(0.8454)\n",
      "21052 Traning Loss: tensor(0.8454)\n",
      "21053 Traning Loss: tensor(0.8453)\n",
      "21054 Traning Loss: tensor(0.8452)\n",
      "21055 Traning Loss: tensor(0.8452)\n",
      "21056 Traning Loss: tensor(0.8451)\n",
      "21057 Traning Loss: tensor(0.8451)\n",
      "21058 Traning Loss: tensor(0.8450)\n",
      "21059 Traning Loss: tensor(0.8449)\n",
      "21060 Traning Loss: tensor(0.8449)\n",
      "21061 Traning Loss: tensor(0.8448)\n",
      "21062 Traning Loss: tensor(0.8448)\n",
      "21063 Traning Loss: tensor(0.8447)\n",
      "21064 Traning Loss: tensor(0.8447)\n",
      "21065 Traning Loss: tensor(0.8446)\n",
      "21066 Traning Loss: tensor(0.8445)\n",
      "21067 Traning Loss: tensor(0.8445)\n",
      "21068 Traning Loss: tensor(0.8444)\n",
      "21069 Traning Loss: tensor(0.8444)\n",
      "21070 Traning Loss: tensor(0.8443)\n",
      "21071 Traning Loss: tensor(0.8442)\n",
      "21072 Traning Loss: tensor(0.8442)\n",
      "21073 Traning Loss: tensor(0.8441)\n",
      "21074 Traning Loss: tensor(0.8441)\n",
      "21075 Traning Loss: tensor(0.8440)\n",
      "21076 Traning Loss: tensor(0.8439)\n",
      "21077 Traning Loss: tensor(0.8439)\n",
      "21078 Traning Loss: tensor(0.8438)\n",
      "21079 Traning Loss: tensor(0.8438)\n",
      "21080 Traning Loss: tensor(0.8437)\n",
      "21081 Traning Loss: tensor(0.8436)\n",
      "21082 Traning Loss: tensor(0.8436)\n",
      "21083 Traning Loss: tensor(0.8435)\n",
      "21084 Traning Loss: tensor(0.8435)\n",
      "21085 Traning Loss: tensor(0.8434)\n",
      "21086 Traning Loss: tensor(0.8434)\n",
      "21087 Traning Loss: tensor(0.8433)\n",
      "21088 Traning Loss: tensor(0.8432)\n",
      "21089 Traning Loss: tensor(0.8432)\n",
      "21090 Traning Loss: tensor(0.8431)\n",
      "21091 Traning Loss: tensor(0.8431)\n",
      "21092 Traning Loss: tensor(0.8430)\n",
      "21093 Traning Loss: tensor(0.8429)\n",
      "21094 Traning Loss: tensor(0.8429)\n",
      "21095 Traning Loss: tensor(0.8428)\n",
      "21096 Traning Loss: tensor(0.8428)\n",
      "21097 Traning Loss: tensor(0.8427)\n",
      "21098 Traning Loss: tensor(0.8426)\n",
      "21099 Traning Loss: tensor(0.8426)\n",
      "21100 Traning Loss: tensor(0.8425)\n",
      "21101 Traning Loss: tensor(0.8425)\n",
      "21102 Traning Loss: tensor(0.8424)\n",
      "21103 Traning Loss: tensor(0.8424)\n",
      "21104 Traning Loss: tensor(0.8423)\n",
      "21105 Traning Loss: tensor(0.8422)\n",
      "21106 Traning Loss: tensor(0.8422)\n",
      "21107 Traning Loss: tensor(0.8421)\n",
      "21108 Traning Loss: tensor(0.8421)\n",
      "21109 Traning Loss: tensor(0.8420)\n",
      "21110 Traning Loss: tensor(0.8419)\n",
      "21111 Traning Loss: tensor(0.8419)\n",
      "21112 Traning Loss: tensor(0.8418)\n",
      "21113 Traning Loss: tensor(0.8418)\n",
      "21114 Traning Loss: tensor(0.8417)\n",
      "21115 Traning Loss: tensor(0.8417)\n",
      "21116 Traning Loss: tensor(0.8416)\n",
      "21117 Traning Loss: tensor(0.8415)\n",
      "21118 Traning Loss: tensor(0.8415)\n",
      "21119 Traning Loss: tensor(0.8414)\n",
      "21120 Traning Loss: tensor(0.8414)\n",
      "21121 Traning Loss: tensor(0.8413)\n",
      "21122 Traning Loss: tensor(0.8412)\n",
      "21123 Traning Loss: tensor(0.8412)\n",
      "21124 Traning Loss: tensor(0.8411)\n",
      "21125 Traning Loss: tensor(0.8411)\n",
      "21126 Traning Loss: tensor(0.8410)\n",
      "21127 Traning Loss: tensor(0.8410)\n",
      "21128 Traning Loss: tensor(0.8409)\n",
      "21129 Traning Loss: tensor(0.8408)\n",
      "21130 Traning Loss: tensor(0.8408)\n",
      "21131 Traning Loss: tensor(0.8407)\n",
      "21132 Traning Loss: tensor(0.8407)\n",
      "21133 Traning Loss: tensor(0.8406)\n",
      "21134 Traning Loss: tensor(0.8406)\n",
      "21135 Traning Loss: tensor(0.8405)\n",
      "21136 Traning Loss: tensor(0.8404)\n",
      "21137 Traning Loss: tensor(0.8404)\n",
      "21138 Traning Loss: tensor(0.8403)\n",
      "21139 Traning Loss: tensor(0.8403)\n",
      "21140 Traning Loss: tensor(0.8402)\n",
      "21141 Traning Loss: tensor(0.8402)\n",
      "21142 Traning Loss: tensor(0.8401)\n",
      "21143 Traning Loss: tensor(0.8400)\n",
      "21144 Traning Loss: tensor(0.8400)\n",
      "21145 Traning Loss: tensor(0.8399)\n",
      "21146 Traning Loss: tensor(0.8399)\n",
      "21147 Traning Loss: tensor(0.8398)\n",
      "21148 Traning Loss: tensor(0.8397)\n",
      "21149 Traning Loss: tensor(0.8397)\n",
      "21150 Traning Loss: tensor(0.8396)\n",
      "21151 Traning Loss: tensor(0.8396)\n",
      "21152 Traning Loss: tensor(0.8395)\n",
      "21153 Traning Loss: tensor(0.8395)\n",
      "21154 Traning Loss: tensor(0.8394)\n",
      "21155 Traning Loss: tensor(0.8393)\n",
      "21156 Traning Loss: tensor(0.8393)\n",
      "21157 Traning Loss: tensor(0.8392)\n",
      "21158 Traning Loss: tensor(0.8392)\n",
      "21159 Traning Loss: tensor(0.8391)\n",
      "21160 Traning Loss: tensor(0.8391)\n",
      "21161 Traning Loss: tensor(0.8390)\n",
      "21162 Traning Loss: tensor(0.8389)\n",
      "21163 Traning Loss: tensor(0.8389)\n",
      "21164 Traning Loss: tensor(0.8388)\n",
      "21165 Traning Loss: tensor(0.8388)\n",
      "21166 Traning Loss: tensor(0.8387)\n",
      "21167 Traning Loss: tensor(0.8387)\n",
      "21168 Traning Loss: tensor(0.8386)\n",
      "21169 Traning Loss: tensor(0.8385)\n",
      "21170 Traning Loss: tensor(0.8385)\n",
      "21171 Traning Loss: tensor(0.8384)\n",
      "21172 Traning Loss: tensor(0.8384)\n",
      "21173 Traning Loss: tensor(0.8383)\n",
      "21174 Traning Loss: tensor(0.8383)\n",
      "21175 Traning Loss: tensor(0.8382)\n",
      "21176 Traning Loss: tensor(0.8381)\n",
      "21177 Traning Loss: tensor(0.8381)\n",
      "21178 Traning Loss: tensor(0.8380)\n",
      "21179 Traning Loss: tensor(0.8380)\n",
      "21180 Traning Loss: tensor(0.8379)\n",
      "21181 Traning Loss: tensor(0.8379)\n",
      "21182 Traning Loss: tensor(0.8378)\n",
      "21183 Traning Loss: tensor(0.8377)\n",
      "21184 Traning Loss: tensor(0.8377)\n",
      "21185 Traning Loss: tensor(0.8376)\n",
      "21186 Traning Loss: tensor(0.8376)\n",
      "21187 Traning Loss: tensor(0.8375)\n",
      "21188 Traning Loss: tensor(0.8375)\n",
      "21189 Traning Loss: tensor(0.8374)\n",
      "21190 Traning Loss: tensor(0.8374)\n",
      "21191 Traning Loss: tensor(0.8373)\n",
      "21192 Traning Loss: tensor(0.8372)\n",
      "21193 Traning Loss: tensor(0.8372)\n",
      "21194 Traning Loss: tensor(0.8371)\n",
      "21195 Traning Loss: tensor(0.8371)\n",
      "21196 Traning Loss: tensor(0.8370)\n",
      "21197 Traning Loss: tensor(0.8370)\n",
      "21198 Traning Loss: tensor(0.8369)\n",
      "21199 Traning Loss: tensor(0.8368)\n",
      "21200 Traning Loss: tensor(0.8368)\n",
      "21201 Traning Loss: tensor(0.8367)\n",
      "21202 Traning Loss: tensor(0.8367)\n",
      "21203 Traning Loss: tensor(0.8366)\n",
      "21204 Traning Loss: tensor(0.8366)\n",
      "21205 Traning Loss: tensor(0.8365)\n",
      "21206 Traning Loss: tensor(0.8365)\n",
      "21207 Traning Loss: tensor(0.8364)\n",
      "21208 Traning Loss: tensor(0.8363)\n",
      "21209 Traning Loss: tensor(0.8363)\n",
      "21210 Traning Loss: tensor(0.8362)\n",
      "21211 Traning Loss: tensor(0.8362)\n",
      "21212 Traning Loss: tensor(0.8361)\n",
      "21213 Traning Loss: tensor(0.8361)\n",
      "21214 Traning Loss: tensor(0.8360)\n",
      "21215 Traning Loss: tensor(0.8359)\n",
      "21216 Traning Loss: tensor(0.8359)\n",
      "21217 Traning Loss: tensor(0.8358)\n",
      "21218 Traning Loss: tensor(0.8358)\n",
      "21219 Traning Loss: tensor(0.8357)\n",
      "21220 Traning Loss: tensor(0.8357)\n",
      "21221 Traning Loss: tensor(0.8356)\n",
      "21222 Traning Loss: tensor(0.8356)\n",
      "21223 Traning Loss: tensor(0.8355)\n",
      "21224 Traning Loss: tensor(0.8354)\n",
      "21225 Traning Loss: tensor(0.8354)\n",
      "21226 Traning Loss: tensor(0.8353)\n",
      "21227 Traning Loss: tensor(0.8353)\n",
      "21228 Traning Loss: tensor(0.8352)\n",
      "21229 Traning Loss: tensor(0.8352)\n",
      "21230 Traning Loss: tensor(0.8351)\n",
      "21231 Traning Loss: tensor(0.8351)\n",
      "21232 Traning Loss: tensor(0.8350)\n",
      "21233 Traning Loss: tensor(0.8349)\n",
      "21234 Traning Loss: tensor(0.8349)\n",
      "21235 Traning Loss: tensor(0.8348)\n",
      "21236 Traning Loss: tensor(0.8348)\n",
      "21237 Traning Loss: tensor(0.8347)\n",
      "21238 Traning Loss: tensor(0.8347)\n",
      "21239 Traning Loss: tensor(0.8346)\n",
      "21240 Traning Loss: tensor(0.8346)\n",
      "21241 Traning Loss: tensor(0.8345)\n",
      "21242 Traning Loss: tensor(0.8344)\n",
      "21243 Traning Loss: tensor(0.8344)\n",
      "21244 Traning Loss: tensor(0.8343)\n",
      "21245 Traning Loss: tensor(0.8343)\n",
      "21246 Traning Loss: tensor(0.8342)\n",
      "21247 Traning Loss: tensor(0.8342)\n",
      "21248 Traning Loss: tensor(0.8341)\n",
      "21249 Traning Loss: tensor(0.8341)\n",
      "21250 Traning Loss: tensor(0.8340)\n",
      "21251 Traning Loss: tensor(0.8339)\n",
      "21252 Traning Loss: tensor(0.8339)\n",
      "21253 Traning Loss: tensor(0.8338)\n",
      "21254 Traning Loss: tensor(0.8338)\n",
      "21255 Traning Loss: tensor(0.8337)\n",
      "21256 Traning Loss: tensor(0.8337)\n",
      "21257 Traning Loss: tensor(0.8336)\n",
      "21258 Traning Loss: tensor(0.8336)\n",
      "21259 Traning Loss: tensor(0.8335)\n",
      "21260 Traning Loss: tensor(0.8334)\n",
      "21261 Traning Loss: tensor(0.8334)\n",
      "21262 Traning Loss: tensor(0.8333)\n",
      "21263 Traning Loss: tensor(0.8333)\n",
      "21264 Traning Loss: tensor(0.8332)\n",
      "21265 Traning Loss: tensor(0.8332)\n",
      "21266 Traning Loss: tensor(0.8331)\n",
      "21267 Traning Loss: tensor(0.8331)\n",
      "21268 Traning Loss: tensor(0.8330)\n",
      "21269 Traning Loss: tensor(0.8330)\n",
      "21270 Traning Loss: tensor(0.8329)\n",
      "21271 Traning Loss: tensor(0.8328)\n",
      "21272 Traning Loss: tensor(0.8328)\n",
      "21273 Traning Loss: tensor(0.8327)\n",
      "21274 Traning Loss: tensor(0.8327)\n",
      "21275 Traning Loss: tensor(0.8326)\n",
      "21276 Traning Loss: tensor(0.8326)\n",
      "21277 Traning Loss: tensor(0.8325)\n",
      "21278 Traning Loss: tensor(0.8325)\n",
      "21279 Traning Loss: tensor(0.8324)\n",
      "21280 Traning Loss: tensor(0.8323)\n",
      "21281 Traning Loss: tensor(0.8323)\n",
      "21282 Traning Loss: tensor(0.8322)\n",
      "21283 Traning Loss: tensor(0.8322)\n",
      "21284 Traning Loss: tensor(0.8321)\n",
      "21285 Traning Loss: tensor(0.8321)\n",
      "21286 Traning Loss: tensor(0.8320)\n",
      "21287 Traning Loss: tensor(0.8320)\n",
      "21288 Traning Loss: tensor(0.8319)\n",
      "21289 Traning Loss: tensor(0.8319)\n",
      "21290 Traning Loss: tensor(0.8318)\n",
      "21291 Traning Loss: tensor(0.8317)\n",
      "21292 Traning Loss: tensor(0.8317)\n",
      "21293 Traning Loss: tensor(0.8316)\n",
      "21294 Traning Loss: tensor(0.8316)\n",
      "21295 Traning Loss: tensor(0.8315)\n",
      "21296 Traning Loss: tensor(0.8315)\n",
      "21297 Traning Loss: tensor(0.8314)\n",
      "21298 Traning Loss: tensor(0.8314)\n",
      "21299 Traning Loss: tensor(0.8313)\n",
      "21300 Traning Loss: tensor(0.8313)\n",
      "21301 Traning Loss: tensor(0.8312)\n",
      "21302 Traning Loss: tensor(0.8312)\n",
      "21303 Traning Loss: tensor(0.8311)\n",
      "21304 Traning Loss: tensor(0.8310)\n",
      "21305 Traning Loss: tensor(0.8310)\n",
      "21306 Traning Loss: tensor(0.8309)\n",
      "21307 Traning Loss: tensor(0.8309)\n",
      "21308 Traning Loss: tensor(0.8308)\n",
      "21309 Traning Loss: tensor(0.8308)\n",
      "21310 Traning Loss: tensor(0.8307)\n",
      "21311 Traning Loss: tensor(0.8307)\n",
      "21312 Traning Loss: tensor(0.8306)\n",
      "21313 Traning Loss: tensor(0.8306)\n",
      "21314 Traning Loss: tensor(0.8305)\n",
      "21315 Traning Loss: tensor(0.8304)\n",
      "21316 Traning Loss: tensor(0.8304)\n",
      "21317 Traning Loss: tensor(0.8303)\n",
      "21318 Traning Loss: tensor(0.8303)\n",
      "21319 Traning Loss: tensor(0.8302)\n",
      "21320 Traning Loss: tensor(0.8302)\n",
      "21321 Traning Loss: tensor(0.8301)\n",
      "21322 Traning Loss: tensor(0.8301)\n",
      "21323 Traning Loss: tensor(0.8300)\n",
      "21324 Traning Loss: tensor(0.8300)\n",
      "21325 Traning Loss: tensor(0.8299)\n",
      "21326 Traning Loss: tensor(0.8299)\n",
      "21327 Traning Loss: tensor(0.8298)\n",
      "21328 Traning Loss: tensor(0.8297)\n",
      "21329 Traning Loss: tensor(0.8297)\n",
      "21330 Traning Loss: tensor(0.8296)\n",
      "21331 Traning Loss: tensor(0.8296)\n",
      "21332 Traning Loss: tensor(0.8295)\n",
      "21333 Traning Loss: tensor(0.8295)\n",
      "21334 Traning Loss: tensor(0.8294)\n",
      "21335 Traning Loss: tensor(0.8294)\n",
      "21336 Traning Loss: tensor(0.8293)\n",
      "21337 Traning Loss: tensor(0.8293)\n",
      "21338 Traning Loss: tensor(0.8292)\n",
      "21339 Traning Loss: tensor(0.8292)\n",
      "21340 Traning Loss: tensor(0.8291)\n",
      "21341 Traning Loss: tensor(0.8290)\n",
      "21342 Traning Loss: tensor(0.8290)\n",
      "21343 Traning Loss: tensor(0.8289)\n",
      "21344 Traning Loss: tensor(0.8289)\n",
      "21345 Traning Loss: tensor(0.8288)\n",
      "21346 Traning Loss: tensor(0.8288)\n",
      "21347 Traning Loss: tensor(0.8287)\n",
      "21348 Traning Loss: tensor(0.8287)\n",
      "21349 Traning Loss: tensor(0.8286)\n",
      "21350 Traning Loss: tensor(0.8286)\n",
      "21351 Traning Loss: tensor(0.8285)\n",
      "21352 Traning Loss: tensor(0.8285)\n",
      "21353 Traning Loss: tensor(0.8284)\n",
      "21354 Traning Loss: tensor(0.8284)\n",
      "21355 Traning Loss: tensor(0.8283)\n",
      "21356 Traning Loss: tensor(0.8282)\n",
      "21357 Traning Loss: tensor(0.8282)\n",
      "21358 Traning Loss: tensor(0.8281)\n",
      "21359 Traning Loss: tensor(0.8281)\n",
      "21360 Traning Loss: tensor(0.8280)\n",
      "21361 Traning Loss: tensor(0.8280)\n",
      "21362 Traning Loss: tensor(0.8279)\n",
      "21363 Traning Loss: tensor(0.8279)\n",
      "21364 Traning Loss: tensor(0.8278)\n",
      "21365 Traning Loss: tensor(0.8278)\n",
      "21366 Traning Loss: tensor(0.8277)\n",
      "21367 Traning Loss: tensor(0.8277)\n",
      "21368 Traning Loss: tensor(0.8276)\n",
      "21369 Traning Loss: tensor(0.8276)\n",
      "21370 Traning Loss: tensor(0.8275)\n",
      "21371 Traning Loss: tensor(0.8275)\n",
      "21372 Traning Loss: tensor(0.8274)\n",
      "21373 Traning Loss: tensor(0.8273)\n",
      "21374 Traning Loss: tensor(0.8273)\n",
      "21375 Traning Loss: tensor(0.8272)\n",
      "21376 Traning Loss: tensor(0.8272)\n",
      "21377 Traning Loss: tensor(0.8271)\n",
      "21378 Traning Loss: tensor(0.8271)\n",
      "21379 Traning Loss: tensor(0.8270)\n",
      "21380 Traning Loss: tensor(0.8270)\n",
      "21381 Traning Loss: tensor(0.8269)\n",
      "21382 Traning Loss: tensor(0.8269)\n",
      "21383 Traning Loss: tensor(0.8268)\n",
      "21384 Traning Loss: tensor(0.8268)\n",
      "21385 Traning Loss: tensor(0.8267)\n",
      "21386 Traning Loss: tensor(0.8267)\n",
      "21387 Traning Loss: tensor(0.8266)\n",
      "21388 Traning Loss: tensor(0.8266)\n",
      "21389 Traning Loss: tensor(0.8265)\n",
      "21390 Traning Loss: tensor(0.8264)\n",
      "21391 Traning Loss: tensor(0.8264)\n",
      "21392 Traning Loss: tensor(0.8263)\n",
      "21393 Traning Loss: tensor(0.8263)\n",
      "21394 Traning Loss: tensor(0.8262)\n",
      "21395 Traning Loss: tensor(0.8262)\n",
      "21396 Traning Loss: tensor(0.8261)\n",
      "21397 Traning Loss: tensor(0.8261)\n",
      "21398 Traning Loss: tensor(0.8260)\n",
      "21399 Traning Loss: tensor(0.8260)\n",
      "21400 Traning Loss: tensor(0.8259)\n",
      "21401 Traning Loss: tensor(0.8259)\n",
      "21402 Traning Loss: tensor(0.8258)\n",
      "21403 Traning Loss: tensor(0.8258)\n",
      "21404 Traning Loss: tensor(0.8257)\n",
      "21405 Traning Loss: tensor(0.8257)\n",
      "21406 Traning Loss: tensor(0.8256)\n",
      "21407 Traning Loss: tensor(0.8256)\n",
      "21408 Traning Loss: tensor(0.8255)\n",
      "21409 Traning Loss: tensor(0.8255)\n",
      "21410 Traning Loss: tensor(0.8254)\n",
      "21411 Traning Loss: tensor(0.8253)\n",
      "21412 Traning Loss: tensor(0.8253)\n",
      "21413 Traning Loss: tensor(0.8252)\n",
      "21414 Traning Loss: tensor(0.8252)\n",
      "21415 Traning Loss: tensor(0.8251)\n",
      "21416 Traning Loss: tensor(0.8251)\n",
      "21417 Traning Loss: tensor(0.8250)\n",
      "21418 Traning Loss: tensor(0.8250)\n",
      "21419 Traning Loss: tensor(0.8249)\n",
      "21420 Traning Loss: tensor(0.8249)\n",
      "21421 Traning Loss: tensor(0.8248)\n",
      "21422 Traning Loss: tensor(0.8248)\n",
      "21423 Traning Loss: tensor(0.8247)\n",
      "21424 Traning Loss: tensor(0.8247)\n",
      "21425 Traning Loss: tensor(0.8246)\n",
      "21426 Traning Loss: tensor(0.8246)\n",
      "21427 Traning Loss: tensor(0.8245)\n",
      "21428 Traning Loss: tensor(0.8245)\n",
      "21429 Traning Loss: tensor(0.8244)\n",
      "21430 Traning Loss: tensor(0.8244)\n",
      "21431 Traning Loss: tensor(0.8243)\n",
      "21432 Traning Loss: tensor(0.8243)\n",
      "21433 Traning Loss: tensor(0.8242)\n",
      "21434 Traning Loss: tensor(0.8241)\n",
      "21435 Traning Loss: tensor(0.8241)\n",
      "21436 Traning Loss: tensor(0.8240)\n",
      "21437 Traning Loss: tensor(0.8240)\n",
      "21438 Traning Loss: tensor(0.8239)\n",
      "21439 Traning Loss: tensor(0.8239)\n",
      "21440 Traning Loss: tensor(0.8238)\n",
      "21441 Traning Loss: tensor(0.8238)\n",
      "21442 Traning Loss: tensor(0.8237)\n",
      "21443 Traning Loss: tensor(0.8237)\n",
      "21444 Traning Loss: tensor(0.8236)\n",
      "21445 Traning Loss: tensor(0.8236)\n",
      "21446 Traning Loss: tensor(0.8235)\n",
      "21447 Traning Loss: tensor(0.8235)\n",
      "21448 Traning Loss: tensor(0.8234)\n",
      "21449 Traning Loss: tensor(0.8234)\n",
      "21450 Traning Loss: tensor(0.8233)\n",
      "21451 Traning Loss: tensor(0.8233)\n",
      "21452 Traning Loss: tensor(0.8232)\n",
      "21453 Traning Loss: tensor(0.8232)\n",
      "21454 Traning Loss: tensor(0.8231)\n",
      "21455 Traning Loss: tensor(0.8231)\n",
      "21456 Traning Loss: tensor(0.8230)\n",
      "21457 Traning Loss: tensor(0.8230)\n",
      "21458 Traning Loss: tensor(0.8229)\n",
      "21459 Traning Loss: tensor(0.8229)\n",
      "21460 Traning Loss: tensor(0.8228)\n",
      "21461 Traning Loss: tensor(0.8228)\n",
      "21462 Traning Loss: tensor(0.8227)\n",
      "21463 Traning Loss: tensor(0.8227)\n",
      "21464 Traning Loss: tensor(0.8226)\n",
      "21465 Traning Loss: tensor(0.8226)\n",
      "21466 Traning Loss: tensor(0.8225)\n",
      "21467 Traning Loss: tensor(0.8224)\n",
      "21468 Traning Loss: tensor(0.8224)\n",
      "21469 Traning Loss: tensor(0.8223)\n",
      "21470 Traning Loss: tensor(0.8223)\n",
      "21471 Traning Loss: tensor(0.8222)\n",
      "21472 Traning Loss: tensor(0.8222)\n",
      "21473 Traning Loss: tensor(0.8221)\n",
      "21474 Traning Loss: tensor(0.8221)\n",
      "21475 Traning Loss: tensor(0.8220)\n",
      "21476 Traning Loss: tensor(0.8220)\n",
      "21477 Traning Loss: tensor(0.8219)\n",
      "21478 Traning Loss: tensor(0.8219)\n",
      "21479 Traning Loss: tensor(0.8218)\n",
      "21480 Traning Loss: tensor(0.8218)\n",
      "21481 Traning Loss: tensor(0.8217)\n",
      "21482 Traning Loss: tensor(0.8217)\n",
      "21483 Traning Loss: tensor(0.8216)\n",
      "21484 Traning Loss: tensor(0.8216)\n",
      "21485 Traning Loss: tensor(0.8215)\n",
      "21486 Traning Loss: tensor(0.8215)\n",
      "21487 Traning Loss: tensor(0.8214)\n",
      "21488 Traning Loss: tensor(0.8214)\n",
      "21489 Traning Loss: tensor(0.8213)\n",
      "21490 Traning Loss: tensor(0.8213)\n",
      "21491 Traning Loss: tensor(0.8212)\n",
      "21492 Traning Loss: tensor(0.8212)\n",
      "21493 Traning Loss: tensor(0.8211)\n",
      "21494 Traning Loss: tensor(0.8211)\n",
      "21495 Traning Loss: tensor(0.9343)\n",
      "21496 Traning Loss: tensor(0.9342)\n",
      "21497 Traning Loss: tensor(0.9340)\n",
      "21498 Traning Loss: tensor(0.9338)\n",
      "21499 Traning Loss: tensor(0.9336)\n",
      "21500 Traning Loss: tensor(0.9334)\n",
      "21501 Traning Loss: tensor(0.9332)\n",
      "21502 Traning Loss: tensor(0.9330)\n",
      "21503 Traning Loss: tensor(0.9328)\n",
      "21504 Traning Loss: tensor(0.9326)\n",
      "21505 Traning Loss: tensor(0.9324)\n",
      "21506 Traning Loss: tensor(0.9322)\n",
      "21507 Traning Loss: tensor(0.9320)\n",
      "21508 Traning Loss: tensor(0.9318)\n",
      "21509 Traning Loss: tensor(0.9316)\n",
      "21510 Traning Loss: tensor(0.9314)\n",
      "21511 Traning Loss: tensor(0.9313)\n",
      "21512 Traning Loss: tensor(0.9311)\n",
      "21513 Traning Loss: tensor(0.9309)\n",
      "21514 Traning Loss: tensor(0.9307)\n",
      "21515 Traning Loss: tensor(0.9305)\n",
      "21516 Traning Loss: tensor(0.9304)\n",
      "21517 Traning Loss: tensor(0.9302)\n",
      "21518 Traning Loss: tensor(0.9300)\n",
      "21519 Traning Loss: tensor(0.9298)\n",
      "21520 Traning Loss: tensor(0.9296)\n",
      "21521 Traning Loss: tensor(0.9294)\n",
      "21522 Traning Loss: tensor(0.9292)\n",
      "21523 Traning Loss: tensor(0.9290)\n",
      "21524 Traning Loss: tensor(0.9288)\n",
      "21525 Traning Loss: tensor(0.9286)\n",
      "21526 Traning Loss: tensor(0.9284)\n",
      "21527 Traning Loss: tensor(0.9282)\n",
      "21528 Traning Loss: tensor(0.9280)\n",
      "21529 Traning Loss: tensor(0.9278)\n",
      "21530 Traning Loss: tensor(0.9276)\n",
      "21531 Traning Loss: tensor(0.9274)\n",
      "21532 Traning Loss: tensor(0.9272)\n",
      "21533 Traning Loss: tensor(0.9270)\n",
      "21534 Traning Loss: tensor(0.9268)\n",
      "21535 Traning Loss: tensor(0.9266)\n",
      "21536 Traning Loss: tensor(0.9264)\n",
      "21537 Traning Loss: tensor(0.9262)\n",
      "21538 Traning Loss: tensor(0.9261)\n",
      "21539 Traning Loss: tensor(0.9259)\n",
      "21540 Traning Loss: tensor(0.9257)\n",
      "21541 Traning Loss: tensor(0.9255)\n",
      "21542 Traning Loss: tensor(0.9253)\n",
      "21543 Traning Loss: tensor(0.9251)\n",
      "21544 Traning Loss: tensor(0.9249)\n",
      "21545 Traning Loss: tensor(0.9247)\n",
      "21546 Traning Loss: tensor(0.9245)\n",
      "21547 Traning Loss: tensor(0.9243)\n",
      "21548 Traning Loss: tensor(0.9242)\n",
      "21549 Traning Loss: tensor(0.9240)\n",
      "21550 Traning Loss: tensor(0.9238)\n",
      "21551 Traning Loss: tensor(0.9236)\n",
      "21552 Traning Loss: tensor(0.9234)\n",
      "21553 Traning Loss: tensor(0.9232)\n",
      "21554 Traning Loss: tensor(0.9230)\n",
      "21555 Traning Loss: tensor(0.9229)\n",
      "21556 Traning Loss: tensor(0.9227)\n",
      "21557 Traning Loss: tensor(0.9225)\n",
      "21558 Traning Loss: tensor(0.9223)\n",
      "21559 Traning Loss: tensor(0.9221)\n",
      "21560 Traning Loss: tensor(0.9219)\n",
      "21561 Traning Loss: tensor(0.9218)\n",
      "21562 Traning Loss: tensor(0.9216)\n",
      "21563 Traning Loss: tensor(0.9214)\n",
      "21564 Traning Loss: tensor(0.9212)\n",
      "21565 Traning Loss: tensor(0.9210)\n",
      "21566 Traning Loss: tensor(0.9209)\n",
      "21567 Traning Loss: tensor(0.9207)\n",
      "21568 Traning Loss: tensor(0.9205)\n",
      "21569 Traning Loss: tensor(0.9203)\n",
      "21570 Traning Loss: tensor(0.9201)\n",
      "21571 Traning Loss: tensor(0.9200)\n",
      "21572 Traning Loss: tensor(0.9198)\n",
      "21573 Traning Loss: tensor(0.9196)\n",
      "21574 Traning Loss: tensor(0.9194)\n",
      "21575 Traning Loss: tensor(0.9193)\n",
      "21576 Traning Loss: tensor(0.9191)\n",
      "21577 Traning Loss: tensor(0.9189)\n",
      "21578 Traning Loss: tensor(0.9187)\n",
      "21579 Traning Loss: tensor(0.9186)\n",
      "21580 Traning Loss: tensor(0.9184)\n",
      "21581 Traning Loss: tensor(0.9182)\n",
      "21582 Traning Loss: tensor(0.9180)\n",
      "21583 Traning Loss: tensor(0.9178)\n",
      "21584 Traning Loss: tensor(0.9177)\n",
      "21585 Traning Loss: tensor(0.9175)\n",
      "21586 Traning Loss: tensor(0.9173)\n",
      "21587 Traning Loss: tensor(0.9172)\n",
      "21588 Traning Loss: tensor(0.9170)\n",
      "21589 Traning Loss: tensor(0.9168)\n",
      "21590 Traning Loss: tensor(0.9166)\n",
      "21591 Traning Loss: tensor(0.9165)\n",
      "21592 Traning Loss: tensor(0.9163)\n",
      "21593 Traning Loss: tensor(0.9161)\n",
      "21594 Traning Loss: tensor(0.9159)\n",
      "21595 Traning Loss: tensor(0.9158)\n",
      "21596 Traning Loss: tensor(0.9156)\n",
      "21597 Traning Loss: tensor(0.9154)\n",
      "21598 Traning Loss: tensor(0.9153)\n",
      "21599 Traning Loss: tensor(0.9151)\n",
      "21600 Traning Loss: tensor(0.9149)\n",
      "21601 Traning Loss: tensor(0.9148)\n",
      "21602 Traning Loss: tensor(0.9146)\n",
      "21603 Traning Loss: tensor(0.9144)\n",
      "21604 Traning Loss: tensor(0.9142)\n",
      "21605 Traning Loss: tensor(0.9141)\n",
      "21606 Traning Loss: tensor(0.9139)\n",
      "21607 Traning Loss: tensor(0.9137)\n",
      "21608 Traning Loss: tensor(0.9136)\n",
      "21609 Traning Loss: tensor(0.9134)\n",
      "21610 Traning Loss: tensor(0.9132)\n",
      "21611 Traning Loss: tensor(0.9131)\n",
      "21612 Traning Loss: tensor(0.9129)\n",
      "21613 Traning Loss: tensor(0.9127)\n",
      "21614 Traning Loss: tensor(0.9126)\n",
      "21615 Traning Loss: tensor(0.9124)\n",
      "21616 Traning Loss: tensor(0.9122)\n",
      "21617 Traning Loss: tensor(0.9121)\n",
      "21618 Traning Loss: tensor(0.9119)\n",
      "21619 Traning Loss: tensor(0.9117)\n",
      "21620 Traning Loss: tensor(0.9116)\n",
      "21621 Traning Loss: tensor(0.9114)\n",
      "21622 Traning Loss: tensor(0.9113)\n",
      "21623 Traning Loss: tensor(0.9111)\n",
      "21624 Traning Loss: tensor(0.9109)\n",
      "21625 Traning Loss: tensor(0.9108)\n",
      "21626 Traning Loss: tensor(0.9106)\n",
      "21627 Traning Loss: tensor(0.9104)\n",
      "21628 Traning Loss: tensor(0.9103)\n",
      "21629 Traning Loss: tensor(0.9101)\n",
      "21630 Traning Loss: tensor(0.9100)\n",
      "21631 Traning Loss: tensor(0.9098)\n",
      "21632 Traning Loss: tensor(0.9096)\n",
      "21633 Traning Loss: tensor(0.9095)\n",
      "21634 Traning Loss: tensor(0.9093)\n",
      "21635 Traning Loss: tensor(0.9091)\n",
      "21636 Traning Loss: tensor(0.9090)\n",
      "21637 Traning Loss: tensor(0.9088)\n",
      "21638 Traning Loss: tensor(0.9087)\n",
      "21639 Traning Loss: tensor(0.9085)\n",
      "21640 Traning Loss: tensor(0.9083)\n",
      "21641 Traning Loss: tensor(0.9082)\n",
      "21642 Traning Loss: tensor(0.9080)\n",
      "21643 Traning Loss: tensor(0.9079)\n",
      "21644 Traning Loss: tensor(0.9077)\n",
      "21645 Traning Loss: tensor(0.9076)\n",
      "21646 Traning Loss: tensor(0.9074)\n",
      "21647 Traning Loss: tensor(0.9072)\n",
      "21648 Traning Loss: tensor(0.9071)\n",
      "21649 Traning Loss: tensor(0.9069)\n",
      "21650 Traning Loss: tensor(0.9068)\n",
      "21651 Traning Loss: tensor(0.9066)\n",
      "21652 Traning Loss: tensor(0.9065)\n",
      "21653 Traning Loss: tensor(0.9063)\n",
      "21654 Traning Loss: tensor(0.9061)\n",
      "21655 Traning Loss: tensor(0.9060)\n",
      "21656 Traning Loss: tensor(0.9058)\n",
      "21657 Traning Loss: tensor(0.9057)\n",
      "21658 Traning Loss: tensor(0.9055)\n",
      "21659 Traning Loss: tensor(0.9054)\n",
      "21660 Traning Loss: tensor(0.9052)\n",
      "21661 Traning Loss: tensor(0.9051)\n",
      "21662 Traning Loss: tensor(0.9049)\n",
      "21663 Traning Loss: tensor(0.9047)\n",
      "21664 Traning Loss: tensor(0.9046)\n",
      "21665 Traning Loss: tensor(0.9044)\n",
      "21666 Traning Loss: tensor(0.9043)\n",
      "21667 Traning Loss: tensor(0.9041)\n",
      "21668 Traning Loss: tensor(0.9040)\n",
      "21669 Traning Loss: tensor(0.9038)\n",
      "21670 Traning Loss: tensor(0.9037)\n",
      "21671 Traning Loss: tensor(0.9035)\n",
      "21672 Traning Loss: tensor(0.9034)\n",
      "21673 Traning Loss: tensor(0.9032)\n",
      "21674 Traning Loss: tensor(0.9031)\n",
      "21675 Traning Loss: tensor(0.9029)\n",
      "21676 Traning Loss: tensor(0.9028)\n",
      "21677 Traning Loss: tensor(0.9026)\n",
      "21678 Traning Loss: tensor(0.9025)\n",
      "21679 Traning Loss: tensor(0.9023)\n",
      "21680 Traning Loss: tensor(0.9022)\n",
      "21681 Traning Loss: tensor(0.9020)\n",
      "21682 Traning Loss: tensor(0.9019)\n",
      "21683 Traning Loss: tensor(0.9017)\n",
      "21684 Traning Loss: tensor(0.9016)\n",
      "21685 Traning Loss: tensor(0.9014)\n",
      "21686 Traning Loss: tensor(0.9013)\n",
      "21687 Traning Loss: tensor(0.9011)\n",
      "21688 Traning Loss: tensor(0.9010)\n",
      "21689 Traning Loss: tensor(0.9008)\n",
      "21690 Traning Loss: tensor(0.9007)\n",
      "21691 Traning Loss: tensor(0.9005)\n",
      "21692 Traning Loss: tensor(0.9004)\n",
      "21693 Traning Loss: tensor(0.9002)\n",
      "21694 Traning Loss: tensor(0.9001)\n",
      "21695 Traning Loss: tensor(0.8999)\n",
      "21696 Traning Loss: tensor(0.8998)\n",
      "21697 Traning Loss: tensor(0.8996)\n",
      "21698 Traning Loss: tensor(0.8995)\n",
      "21699 Traning Loss: tensor(0.8994)\n",
      "21700 Traning Loss: tensor(0.8992)\n",
      "21701 Traning Loss: tensor(0.8991)\n",
      "21702 Traning Loss: tensor(0.8989)\n",
      "21703 Traning Loss: tensor(0.8988)\n",
      "21704 Traning Loss: tensor(0.8986)\n",
      "21705 Traning Loss: tensor(0.8985)\n",
      "21706 Traning Loss: tensor(0.8983)\n",
      "21707 Traning Loss: tensor(0.8982)\n",
      "21708 Traning Loss: tensor(0.8981)\n",
      "21709 Traning Loss: tensor(0.8979)\n",
      "21710 Traning Loss: tensor(0.8978)\n",
      "21711 Traning Loss: tensor(0.8976)\n",
      "21712 Traning Loss: tensor(0.8975)\n",
      "21713 Traning Loss: tensor(0.8973)\n",
      "21714 Traning Loss: tensor(0.8972)\n",
      "21715 Traning Loss: tensor(0.8970)\n",
      "21716 Traning Loss: tensor(0.8969)\n",
      "21717 Traning Loss: tensor(0.8968)\n",
      "21718 Traning Loss: tensor(0.8966)\n",
      "21719 Traning Loss: tensor(0.8965)\n",
      "21720 Traning Loss: tensor(0.8963)\n",
      "21721 Traning Loss: tensor(0.8962)\n",
      "21722 Traning Loss: tensor(0.8961)\n",
      "21723 Traning Loss: tensor(0.8959)\n",
      "21724 Traning Loss: tensor(0.8958)\n",
      "21725 Traning Loss: tensor(0.8956)\n",
      "21726 Traning Loss: tensor(0.8955)\n",
      "21727 Traning Loss: tensor(0.8954)\n",
      "21728 Traning Loss: tensor(0.8952)\n",
      "21729 Traning Loss: tensor(0.8951)\n",
      "21730 Traning Loss: tensor(0.8949)\n",
      "21731 Traning Loss: tensor(0.8948)\n",
      "21732 Traning Loss: tensor(0.8947)\n",
      "21733 Traning Loss: tensor(0.8945)\n",
      "21734 Traning Loss: tensor(0.8944)\n",
      "21735 Traning Loss: tensor(0.8942)\n",
      "21736 Traning Loss: tensor(0.8941)\n",
      "21737 Traning Loss: tensor(0.8940)\n",
      "21738 Traning Loss: tensor(0.8938)\n",
      "21739 Traning Loss: tensor(0.8937)\n",
      "21740 Traning Loss: tensor(0.8935)\n",
      "21741 Traning Loss: tensor(0.8934)\n",
      "21742 Traning Loss: tensor(0.8933)\n",
      "21743 Traning Loss: tensor(0.8931)\n",
      "21744 Traning Loss: tensor(0.8930)\n",
      "21745 Traning Loss: tensor(0.8929)\n",
      "21746 Traning Loss: tensor(0.8927)\n",
      "21747 Traning Loss: tensor(0.8926)\n",
      "21748 Traning Loss: tensor(0.8925)\n",
      "21749 Traning Loss: tensor(0.8923)\n",
      "21750 Traning Loss: tensor(0.8922)\n",
      "21751 Traning Loss: tensor(0.8920)\n",
      "21752 Traning Loss: tensor(0.8919)\n",
      "21753 Traning Loss: tensor(0.8918)\n",
      "21754 Traning Loss: tensor(0.8916)\n",
      "21755 Traning Loss: tensor(0.8915)\n",
      "21756 Traning Loss: tensor(0.8914)\n",
      "21757 Traning Loss: tensor(0.8912)\n",
      "21758 Traning Loss: tensor(0.8911)\n",
      "21759 Traning Loss: tensor(0.8910)\n",
      "21760 Traning Loss: tensor(0.8908)\n",
      "21761 Traning Loss: tensor(0.8907)\n",
      "21762 Traning Loss: tensor(0.8906)\n",
      "21763 Traning Loss: tensor(0.8904)\n",
      "21764 Traning Loss: tensor(0.8903)\n",
      "21765 Traning Loss: tensor(0.8902)\n",
      "21766 Traning Loss: tensor(0.8900)\n",
      "21767 Traning Loss: tensor(0.8899)\n",
      "21768 Traning Loss: tensor(0.8898)\n",
      "21769 Traning Loss: tensor(0.8896)\n",
      "21770 Traning Loss: tensor(0.8895)\n",
      "21771 Traning Loss: tensor(0.8894)\n",
      "21772 Traning Loss: tensor(0.8892)\n",
      "21773 Traning Loss: tensor(0.8891)\n",
      "21774 Traning Loss: tensor(0.8890)\n",
      "21775 Traning Loss: tensor(0.8889)\n",
      "21776 Traning Loss: tensor(0.8887)\n",
      "21777 Traning Loss: tensor(0.8886)\n",
      "21778 Traning Loss: tensor(0.8885)\n",
      "21779 Traning Loss: tensor(0.8883)\n",
      "21780 Traning Loss: tensor(0.8882)\n",
      "21781 Traning Loss: tensor(0.8881)\n",
      "21782 Traning Loss: tensor(0.8879)\n",
      "21783 Traning Loss: tensor(0.8878)\n",
      "21784 Traning Loss: tensor(0.8877)\n",
      "21785 Traning Loss: tensor(0.8876)\n",
      "21786 Traning Loss: tensor(0.8874)\n",
      "21787 Traning Loss: tensor(0.8873)\n",
      "21788 Traning Loss: tensor(0.8872)\n",
      "21789 Traning Loss: tensor(0.8870)\n",
      "21790 Traning Loss: tensor(0.8869)\n",
      "21791 Traning Loss: tensor(0.8868)\n",
      "21792 Traning Loss: tensor(0.8867)\n",
      "21793 Traning Loss: tensor(0.8865)\n",
      "21794 Traning Loss: tensor(0.8864)\n",
      "21795 Traning Loss: tensor(0.8863)\n",
      "21796 Traning Loss: tensor(0.8861)\n",
      "21797 Traning Loss: tensor(0.8860)\n",
      "21798 Traning Loss: tensor(0.8859)\n",
      "21799 Traning Loss: tensor(0.8858)\n",
      "21800 Traning Loss: tensor(0.8856)\n",
      "21801 Traning Loss: tensor(0.8855)\n",
      "21802 Traning Loss: tensor(0.8854)\n",
      "21803 Traning Loss: tensor(0.8853)\n",
      "21804 Traning Loss: tensor(0.8851)\n",
      "21805 Traning Loss: tensor(0.8850)\n",
      "21806 Traning Loss: tensor(0.8849)\n",
      "21807 Traning Loss: tensor(0.8848)\n",
      "21808 Traning Loss: tensor(0.8846)\n",
      "21809 Traning Loss: tensor(0.8845)\n",
      "21810 Traning Loss: tensor(0.8844)\n",
      "21811 Traning Loss: tensor(0.8843)\n",
      "21812 Traning Loss: tensor(0.8841)\n",
      "21813 Traning Loss: tensor(0.8840)\n",
      "21814 Traning Loss: tensor(0.8839)\n",
      "21815 Traning Loss: tensor(0.8838)\n",
      "21816 Traning Loss: tensor(0.8836)\n",
      "21817 Traning Loss: tensor(0.8835)\n",
      "21818 Traning Loss: tensor(0.8834)\n",
      "21819 Traning Loss: tensor(0.8833)\n",
      "21820 Traning Loss: tensor(0.8831)\n",
      "21821 Traning Loss: tensor(0.8830)\n",
      "21822 Traning Loss: tensor(0.8829)\n",
      "21823 Traning Loss: tensor(0.8828)\n",
      "21824 Traning Loss: tensor(0.8827)\n",
      "21825 Traning Loss: tensor(0.8825)\n",
      "21826 Traning Loss: tensor(0.8824)\n",
      "21827 Traning Loss: tensor(0.8823)\n",
      "21828 Traning Loss: tensor(0.8822)\n",
      "21829 Traning Loss: tensor(0.8821)\n",
      "21830 Traning Loss: tensor(0.8819)\n",
      "21831 Traning Loss: tensor(0.8818)\n",
      "21832 Traning Loss: tensor(0.8817)\n",
      "21833 Traning Loss: tensor(0.8816)\n",
      "21834 Traning Loss: tensor(0.8814)\n",
      "21835 Traning Loss: tensor(0.8813)\n",
      "21836 Traning Loss: tensor(0.8812)\n",
      "21837 Traning Loss: tensor(0.8811)\n",
      "21838 Traning Loss: tensor(0.8810)\n",
      "21839 Traning Loss: tensor(0.8808)\n",
      "21840 Traning Loss: tensor(0.8807)\n",
      "21841 Traning Loss: tensor(0.8806)\n",
      "21842 Traning Loss: tensor(0.8805)\n",
      "21843 Traning Loss: tensor(0.8804)\n",
      "21844 Traning Loss: tensor(0.8802)\n",
      "21845 Traning Loss: tensor(0.8801)\n",
      "21846 Traning Loss: tensor(0.8800)\n",
      "21847 Traning Loss: tensor(0.8799)\n",
      "21848 Traning Loss: tensor(0.8798)\n",
      "21849 Traning Loss: tensor(0.8797)\n",
      "21850 Traning Loss: tensor(0.8795)\n",
      "21851 Traning Loss: tensor(0.8794)\n",
      "21852 Traning Loss: tensor(0.8793)\n",
      "21853 Traning Loss: tensor(0.8792)\n",
      "21854 Traning Loss: tensor(0.8791)\n",
      "21855 Traning Loss: tensor(0.8790)\n",
      "21856 Traning Loss: tensor(0.8788)\n",
      "21857 Traning Loss: tensor(0.8787)\n",
      "21858 Traning Loss: tensor(0.8786)\n",
      "21859 Traning Loss: tensor(0.8785)\n",
      "21860 Traning Loss: tensor(0.8784)\n",
      "21861 Traning Loss: tensor(0.8783)\n",
      "21862 Traning Loss: tensor(0.8781)\n",
      "21863 Traning Loss: tensor(0.8780)\n",
      "21864 Traning Loss: tensor(0.8779)\n",
      "21865 Traning Loss: tensor(0.8778)\n",
      "21866 Traning Loss: tensor(0.8777)\n",
      "21867 Traning Loss: tensor(0.8776)\n",
      "21868 Traning Loss: tensor(0.8774)\n",
      "21869 Traning Loss: tensor(0.8773)\n",
      "21870 Traning Loss: tensor(0.8772)\n",
      "21871 Traning Loss: tensor(0.8771)\n",
      "21872 Traning Loss: tensor(0.8770)\n",
      "21873 Traning Loss: tensor(0.8769)\n",
      "21874 Traning Loss: tensor(0.8768)\n",
      "21875 Traning Loss: tensor(0.8766)\n",
      "21876 Traning Loss: tensor(0.8765)\n",
      "21877 Traning Loss: tensor(0.8764)\n",
      "21878 Traning Loss: tensor(0.8763)\n",
      "21879 Traning Loss: tensor(0.8762)\n",
      "21880 Traning Loss: tensor(0.8761)\n",
      "21881 Traning Loss: tensor(0.8760)\n",
      "21882 Traning Loss: tensor(0.8758)\n",
      "21883 Traning Loss: tensor(0.8757)\n",
      "21884 Traning Loss: tensor(0.8756)\n",
      "21885 Traning Loss: tensor(0.8755)\n",
      "21886 Traning Loss: tensor(0.8754)\n",
      "21887 Traning Loss: tensor(0.8753)\n",
      "21888 Traning Loss: tensor(0.8752)\n",
      "21889 Traning Loss: tensor(0.8751)\n",
      "21890 Traning Loss: tensor(0.8749)\n",
      "21891 Traning Loss: tensor(0.8748)\n",
      "21892 Traning Loss: tensor(0.8747)\n",
      "21893 Traning Loss: tensor(0.8746)\n",
      "21894 Traning Loss: tensor(0.8745)\n",
      "21895 Traning Loss: tensor(0.8744)\n",
      "21896 Traning Loss: tensor(0.8743)\n",
      "21897 Traning Loss: tensor(0.8742)\n",
      "21898 Traning Loss: tensor(0.8741)\n",
      "21899 Traning Loss: tensor(0.8739)\n",
      "21900 Traning Loss: tensor(0.8738)\n",
      "21901 Traning Loss: tensor(0.8737)\n",
      "21902 Traning Loss: tensor(0.8736)\n",
      "21903 Traning Loss: tensor(0.8735)\n",
      "21904 Traning Loss: tensor(0.8734)\n",
      "21905 Traning Loss: tensor(0.8733)\n",
      "21906 Traning Loss: tensor(0.8732)\n",
      "21907 Traning Loss: tensor(0.8731)\n",
      "21908 Traning Loss: tensor(0.8730)\n",
      "21909 Traning Loss: tensor(0.8728)\n",
      "21910 Traning Loss: tensor(0.8727)\n",
      "21911 Traning Loss: tensor(0.8726)\n",
      "21912 Traning Loss: tensor(0.8725)\n",
      "21913 Traning Loss: tensor(0.8724)\n",
      "21914 Traning Loss: tensor(0.8723)\n",
      "21915 Traning Loss: tensor(0.8722)\n",
      "21916 Traning Loss: tensor(0.8721)\n",
      "21917 Traning Loss: tensor(0.8720)\n",
      "21918 Traning Loss: tensor(0.8719)\n",
      "21919 Traning Loss: tensor(0.8718)\n",
      "21920 Traning Loss: tensor(0.8717)\n",
      "21921 Traning Loss: tensor(0.8715)\n",
      "21922 Traning Loss: tensor(0.8714)\n",
      "21923 Traning Loss: tensor(0.8713)\n",
      "21924 Traning Loss: tensor(0.8712)\n",
      "21925 Traning Loss: tensor(0.8711)\n",
      "21926 Traning Loss: tensor(0.8710)\n",
      "21927 Traning Loss: tensor(0.8709)\n",
      "21928 Traning Loss: tensor(0.8708)\n",
      "21929 Traning Loss: tensor(0.8707)\n",
      "21930 Traning Loss: tensor(0.8706)\n",
      "21931 Traning Loss: tensor(0.8705)\n",
      "21932 Traning Loss: tensor(0.8704)\n",
      "21933 Traning Loss: tensor(0.8703)\n",
      "21934 Traning Loss: tensor(0.8702)\n",
      "21935 Traning Loss: tensor(0.8701)\n",
      "21936 Traning Loss: tensor(0.8700)\n",
      "21937 Traning Loss: tensor(0.8698)\n",
      "21938 Traning Loss: tensor(0.8697)\n",
      "21939 Traning Loss: tensor(0.8696)\n",
      "21940 Traning Loss: tensor(0.8695)\n",
      "21941 Traning Loss: tensor(0.8694)\n",
      "21942 Traning Loss: tensor(0.8693)\n",
      "21943 Traning Loss: tensor(0.8692)\n",
      "21944 Traning Loss: tensor(0.8691)\n",
      "21945 Traning Loss: tensor(0.8690)\n",
      "21946 Traning Loss: tensor(0.8689)\n",
      "21947 Traning Loss: tensor(0.8688)\n",
      "21948 Traning Loss: tensor(0.8687)\n",
      "21949 Traning Loss: tensor(0.8686)\n",
      "21950 Traning Loss: tensor(0.8685)\n",
      "21951 Traning Loss: tensor(0.8684)\n",
      "21952 Traning Loss: tensor(0.8683)\n",
      "21953 Traning Loss: tensor(0.8682)\n",
      "21954 Traning Loss: tensor(0.8681)\n",
      "21955 Traning Loss: tensor(0.8680)\n",
      "21956 Traning Loss: tensor(0.8679)\n",
      "21957 Traning Loss: tensor(0.8678)\n",
      "21958 Traning Loss: tensor(0.8677)\n",
      "21959 Traning Loss: tensor(0.8676)\n",
      "21960 Traning Loss: tensor(0.8675)\n",
      "21961 Traning Loss: tensor(0.8674)\n",
      "21962 Traning Loss: tensor(0.8673)\n",
      "21963 Traning Loss: tensor(0.8672)\n",
      "21964 Traning Loss: tensor(0.8671)\n",
      "21965 Traning Loss: tensor(0.8670)\n",
      "21966 Traning Loss: tensor(0.8669)\n",
      "21967 Traning Loss: tensor(0.8668)\n",
      "21968 Traning Loss: tensor(0.8667)\n",
      "21969 Traning Loss: tensor(0.8666)\n",
      "21970 Traning Loss: tensor(0.8665)\n",
      "21971 Traning Loss: tensor(0.8664)\n",
      "21972 Traning Loss: tensor(0.8663)\n",
      "21973 Traning Loss: tensor(0.8662)\n",
      "21974 Traning Loss: tensor(0.8661)\n",
      "21975 Traning Loss: tensor(0.8660)\n",
      "21976 Traning Loss: tensor(0.8659)\n",
      "21977 Traning Loss: tensor(0.8658)\n",
      "21978 Traning Loss: tensor(0.8657)\n",
      "21979 Traning Loss: tensor(0.8656)\n",
      "21980 Traning Loss: tensor(0.8655)\n",
      "21981 Traning Loss: tensor(0.8654)\n",
      "21982 Traning Loss: tensor(0.8653)\n",
      "21983 Traning Loss: tensor(0.8652)\n",
      "21984 Traning Loss: tensor(0.8651)\n",
      "21985 Traning Loss: tensor(0.8650)\n",
      "21986 Traning Loss: tensor(0.8649)\n",
      "21987 Traning Loss: tensor(0.8648)\n",
      "21988 Traning Loss: tensor(0.8647)\n",
      "21989 Traning Loss: tensor(0.8646)\n",
      "21990 Traning Loss: tensor(0.8645)\n",
      "21991 Traning Loss: tensor(0.8644)\n",
      "21992 Traning Loss: tensor(0.8643)\n",
      "21993 Traning Loss: tensor(0.8642)\n",
      "21994 Traning Loss: tensor(0.8641)\n",
      "21995 Traning Loss: tensor(0.8640)\n",
      "21996 Traning Loss: tensor(0.8639)\n",
      "21997 Traning Loss: tensor(0.8638)\n",
      "21998 Traning Loss: tensor(0.8637)\n",
      "21999 Traning Loss: tensor(0.8636)\n",
      "22000 Traning Loss: tensor(0.8635)\n",
      "22001 Traning Loss: tensor(0.8634)\n",
      "22002 Traning Loss: tensor(0.8633)\n",
      "22003 Traning Loss: tensor(0.8632)\n",
      "22004 Traning Loss: tensor(0.8631)\n",
      "22005 Traning Loss: tensor(0.8630)\n",
      "22006 Traning Loss: tensor(0.8629)\n",
      "22007 Traning Loss: tensor(0.8628)\n",
      "22008 Traning Loss: tensor(0.8627)\n",
      "22009 Traning Loss: tensor(0.8626)\n",
      "22010 Traning Loss: tensor(0.8625)\n",
      "22011 Traning Loss: tensor(0.8624)\n",
      "22012 Traning Loss: tensor(0.8623)\n",
      "22013 Traning Loss: tensor(0.8622)\n",
      "22014 Traning Loss: tensor(0.8621)\n",
      "22015 Traning Loss: tensor(0.8621)\n",
      "22016 Traning Loss: tensor(0.8620)\n",
      "22017 Traning Loss: tensor(0.8619)\n",
      "22018 Traning Loss: tensor(0.8618)\n",
      "22019 Traning Loss: tensor(0.8617)\n",
      "22020 Traning Loss: tensor(0.8616)\n",
      "22021 Traning Loss: tensor(0.8615)\n",
      "22022 Traning Loss: tensor(0.8614)\n",
      "22023 Traning Loss: tensor(0.8613)\n",
      "22024 Traning Loss: tensor(0.8612)\n",
      "22025 Traning Loss: tensor(0.8611)\n",
      "22026 Traning Loss: tensor(0.8610)\n",
      "22027 Traning Loss: tensor(0.8609)\n",
      "22028 Traning Loss: tensor(0.8608)\n",
      "22029 Traning Loss: tensor(0.8607)\n",
      "22030 Traning Loss: tensor(0.8606)\n",
      "22031 Traning Loss: tensor(0.8605)\n",
      "22032 Traning Loss: tensor(0.8605)\n",
      "22033 Traning Loss: tensor(0.8604)\n",
      "22034 Traning Loss: tensor(0.8603)\n",
      "22035 Traning Loss: tensor(0.8602)\n",
      "22036 Traning Loss: tensor(0.8601)\n",
      "22037 Traning Loss: tensor(0.8600)\n",
      "22038 Traning Loss: tensor(0.8599)\n",
      "22039 Traning Loss: tensor(0.8598)\n",
      "22040 Traning Loss: tensor(0.8597)\n",
      "22041 Traning Loss: tensor(0.8596)\n",
      "22042 Traning Loss: tensor(0.8595)\n",
      "22043 Traning Loss: tensor(0.8594)\n",
      "22044 Traning Loss: tensor(0.8593)\n",
      "22045 Traning Loss: tensor(0.8593)\n",
      "22046 Traning Loss: tensor(0.8592)\n",
      "22047 Traning Loss: tensor(0.8591)\n",
      "22048 Traning Loss: tensor(0.8590)\n",
      "22049 Traning Loss: tensor(0.8589)\n",
      "22050 Traning Loss: tensor(0.8588)\n",
      "22051 Traning Loss: tensor(0.8587)\n",
      "22052 Traning Loss: tensor(0.8586)\n",
      "22053 Traning Loss: tensor(0.8585)\n",
      "22054 Traning Loss: tensor(0.8584)\n",
      "22055 Traning Loss: tensor(0.8583)\n",
      "22056 Traning Loss: tensor(0.8583)\n",
      "22057 Traning Loss: tensor(0.8582)\n",
      "22058 Traning Loss: tensor(0.8581)\n",
      "22059 Traning Loss: tensor(0.8580)\n",
      "22060 Traning Loss: tensor(0.8579)\n",
      "22061 Traning Loss: tensor(0.8578)\n",
      "22062 Traning Loss: tensor(0.8577)\n",
      "22063 Traning Loss: tensor(0.8576)\n",
      "22064 Traning Loss: tensor(0.8575)\n",
      "22065 Traning Loss: tensor(0.8574)\n",
      "22066 Traning Loss: tensor(0.8574)\n",
      "22067 Traning Loss: tensor(0.8573)\n",
      "22068 Traning Loss: tensor(0.8572)\n",
      "22069 Traning Loss: tensor(0.8571)\n",
      "22070 Traning Loss: tensor(0.8570)\n",
      "22071 Traning Loss: tensor(0.8569)\n",
      "22072 Traning Loss: tensor(0.8568)\n",
      "22073 Traning Loss: tensor(0.8567)\n",
      "22074 Traning Loss: tensor(0.8566)\n",
      "22075 Traning Loss: tensor(0.8566)\n",
      "22076 Traning Loss: tensor(0.8565)\n",
      "22077 Traning Loss: tensor(0.8564)\n",
      "22078 Traning Loss: tensor(0.8563)\n",
      "22079 Traning Loss: tensor(0.8562)\n",
      "22080 Traning Loss: tensor(0.8561)\n",
      "22081 Traning Loss: tensor(0.8560)\n",
      "22082 Traning Loss: tensor(0.8559)\n",
      "22083 Traning Loss: tensor(0.8559)\n",
      "22084 Traning Loss: tensor(0.8558)\n",
      "22085 Traning Loss: tensor(0.8557)\n",
      "22086 Traning Loss: tensor(0.8556)\n",
      "22087 Traning Loss: tensor(0.8555)\n",
      "22088 Traning Loss: tensor(0.8554)\n",
      "22089 Traning Loss: tensor(0.8553)\n",
      "22090 Traning Loss: tensor(0.8552)\n",
      "22091 Traning Loss: tensor(0.8552)\n",
      "22092 Traning Loss: tensor(0.8551)\n",
      "22093 Traning Loss: tensor(0.8550)\n",
      "22094 Traning Loss: tensor(0.8549)\n",
      "22095 Traning Loss: tensor(0.8548)\n",
      "22096 Traning Loss: tensor(0.8547)\n",
      "22097 Traning Loss: tensor(0.8546)\n",
      "22098 Traning Loss: tensor(0.8546)\n",
      "22099 Traning Loss: tensor(0.8545)\n",
      "22100 Traning Loss: tensor(0.8544)\n",
      "22101 Traning Loss: tensor(0.8543)\n",
      "22102 Traning Loss: tensor(0.8542)\n",
      "22103 Traning Loss: tensor(0.8541)\n",
      "22104 Traning Loss: tensor(0.8540)\n",
      "22105 Traning Loss: tensor(0.8540)\n",
      "22106 Traning Loss: tensor(0.8539)\n",
      "22107 Traning Loss: tensor(0.8538)\n",
      "22108 Traning Loss: tensor(0.8537)\n",
      "22109 Traning Loss: tensor(0.8536)\n",
      "22110 Traning Loss: tensor(0.8535)\n",
      "22111 Traning Loss: tensor(0.8535)\n",
      "22112 Traning Loss: tensor(0.8534)\n",
      "22113 Traning Loss: tensor(0.8533)\n",
      "22114 Traning Loss: tensor(0.8532)\n",
      "22115 Traning Loss: tensor(0.8531)\n",
      "22116 Traning Loss: tensor(0.8530)\n",
      "22117 Traning Loss: tensor(0.8530)\n",
      "22118 Traning Loss: tensor(0.8529)\n",
      "22119 Traning Loss: tensor(0.8528)\n",
      "22120 Traning Loss: tensor(0.8527)\n",
      "22121 Traning Loss: tensor(0.8526)\n",
      "22122 Traning Loss: tensor(0.8525)\n",
      "22123 Traning Loss: tensor(0.8525)\n",
      "22124 Traning Loss: tensor(0.8524)\n",
      "22125 Traning Loss: tensor(0.8523)\n",
      "22126 Traning Loss: tensor(0.8522)\n",
      "22127 Traning Loss: tensor(0.8521)\n",
      "22128 Traning Loss: tensor(0.8520)\n",
      "22129 Traning Loss: tensor(0.8520)\n",
      "22130 Traning Loss: tensor(0.8519)\n",
      "22131 Traning Loss: tensor(0.8518)\n",
      "22132 Traning Loss: tensor(0.8517)\n",
      "22133 Traning Loss: tensor(0.8516)\n",
      "22134 Traning Loss: tensor(0.8515)\n",
      "22135 Traning Loss: tensor(0.8515)\n",
      "22136 Traning Loss: tensor(0.8514)\n",
      "22137 Traning Loss: tensor(0.8513)\n",
      "22138 Traning Loss: tensor(0.8512)\n",
      "22139 Traning Loss: tensor(0.8511)\n",
      "22140 Traning Loss: tensor(0.8511)\n",
      "22141 Traning Loss: tensor(0.8510)\n",
      "22142 Traning Loss: tensor(0.8509)\n",
      "22143 Traning Loss: tensor(0.8508)\n",
      "22144 Traning Loss: tensor(0.8507)\n",
      "22145 Traning Loss: tensor(0.8506)\n",
      "22146 Traning Loss: tensor(0.8506)\n",
      "22147 Traning Loss: tensor(0.8505)\n",
      "22148 Traning Loss: tensor(0.8504)\n",
      "22149 Traning Loss: tensor(0.8503)\n",
      "22150 Traning Loss: tensor(0.8502)\n",
      "22151 Traning Loss: tensor(0.8502)\n",
      "22152 Traning Loss: tensor(0.8501)\n",
      "22153 Traning Loss: tensor(0.8500)\n",
      "22154 Traning Loss: tensor(0.8499)\n",
      "22155 Traning Loss: tensor(0.8498)\n",
      "22156 Traning Loss: tensor(0.8498)\n",
      "22157 Traning Loss: tensor(0.8497)\n",
      "22158 Traning Loss: tensor(0.8496)\n",
      "22159 Traning Loss: tensor(0.8495)\n",
      "22160 Traning Loss: tensor(0.8494)\n",
      "22161 Traning Loss: tensor(0.8494)\n",
      "22162 Traning Loss: tensor(0.8493)\n",
      "22163 Traning Loss: tensor(0.8492)\n",
      "22164 Traning Loss: tensor(0.8491)\n",
      "22165 Traning Loss: tensor(0.8490)\n",
      "22166 Traning Loss: tensor(0.8490)\n",
      "22167 Traning Loss: tensor(0.8489)\n",
      "22168 Traning Loss: tensor(0.8488)\n",
      "22169 Traning Loss: tensor(0.8487)\n",
      "22170 Traning Loss: tensor(0.8487)\n",
      "22171 Traning Loss: tensor(0.8486)\n",
      "22172 Traning Loss: tensor(0.8485)\n",
      "22173 Traning Loss: tensor(0.8484)\n",
      "22174 Traning Loss: tensor(0.8483)\n",
      "22175 Traning Loss: tensor(0.8483)\n",
      "22176 Traning Loss: tensor(0.8482)\n",
      "22177 Traning Loss: tensor(0.8481)\n",
      "22178 Traning Loss: tensor(0.8480)\n",
      "22179 Traning Loss: tensor(0.8480)\n",
      "22180 Traning Loss: tensor(0.8479)\n",
      "22181 Traning Loss: tensor(0.8478)\n",
      "22182 Traning Loss: tensor(0.8477)\n",
      "22183 Traning Loss: tensor(0.8476)\n",
      "22184 Traning Loss: tensor(0.8476)\n",
      "22185 Traning Loss: tensor(0.8475)\n",
      "22186 Traning Loss: tensor(0.8474)\n",
      "22187 Traning Loss: tensor(0.8473)\n",
      "22188 Traning Loss: tensor(0.8473)\n",
      "22189 Traning Loss: tensor(0.8472)\n",
      "22190 Traning Loss: tensor(0.8471)\n",
      "22191 Traning Loss: tensor(0.8470)\n",
      "22192 Traning Loss: tensor(0.8470)\n",
      "22193 Traning Loss: tensor(0.8469)\n",
      "22194 Traning Loss: tensor(0.8468)\n",
      "22195 Traning Loss: tensor(0.8467)\n",
      "22196 Traning Loss: tensor(0.8466)\n",
      "22197 Traning Loss: tensor(0.8466)\n",
      "22198 Traning Loss: tensor(0.8465)\n",
      "22199 Traning Loss: tensor(0.8464)\n",
      "22200 Traning Loss: tensor(0.8463)\n",
      "22201 Traning Loss: tensor(0.8463)\n",
      "22202 Traning Loss: tensor(0.8462)\n",
      "22203 Traning Loss: tensor(0.8461)\n",
      "22204 Traning Loss: tensor(0.8460)\n",
      "22205 Traning Loss: tensor(0.8460)\n",
      "22206 Traning Loss: tensor(0.8459)\n",
      "22207 Traning Loss: tensor(0.8458)\n",
      "22208 Traning Loss: tensor(0.8457)\n",
      "22209 Traning Loss: tensor(0.8457)\n",
      "22210 Traning Loss: tensor(0.8456)\n",
      "22211 Traning Loss: tensor(0.8455)\n",
      "22212 Traning Loss: tensor(0.8454)\n",
      "22213 Traning Loss: tensor(0.8454)\n",
      "22214 Traning Loss: tensor(0.8453)\n",
      "22215 Traning Loss: tensor(0.8452)\n",
      "22216 Traning Loss: tensor(0.8451)\n",
      "22217 Traning Loss: tensor(0.8451)\n",
      "22218 Traning Loss: tensor(0.8450)\n",
      "22219 Traning Loss: tensor(0.8449)\n",
      "22220 Traning Loss: tensor(0.8448)\n",
      "22221 Traning Loss: tensor(0.8448)\n",
      "22222 Traning Loss: tensor(0.8447)\n",
      "22223 Traning Loss: tensor(0.8446)\n",
      "22224 Traning Loss: tensor(0.8446)\n",
      "22225 Traning Loss: tensor(0.8445)\n",
      "22226 Traning Loss: tensor(0.8444)\n",
      "22227 Traning Loss: tensor(0.8443)\n",
      "22228 Traning Loss: tensor(0.8443)\n",
      "22229 Traning Loss: tensor(0.8442)\n",
      "22230 Traning Loss: tensor(0.8441)\n",
      "22231 Traning Loss: tensor(0.8440)\n",
      "22232 Traning Loss: tensor(0.8440)\n",
      "22233 Traning Loss: tensor(0.8439)\n",
      "22234 Traning Loss: tensor(0.8438)\n",
      "22235 Traning Loss: tensor(0.8438)\n",
      "22236 Traning Loss: tensor(0.8437)\n",
      "22237 Traning Loss: tensor(0.8436)\n",
      "22238 Traning Loss: tensor(0.8435)\n",
      "22239 Traning Loss: tensor(0.8435)\n",
      "22240 Traning Loss: tensor(0.8434)\n",
      "22241 Traning Loss: tensor(0.8433)\n",
      "22242 Traning Loss: tensor(0.8432)\n",
      "22243 Traning Loss: tensor(0.8432)\n",
      "22244 Traning Loss: tensor(0.8431)\n",
      "22245 Traning Loss: tensor(0.8430)\n",
      "22246 Traning Loss: tensor(0.8430)\n",
      "22247 Traning Loss: tensor(0.8429)\n",
      "22248 Traning Loss: tensor(0.8428)\n",
      "22249 Traning Loss: tensor(0.8427)\n",
      "22250 Traning Loss: tensor(0.8427)\n",
      "22251 Traning Loss: tensor(0.8426)\n",
      "22252 Traning Loss: tensor(0.8425)\n",
      "22253 Traning Loss: tensor(0.8425)\n",
      "22254 Traning Loss: tensor(0.8424)\n",
      "22255 Traning Loss: tensor(0.8423)\n",
      "22256 Traning Loss: tensor(0.8422)\n",
      "22257 Traning Loss: tensor(0.8422)\n",
      "22258 Traning Loss: tensor(0.8421)\n",
      "22259 Traning Loss: tensor(0.8420)\n",
      "22260 Traning Loss: tensor(0.8420)\n",
      "22261 Traning Loss: tensor(0.8419)\n",
      "22262 Traning Loss: tensor(0.8418)\n",
      "22263 Traning Loss: tensor(0.8418)\n",
      "22264 Traning Loss: tensor(0.8417)\n",
      "22265 Traning Loss: tensor(0.8416)\n",
      "22266 Traning Loss: tensor(0.8415)\n",
      "22267 Traning Loss: tensor(0.8415)\n",
      "22268 Traning Loss: tensor(0.8414)\n",
      "22269 Traning Loss: tensor(0.8413)\n",
      "22270 Traning Loss: tensor(0.8413)\n",
      "22271 Traning Loss: tensor(0.8412)\n",
      "22272 Traning Loss: tensor(0.8411)\n",
      "22273 Traning Loss: tensor(0.8411)\n",
      "22274 Traning Loss: tensor(0.8410)\n",
      "22275 Traning Loss: tensor(0.8409)\n",
      "22276 Traning Loss: tensor(0.8408)\n",
      "22277 Traning Loss: tensor(0.8408)\n",
      "22278 Traning Loss: tensor(0.8407)\n",
      "22279 Traning Loss: tensor(0.8406)\n",
      "22280 Traning Loss: tensor(0.8406)\n",
      "22281 Traning Loss: tensor(0.8405)\n",
      "22282 Traning Loss: tensor(0.8404)\n",
      "22283 Traning Loss: tensor(0.8404)\n",
      "22284 Traning Loss: tensor(0.8403)\n",
      "22285 Traning Loss: tensor(0.8402)\n",
      "22286 Traning Loss: tensor(0.8402)\n",
      "22287 Traning Loss: tensor(0.8401)\n",
      "22288 Traning Loss: tensor(0.8400)\n",
      "22289 Traning Loss: tensor(0.8400)\n",
      "22290 Traning Loss: tensor(0.8399)\n",
      "22291 Traning Loss: tensor(0.8398)\n",
      "22292 Traning Loss: tensor(0.8398)\n",
      "22293 Traning Loss: tensor(0.8397)\n",
      "22294 Traning Loss: tensor(0.8396)\n",
      "22295 Traning Loss: tensor(0.8395)\n",
      "22296 Traning Loss: tensor(0.8395)\n",
      "22297 Traning Loss: tensor(0.8394)\n",
      "22298 Traning Loss: tensor(0.8393)\n",
      "22299 Traning Loss: tensor(0.8393)\n",
      "22300 Traning Loss: tensor(0.8392)\n",
      "22301 Traning Loss: tensor(0.8391)\n",
      "22302 Traning Loss: tensor(0.8391)\n",
      "22303 Traning Loss: tensor(0.8390)\n",
      "22304 Traning Loss: tensor(0.8389)\n",
      "22305 Traning Loss: tensor(0.8389)\n",
      "22306 Traning Loss: tensor(0.8388)\n",
      "22307 Traning Loss: tensor(0.8387)\n",
      "22308 Traning Loss: tensor(0.8387)\n",
      "22309 Traning Loss: tensor(0.8386)\n",
      "22310 Traning Loss: tensor(0.8385)\n",
      "22311 Traning Loss: tensor(0.8385)\n",
      "22312 Traning Loss: tensor(0.8384)\n",
      "22313 Traning Loss: tensor(0.8383)\n",
      "22314 Traning Loss: tensor(0.8383)\n",
      "22315 Traning Loss: tensor(0.8382)\n",
      "22316 Traning Loss: tensor(0.8381)\n",
      "22317 Traning Loss: tensor(0.8381)\n",
      "22318 Traning Loss: tensor(0.8380)\n",
      "22319 Traning Loss: tensor(0.8379)\n",
      "22320 Traning Loss: tensor(0.8379)\n",
      "22321 Traning Loss: tensor(0.8378)\n",
      "22322 Traning Loss: tensor(0.8378)\n",
      "22323 Traning Loss: tensor(0.8377)\n",
      "22324 Traning Loss: tensor(0.8376)\n",
      "22325 Traning Loss: tensor(0.8376)\n",
      "22326 Traning Loss: tensor(0.8375)\n",
      "22327 Traning Loss: tensor(0.8374)\n",
      "22328 Traning Loss: tensor(0.8374)\n",
      "22329 Traning Loss: tensor(0.8373)\n",
      "22330 Traning Loss: tensor(0.8372)\n",
      "22331 Traning Loss: tensor(0.8372)\n",
      "22332 Traning Loss: tensor(0.8371)\n",
      "22333 Traning Loss: tensor(0.8370)\n",
      "22334 Traning Loss: tensor(0.8370)\n",
      "22335 Traning Loss: tensor(0.8369)\n",
      "22336 Traning Loss: tensor(0.8368)\n",
      "22337 Traning Loss: tensor(0.8368)\n",
      "22338 Traning Loss: tensor(0.8367)\n",
      "22339 Traning Loss: tensor(0.8366)\n",
      "22340 Traning Loss: tensor(0.8366)\n",
      "22341 Traning Loss: tensor(0.8365)\n",
      "22342 Traning Loss: tensor(0.8365)\n",
      "22343 Traning Loss: tensor(0.8364)\n",
      "22344 Traning Loss: tensor(0.8363)\n",
      "22345 Traning Loss: tensor(0.8363)\n",
      "22346 Traning Loss: tensor(0.8362)\n",
      "22347 Traning Loss: tensor(0.8361)\n",
      "22348 Traning Loss: tensor(0.8361)\n",
      "22349 Traning Loss: tensor(0.8360)\n",
      "22350 Traning Loss: tensor(0.8359)\n",
      "22351 Traning Loss: tensor(0.8359)\n",
      "22352 Traning Loss: tensor(0.8358)\n",
      "22353 Traning Loss: tensor(0.8358)\n",
      "22354 Traning Loss: tensor(0.8357)\n",
      "22355 Traning Loss: tensor(0.8356)\n",
      "22356 Traning Loss: tensor(0.8356)\n",
      "22357 Traning Loss: tensor(0.8355)\n",
      "22358 Traning Loss: tensor(0.8354)\n",
      "22359 Traning Loss: tensor(0.8354)\n",
      "22360 Traning Loss: tensor(0.8353)\n",
      "22361 Traning Loss: tensor(0.8353)\n",
      "22362 Traning Loss: tensor(0.8352)\n",
      "22363 Traning Loss: tensor(0.8351)\n",
      "22364 Traning Loss: tensor(0.8351)\n",
      "22365 Traning Loss: tensor(0.8350)\n",
      "22366 Traning Loss: tensor(0.8349)\n",
      "22367 Traning Loss: tensor(0.8349)\n",
      "22368 Traning Loss: tensor(0.8348)\n",
      "22369 Traning Loss: tensor(0.8348)\n",
      "22370 Traning Loss: tensor(0.8347)\n",
      "22371 Traning Loss: tensor(0.8346)\n",
      "22372 Traning Loss: tensor(0.8346)\n",
      "22373 Traning Loss: tensor(0.8345)\n",
      "22374 Traning Loss: tensor(0.8344)\n",
      "22375 Traning Loss: tensor(0.8344)\n",
      "22376 Traning Loss: tensor(0.8343)\n",
      "22377 Traning Loss: tensor(0.8343)\n",
      "22378 Traning Loss: tensor(0.8342)\n",
      "22379 Traning Loss: tensor(0.8341)\n",
      "22380 Traning Loss: tensor(0.8341)\n",
      "22381 Traning Loss: tensor(0.8340)\n",
      "22382 Traning Loss: tensor(0.8340)\n",
      "22383 Traning Loss: tensor(0.8339)\n",
      "22384 Traning Loss: tensor(0.8338)\n",
      "22385 Traning Loss: tensor(0.8338)\n",
      "22386 Traning Loss: tensor(0.8337)\n",
      "22387 Traning Loss: tensor(0.8336)\n",
      "22388 Traning Loss: tensor(0.8336)\n",
      "22389 Traning Loss: tensor(0.8335)\n",
      "22390 Traning Loss: tensor(0.8335)\n",
      "22391 Traning Loss: tensor(0.8334)\n",
      "22392 Traning Loss: tensor(0.8333)\n",
      "22393 Traning Loss: tensor(0.8333)\n",
      "22394 Traning Loss: tensor(0.8332)\n",
      "22395 Traning Loss: tensor(0.8332)\n",
      "22396 Traning Loss: tensor(0.8331)\n",
      "22397 Traning Loss: tensor(0.8330)\n",
      "22398 Traning Loss: tensor(0.8330)\n",
      "22399 Traning Loss: tensor(0.8329)\n",
      "22400 Traning Loss: tensor(0.8329)\n",
      "22401 Traning Loss: tensor(0.8328)\n",
      "22402 Traning Loss: tensor(0.8327)\n",
      "22403 Traning Loss: tensor(0.8327)\n",
      "22404 Traning Loss: tensor(0.8326)\n",
      "22405 Traning Loss: tensor(0.8326)\n",
      "22406 Traning Loss: tensor(0.8325)\n",
      "22407 Traning Loss: tensor(0.8324)\n",
      "22408 Traning Loss: tensor(0.8324)\n",
      "22409 Traning Loss: tensor(0.8323)\n",
      "22410 Traning Loss: tensor(0.8323)\n",
      "22411 Traning Loss: tensor(0.8322)\n",
      "22412 Traning Loss: tensor(0.8322)\n",
      "22413 Traning Loss: tensor(0.8321)\n",
      "22414 Traning Loss: tensor(0.8320)\n",
      "22415 Traning Loss: tensor(0.8320)\n",
      "22416 Traning Loss: tensor(0.8319)\n",
      "22417 Traning Loss: tensor(0.8319)\n",
      "22418 Traning Loss: tensor(0.8318)\n",
      "22419 Traning Loss: tensor(0.8317)\n",
      "22420 Traning Loss: tensor(0.8317)\n",
      "22421 Traning Loss: tensor(0.8316)\n",
      "22422 Traning Loss: tensor(0.8316)\n",
      "22423 Traning Loss: tensor(0.8315)\n",
      "22424 Traning Loss: tensor(0.8314)\n",
      "22425 Traning Loss: tensor(0.8314)\n",
      "22426 Traning Loss: tensor(0.8313)\n",
      "22427 Traning Loss: tensor(0.8313)\n",
      "22428 Traning Loss: tensor(0.8312)\n",
      "22429 Traning Loss: tensor(0.8312)\n",
      "22430 Traning Loss: tensor(0.8311)\n",
      "22431 Traning Loss: tensor(0.8310)\n",
      "22432 Traning Loss: tensor(0.8310)\n",
      "22433 Traning Loss: tensor(0.8309)\n",
      "22434 Traning Loss: tensor(0.8309)\n",
      "22435 Traning Loss: tensor(0.8308)\n",
      "22436 Traning Loss: tensor(0.8308)\n",
      "22437 Traning Loss: tensor(0.8307)\n",
      "22438 Traning Loss: tensor(0.8306)\n",
      "22439 Traning Loss: tensor(0.8306)\n",
      "22440 Traning Loss: tensor(0.8305)\n",
      "22441 Traning Loss: tensor(0.8305)\n",
      "22442 Traning Loss: tensor(0.8304)\n",
      "22443 Traning Loss: tensor(0.8304)\n",
      "22444 Traning Loss: tensor(0.8303)\n",
      "22445 Traning Loss: tensor(0.8302)\n",
      "22446 Traning Loss: tensor(0.8302)\n",
      "22447 Traning Loss: tensor(0.8301)\n",
      "22448 Traning Loss: tensor(0.8301)\n",
      "22449 Traning Loss: tensor(0.8300)\n",
      "22450 Traning Loss: tensor(0.8300)\n",
      "22451 Traning Loss: tensor(0.8299)\n",
      "22452 Traning Loss: tensor(0.8298)\n",
      "22453 Traning Loss: tensor(0.8298)\n",
      "22454 Traning Loss: tensor(0.8297)\n",
      "22455 Traning Loss: tensor(0.8297)\n",
      "22456 Traning Loss: tensor(0.8296)\n",
      "22457 Traning Loss: tensor(0.8296)\n",
      "22458 Traning Loss: tensor(0.8295)\n",
      "22459 Traning Loss: tensor(0.8294)\n",
      "22460 Traning Loss: tensor(0.8294)\n",
      "22461 Traning Loss: tensor(0.8293)\n",
      "22462 Traning Loss: tensor(0.8293)\n",
      "22463 Traning Loss: tensor(0.8292)\n",
      "22464 Traning Loss: tensor(0.8292)\n",
      "22465 Traning Loss: tensor(0.8291)\n",
      "22466 Traning Loss: tensor(0.8291)\n",
      "22467 Traning Loss: tensor(0.8290)\n",
      "22468 Traning Loss: tensor(0.8289)\n",
      "22469 Traning Loss: tensor(0.8289)\n",
      "22470 Traning Loss: tensor(0.8288)\n",
      "22471 Traning Loss: tensor(0.8288)\n",
      "22472 Traning Loss: tensor(0.8287)\n",
      "22473 Traning Loss: tensor(0.8287)\n",
      "22474 Traning Loss: tensor(0.8286)\n",
      "22475 Traning Loss: tensor(0.8286)\n",
      "22476 Traning Loss: tensor(0.8285)\n",
      "22477 Traning Loss: tensor(0.8284)\n",
      "22478 Traning Loss: tensor(0.8284)\n",
      "22479 Traning Loss: tensor(0.8283)\n",
      "22480 Traning Loss: tensor(0.8283)\n",
      "22481 Traning Loss: tensor(0.8282)\n",
      "22482 Traning Loss: tensor(0.8282)\n",
      "22483 Traning Loss: tensor(0.8281)\n",
      "22484 Traning Loss: tensor(0.8281)\n",
      "22485 Traning Loss: tensor(0.8280)\n",
      "22486 Traning Loss: tensor(0.8280)\n",
      "22487 Traning Loss: tensor(0.8279)\n",
      "22488 Traning Loss: tensor(0.8278)\n",
      "22489 Traning Loss: tensor(0.8278)\n",
      "22490 Traning Loss: tensor(0.8277)\n",
      "22491 Traning Loss: tensor(0.8277)\n",
      "22492 Traning Loss: tensor(0.8276)\n",
      "22493 Traning Loss: tensor(0.8276)\n",
      "22494 Traning Loss: tensor(0.8275)\n",
      "22495 Traning Loss: tensor(0.8275)\n",
      "22496 Traning Loss: tensor(0.8274)\n",
      "22497 Traning Loss: tensor(0.8274)\n",
      "22498 Traning Loss: tensor(0.8273)\n",
      "22499 Traning Loss: tensor(0.8273)\n",
      "22500 Traning Loss: tensor(0.8272)\n",
      "22501 Traning Loss: tensor(0.8271)\n",
      "22502 Traning Loss: tensor(0.8271)\n",
      "22503 Traning Loss: tensor(0.8270)\n",
      "22504 Traning Loss: tensor(0.8270)\n",
      "22505 Traning Loss: tensor(0.8269)\n",
      "22506 Traning Loss: tensor(0.8269)\n",
      "22507 Traning Loss: tensor(0.8268)\n",
      "22508 Traning Loss: tensor(0.8268)\n",
      "22509 Traning Loss: tensor(0.8267)\n",
      "22510 Traning Loss: tensor(0.8267)\n",
      "22511 Traning Loss: tensor(0.8266)\n",
      "22512 Traning Loss: tensor(0.8266)\n",
      "22513 Traning Loss: tensor(0.8265)\n",
      "22514 Traning Loss: tensor(0.8265)\n",
      "22515 Traning Loss: tensor(0.8264)\n",
      "22516 Traning Loss: tensor(0.8263)\n",
      "22517 Traning Loss: tensor(0.8263)\n",
      "22518 Traning Loss: tensor(0.8262)\n",
      "22519 Traning Loss: tensor(0.8262)\n",
      "22520 Traning Loss: tensor(0.8261)\n",
      "22521 Traning Loss: tensor(0.8261)\n",
      "22522 Traning Loss: tensor(0.8260)\n",
      "22523 Traning Loss: tensor(0.8260)\n",
      "22524 Traning Loss: tensor(0.8259)\n",
      "22525 Traning Loss: tensor(0.8259)\n",
      "22526 Traning Loss: tensor(0.8258)\n",
      "22527 Traning Loss: tensor(0.8258)\n",
      "22528 Traning Loss: tensor(0.8257)\n",
      "22529 Traning Loss: tensor(0.8257)\n",
      "22530 Traning Loss: tensor(0.8256)\n",
      "22531 Traning Loss: tensor(0.8256)\n",
      "22532 Traning Loss: tensor(0.8255)\n",
      "22533 Traning Loss: tensor(0.8255)\n",
      "22534 Traning Loss: tensor(0.8254)\n",
      "22535 Traning Loss: tensor(0.8254)\n",
      "22536 Traning Loss: tensor(0.8253)\n",
      "22537 Traning Loss: tensor(0.8253)\n",
      "22538 Traning Loss: tensor(0.8252)\n",
      "22539 Traning Loss: tensor(0.8252)\n",
      "22540 Traning Loss: tensor(0.8251)\n",
      "22541 Traning Loss: tensor(0.8251)\n",
      "22542 Traning Loss: tensor(0.8250)\n",
      "22543 Traning Loss: tensor(0.8249)\n",
      "22544 Traning Loss: tensor(0.8249)\n",
      "22545 Traning Loss: tensor(0.8248)\n",
      "22546 Traning Loss: tensor(0.8248)\n",
      "22547 Traning Loss: tensor(0.8247)\n",
      "22548 Traning Loss: tensor(0.8247)\n",
      "22549 Traning Loss: tensor(0.8246)\n",
      "22550 Traning Loss: tensor(0.8246)\n",
      "22551 Traning Loss: tensor(0.8245)\n",
      "22552 Traning Loss: tensor(0.8245)\n",
      "22553 Traning Loss: tensor(0.8244)\n",
      "22554 Traning Loss: tensor(0.8244)\n",
      "22555 Traning Loss: tensor(0.8243)\n",
      "22556 Traning Loss: tensor(0.8243)\n",
      "22557 Traning Loss: tensor(0.8242)\n",
      "22558 Traning Loss: tensor(0.8242)\n",
      "22559 Traning Loss: tensor(0.8241)\n",
      "22560 Traning Loss: tensor(0.8241)\n",
      "22561 Traning Loss: tensor(0.8240)\n",
      "22562 Traning Loss: tensor(0.8240)\n",
      "22563 Traning Loss: tensor(0.8239)\n",
      "22564 Traning Loss: tensor(0.8239)\n",
      "22565 Traning Loss: tensor(0.8238)\n",
      "22566 Traning Loss: tensor(0.8238)\n",
      "22567 Traning Loss: tensor(0.8237)\n",
      "22568 Traning Loss: tensor(0.8237)\n",
      "22569 Traning Loss: tensor(0.8236)\n",
      "22570 Traning Loss: tensor(0.8236)\n",
      "22571 Traning Loss: tensor(0.8235)\n",
      "22572 Traning Loss: tensor(0.8235)\n",
      "22573 Traning Loss: tensor(0.8234)\n",
      "22574 Traning Loss: tensor(0.8234)\n",
      "22575 Traning Loss: tensor(0.8233)\n",
      "22576 Traning Loss: tensor(0.8233)\n",
      "22577 Traning Loss: tensor(0.8232)\n",
      "22578 Traning Loss: tensor(0.8232)\n",
      "22579 Traning Loss: tensor(0.8231)\n",
      "22580 Traning Loss: tensor(0.8231)\n",
      "22581 Traning Loss: tensor(0.8230)\n",
      "22582 Traning Loss: tensor(0.8230)\n",
      "22583 Traning Loss: tensor(0.8229)\n",
      "22584 Traning Loss: tensor(0.8229)\n",
      "22585 Traning Loss: tensor(0.8229)\n",
      "22586 Traning Loss: tensor(0.8228)\n",
      "22587 Traning Loss: tensor(0.8228)\n",
      "22588 Traning Loss: tensor(0.8227)\n",
      "22589 Traning Loss: tensor(0.8227)\n",
      "22590 Traning Loss: tensor(0.8226)\n",
      "22591 Traning Loss: tensor(0.8226)\n",
      "22592 Traning Loss: tensor(0.8225)\n",
      "22593 Traning Loss: tensor(0.8225)\n",
      "22594 Traning Loss: tensor(0.8224)\n",
      "22595 Traning Loss: tensor(0.8224)\n",
      "22596 Traning Loss: tensor(0.8223)\n",
      "22597 Traning Loss: tensor(0.8223)\n",
      "22598 Traning Loss: tensor(0.8222)\n",
      "22599 Traning Loss: tensor(0.8222)\n",
      "22600 Traning Loss: tensor(0.8221)\n",
      "22601 Traning Loss: tensor(0.8221)\n",
      "22602 Traning Loss: tensor(0.8220)\n",
      "22603 Traning Loss: tensor(0.8220)\n",
      "22604 Traning Loss: tensor(0.8219)\n",
      "22605 Traning Loss: tensor(0.8219)\n",
      "22606 Traning Loss: tensor(0.8218)\n",
      "22607 Traning Loss: tensor(0.8218)\n",
      "22608 Traning Loss: tensor(0.8217)\n",
      "22609 Traning Loss: tensor(0.8217)\n",
      "22610 Traning Loss: tensor(0.8216)\n",
      "22611 Traning Loss: tensor(0.8216)\n",
      "22612 Traning Loss: tensor(0.8216)\n",
      "22613 Traning Loss: tensor(0.8215)\n",
      "22614 Traning Loss: tensor(0.8215)\n",
      "22615 Traning Loss: tensor(0.8214)\n",
      "22616 Traning Loss: tensor(0.8214)\n",
      "22617 Traning Loss: tensor(0.8213)\n",
      "22618 Traning Loss: tensor(0.8213)\n",
      "22619 Traning Loss: tensor(0.8212)\n",
      "22620 Traning Loss: tensor(0.8212)\n",
      "22621 Traning Loss: tensor(0.8211)\n",
      "22622 Traning Loss: tensor(0.8211)\n",
      "22623 Traning Loss: tensor(0.8210)\n",
      "22624 Traning Loss: tensor(0.8210)\n",
      "22625 Traning Loss: tensor(0.8209)\n",
      "22626 Traning Loss: tensor(0.8209)\n",
      "22627 Traning Loss: tensor(0.8208)\n",
      "22628 Traning Loss: tensor(0.8208)\n",
      "22629 Traning Loss: tensor(0.8208)\n",
      "22630 Traning Loss: tensor(0.8207)\n",
      "22631 Traning Loss: tensor(0.8395)\n",
      "22632 Traning Loss: tensor(0.8394)\n",
      "22633 Traning Loss: tensor(0.8394)\n",
      "22634 Traning Loss: tensor(0.8393)\n",
      "22635 Traning Loss: tensor(0.8393)\n",
      "22636 Traning Loss: tensor(0.8392)\n",
      "22637 Traning Loss: tensor(0.8392)\n",
      "22638 Traning Loss: tensor(0.8391)\n",
      "22639 Traning Loss: tensor(0.8391)\n",
      "22640 Traning Loss: tensor(0.8390)\n",
      "22641 Traning Loss: tensor(0.8202)\n",
      "22642 Traning Loss: tensor(0.8202)\n",
      "22643 Traning Loss: tensor(0.8201)\n",
      "22644 Traning Loss: tensor(0.8201)\n",
      "22645 Traning Loss: tensor(0.8200)\n",
      "22646 Traning Loss: tensor(0.8200)\n",
      "22647 Traning Loss: tensor(0.8200)\n",
      "22648 Traning Loss: tensor(0.8199)\n",
      "22649 Traning Loss: tensor(0.8199)\n",
      "22650 Traning Loss: tensor(0.8198)\n",
      "22651 Traning Loss: tensor(0.8198)\n",
      "22652 Traning Loss: tensor(0.8197)\n",
      "22653 Traning Loss: tensor(0.8384)\n",
      "22654 Traning Loss: tensor(0.8384)\n",
      "22655 Traning Loss: tensor(0.8383)\n",
      "22656 Traning Loss: tensor(0.8383)\n",
      "22657 Traning Loss: tensor(0.8195)\n",
      "22658 Traning Loss: tensor(0.8195)\n",
      "22659 Traning Loss: tensor(0.8194)\n",
      "22660 Traning Loss: tensor(0.8194)\n",
      "22661 Traning Loss: tensor(0.8193)\n",
      "22662 Traning Loss: tensor(0.8380)\n",
      "22663 Traning Loss: tensor(0.8379)\n",
      "22664 Traning Loss: tensor(0.8379)\n",
      "22665 Traning Loss: tensor(0.8192)\n",
      "22666 Traning Loss: tensor(0.8191)\n",
      "22667 Traning Loss: tensor(0.8191)\n",
      "22668 Traning Loss: tensor(0.8190)\n",
      "22669 Traning Loss: tensor(0.8190)\n",
      "22670 Traning Loss: tensor(0.8189)\n",
      "22671 Traning Loss: tensor(0.8376)\n",
      "22672 Traning Loss: tensor(0.8375)\n",
      "22673 Traning Loss: tensor(0.8188)\n",
      "22674 Traning Loss: tensor(0.8188)\n",
      "22675 Traning Loss: tensor(0.8374)\n",
      "22676 Traning Loss: tensor(0.8187)\n",
      "22677 Traning Loss: tensor(0.8186)\n",
      "22678 Traning Loss: tensor(0.8186)\n",
      "22679 Traning Loss: tensor(0.8372)\n",
      "22680 Traning Loss: tensor(0.8372)\n",
      "22681 Traning Loss: tensor(0.8185)\n",
      "22682 Traning Loss: tensor(0.8184)\n",
      "22683 Traning Loss: tensor(0.8184)\n",
      "22684 Traning Loss: tensor(0.8183)\n",
      "22685 Traning Loss: tensor(0.8369)\n",
      "22686 Traning Loss: tensor(0.8369)\n",
      "22687 Traning Loss: tensor(0.8182)\n",
      "22688 Traning Loss: tensor(0.8182)\n",
      "22689 Traning Loss: tensor(0.8181)\n",
      "22690 Traning Loss: tensor(0.8181)\n",
      "22691 Traning Loss: tensor(0.8367)\n",
      "22692 Traning Loss: tensor(0.8366)\n",
      "22693 Traning Loss: tensor(0.8180)\n",
      "22694 Traning Loss: tensor(0.8179)\n",
      "22695 Traning Loss: tensor(0.8179)\n",
      "22696 Traning Loss: tensor(0.8178)\n",
      "22697 Traning Loss: tensor(0.8364)\n",
      "22698 Traning Loss: tensor(0.8177)\n",
      "22699 Traning Loss: tensor(0.8363)\n",
      "22700 Traning Loss: tensor(0.8177)\n",
      "22701 Traning Loss: tensor(0.8176)\n",
      "22702 Traning Loss: tensor(0.8176)\n",
      "22703 Traning Loss: tensor(0.8361)\n",
      "22704 Traning Loss: tensor(0.8361)\n",
      "22705 Traning Loss: tensor(0.8174)\n",
      "22706 Traning Loss: tensor(0.8174)\n",
      "22707 Traning Loss: tensor(0.8174)\n",
      "22708 Traning Loss: tensor(0.8173)\n",
      "22709 Traning Loss: tensor(0.8173)\n",
      "22710 Traning Loss: tensor(0.8358)\n",
      "22711 Traning Loss: tensor(0.8357)\n",
      "22712 Traning Loss: tensor(0.8171)\n",
      "22713 Traning Loss: tensor(0.8171)\n",
      "22714 Traning Loss: tensor(0.8171)\n",
      "22715 Traning Loss: tensor(0.8170)\n",
      "22716 Traning Loss: tensor(0.8355)\n",
      "22717 Traning Loss: tensor(0.8355)\n",
      "22718 Traning Loss: tensor(0.8169)\n",
      "22719 Traning Loss: tensor(0.8169)\n",
      "22720 Traning Loss: tensor(0.8168)\n",
      "22721 Traning Loss: tensor(0.8168)\n",
      "22722 Traning Loss: tensor(0.8167)\n",
      "22723 Traning Loss: tensor(0.8352)\n",
      "22724 Traning Loss: tensor(0.8352)\n",
      "22725 Traning Loss: tensor(0.8166)\n",
      "22726 Traning Loss: tensor(0.8166)\n",
      "22727 Traning Loss: tensor(0.8165)\n",
      "22728 Traning Loss: tensor(0.8165)\n",
      "22729 Traning Loss: tensor(0.8349)\n",
      "22730 Traning Loss: tensor(0.8349)\n",
      "22731 Traning Loss: tensor(0.8163)\n",
      "22732 Traning Loss: tensor(0.8163)\n",
      "22733 Traning Loss: tensor(0.8163)\n",
      "22734 Traning Loss: tensor(0.8162)\n",
      "22735 Traning Loss: tensor(0.8162)\n",
      "22736 Traning Loss: tensor(0.8346)\n",
      "22737 Traning Loss: tensor(0.8346)\n",
      "22738 Traning Loss: tensor(0.8161)\n",
      "22739 Traning Loss: tensor(0.8160)\n",
      "22740 Traning Loss: tensor(0.8160)\n",
      "22741 Traning Loss: tensor(0.8159)\n",
      "22742 Traning Loss: tensor(0.8159)\n",
      "22743 Traning Loss: tensor(0.8343)\n",
      "22744 Traning Loss: tensor(0.8343)\n",
      "22745 Traning Loss: tensor(0.8158)\n",
      "22746 Traning Loss: tensor(0.8157)\n",
      "22747 Traning Loss: tensor(0.8157)\n",
      "22748 Traning Loss: tensor(0.8156)\n",
      "22749 Traning Loss: tensor(0.8156)\n",
      "22750 Traning Loss: tensor(0.8340)\n",
      "22751 Traning Loss: tensor(0.8340)\n",
      "22752 Traning Loss: tensor(0.8155)\n",
      "22753 Traning Loss: tensor(0.8154)\n",
      "22754 Traning Loss: tensor(0.8154)\n",
      "22755 Traning Loss: tensor(0.8154)\n",
      "22756 Traning Loss: tensor(0.8337)\n",
      "22757 Traning Loss: tensor(0.8153)\n",
      "22758 Traning Loss: tensor(0.8152)\n",
      "22759 Traning Loss: tensor(0.8336)\n",
      "22760 Traning Loss: tensor(0.8151)\n",
      "22761 Traning Loss: tensor(0.8151)\n",
      "22762 Traning Loss: tensor(0.8151)\n",
      "22763 Traning Loss: tensor(0.8334)\n",
      "22764 Traning Loss: tensor(0.8150)\n",
      "22765 Traning Loss: tensor(0.8149)\n",
      "22766 Traning Loss: tensor(0.8149)\n",
      "22767 Traning Loss: tensor(0.8333)\n",
      "22768 Traning Loss: tensor(0.8332)\n",
      "22769 Traning Loss: tensor(0.8148)\n",
      "22770 Traning Loss: tensor(0.8147)\n",
      "22771 Traning Loss: tensor(0.8147)\n",
      "22772 Traning Loss: tensor(0.8147)\n",
      "22773 Traning Loss: tensor(0.8146)\n",
      "22774 Traning Loss: tensor(0.8146)\n",
      "22775 Traning Loss: tensor(0.8145)\n",
      "22776 Traning Loss: tensor(0.8329)\n",
      "22777 Traning Loss: tensor(0.8328)\n",
      "22778 Traning Loss: tensor(0.8328)\n",
      "22779 Traning Loss: tensor(0.8144)\n",
      "22780 Traning Loss: tensor(0.8143)\n",
      "22781 Traning Loss: tensor(0.8143)\n",
      "22782 Traning Loss: tensor(0.8143)\n",
      "22783 Traning Loss: tensor(0.8142)\n",
      "22784 Traning Loss: tensor(0.8142)\n",
      "22785 Traning Loss: tensor(0.8141)\n",
      "22786 Traning Loss: tensor(0.8141)\n",
      "22787 Traning Loss: tensor(0.8140)\n",
      "22788 Traning Loss: tensor(0.8324)\n",
      "22789 Traning Loss: tensor(0.8323)\n",
      "22790 Traning Loss: tensor(0.8323)\n",
      "22791 Traning Loss: tensor(0.8139)\n",
      "22792 Traning Loss: tensor(0.8138)\n",
      "22793 Traning Loss: tensor(0.8138)\n",
      "22794 Traning Loss: tensor(0.8138)\n",
      "22795 Traning Loss: tensor(0.8137)\n",
      "22796 Traning Loss: tensor(0.8137)\n",
      "22797 Traning Loss: tensor(0.8136)\n",
      "22798 Traning Loss: tensor(0.8136)\n",
      "22799 Traning Loss: tensor(0.8319)\n",
      "22800 Traning Loss: tensor(0.8318)\n",
      "22801 Traning Loss: tensor(0.8135)\n",
      "22802 Traning Loss: tensor(0.8134)\n",
      "22803 Traning Loss: tensor(0.8134)\n",
      "22804 Traning Loss: tensor(0.8134)\n",
      "22805 Traning Loss: tensor(0.8316)\n",
      "22806 Traning Loss: tensor(0.8133)\n",
      "22807 Traning Loss: tensor(0.8132)\n",
      "22808 Traning Loss: tensor(0.8132)\n",
      "22809 Traning Loss: tensor(0.8315)\n",
      "22810 Traning Loss: tensor(0.8131)\n",
      "22811 Traning Loss: tensor(0.8131)\n",
      "22812 Traning Loss: tensor(0.8130)\n",
      "22813 Traning Loss: tensor(0.8313)\n",
      "22814 Traning Loss: tensor(0.8130)\n",
      "22815 Traning Loss: tensor(0.8129)\n",
      "22816 Traning Loss: tensor(0.8129)\n",
      "22817 Traning Loss: tensor(0.8129)\n",
      "22818 Traning Loss: tensor(0.8311)\n",
      "22819 Traning Loss: tensor(0.8310)\n",
      "22820 Traning Loss: tensor(0.8127)\n",
      "22821 Traning Loss: tensor(0.8127)\n",
      "22822 Traning Loss: tensor(0.8127)\n",
      "22823 Traning Loss: tensor(0.8126)\n",
      "22824 Traning Loss: tensor(0.8126)\n",
      "22825 Traning Loss: tensor(0.8125)\n",
      "22826 Traning Loss: tensor(0.8125)\n",
      "22827 Traning Loss: tensor(0.8125)\n",
      "22828 Traning Loss: tensor(0.8307)\n",
      "22829 Traning Loss: tensor(0.8306)\n",
      "22830 Traning Loss: tensor(0.8123)\n",
      "22831 Traning Loss: tensor(0.8123)\n",
      "22832 Traning Loss: tensor(0.8123)\n",
      "22833 Traning Loss: tensor(0.8122)\n",
      "22834 Traning Loss: tensor(0.8122)\n",
      "22835 Traning Loss: tensor(0.8304)\n",
      "22836 Traning Loss: tensor(0.8121)\n",
      "22837 Traning Loss: tensor(0.8121)\n",
      "22838 Traning Loss: tensor(0.8120)\n",
      "22839 Traning Loss: tensor(0.8302)\n",
      "22840 Traning Loss: tensor(0.8119)\n",
      "22841 Traning Loss: tensor(0.8119)\n",
      "22842 Traning Loss: tensor(0.8119)\n",
      "22843 Traning Loss: tensor(0.8118)\n",
      "22844 Traning Loss: tensor(0.8300)\n",
      "22845 Traning Loss: tensor(0.8299)\n",
      "22846 Traning Loss: tensor(0.8117)\n",
      "22847 Traning Loss: tensor(0.8117)\n",
      "22848 Traning Loss: tensor(0.8116)\n",
      "22849 Traning Loss: tensor(0.8116)\n",
      "22850 Traning Loss: tensor(0.8116)\n",
      "22851 Traning Loss: tensor(0.8115)\n",
      "22852 Traning Loss: tensor(0.8115)\n",
      "22853 Traning Loss: tensor(0.8114)\n",
      "22854 Traning Loss: tensor(0.8114)\n",
      "22855 Traning Loss: tensor(0.8295)\n",
      "22856 Traning Loss: tensor(0.8295)\n",
      "22857 Traning Loss: tensor(0.8113)\n",
      "22858 Traning Loss: tensor(0.8112)\n",
      "22859 Traning Loss: tensor(0.8112)\n",
      "22860 Traning Loss: tensor(0.8112)\n",
      "22861 Traning Loss: tensor(0.8111)\n",
      "22862 Traning Loss: tensor(0.8111)\n",
      "22863 Traning Loss: tensor(0.8111)\n",
      "22864 Traning Loss: tensor(0.8292)\n",
      "22865 Traning Loss: tensor(0.8291)\n",
      "22866 Traning Loss: tensor(0.8109)\n",
      "22867 Traning Loss: tensor(0.8109)\n",
      "22868 Traning Loss: tensor(0.8109)\n",
      "22869 Traning Loss: tensor(0.8108)\n",
      "22870 Traning Loss: tensor(0.8108)\n",
      "22871 Traning Loss: tensor(0.8107)\n",
      "22872 Traning Loss: tensor(0.8107)\n",
      "22873 Traning Loss: tensor(0.8107)\n",
      "22874 Traning Loss: tensor(0.8287)\n",
      "22875 Traning Loss: tensor(0.8287)\n",
      "22876 Traning Loss: tensor(0.8106)\n",
      "22877 Traning Loss: tensor(0.8105)\n",
      "22878 Traning Loss: tensor(0.8105)\n",
      "22879 Traning Loss: tensor(0.8104)\n",
      "22880 Traning Loss: tensor(0.8104)\n",
      "22881 Traning Loss: tensor(0.8104)\n",
      "22882 Traning Loss: tensor(0.8103)\n",
      "22883 Traning Loss: tensor(0.8103)\n",
      "22884 Traning Loss: tensor(0.8283)\n",
      "22885 Traning Loss: tensor(0.8283)\n",
      "22886 Traning Loss: tensor(0.8102)\n",
      "22887 Traning Loss: tensor(0.8101)\n",
      "22888 Traning Loss: tensor(0.8101)\n",
      "22889 Traning Loss: tensor(0.8101)\n",
      "22890 Traning Loss: tensor(0.8100)\n",
      "22891 Traning Loss: tensor(0.8100)\n",
      "22892 Traning Loss: tensor(0.8099)\n",
      "22893 Traning Loss: tensor(0.8099)\n",
      "22894 Traning Loss: tensor(0.8099)\n",
      "22895 Traning Loss: tensor(0.8279)\n",
      "22896 Traning Loss: tensor(0.8279)\n",
      "22897 Traning Loss: tensor(0.8098)\n",
      "22898 Traning Loss: tensor(0.8097)\n",
      "22899 Traning Loss: tensor(0.8097)\n",
      "22900 Traning Loss: tensor(0.8096)\n",
      "22901 Traning Loss: tensor(0.8096)\n",
      "22902 Traning Loss: tensor(0.8096)\n",
      "22903 Traning Loss: tensor(0.8095)\n",
      "22904 Traning Loss: tensor(0.8095)\n",
      "22905 Traning Loss: tensor(0.8095)\n",
      "22906 Traning Loss: tensor(0.8275)\n",
      "22907 Traning Loss: tensor(0.8274)\n",
      "22908 Traning Loss: tensor(0.8093)\n",
      "22909 Traning Loss: tensor(0.8093)\n",
      "22910 Traning Loss: tensor(0.8093)\n",
      "22911 Traning Loss: tensor(0.8092)\n",
      "22912 Traning Loss: tensor(0.8092)\n",
      "22913 Traning Loss: tensor(0.8092)\n",
      "22914 Traning Loss: tensor(0.8091)\n",
      "22915 Traning Loss: tensor(0.8091)\n",
      "22916 Traning Loss: tensor(0.8090)\n",
      "22917 Traning Loss: tensor(0.8090)\n",
      "22918 Traning Loss: tensor(0.8270)\n",
      "22919 Traning Loss: tensor(0.8269)\n",
      "22920 Traning Loss: tensor(0.8089)\n",
      "22921 Traning Loss: tensor(0.8089)\n",
      "22922 Traning Loss: tensor(0.8088)\n",
      "22923 Traning Loss: tensor(0.8088)\n",
      "22924 Traning Loss: tensor(0.8087)\n",
      "22925 Traning Loss: tensor(0.8087)\n",
      "22926 Traning Loss: tensor(0.8087)\n",
      "22927 Traning Loss: tensor(0.8086)\n",
      "22928 Traning Loss: tensor(0.8086)\n",
      "22929 Traning Loss: tensor(0.8086)\n",
      "22930 Traning Loss: tensor(0.8265)\n",
      "22931 Traning Loss: tensor(0.8265)\n",
      "22932 Traning Loss: tensor(0.8084)\n",
      "22933 Traning Loss: tensor(0.8084)\n",
      "22934 Traning Loss: tensor(0.8084)\n",
      "22935 Traning Loss: tensor(0.8083)\n",
      "22936 Traning Loss: tensor(0.8083)\n",
      "22937 Traning Loss: tensor(0.8083)\n",
      "22938 Traning Loss: tensor(0.8082)\n",
      "22939 Traning Loss: tensor(0.8082)\n",
      "22940 Traning Loss: tensor(0.8081)\n",
      "22941 Traning Loss: tensor(0.8081)\n",
      "22942 Traning Loss: tensor(0.8081)\n",
      "22943 Traning Loss: tensor(0.8260)\n",
      "22944 Traning Loss: tensor(0.8259)\n",
      "22945 Traning Loss: tensor(0.8080)\n",
      "22946 Traning Loss: tensor(0.8079)\n",
      "22947 Traning Loss: tensor(0.8079)\n",
      "22948 Traning Loss: tensor(0.8079)\n",
      "22949 Traning Loss: tensor(0.8078)\n",
      "22950 Traning Loss: tensor(0.8078)\n",
      "22951 Traning Loss: tensor(0.8077)\n",
      "22952 Traning Loss: tensor(0.8077)\n",
      "22953 Traning Loss: tensor(0.8077)\n",
      "22954 Traning Loss: tensor(0.8076)\n",
      "22955 Traning Loss: tensor(0.8076)\n",
      "22956 Traning Loss: tensor(0.8076)\n",
      "22957 Traning Loss: tensor(0.8254)\n",
      "22958 Traning Loss: tensor(0.8254)\n",
      "22959 Traning Loss: tensor(0.8075)\n",
      "22960 Traning Loss: tensor(0.8074)\n",
      "22961 Traning Loss: tensor(0.8074)\n",
      "22962 Traning Loss: tensor(0.8073)\n",
      "22963 Traning Loss: tensor(0.8073)\n",
      "22964 Traning Loss: tensor(0.8073)\n",
      "22965 Traning Loss: tensor(0.8072)\n",
      "22966 Traning Loss: tensor(0.8072)\n",
      "22967 Traning Loss: tensor(0.8072)\n",
      "22968 Traning Loss: tensor(0.8071)\n",
      "22969 Traning Loss: tensor(0.8071)\n",
      "22970 Traning Loss: tensor(0.8070)\n",
      "22971 Traning Loss: tensor(0.8249)\n",
      "22972 Traning Loss: tensor(0.8249)\n",
      "22973 Traning Loss: tensor(0.8069)\n",
      "22974 Traning Loss: tensor(0.8069)\n",
      "22975 Traning Loss: tensor(0.8069)\n",
      "22976 Traning Loss: tensor(0.8068)\n",
      "22977 Traning Loss: tensor(0.8068)\n",
      "22978 Traning Loss: tensor(0.8068)\n",
      "22979 Traning Loss: tensor(0.8067)\n",
      "22980 Traning Loss: tensor(0.8067)\n",
      "22981 Traning Loss: tensor(0.8067)\n",
      "22982 Traning Loss: tensor(0.8066)\n",
      "22983 Traning Loss: tensor(0.8066)\n",
      "22984 Traning Loss: tensor(0.8065)\n",
      "22985 Traning Loss: tensor(0.8065)\n",
      "22986 Traning Loss: tensor(0.8065)\n",
      "22987 Traning Loss: tensor(0.8243)\n",
      "22988 Traning Loss: tensor(0.8064)\n",
      "22989 Traning Loss: tensor(0.8064)\n",
      "22990 Traning Loss: tensor(0.8063)\n",
      "22991 Traning Loss: tensor(0.8063)\n",
      "22992 Traning Loss: tensor(0.8241)\n",
      "22993 Traning Loss: tensor(0.8062)\n",
      "22994 Traning Loss: tensor(0.8062)\n",
      "22995 Traning Loss: tensor(0.8061)\n",
      "22996 Traning Loss: tensor(0.8061)\n",
      "22997 Traning Loss: tensor(0.8061)\n",
      "22998 Traning Loss: tensor(0.8060)\n",
      "22999 Traning Loss: tensor(0.8060)\n",
      "23000 Traning Loss: tensor(0.8060)\n",
      "23001 Traning Loss: tensor(0.8059)\n",
      "23002 Traning Loss: tensor(0.8059)\n",
      "23003 Traning Loss: tensor(0.8237)\n",
      "23004 Traning Loss: tensor(0.8058)\n",
      "23005 Traning Loss: tensor(0.8058)\n",
      "23006 Traning Loss: tensor(0.8058)\n",
      "23007 Traning Loss: tensor(0.8057)\n",
      "23008 Traning Loss: tensor(0.8057)\n",
      "23009 Traning Loss: tensor(0.8056)\n",
      "23010 Traning Loss: tensor(0.8056)\n",
      "23011 Traning Loss: tensor(0.8234)\n",
      "23012 Traning Loss: tensor(0.8055)\n",
      "23013 Traning Loss: tensor(0.8055)\n",
      "23014 Traning Loss: tensor(0.8055)\n",
      "23015 Traning Loss: tensor(0.8054)\n",
      "23016 Traning Loss: tensor(0.8054)\n",
      "23017 Traning Loss: tensor(0.8054)\n",
      "23018 Traning Loss: tensor(0.8053)\n",
      "23019 Traning Loss: tensor(0.8053)\n",
      "23020 Traning Loss: tensor(0.8053)\n",
      "23021 Traning Loss: tensor(0.8052)\n",
      "23022 Traning Loss: tensor(0.8229)\n",
      "23023 Traning Loss: tensor(0.8052)\n",
      "23024 Traning Loss: tensor(0.8051)\n",
      "23025 Traning Loss: tensor(0.8051)\n",
      "23026 Traning Loss: tensor(0.8050)\n",
      "23027 Traning Loss: tensor(0.8050)\n",
      "23028 Traning Loss: tensor(0.8050)\n",
      "23029 Traning Loss: tensor(0.8049)\n",
      "23030 Traning Loss: tensor(0.8049)\n",
      "23031 Traning Loss: tensor(0.8049)\n",
      "23032 Traning Loss: tensor(0.8226)\n",
      "23033 Traning Loss: tensor(0.8048)\n",
      "23034 Traning Loss: tensor(0.8048)\n",
      "23035 Traning Loss: tensor(0.8047)\n",
      "23036 Traning Loss: tensor(0.8047)\n",
      "23037 Traning Loss: tensor(0.8047)\n",
      "23038 Traning Loss: tensor(0.8046)\n",
      "23039 Traning Loss: tensor(0.8046)\n",
      "23040 Traning Loss: tensor(0.8046)\n",
      "23041 Traning Loss: tensor(0.8045)\n",
      "23042 Traning Loss: tensor(0.8045)\n",
      "23043 Traning Loss: tensor(0.8044)\n",
      "23044 Traning Loss: tensor(0.8221)\n",
      "23045 Traning Loss: tensor(0.8044)\n",
      "23046 Traning Loss: tensor(0.8043)\n",
      "23047 Traning Loss: tensor(0.8043)\n",
      "23048 Traning Loss: tensor(0.8043)\n",
      "23049 Traning Loss: tensor(0.8042)\n",
      "23050 Traning Loss: tensor(0.8042)\n",
      "23051 Traning Loss: tensor(0.8042)\n",
      "23052 Traning Loss: tensor(0.8041)\n",
      "23053 Traning Loss: tensor(0.8041)\n",
      "23054 Traning Loss: tensor(0.8041)\n",
      "23055 Traning Loss: tensor(0.8040)\n",
      "23056 Traning Loss: tensor(0.8040)\n",
      "23057 Traning Loss: tensor(0.8216)\n",
      "23058 Traning Loss: tensor(0.8039)\n",
      "23059 Traning Loss: tensor(0.8039)\n",
      "23060 Traning Loss: tensor(0.8039)\n",
      "23061 Traning Loss: tensor(0.8038)\n",
      "23062 Traning Loss: tensor(0.8038)\n",
      "23063 Traning Loss: tensor(0.8038)\n",
      "23064 Traning Loss: tensor(0.8037)\n",
      "23065 Traning Loss: tensor(0.8037)\n",
      "23066 Traning Loss: tensor(0.8036)\n",
      "23067 Traning Loss: tensor(0.8036)\n",
      "23068 Traning Loss: tensor(0.8036)\n",
      "23069 Traning Loss: tensor(0.8035)\n",
      "23070 Traning Loss: tensor(0.8035)\n",
      "23071 Traning Loss: tensor(0.8035)\n",
      "23072 Traning Loss: tensor(0.8211)\n",
      "23073 Traning Loss: tensor(0.8034)\n",
      "23074 Traning Loss: tensor(0.8034)\n",
      "23075 Traning Loss: tensor(0.8033)\n",
      "23076 Traning Loss: tensor(0.8033)\n",
      "23077 Traning Loss: tensor(0.8033)\n",
      "23078 Traning Loss: tensor(0.8032)\n",
      "23079 Traning Loss: tensor(0.8032)\n",
      "23080 Traning Loss: tensor(0.8032)\n",
      "23081 Traning Loss: tensor(0.8031)\n",
      "23082 Traning Loss: tensor(0.8031)\n",
      "23083 Traning Loss: tensor(0.8031)\n",
      "23084 Traning Loss: tensor(0.8030)\n",
      "23085 Traning Loss: tensor(0.8030)\n",
      "23086 Traning Loss: tensor(0.8030)\n",
      "23087 Traning Loss: tensor(0.8029)\n",
      "23088 Traning Loss: tensor(0.8205)\n",
      "23089 Traning Loss: tensor(0.8029)\n",
      "23090 Traning Loss: tensor(0.8028)\n",
      "23091 Traning Loss: tensor(0.8028)\n",
      "23092 Traning Loss: tensor(0.8028)\n",
      "23093 Traning Loss: tensor(0.8027)\n",
      "23094 Traning Loss: tensor(0.8027)\n",
      "23095 Traning Loss: tensor(0.8027)\n",
      "23096 Traning Loss: tensor(0.8026)\n",
      "23097 Traning Loss: tensor(0.8026)\n",
      "23098 Traning Loss: tensor(0.8025)\n",
      "23099 Traning Loss: tensor(0.8025)\n",
      "23100 Traning Loss: tensor(0.8025)\n",
      "23101 Traning Loss: tensor(0.8024)\n",
      "23102 Traning Loss: tensor(0.8024)\n",
      "23103 Traning Loss: tensor(0.8024)\n",
      "23104 Traning Loss: tensor(0.8023)\n",
      "23105 Traning Loss: tensor(0.8023)\n",
      "23106 Traning Loss: tensor(0.8023)\n",
      "23107 Traning Loss: tensor(0.8022)\n",
      "23108 Traning Loss: tensor(0.8022)\n",
      "23109 Traning Loss: tensor(0.8022)\n",
      "23110 Traning Loss: tensor(0.8197)\n",
      "23111 Traning Loss: tensor(0.8021)\n",
      "23112 Traning Loss: tensor(0.8021)\n",
      "23113 Traning Loss: tensor(0.8020)\n",
      "23114 Traning Loss: tensor(0.8020)\n",
      "23115 Traning Loss: tensor(0.8020)\n",
      "23116 Traning Loss: tensor(0.8019)\n",
      "23117 Traning Loss: tensor(0.8019)\n",
      "23118 Traning Loss: tensor(0.8019)\n",
      "23119 Traning Loss: tensor(0.8018)\n",
      "23120 Traning Loss: tensor(0.8018)\n",
      "23121 Traning Loss: tensor(0.8018)\n",
      "23122 Traning Loss: tensor(0.8017)\n",
      "23123 Traning Loss: tensor(0.8017)\n",
      "23124 Traning Loss: tensor(0.8017)\n",
      "23125 Traning Loss: tensor(0.8016)\n",
      "23126 Traning Loss: tensor(0.8016)\n",
      "23127 Traning Loss: tensor(0.8016)\n",
      "23128 Traning Loss: tensor(0.8015)\n",
      "23129 Traning Loss: tensor(0.8015)\n",
      "23130 Traning Loss: tensor(0.8015)\n",
      "23131 Traning Loss: tensor(0.8014)\n",
      "23132 Traning Loss: tensor(0.8014)\n",
      "23133 Traning Loss: tensor(0.8014)\n",
      "23134 Traning Loss: tensor(0.8013)\n",
      "23135 Traning Loss: tensor(0.8013)\n",
      "23136 Traning Loss: tensor(0.8013)\n",
      "23137 Traning Loss: tensor(0.8012)\n",
      "23138 Traning Loss: tensor(0.8012)\n",
      "23139 Traning Loss: tensor(0.8012)\n",
      "23140 Traning Loss: tensor(0.8011)\n",
      "23141 Traning Loss: tensor(0.8011)\n",
      "23142 Traning Loss: tensor(0.8011)\n",
      "23143 Traning Loss: tensor(0.8010)\n",
      "23144 Traning Loss: tensor(0.8010)\n",
      "23145 Traning Loss: tensor(0.8184)\n",
      "23146 Traning Loss: tensor(0.8009)\n",
      "23147 Traning Loss: tensor(0.8009)\n",
      "23148 Traning Loss: tensor(0.8009)\n",
      "23149 Traning Loss: tensor(0.8008)\n",
      "23150 Traning Loss: tensor(0.8008)\n",
      "23151 Traning Loss: tensor(0.8008)\n",
      "23152 Traning Loss: tensor(0.8007)\n",
      "23153 Traning Loss: tensor(0.8007)\n",
      "23154 Traning Loss: tensor(0.8007)\n",
      "23155 Traning Loss: tensor(0.8006)\n",
      "23156 Traning Loss: tensor(0.8006)\n",
      "23157 Traning Loss: tensor(0.8006)\n",
      "23158 Traning Loss: tensor(0.8005)\n",
      "23159 Traning Loss: tensor(0.8005)\n",
      "23160 Traning Loss: tensor(0.8005)\n",
      "23161 Traning Loss: tensor(0.8004)\n",
      "23162 Traning Loss: tensor(0.8004)\n",
      "23163 Traning Loss: tensor(0.8004)\n",
      "23164 Traning Loss: tensor(0.8003)\n",
      "23165 Traning Loss: tensor(0.8003)\n",
      "23166 Traning Loss: tensor(0.8003)\n",
      "23167 Traning Loss: tensor(0.8002)\n",
      "23168 Traning Loss: tensor(0.8002)\n",
      "23169 Traning Loss: tensor(0.8002)\n",
      "23170 Traning Loss: tensor(0.8001)\n",
      "23171 Traning Loss: tensor(0.8001)\n",
      "23172 Traning Loss: tensor(0.8001)\n",
      "23173 Traning Loss: tensor(0.8000)\n",
      "23174 Traning Loss: tensor(0.8000)\n",
      "23175 Traning Loss: tensor(0.8000)\n",
      "23176 Traning Loss: tensor(0.7999)\n",
      "23177 Traning Loss: tensor(0.7999)\n",
      "23178 Traning Loss: tensor(0.7999)\n",
      "23179 Traning Loss: tensor(0.7998)\n",
      "23180 Traning Loss: tensor(0.7998)\n",
      "23181 Traning Loss: tensor(0.7998)\n",
      "23182 Traning Loss: tensor(0.7997)\n",
      "23183 Traning Loss: tensor(0.7997)\n",
      "23184 Traning Loss: tensor(0.7997)\n",
      "23185 Traning Loss: tensor(0.7996)\n",
      "23186 Traning Loss: tensor(0.7996)\n",
      "23187 Traning Loss: tensor(0.7996)\n",
      "23188 Traning Loss: tensor(0.7995)\n",
      "23189 Traning Loss: tensor(0.7995)\n",
      "23190 Traning Loss: tensor(0.7995)\n",
      "23191 Traning Loss: tensor(0.7995)\n",
      "23192 Traning Loss: tensor(0.7994)\n",
      "23193 Traning Loss: tensor(0.7994)\n",
      "23194 Traning Loss: tensor(0.7994)\n",
      "23195 Traning Loss: tensor(0.7993)\n",
      "23196 Traning Loss: tensor(0.7993)\n",
      "23197 Traning Loss: tensor(0.7993)\n",
      "23198 Traning Loss: tensor(0.7992)\n",
      "23199 Traning Loss: tensor(0.7992)\n",
      "23200 Traning Loss: tensor(0.7992)\n",
      "23201 Traning Loss: tensor(0.7991)\n",
      "23202 Traning Loss: tensor(0.7991)\n",
      "23203 Traning Loss: tensor(0.7991)\n",
      "23204 Traning Loss: tensor(0.7990)\n",
      "23205 Traning Loss: tensor(0.7990)\n",
      "23206 Traning Loss: tensor(0.7990)\n",
      "23207 Traning Loss: tensor(0.7989)\n",
      "23208 Traning Loss: tensor(0.7989)\n",
      "23209 Traning Loss: tensor(0.7989)\n",
      "23210 Traning Loss: tensor(0.7988)\n",
      "23211 Traning Loss: tensor(0.7988)\n",
      "23212 Traning Loss: tensor(0.7988)\n",
      "23213 Traning Loss: tensor(0.7987)\n",
      "23214 Traning Loss: tensor(0.7987)\n",
      "23215 Traning Loss: tensor(0.7987)\n",
      "23216 Traning Loss: tensor(0.7986)\n",
      "23217 Traning Loss: tensor(0.7986)\n",
      "23218 Traning Loss: tensor(0.7986)\n",
      "23219 Traning Loss: tensor(0.7985)\n",
      "23220 Traning Loss: tensor(0.7985)\n",
      "23221 Traning Loss: tensor(0.7985)\n",
      "23222 Traning Loss: tensor(0.7984)\n",
      "23223 Traning Loss: tensor(0.7984)\n",
      "23224 Traning Loss: tensor(0.7984)\n",
      "23225 Traning Loss: tensor(0.7983)\n",
      "23226 Traning Loss: tensor(0.7983)\n",
      "23227 Traning Loss: tensor(0.7983)\n",
      "23228 Traning Loss: tensor(0.7983)\n",
      "23229 Traning Loss: tensor(0.7982)\n",
      "23230 Traning Loss: tensor(0.7982)\n",
      "23231 Traning Loss: tensor(0.7982)\n",
      "23232 Traning Loss: tensor(0.7981)\n",
      "23233 Traning Loss: tensor(0.7981)\n",
      "23234 Traning Loss: tensor(0.7981)\n",
      "23235 Traning Loss: tensor(0.7980)\n",
      "23236 Traning Loss: tensor(0.7980)\n",
      "23237 Traning Loss: tensor(0.7980)\n",
      "23238 Traning Loss: tensor(0.7979)\n",
      "23239 Traning Loss: tensor(0.7979)\n",
      "23240 Traning Loss: tensor(0.7979)\n",
      "23241 Traning Loss: tensor(0.7978)\n",
      "23242 Traning Loss: tensor(0.7978)\n",
      "23243 Traning Loss: tensor(0.7978)\n",
      "23244 Traning Loss: tensor(0.7977)\n",
      "23245 Traning Loss: tensor(0.7977)\n",
      "23246 Traning Loss: tensor(0.7977)\n",
      "23247 Traning Loss: tensor(0.7976)\n",
      "23248 Traning Loss: tensor(0.7976)\n",
      "23249 Traning Loss: tensor(0.7976)\n",
      "23250 Traning Loss: tensor(0.7975)\n",
      "23251 Traning Loss: tensor(0.7975)\n",
      "23252 Traning Loss: tensor(0.7975)\n",
      "23253 Traning Loss: tensor(0.7974)\n",
      "23254 Traning Loss: tensor(0.7974)\n",
      "23255 Traning Loss: tensor(0.7974)\n",
      "23256 Traning Loss: tensor(0.7974)\n",
      "23257 Traning Loss: tensor(0.7973)\n",
      "23258 Traning Loss: tensor(0.7973)\n",
      "23259 Traning Loss: tensor(0.7973)\n",
      "23260 Traning Loss: tensor(0.7972)\n",
      "23261 Traning Loss: tensor(0.7972)\n",
      "23262 Traning Loss: tensor(0.7972)\n",
      "23263 Traning Loss: tensor(0.7971)\n",
      "23264 Traning Loss: tensor(0.7971)\n",
      "23265 Traning Loss: tensor(0.7971)\n",
      "23266 Traning Loss: tensor(0.7970)\n",
      "23267 Traning Loss: tensor(0.7970)\n",
      "23268 Traning Loss: tensor(0.7970)\n",
      "23269 Traning Loss: tensor(0.7969)\n",
      "23270 Traning Loss: tensor(0.7969)\n",
      "23271 Traning Loss: tensor(0.7969)\n",
      "23272 Traning Loss: tensor(0.7968)\n",
      "23273 Traning Loss: tensor(0.7968)\n",
      "23274 Traning Loss: tensor(0.7968)\n",
      "23275 Traning Loss: tensor(0.7967)\n",
      "23276 Traning Loss: tensor(0.7967)\n",
      "23277 Traning Loss: tensor(0.7967)\n",
      "23278 Traning Loss: tensor(0.7966)\n",
      "23279 Traning Loss: tensor(0.7966)\n",
      "23280 Traning Loss: tensor(0.7966)\n",
      "23281 Traning Loss: tensor(0.7966)\n",
      "23282 Traning Loss: tensor(0.7965)\n",
      "23283 Traning Loss: tensor(0.7965)\n",
      "23284 Traning Loss: tensor(0.7965)\n",
      "23285 Traning Loss: tensor(0.7964)\n",
      "23286 Traning Loss: tensor(0.7964)\n",
      "23287 Traning Loss: tensor(0.7964)\n",
      "23288 Traning Loss: tensor(0.7963)\n",
      "23289 Traning Loss: tensor(0.7963)\n",
      "23290 Traning Loss: tensor(0.7963)\n",
      "23291 Traning Loss: tensor(0.7962)\n",
      "23292 Traning Loss: tensor(0.7962)\n",
      "23293 Traning Loss: tensor(0.7962)\n",
      "23294 Traning Loss: tensor(0.7961)\n",
      "23295 Traning Loss: tensor(0.7961)\n",
      "23296 Traning Loss: tensor(0.7961)\n",
      "23297 Traning Loss: tensor(0.7960)\n",
      "23298 Traning Loss: tensor(0.7960)\n",
      "23299 Traning Loss: tensor(0.7960)\n",
      "23300 Traning Loss: tensor(0.7960)\n",
      "23301 Traning Loss: tensor(0.7959)\n",
      "23302 Traning Loss: tensor(0.7959)\n",
      "23303 Traning Loss: tensor(0.7959)\n",
      "23304 Traning Loss: tensor(0.7958)\n",
      "23305 Traning Loss: tensor(0.7958)\n",
      "23306 Traning Loss: tensor(0.7958)\n",
      "23307 Traning Loss: tensor(0.7957)\n",
      "23308 Traning Loss: tensor(0.7957)\n",
      "23309 Traning Loss: tensor(0.7957)\n",
      "23310 Traning Loss: tensor(0.7956)\n",
      "23311 Traning Loss: tensor(0.7956)\n",
      "23312 Traning Loss: tensor(0.7956)\n",
      "23313 Traning Loss: tensor(0.7955)\n",
      "23314 Traning Loss: tensor(0.7955)\n",
      "23315 Traning Loss: tensor(0.7955)\n",
      "23316 Traning Loss: tensor(0.7954)\n",
      "23317 Traning Loss: tensor(0.7954)\n",
      "23318 Traning Loss: tensor(0.7954)\n",
      "23319 Traning Loss: tensor(0.7953)\n",
      "23320 Traning Loss: tensor(0.7953)\n",
      "23321 Traning Loss: tensor(0.7953)\n",
      "23322 Traning Loss: tensor(0.7953)\n",
      "23323 Traning Loss: tensor(0.7952)\n",
      "23324 Traning Loss: tensor(0.7952)\n",
      "23325 Traning Loss: tensor(0.7952)\n",
      "23326 Traning Loss: tensor(0.7951)\n",
      "23327 Traning Loss: tensor(0.7951)\n",
      "23328 Traning Loss: tensor(0.7951)\n",
      "23329 Traning Loss: tensor(0.7950)\n",
      "23330 Traning Loss: tensor(0.7950)\n",
      "23331 Traning Loss: tensor(0.7950)\n",
      "23332 Traning Loss: tensor(0.7949)\n",
      "23333 Traning Loss: tensor(0.7949)\n",
      "23334 Traning Loss: tensor(0.7949)\n",
      "23335 Traning Loss: tensor(0.7948)\n",
      "23336 Traning Loss: tensor(0.7948)\n",
      "23337 Traning Loss: tensor(0.7948)\n",
      "23338 Traning Loss: tensor(0.7947)\n",
      "23339 Traning Loss: tensor(0.7947)\n",
      "23340 Traning Loss: tensor(0.7947)\n",
      "23341 Traning Loss: tensor(0.7947)\n",
      "23342 Traning Loss: tensor(0.7946)\n",
      "23343 Traning Loss: tensor(0.7946)\n",
      "23344 Traning Loss: tensor(0.7946)\n",
      "23345 Traning Loss: tensor(0.7945)\n",
      "23346 Traning Loss: tensor(0.7945)\n",
      "23347 Traning Loss: tensor(0.7945)\n",
      "23348 Traning Loss: tensor(0.7944)\n",
      "23349 Traning Loss: tensor(0.7944)\n",
      "23350 Traning Loss: tensor(0.7944)\n",
      "23351 Traning Loss: tensor(0.7943)\n",
      "23352 Traning Loss: tensor(0.7943)\n",
      "23353 Traning Loss: tensor(0.7943)\n",
      "23354 Traning Loss: tensor(0.7942)\n",
      "23355 Traning Loss: tensor(0.7942)\n",
      "23356 Traning Loss: tensor(0.7942)\n",
      "23357 Traning Loss: tensor(0.7942)\n",
      "23358 Traning Loss: tensor(0.7941)\n",
      "23359 Traning Loss: tensor(0.7941)\n",
      "23360 Traning Loss: tensor(0.7941)\n",
      "23361 Traning Loss: tensor(0.7940)\n",
      "23362 Traning Loss: tensor(0.7940)\n",
      "23363 Traning Loss: tensor(0.7940)\n",
      "23364 Traning Loss: tensor(0.7939)\n",
      "23365 Traning Loss: tensor(0.7939)\n",
      "23366 Traning Loss: tensor(0.7939)\n",
      "23367 Traning Loss: tensor(0.7938)\n",
      "23368 Traning Loss: tensor(0.7938)\n",
      "23369 Traning Loss: tensor(0.7938)\n",
      "23370 Traning Loss: tensor(0.7937)\n",
      "23371 Traning Loss: tensor(0.7937)\n",
      "23372 Traning Loss: tensor(0.7937)\n",
      "23373 Traning Loss: tensor(0.7936)\n",
      "23374 Traning Loss: tensor(0.7936)\n",
      "23375 Traning Loss: tensor(0.7936)\n",
      "23376 Traning Loss: tensor(0.7936)\n",
      "23377 Traning Loss: tensor(0.7935)\n",
      "23378 Traning Loss: tensor(0.7935)\n",
      "23379 Traning Loss: tensor(0.7935)\n",
      "23380 Traning Loss: tensor(0.7934)\n",
      "23381 Traning Loss: tensor(0.7934)\n",
      "23382 Traning Loss: tensor(0.7934)\n",
      "23383 Traning Loss: tensor(0.7933)\n",
      "23384 Traning Loss: tensor(0.7933)\n",
      "23385 Traning Loss: tensor(0.7933)\n",
      "23386 Traning Loss: tensor(0.7932)\n",
      "23387 Traning Loss: tensor(0.7932)\n",
      "23388 Traning Loss: tensor(0.7932)\n",
      "23389 Traning Loss: tensor(0.7931)\n",
      "23390 Traning Loss: tensor(0.7931)\n",
      "23391 Traning Loss: tensor(0.7931)\n",
      "23392 Traning Loss: tensor(0.7930)\n",
      "23393 Traning Loss: tensor(0.7930)\n",
      "23394 Traning Loss: tensor(0.7930)\n",
      "23395 Traning Loss: tensor(0.7930)\n",
      "23396 Traning Loss: tensor(0.7929)\n",
      "23397 Traning Loss: tensor(0.7929)\n",
      "23398 Traning Loss: tensor(0.7929)\n",
      "23399 Traning Loss: tensor(0.7928)\n",
      "23400 Traning Loss: tensor(0.7928)\n",
      "23401 Traning Loss: tensor(0.7928)\n",
      "23402 Traning Loss: tensor(0.7927)\n",
      "23403 Traning Loss: tensor(0.7927)\n",
      "23404 Traning Loss: tensor(0.7927)\n",
      "23405 Traning Loss: tensor(0.7926)\n",
      "23406 Traning Loss: tensor(0.7926)\n",
      "23407 Traning Loss: tensor(0.7926)\n",
      "23408 Traning Loss: tensor(0.7925)\n",
      "23409 Traning Loss: tensor(0.7925)\n",
      "23410 Traning Loss: tensor(0.7925)\n",
      "23411 Traning Loss: tensor(0.7924)\n",
      "23412 Traning Loss: tensor(0.7924)\n",
      "23413 Traning Loss: tensor(0.7924)\n",
      "23414 Traning Loss: tensor(0.7924)\n",
      "23415 Traning Loss: tensor(0.7923)\n",
      "23416 Traning Loss: tensor(0.7923)\n",
      "23417 Traning Loss: tensor(0.7923)\n",
      "23418 Traning Loss: tensor(0.7922)\n",
      "23419 Traning Loss: tensor(0.7922)\n",
      "23420 Traning Loss: tensor(0.7922)\n",
      "23421 Traning Loss: tensor(0.7921)\n",
      "23422 Traning Loss: tensor(0.7921)\n",
      "23423 Traning Loss: tensor(0.7921)\n",
      "23424 Traning Loss: tensor(0.7920)\n",
      "23425 Traning Loss: tensor(0.7920)\n",
      "23426 Traning Loss: tensor(0.7920)\n",
      "23427 Traning Loss: tensor(0.7919)\n",
      "23428 Traning Loss: tensor(0.7919)\n",
      "23429 Traning Loss: tensor(0.7919)\n",
      "23430 Traning Loss: tensor(0.7918)\n",
      "23431 Traning Loss: tensor(0.7918)\n",
      "23432 Traning Loss: tensor(0.7918)\n",
      "23433 Traning Loss: tensor(0.7918)\n",
      "23434 Traning Loss: tensor(0.7917)\n",
      "23435 Traning Loss: tensor(0.7917)\n",
      "23436 Traning Loss: tensor(0.7917)\n",
      "23437 Traning Loss: tensor(0.7916)\n",
      "23438 Traning Loss: tensor(0.7916)\n",
      "23439 Traning Loss: tensor(0.7916)\n",
      "23440 Traning Loss: tensor(0.7915)\n",
      "23441 Traning Loss: tensor(0.7915)\n",
      "23442 Traning Loss: tensor(0.7915)\n",
      "23443 Traning Loss: tensor(0.7914)\n",
      "23444 Traning Loss: tensor(0.7914)\n",
      "23445 Traning Loss: tensor(0.7914)\n",
      "23446 Traning Loss: tensor(0.7913)\n",
      "23447 Traning Loss: tensor(0.7913)\n",
      "23448 Traning Loss: tensor(0.7913)\n",
      "23449 Traning Loss: tensor(0.7912)\n",
      "23450 Traning Loss: tensor(0.7912)\n",
      "23451 Traning Loss: tensor(0.7912)\n",
      "23452 Traning Loss: tensor(0.7911)\n",
      "23453 Traning Loss: tensor(0.7911)\n",
      "23454 Traning Loss: tensor(0.7911)\n",
      "23455 Traning Loss: tensor(0.7911)\n",
      "23456 Traning Loss: tensor(0.7910)\n",
      "23457 Traning Loss: tensor(0.7910)\n",
      "23458 Traning Loss: tensor(0.7910)\n",
      "23459 Traning Loss: tensor(0.7909)\n",
      "23460 Traning Loss: tensor(0.7909)\n",
      "23461 Traning Loss: tensor(0.7909)\n",
      "23462 Traning Loss: tensor(0.7908)\n",
      "23463 Traning Loss: tensor(0.7908)\n",
      "23464 Traning Loss: tensor(0.7908)\n",
      "23465 Traning Loss: tensor(0.7907)\n",
      "23466 Traning Loss: tensor(0.7907)\n",
      "23467 Traning Loss: tensor(0.7907)\n",
      "23468 Traning Loss: tensor(0.7906)\n",
      "23469 Traning Loss: tensor(0.7906)\n",
      "23470 Traning Loss: tensor(0.7906)\n",
      "23471 Traning Loss: tensor(0.7905)\n",
      "23472 Traning Loss: tensor(0.7905)\n",
      "23473 Traning Loss: tensor(0.7905)\n",
      "23474 Traning Loss: tensor(0.7904)\n",
      "23475 Traning Loss: tensor(0.7904)\n",
      "23476 Traning Loss: tensor(0.7904)\n",
      "23477 Traning Loss: tensor(0.7904)\n",
      "23478 Traning Loss: tensor(0.7903)\n",
      "23479 Traning Loss: tensor(0.7903)\n",
      "23480 Traning Loss: tensor(0.7903)\n",
      "23481 Traning Loss: tensor(0.7902)\n",
      "23482 Traning Loss: tensor(0.7902)\n",
      "23483 Traning Loss: tensor(0.7902)\n",
      "23484 Traning Loss: tensor(0.7901)\n",
      "23485 Traning Loss: tensor(0.7901)\n",
      "23486 Traning Loss: tensor(0.7901)\n",
      "23487 Traning Loss: tensor(0.7900)\n",
      "23488 Traning Loss: tensor(0.7900)\n",
      "23489 Traning Loss: tensor(0.7900)\n",
      "23490 Traning Loss: tensor(0.7899)\n",
      "23491 Traning Loss: tensor(0.7899)\n",
      "23492 Traning Loss: tensor(0.7899)\n",
      "23493 Traning Loss: tensor(0.7898)\n",
      "23494 Traning Loss: tensor(0.7898)\n",
      "23495 Traning Loss: tensor(0.7898)\n",
      "23496 Traning Loss: tensor(0.7897)\n",
      "23497 Traning Loss: tensor(0.7897)\n",
      "23498 Traning Loss: tensor(0.7897)\n",
      "23499 Traning Loss: tensor(0.7896)\n",
      "23500 Traning Loss: tensor(0.7896)\n",
      "23501 Traning Loss: tensor(0.7896)\n",
      "23502 Traning Loss: tensor(0.7896)\n",
      "23503 Traning Loss: tensor(0.7895)\n",
      "23504 Traning Loss: tensor(0.7895)\n",
      "23505 Traning Loss: tensor(0.7895)\n",
      "23506 Traning Loss: tensor(0.7894)\n",
      "23507 Traning Loss: tensor(0.7894)\n",
      "23508 Traning Loss: tensor(0.7894)\n",
      "23509 Traning Loss: tensor(0.7893)\n",
      "23510 Traning Loss: tensor(0.7893)\n",
      "23511 Traning Loss: tensor(0.7893)\n",
      "23512 Traning Loss: tensor(0.7892)\n",
      "23513 Traning Loss: tensor(0.7892)\n",
      "23514 Traning Loss: tensor(0.7892)\n",
      "23515 Traning Loss: tensor(0.7891)\n",
      "23516 Traning Loss: tensor(0.7891)\n",
      "23517 Traning Loss: tensor(0.7891)\n",
      "23518 Traning Loss: tensor(0.7890)\n",
      "23519 Traning Loss: tensor(0.7890)\n",
      "23520 Traning Loss: tensor(0.7890)\n",
      "23521 Traning Loss: tensor(0.7889)\n",
      "23522 Traning Loss: tensor(0.7889)\n",
      "23523 Traning Loss: tensor(0.7889)\n",
      "23524 Traning Loss: tensor(0.7888)\n",
      "23525 Traning Loss: tensor(0.7888)\n",
      "23526 Traning Loss: tensor(0.7888)\n",
      "23527 Traning Loss: tensor(0.7887)\n",
      "23528 Traning Loss: tensor(0.7887)\n",
      "23529 Traning Loss: tensor(0.7887)\n",
      "23530 Traning Loss: tensor(0.7886)\n",
      "23531 Traning Loss: tensor(0.7886)\n",
      "23532 Traning Loss: tensor(0.7886)\n",
      "23533 Traning Loss: tensor(0.7885)\n",
      "23534 Traning Loss: tensor(0.7885)\n",
      "23535 Traning Loss: tensor(0.7885)\n",
      "23536 Traning Loss: tensor(0.7885)\n",
      "23537 Traning Loss: tensor(0.7884)\n",
      "23538 Traning Loss: tensor(0.7884)\n",
      "23539 Traning Loss: tensor(0.7884)\n",
      "23540 Traning Loss: tensor(0.7883)\n",
      "23541 Traning Loss: tensor(0.7883)\n",
      "23542 Traning Loss: tensor(0.7883)\n",
      "23543 Traning Loss: tensor(0.7882)\n",
      "23544 Traning Loss: tensor(0.7882)\n",
      "23545 Traning Loss: tensor(0.7882)\n",
      "23546 Traning Loss: tensor(0.7881)\n",
      "23547 Traning Loss: tensor(0.7881)\n",
      "23548 Traning Loss: tensor(0.7881)\n",
      "23549 Traning Loss: tensor(0.7880)\n",
      "23550 Traning Loss: tensor(0.7880)\n",
      "23551 Traning Loss: tensor(0.7880)\n",
      "23552 Traning Loss: tensor(0.7879)\n",
      "23553 Traning Loss: tensor(0.7879)\n",
      "23554 Traning Loss: tensor(0.7879)\n",
      "23555 Traning Loss: tensor(0.7878)\n",
      "23556 Traning Loss: tensor(0.7878)\n",
      "23557 Traning Loss: tensor(0.7878)\n",
      "23558 Traning Loss: tensor(0.7877)\n",
      "23559 Traning Loss: tensor(0.7877)\n",
      "23560 Traning Loss: tensor(0.7877)\n",
      "23561 Traning Loss: tensor(0.7876)\n",
      "23562 Traning Loss: tensor(0.7876)\n",
      "23563 Traning Loss: tensor(0.7876)\n",
      "23564 Traning Loss: tensor(0.7875)\n",
      "23565 Traning Loss: tensor(0.7875)\n",
      "23566 Traning Loss: tensor(0.7875)\n",
      "23567 Traning Loss: tensor(0.7874)\n",
      "23568 Traning Loss: tensor(0.7874)\n",
      "23569 Traning Loss: tensor(0.7874)\n",
      "23570 Traning Loss: tensor(0.7873)\n",
      "23571 Traning Loss: tensor(0.7873)\n",
      "23572 Traning Loss: tensor(0.7873)\n",
      "23573 Traning Loss: tensor(0.7872)\n",
      "23574 Traning Loss: tensor(0.7872)\n",
      "23575 Traning Loss: tensor(0.7872)\n",
      "23576 Traning Loss: tensor(0.7871)\n",
      "23577 Traning Loss: tensor(0.7871)\n",
      "23578 Traning Loss: tensor(0.7871)\n",
      "23579 Traning Loss: tensor(0.7870)\n",
      "23580 Traning Loss: tensor(0.7870)\n",
      "23581 Traning Loss: tensor(0.7870)\n",
      "23582 Traning Loss: tensor(0.7869)\n",
      "23583 Traning Loss: tensor(0.7869)\n",
      "23584 Traning Loss: tensor(0.7869)\n",
      "23585 Traning Loss: tensor(0.7868)\n",
      "23586 Traning Loss: tensor(0.7868)\n",
      "23587 Traning Loss: tensor(0.7868)\n",
      "23588 Traning Loss: tensor(0.7867)\n",
      "23589 Traning Loss: tensor(0.7867)\n",
      "23590 Traning Loss: tensor(0.7867)\n",
      "23591 Traning Loss: tensor(0.7866)\n",
      "23592 Traning Loss: tensor(0.7866)\n",
      "23593 Traning Loss: tensor(0.7866)\n",
      "23594 Traning Loss: tensor(0.7865)\n",
      "23595 Traning Loss: tensor(0.7865)\n",
      "23596 Traning Loss: tensor(0.7865)\n",
      "23597 Traning Loss: tensor(0.7864)\n",
      "23598 Traning Loss: tensor(0.7864)\n",
      "23599 Traning Loss: tensor(0.7864)\n",
      "23600 Traning Loss: tensor(0.7863)\n",
      "23601 Traning Loss: tensor(0.7863)\n",
      "23602 Traning Loss: tensor(0.7863)\n",
      "23603 Traning Loss: tensor(0.7862)\n",
      "23604 Traning Loss: tensor(0.7862)\n",
      "23605 Traning Loss: tensor(0.7862)\n",
      "23606 Traning Loss: tensor(0.7861)\n",
      "23607 Traning Loss: tensor(0.7861)\n",
      "23608 Traning Loss: tensor(0.7861)\n",
      "23609 Traning Loss: tensor(0.7860)\n",
      "23610 Traning Loss: tensor(0.7860)\n",
      "23611 Traning Loss: tensor(0.7860)\n",
      "23612 Traning Loss: tensor(0.7859)\n",
      "23613 Traning Loss: tensor(0.7859)\n",
      "23614 Traning Loss: tensor(0.7859)\n",
      "23615 Traning Loss: tensor(0.7858)\n",
      "23616 Traning Loss: tensor(0.7858)\n",
      "23617 Traning Loss: tensor(0.7858)\n",
      "23618 Traning Loss: tensor(0.7857)\n",
      "23619 Traning Loss: tensor(0.7857)\n",
      "23620 Traning Loss: tensor(0.7857)\n",
      "23621 Traning Loss: tensor(0.7856)\n",
      "23622 Traning Loss: tensor(0.7856)\n",
      "23623 Traning Loss: tensor(0.7856)\n",
      "23624 Traning Loss: tensor(0.7855)\n",
      "23625 Traning Loss: tensor(0.7855)\n",
      "23626 Traning Loss: tensor(0.7855)\n",
      "23627 Traning Loss: tensor(0.7854)\n",
      "23628 Traning Loss: tensor(0.7854)\n",
      "23629 Traning Loss: tensor(0.7854)\n",
      "23630 Traning Loss: tensor(0.7853)\n",
      "23631 Traning Loss: tensor(0.7853)\n",
      "23632 Traning Loss: tensor(0.7853)\n",
      "23633 Traning Loss: tensor(0.7852)\n",
      "23634 Traning Loss: tensor(0.7852)\n",
      "23635 Traning Loss: tensor(0.7852)\n",
      "23636 Traning Loss: tensor(0.7851)\n",
      "23637 Traning Loss: tensor(0.7851)\n",
      "23638 Traning Loss: tensor(0.7851)\n",
      "23639 Traning Loss: tensor(0.7850)\n",
      "23640 Traning Loss: tensor(0.7850)\n",
      "23641 Traning Loss: tensor(0.7850)\n",
      "23642 Traning Loss: tensor(0.7849)\n",
      "23643 Traning Loss: tensor(0.7849)\n",
      "23644 Traning Loss: tensor(0.7849)\n",
      "23645 Traning Loss: tensor(0.7848)\n",
      "23646 Traning Loss: tensor(0.7848)\n",
      "23647 Traning Loss: tensor(0.7848)\n",
      "23648 Traning Loss: tensor(0.7847)\n",
      "23649 Traning Loss: tensor(0.7847)\n",
      "23650 Traning Loss: tensor(0.7846)\n",
      "23651 Traning Loss: tensor(0.7846)\n",
      "23652 Traning Loss: tensor(0.7846)\n",
      "23653 Traning Loss: tensor(0.7845)\n",
      "23654 Traning Loss: tensor(0.7845)\n",
      "23655 Traning Loss: tensor(0.7845)\n",
      "23656 Traning Loss: tensor(0.7844)\n",
      "23657 Traning Loss: tensor(0.7844)\n",
      "23658 Traning Loss: tensor(0.7844)\n",
      "23659 Traning Loss: tensor(0.7843)\n",
      "23660 Traning Loss: tensor(0.7843)\n",
      "23661 Traning Loss: tensor(0.7843)\n",
      "23662 Traning Loss: tensor(0.7842)\n",
      "23663 Traning Loss: tensor(0.7842)\n",
      "23664 Traning Loss: tensor(0.7842)\n",
      "23665 Traning Loss: tensor(0.7841)\n",
      "23666 Traning Loss: tensor(0.7841)\n",
      "23667 Traning Loss: tensor(0.7841)\n",
      "23668 Traning Loss: tensor(0.7840)\n",
      "23669 Traning Loss: tensor(0.7840)\n",
      "23670 Traning Loss: tensor(0.7840)\n",
      "23671 Traning Loss: tensor(0.7839)\n",
      "23672 Traning Loss: tensor(0.7839)\n",
      "23673 Traning Loss: tensor(0.7839)\n",
      "23674 Traning Loss: tensor(0.7838)\n",
      "23675 Traning Loss: tensor(0.7838)\n",
      "23676 Traning Loss: tensor(0.7837)\n",
      "23677 Traning Loss: tensor(0.7837)\n",
      "23678 Traning Loss: tensor(0.7837)\n",
      "23679 Traning Loss: tensor(0.7836)\n",
      "23680 Traning Loss: tensor(0.7836)\n",
      "23681 Traning Loss: tensor(0.7836)\n",
      "23682 Traning Loss: tensor(0.7835)\n",
      "23683 Traning Loss: tensor(0.7835)\n",
      "23684 Traning Loss: tensor(0.7835)\n",
      "23685 Traning Loss: tensor(0.7834)\n",
      "23686 Traning Loss: tensor(0.7834)\n",
      "23687 Traning Loss: tensor(0.7834)\n",
      "23688 Traning Loss: tensor(0.7833)\n",
      "23689 Traning Loss: tensor(0.7833)\n",
      "23690 Traning Loss: tensor(0.7833)\n",
      "23691 Traning Loss: tensor(0.7832)\n",
      "23692 Traning Loss: tensor(0.7832)\n",
      "23693 Traning Loss: tensor(0.7832)\n",
      "23694 Traning Loss: tensor(0.7831)\n",
      "23695 Traning Loss: tensor(0.7831)\n",
      "23696 Traning Loss: tensor(0.7830)\n",
      "23697 Traning Loss: tensor(0.7830)\n",
      "23698 Traning Loss: tensor(0.7830)\n",
      "23699 Traning Loss: tensor(0.7829)\n",
      "23700 Traning Loss: tensor(0.7829)\n",
      "23701 Traning Loss: tensor(0.7829)\n",
      "23702 Traning Loss: tensor(0.7828)\n",
      "23703 Traning Loss: tensor(0.7828)\n",
      "23704 Traning Loss: tensor(0.7828)\n",
      "23705 Traning Loss: tensor(0.7827)\n",
      "23706 Traning Loss: tensor(0.7827)\n",
      "23707 Traning Loss: tensor(0.7827)\n",
      "23708 Traning Loss: tensor(0.7826)\n",
      "23709 Traning Loss: tensor(0.7826)\n",
      "23710 Traning Loss: tensor(0.7825)\n",
      "23711 Traning Loss: tensor(0.7825)\n",
      "23712 Traning Loss: tensor(0.7825)\n",
      "23713 Traning Loss: tensor(0.7824)\n",
      "23714 Traning Loss: tensor(0.7824)\n",
      "23715 Traning Loss: tensor(0.7824)\n",
      "23716 Traning Loss: tensor(0.7823)\n",
      "23717 Traning Loss: tensor(0.7823)\n",
      "23718 Traning Loss: tensor(0.7823)\n",
      "23719 Traning Loss: tensor(0.7822)\n",
      "23720 Traning Loss: tensor(0.7822)\n",
      "23721 Traning Loss: tensor(0.7822)\n",
      "23722 Traning Loss: tensor(0.7821)\n",
      "23723 Traning Loss: tensor(0.7821)\n",
      "23724 Traning Loss: tensor(0.7820)\n",
      "23725 Traning Loss: tensor(0.7820)\n",
      "23726 Traning Loss: tensor(0.7820)\n",
      "23727 Traning Loss: tensor(0.7819)\n",
      "23728 Traning Loss: tensor(0.7819)\n",
      "23729 Traning Loss: tensor(0.7819)\n",
      "23730 Traning Loss: tensor(0.7818)\n",
      "23731 Traning Loss: tensor(0.7818)\n",
      "23732 Traning Loss: tensor(0.7818)\n",
      "23733 Traning Loss: tensor(0.7817)\n",
      "23734 Traning Loss: tensor(0.7817)\n",
      "23735 Traning Loss: tensor(0.7816)\n",
      "23736 Traning Loss: tensor(0.7816)\n",
      "23737 Traning Loss: tensor(0.7816)\n",
      "23738 Traning Loss: tensor(0.7815)\n",
      "23739 Traning Loss: tensor(0.7815)\n",
      "23740 Traning Loss: tensor(0.7815)\n",
      "23741 Traning Loss: tensor(0.7814)\n",
      "23742 Traning Loss: tensor(0.7814)\n",
      "23743 Traning Loss: tensor(0.7814)\n",
      "23744 Traning Loss: tensor(0.7813)\n",
      "23745 Traning Loss: tensor(0.7813)\n",
      "23746 Traning Loss: tensor(0.7812)\n",
      "23747 Traning Loss: tensor(0.7812)\n",
      "23748 Traning Loss: tensor(0.7812)\n",
      "23749 Traning Loss: tensor(0.7811)\n",
      "23750 Traning Loss: tensor(0.7811)\n",
      "23751 Traning Loss: tensor(0.7811)\n",
      "23752 Traning Loss: tensor(0.7810)\n",
      "23753 Traning Loss: tensor(0.7810)\n",
      "23754 Traning Loss: tensor(0.7810)\n",
      "23755 Traning Loss: tensor(0.7809)\n",
      "23756 Traning Loss: tensor(0.7809)\n",
      "23757 Traning Loss: tensor(0.7808)\n",
      "23758 Traning Loss: tensor(0.7808)\n",
      "23759 Traning Loss: tensor(0.7808)\n",
      "23760 Traning Loss: tensor(0.7807)\n",
      "23761 Traning Loss: tensor(0.7807)\n",
      "23762 Traning Loss: tensor(0.7807)\n",
      "23763 Traning Loss: tensor(0.7806)\n",
      "23764 Traning Loss: tensor(0.7806)\n",
      "23765 Traning Loss: tensor(0.7805)\n",
      "23766 Traning Loss: tensor(0.7805)\n",
      "23767 Traning Loss: tensor(0.7805)\n",
      "23768 Traning Loss: tensor(0.7804)\n",
      "23769 Traning Loss: tensor(0.7804)\n",
      "23770 Traning Loss: tensor(0.7804)\n",
      "23771 Traning Loss: tensor(0.7803)\n",
      "23772 Traning Loss: tensor(0.7803)\n",
      "23773 Traning Loss: tensor(0.7802)\n",
      "23774 Traning Loss: tensor(0.7802)\n",
      "23775 Traning Loss: tensor(0.7802)\n",
      "23776 Traning Loss: tensor(0.7801)\n",
      "23777 Traning Loss: tensor(0.7801)\n",
      "23778 Traning Loss: tensor(0.7801)\n",
      "23779 Traning Loss: tensor(0.7800)\n",
      "23780 Traning Loss: tensor(0.7800)\n",
      "23781 Traning Loss: tensor(0.7799)\n",
      "23782 Traning Loss: tensor(0.7799)\n",
      "23783 Traning Loss: tensor(0.7799)\n",
      "23784 Traning Loss: tensor(0.7798)\n",
      "23785 Traning Loss: tensor(0.7798)\n",
      "23786 Traning Loss: tensor(0.7798)\n",
      "23787 Traning Loss: tensor(0.7797)\n",
      "23788 Traning Loss: tensor(0.7797)\n",
      "23789 Traning Loss: tensor(0.7796)\n",
      "23790 Traning Loss: tensor(0.7796)\n",
      "23791 Traning Loss: tensor(0.7796)\n",
      "23792 Traning Loss: tensor(0.7795)\n",
      "23793 Traning Loss: tensor(0.7795)\n",
      "23794 Traning Loss: tensor(0.7795)\n",
      "23795 Traning Loss: tensor(0.7794)\n",
      "23796 Traning Loss: tensor(0.7794)\n",
      "23797 Traning Loss: tensor(0.7793)\n",
      "23798 Traning Loss: tensor(0.7793)\n",
      "23799 Traning Loss: tensor(0.7793)\n",
      "23800 Traning Loss: tensor(0.7792)\n",
      "23801 Traning Loss: tensor(0.7792)\n",
      "23802 Traning Loss: tensor(0.7792)\n",
      "23803 Traning Loss: tensor(0.7791)\n",
      "23804 Traning Loss: tensor(0.7791)\n",
      "23805 Traning Loss: tensor(0.7790)\n",
      "23806 Traning Loss: tensor(0.7790)\n",
      "23807 Traning Loss: tensor(0.7790)\n",
      "23808 Traning Loss: tensor(0.7789)\n",
      "23809 Traning Loss: tensor(0.7789)\n",
      "23810 Traning Loss: tensor(0.7788)\n",
      "23811 Traning Loss: tensor(0.7788)\n",
      "23812 Traning Loss: tensor(0.7788)\n",
      "23813 Traning Loss: tensor(0.7787)\n",
      "23814 Traning Loss: tensor(0.7787)\n",
      "23815 Traning Loss: tensor(0.7787)\n",
      "23816 Traning Loss: tensor(0.7786)\n",
      "23817 Traning Loss: tensor(0.7786)\n",
      "23818 Traning Loss: tensor(0.7785)\n",
      "23819 Traning Loss: tensor(0.7785)\n",
      "23820 Traning Loss: tensor(0.7785)\n",
      "23821 Traning Loss: tensor(0.7784)\n",
      "23822 Traning Loss: tensor(0.7784)\n",
      "23823 Traning Loss: tensor(0.7783)\n",
      "23824 Traning Loss: tensor(0.7783)\n",
      "23825 Traning Loss: tensor(0.7783)\n",
      "23826 Traning Loss: tensor(0.7782)\n",
      "23827 Traning Loss: tensor(0.7782)\n",
      "23828 Traning Loss: tensor(0.7781)\n",
      "23829 Traning Loss: tensor(0.7781)\n",
      "23830 Traning Loss: tensor(0.7781)\n",
      "23831 Traning Loss: tensor(0.7780)\n",
      "23832 Traning Loss: tensor(0.7780)\n",
      "23833 Traning Loss: tensor(0.7780)\n",
      "23834 Traning Loss: tensor(0.7779)\n",
      "23835 Traning Loss: tensor(0.7779)\n",
      "23836 Traning Loss: tensor(0.7778)\n",
      "23837 Traning Loss: tensor(0.7778)\n",
      "23838 Traning Loss: tensor(0.7778)\n",
      "23839 Traning Loss: tensor(0.7777)\n",
      "23840 Traning Loss: tensor(0.7777)\n",
      "23841 Traning Loss: tensor(0.7776)\n",
      "23842 Traning Loss: tensor(0.7776)\n",
      "23843 Traning Loss: tensor(0.7776)\n",
      "23844 Traning Loss: tensor(0.7775)\n",
      "23845 Traning Loss: tensor(0.7775)\n",
      "23846 Traning Loss: tensor(0.7774)\n",
      "23847 Traning Loss: tensor(0.7774)\n",
      "23848 Traning Loss: tensor(0.7774)\n",
      "23849 Traning Loss: tensor(0.7773)\n",
      "23850 Traning Loss: tensor(0.7773)\n",
      "23851 Traning Loss: tensor(0.7772)\n",
      "23852 Traning Loss: tensor(0.7772)\n",
      "23853 Traning Loss: tensor(0.7772)\n",
      "23854 Traning Loss: tensor(0.7771)\n",
      "23855 Traning Loss: tensor(0.7771)\n",
      "23856 Traning Loss: tensor(0.7770)\n",
      "23857 Traning Loss: tensor(0.7770)\n",
      "23858 Traning Loss: tensor(0.7770)\n",
      "23859 Traning Loss: tensor(0.7769)\n",
      "23860 Traning Loss: tensor(0.7769)\n",
      "23861 Traning Loss: tensor(0.7768)\n",
      "23862 Traning Loss: tensor(0.7768)\n",
      "23863 Traning Loss: tensor(0.7768)\n",
      "23864 Traning Loss: tensor(0.7767)\n",
      "23865 Traning Loss: tensor(0.7767)\n",
      "23866 Traning Loss: tensor(0.7766)\n",
      "23867 Traning Loss: tensor(0.7766)\n",
      "23868 Traning Loss: tensor(0.7766)\n",
      "23869 Traning Loss: tensor(0.7765)\n",
      "23870 Traning Loss: tensor(0.7765)\n",
      "23871 Traning Loss: tensor(0.7764)\n",
      "23872 Traning Loss: tensor(0.7764)\n",
      "23873 Traning Loss: tensor(0.7764)\n",
      "23874 Traning Loss: tensor(0.7763)\n",
      "23875 Traning Loss: tensor(0.7763)\n",
      "23876 Traning Loss: tensor(0.7762)\n",
      "23877 Traning Loss: tensor(0.7762)\n",
      "23878 Traning Loss: tensor(0.7762)\n",
      "23879 Traning Loss: tensor(0.7761)\n",
      "23880 Traning Loss: tensor(0.7761)\n",
      "23881 Traning Loss: tensor(0.7760)\n",
      "23882 Traning Loss: tensor(0.7760)\n",
      "23883 Traning Loss: tensor(0.7760)\n",
      "23884 Traning Loss: tensor(0.7759)\n",
      "23885 Traning Loss: tensor(0.7759)\n",
      "23886 Traning Loss: tensor(0.7758)\n",
      "23887 Traning Loss: tensor(0.7758)\n",
      "23888 Traning Loss: tensor(0.7757)\n",
      "23889 Traning Loss: tensor(0.7757)\n",
      "23890 Traning Loss: tensor(0.7757)\n",
      "23891 Traning Loss: tensor(0.7756)\n",
      "23892 Traning Loss: tensor(0.7756)\n",
      "23893 Traning Loss: tensor(0.7755)\n",
      "23894 Traning Loss: tensor(0.7755)\n",
      "23895 Traning Loss: tensor(0.7755)\n",
      "23896 Traning Loss: tensor(0.7754)\n",
      "23897 Traning Loss: tensor(0.7754)\n",
      "23898 Traning Loss: tensor(0.7753)\n",
      "23899 Traning Loss: tensor(0.7753)\n",
      "23900 Traning Loss: tensor(0.7753)\n",
      "23901 Traning Loss: tensor(0.7752)\n",
      "23902 Traning Loss: tensor(0.7752)\n",
      "23903 Traning Loss: tensor(0.7751)\n",
      "23904 Traning Loss: tensor(0.7751)\n",
      "23905 Traning Loss: tensor(0.7750)\n",
      "23906 Traning Loss: tensor(0.7750)\n",
      "23907 Traning Loss: tensor(0.7750)\n",
      "23908 Traning Loss: tensor(0.7749)\n",
      "23909 Traning Loss: tensor(0.7749)\n",
      "23910 Traning Loss: tensor(0.7748)\n",
      "23911 Traning Loss: tensor(0.7748)\n",
      "23912 Traning Loss: tensor(0.7748)\n",
      "23913 Traning Loss: tensor(0.7747)\n",
      "23914 Traning Loss: tensor(0.7747)\n",
      "23915 Traning Loss: tensor(0.7746)\n",
      "23916 Traning Loss: tensor(0.7746)\n",
      "23917 Traning Loss: tensor(0.7745)\n",
      "23918 Traning Loss: tensor(0.7745)\n",
      "23919 Traning Loss: tensor(0.7745)\n",
      "23920 Traning Loss: tensor(0.7744)\n",
      "23921 Traning Loss: tensor(0.7744)\n",
      "23922 Traning Loss: tensor(0.7743)\n",
      "23923 Traning Loss: tensor(0.7743)\n",
      "23924 Traning Loss: tensor(0.7742)\n",
      "23925 Traning Loss: tensor(0.7742)\n",
      "23926 Traning Loss: tensor(0.7742)\n",
      "23927 Traning Loss: tensor(0.7741)\n",
      "23928 Traning Loss: tensor(0.7741)\n",
      "23929 Traning Loss: tensor(0.7740)\n",
      "23930 Traning Loss: tensor(0.7740)\n",
      "23931 Traning Loss: tensor(0.7740)\n",
      "23932 Traning Loss: tensor(0.7739)\n",
      "23933 Traning Loss: tensor(0.7739)\n",
      "23934 Traning Loss: tensor(0.7738)\n",
      "23935 Traning Loss: tensor(0.7738)\n",
      "23936 Traning Loss: tensor(0.7737)\n",
      "23937 Traning Loss: tensor(0.7737)\n",
      "23938 Traning Loss: tensor(0.7737)\n",
      "23939 Traning Loss: tensor(0.7736)\n",
      "23940 Traning Loss: tensor(0.7736)\n",
      "23941 Traning Loss: tensor(0.7735)\n",
      "23942 Traning Loss: tensor(0.7735)\n",
      "23943 Traning Loss: tensor(0.7734)\n",
      "23944 Traning Loss: tensor(0.7734)\n",
      "23945 Traning Loss: tensor(0.7734)\n",
      "23946 Traning Loss: tensor(0.7733)\n",
      "23947 Traning Loss: tensor(0.7733)\n",
      "23948 Traning Loss: tensor(0.7732)\n",
      "23949 Traning Loss: tensor(0.7732)\n",
      "23950 Traning Loss: tensor(0.7731)\n",
      "23951 Traning Loss: tensor(0.7731)\n",
      "23952 Traning Loss: tensor(0.7730)\n",
      "23953 Traning Loss: tensor(0.7730)\n",
      "23954 Traning Loss: tensor(0.7730)\n",
      "23955 Traning Loss: tensor(0.7729)\n",
      "23956 Traning Loss: tensor(0.7729)\n",
      "23957 Traning Loss: tensor(0.7728)\n",
      "23958 Traning Loss: tensor(0.7728)\n",
      "23959 Traning Loss: tensor(0.7727)\n",
      "23960 Traning Loss: tensor(0.7727)\n",
      "23961 Traning Loss: tensor(0.7727)\n",
      "23962 Traning Loss: tensor(0.7726)\n",
      "23963 Traning Loss: tensor(0.7726)\n",
      "23964 Traning Loss: tensor(0.7725)\n",
      "23965 Traning Loss: tensor(0.7725)\n",
      "23966 Traning Loss: tensor(0.7724)\n",
      "23967 Traning Loss: tensor(0.7724)\n",
      "23968 Traning Loss: tensor(0.7723)\n",
      "23969 Traning Loss: tensor(0.7723)\n",
      "23970 Traning Loss: tensor(0.7723)\n",
      "23971 Traning Loss: tensor(0.7722)\n",
      "23972 Traning Loss: tensor(0.7722)\n",
      "23973 Traning Loss: tensor(0.7721)\n",
      "23974 Traning Loss: tensor(0.7721)\n",
      "23975 Traning Loss: tensor(0.7720)\n",
      "23976 Traning Loss: tensor(0.7720)\n",
      "23977 Traning Loss: tensor(0.7720)\n",
      "23978 Traning Loss: tensor(0.7719)\n",
      "23979 Traning Loss: tensor(0.7719)\n",
      "23980 Traning Loss: tensor(0.7718)\n",
      "23981 Traning Loss: tensor(0.7718)\n",
      "23982 Traning Loss: tensor(0.7717)\n",
      "23983 Traning Loss: tensor(0.7717)\n",
      "23984 Traning Loss: tensor(0.7716)\n",
      "23985 Traning Loss: tensor(0.7716)\n",
      "23986 Traning Loss: tensor(0.7716)\n",
      "23987 Traning Loss: tensor(0.7715)\n",
      "23988 Traning Loss: tensor(0.7715)\n",
      "23989 Traning Loss: tensor(0.7714)\n",
      "23990 Traning Loss: tensor(0.7714)\n",
      "23991 Traning Loss: tensor(0.7713)\n",
      "23992 Traning Loss: tensor(0.7713)\n",
      "23993 Traning Loss: tensor(0.7712)\n",
      "23994 Traning Loss: tensor(0.7712)\n",
      "23995 Traning Loss: tensor(0.7711)\n",
      "23996 Traning Loss: tensor(0.7711)\n",
      "23997 Traning Loss: tensor(0.7711)\n",
      "23998 Traning Loss: tensor(0.7710)\n",
      "23999 Traning Loss: tensor(0.7710)\n",
      "24000 Traning Loss: tensor(0.7709)\n",
      "24001 Traning Loss: tensor(0.7709)\n",
      "24002 Traning Loss: tensor(0.7708)\n",
      "24003 Traning Loss: tensor(0.7708)\n",
      "24004 Traning Loss: tensor(0.7707)\n",
      "24005 Traning Loss: tensor(0.7707)\n",
      "24006 Traning Loss: tensor(0.7707)\n",
      "24007 Traning Loss: tensor(0.7706)\n",
      "24008 Traning Loss: tensor(0.7706)\n",
      "24009 Traning Loss: tensor(0.7705)\n",
      "24010 Traning Loss: tensor(0.7705)\n",
      "24011 Traning Loss: tensor(0.7704)\n",
      "24012 Traning Loss: tensor(0.7704)\n",
      "24013 Traning Loss: tensor(0.7703)\n",
      "24014 Traning Loss: tensor(0.7703)\n",
      "24015 Traning Loss: tensor(0.7702)\n",
      "24016 Traning Loss: tensor(0.7702)\n",
      "24017 Traning Loss: tensor(0.7701)\n",
      "24018 Traning Loss: tensor(0.7701)\n",
      "24019 Traning Loss: tensor(0.7701)\n",
      "24020 Traning Loss: tensor(0.7700)\n",
      "24021 Traning Loss: tensor(0.7700)\n",
      "24022 Traning Loss: tensor(0.7699)\n",
      "24023 Traning Loss: tensor(0.7699)\n",
      "24024 Traning Loss: tensor(0.8499)\n",
      "24025 Traning Loss: tensor(0.8499)\n",
      "24026 Traning Loss: tensor(0.8498)\n",
      "24027 Traning Loss: tensor(0.8497)\n",
      "24028 Traning Loss: tensor(0.8496)\n",
      "24029 Traning Loss: tensor(0.8495)\n",
      "24030 Traning Loss: tensor(0.8494)\n",
      "24031 Traning Loss: tensor(0.8494)\n",
      "24032 Traning Loss: tensor(0.8493)\n",
      "24033 Traning Loss: tensor(0.8492)\n",
      "24034 Traning Loss: tensor(0.8492)\n",
      "24035 Traning Loss: tensor(0.8491)\n",
      "24036 Traning Loss: tensor(0.8490)\n",
      "24037 Traning Loss: tensor(0.8489)\n",
      "24038 Traning Loss: tensor(0.8488)\n",
      "24039 Traning Loss: tensor(0.8486)\n",
      "24040 Traning Loss: tensor(0.8485)\n",
      "24041 Traning Loss: tensor(0.8483)\n",
      "24042 Traning Loss: tensor(0.8482)\n",
      "24043 Traning Loss: tensor(0.8481)\n",
      "24044 Traning Loss: tensor(0.8479)\n",
      "24045 Traning Loss: tensor(0.8478)\n",
      "24046 Traning Loss: tensor(0.8477)\n",
      "24047 Traning Loss: tensor(0.8475)\n",
      "24048 Traning Loss: tensor(0.8474)\n",
      "24049 Traning Loss: tensor(0.8473)\n",
      "24050 Traning Loss: tensor(0.8471)\n",
      "24051 Traning Loss: tensor(0.8470)\n",
      "24052 Traning Loss: tensor(0.8469)\n",
      "24053 Traning Loss: tensor(0.8467)\n",
      "24054 Traning Loss: tensor(0.8466)\n",
      "24055 Traning Loss: tensor(0.8464)\n",
      "24056 Traning Loss: tensor(0.8463)\n",
      "24057 Traning Loss: tensor(0.8461)\n",
      "24058 Traning Loss: tensor(0.8460)\n",
      "24059 Traning Loss: tensor(0.8459)\n",
      "24060 Traning Loss: tensor(0.8457)\n",
      "24061 Traning Loss: tensor(0.8456)\n",
      "24062 Traning Loss: tensor(0.8454)\n",
      "24063 Traning Loss: tensor(0.8453)\n",
      "24064 Traning Loss: tensor(0.8452)\n",
      "24065 Traning Loss: tensor(0.8450)\n",
      "24066 Traning Loss: tensor(0.8449)\n",
      "24067 Traning Loss: tensor(0.8448)\n",
      "24068 Traning Loss: tensor(0.8446)\n",
      "24069 Traning Loss: tensor(0.8445)\n",
      "24070 Traning Loss: tensor(0.8443)\n",
      "24071 Traning Loss: tensor(0.8442)\n",
      "24072 Traning Loss: tensor(0.8441)\n",
      "24073 Traning Loss: tensor(0.8439)\n",
      "24074 Traning Loss: tensor(0.8438)\n",
      "24075 Traning Loss: tensor(0.8437)\n",
      "24076 Traning Loss: tensor(0.8435)\n",
      "24077 Traning Loss: tensor(0.8434)\n",
      "24078 Traning Loss: tensor(0.8433)\n",
      "24079 Traning Loss: tensor(0.8431)\n",
      "24080 Traning Loss: tensor(0.8430)\n",
      "24081 Traning Loss: tensor(0.8429)\n",
      "24082 Traning Loss: tensor(0.8428)\n",
      "24083 Traning Loss: tensor(0.8426)\n",
      "24084 Traning Loss: tensor(0.8425)\n",
      "24085 Traning Loss: tensor(0.8424)\n",
      "24086 Traning Loss: tensor(0.8422)\n",
      "24087 Traning Loss: tensor(0.8421)\n",
      "24088 Traning Loss: tensor(0.8420)\n",
      "24089 Traning Loss: tensor(0.8419)\n",
      "24090 Traning Loss: tensor(0.8417)\n",
      "24091 Traning Loss: tensor(0.8416)\n",
      "24092 Traning Loss: tensor(0.8415)\n",
      "24093 Traning Loss: tensor(0.8414)\n",
      "24094 Traning Loss: tensor(0.8413)\n",
      "24095 Traning Loss: tensor(0.8411)\n",
      "24096 Traning Loss: tensor(0.8410)\n",
      "24097 Traning Loss: tensor(0.8409)\n",
      "24098 Traning Loss: tensor(0.8408)\n",
      "24099 Traning Loss: tensor(0.8406)\n",
      "24100 Traning Loss: tensor(0.8405)\n",
      "24101 Traning Loss: tensor(0.8404)\n",
      "24102 Traning Loss: tensor(0.8403)\n",
      "24103 Traning Loss: tensor(0.8402)\n",
      "24104 Traning Loss: tensor(0.8401)\n",
      "24105 Traning Loss: tensor(0.8399)\n",
      "24106 Traning Loss: tensor(0.8398)\n",
      "24107 Traning Loss: tensor(0.8397)\n",
      "24108 Traning Loss: tensor(0.8396)\n",
      "24109 Traning Loss: tensor(0.8395)\n",
      "24110 Traning Loss: tensor(0.8394)\n",
      "24111 Traning Loss: tensor(0.8392)\n",
      "24112 Traning Loss: tensor(0.8391)\n",
      "24113 Traning Loss: tensor(0.8390)\n",
      "24114 Traning Loss: tensor(0.8389)\n",
      "24115 Traning Loss: tensor(0.8388)\n",
      "24116 Traning Loss: tensor(0.8387)\n",
      "24117 Traning Loss: tensor(0.8386)\n",
      "24118 Traning Loss: tensor(0.8385)\n",
      "24119 Traning Loss: tensor(0.8384)\n",
      "24120 Traning Loss: tensor(0.8382)\n",
      "24121 Traning Loss: tensor(0.8381)\n",
      "24122 Traning Loss: tensor(0.8380)\n",
      "24123 Traning Loss: tensor(0.8379)\n",
      "24124 Traning Loss: tensor(0.8378)\n",
      "24125 Traning Loss: tensor(0.8377)\n",
      "24126 Traning Loss: tensor(0.8376)\n",
      "24127 Traning Loss: tensor(0.8375)\n",
      "24128 Traning Loss: tensor(0.8374)\n",
      "24129 Traning Loss: tensor(0.8373)\n",
      "24130 Traning Loss: tensor(0.8372)\n",
      "24131 Traning Loss: tensor(0.8371)\n",
      "24132 Traning Loss: tensor(0.8370)\n",
      "24133 Traning Loss: tensor(0.8369)\n",
      "24134 Traning Loss: tensor(0.8368)\n",
      "24135 Traning Loss: tensor(0.8367)\n",
      "24136 Traning Loss: tensor(0.8365)\n",
      "24137 Traning Loss: tensor(0.8364)\n",
      "24138 Traning Loss: tensor(0.8363)\n",
      "24139 Traning Loss: tensor(0.8362)\n",
      "24140 Traning Loss: tensor(0.8361)\n",
      "24141 Traning Loss: tensor(0.8360)\n",
      "24142 Traning Loss: tensor(0.8359)\n",
      "24143 Traning Loss: tensor(0.8358)\n",
      "24144 Traning Loss: tensor(0.8357)\n",
      "24145 Traning Loss: tensor(0.8356)\n",
      "24146 Traning Loss: tensor(0.8355)\n",
      "24147 Traning Loss: tensor(0.8354)\n",
      "24148 Traning Loss: tensor(0.8353)\n",
      "24149 Traning Loss: tensor(0.8353)\n",
      "24150 Traning Loss: tensor(0.8352)\n",
      "24151 Traning Loss: tensor(0.8351)\n",
      "24152 Traning Loss: tensor(0.8350)\n",
      "24153 Traning Loss: tensor(0.8349)\n",
      "24154 Traning Loss: tensor(0.8348)\n",
      "24155 Traning Loss: tensor(0.8347)\n",
      "24156 Traning Loss: tensor(0.8502)\n",
      "24157 Traning Loss: tensor(0.8502)\n",
      "24158 Traning Loss: tensor(0.8502)\n",
      "24159 Traning Loss: tensor(0.8501)\n",
      "24160 Traning Loss: tensor(0.8501)\n",
      "24161 Traning Loss: tensor(0.8501)\n",
      "24162 Traning Loss: tensor(0.8501)\n",
      "24163 Traning Loss: tensor(0.8501)\n",
      "24164 Traning Loss: tensor(0.8501)\n",
      "24165 Traning Loss: tensor(0.8500)\n",
      "24166 Traning Loss: tensor(0.8500)\n",
      "24167 Traning Loss: tensor(0.8500)\n",
      "24168 Traning Loss: tensor(0.8500)\n",
      "24169 Traning Loss: tensor(0.8500)\n",
      "24170 Traning Loss: tensor(0.8500)\n",
      "24171 Traning Loss: tensor(0.8500)\n",
      "24172 Traning Loss: tensor(0.8499)\n",
      "24173 Traning Loss: tensor(0.8499)\n",
      "24174 Traning Loss: tensor(0.8499)\n",
      "24175 Traning Loss: tensor(0.8499)\n",
      "24176 Traning Loss: tensor(0.8499)\n",
      "24177 Traning Loss: tensor(0.8499)\n",
      "24178 Traning Loss: tensor(0.8499)\n",
      "24179 Traning Loss: tensor(0.8499)\n",
      "24180 Traning Loss: tensor(0.8499)\n",
      "24181 Traning Loss: tensor(0.8499)\n",
      "24182 Traning Loss: tensor(0.8499)\n",
      "24183 Traning Loss: tensor(0.8499)\n",
      "24184 Traning Loss: tensor(0.8498)\n",
      "24185 Traning Loss: tensor(0.8498)\n",
      "24186 Traning Loss: tensor(0.8498)\n",
      "24187 Traning Loss: tensor(0.8498)\n",
      "24188 Traning Loss: tensor(0.8498)\n",
      "24189 Traning Loss: tensor(0.8498)\n",
      "24190 Traning Loss: tensor(0.8498)\n",
      "24191 Traning Loss: tensor(0.8498)\n",
      "24192 Traning Loss: tensor(0.8498)\n",
      "24193 Traning Loss: tensor(0.8498)\n",
      "24194 Traning Loss: tensor(0.8498)\n",
      "24195 Traning Loss: tensor(0.8498)\n",
      "24196 Traning Loss: tensor(0.8498)\n",
      "24197 Traning Loss: tensor(0.8498)\n",
      "24198 Traning Loss: tensor(0.8498)\n",
      "24199 Traning Loss: tensor(0.8497)\n",
      "24200 Traning Loss: tensor(0.8497)\n",
      "24201 Traning Loss: tensor(0.8497)\n",
      "24202 Traning Loss: tensor(0.8497)\n",
      "24203 Traning Loss: tensor(0.8497)\n",
      "24204 Traning Loss: tensor(0.8497)\n",
      "24205 Traning Loss: tensor(0.8497)\n",
      "24206 Traning Loss: tensor(0.8497)\n",
      "24207 Traning Loss: tensor(0.8497)\n",
      "24208 Traning Loss: tensor(0.8497)\n",
      "24209 Traning Loss: tensor(0.8497)\n",
      "24210 Traning Loss: tensor(0.8497)\n",
      "24211 Traning Loss: tensor(0.8497)\n",
      "24212 Traning Loss: tensor(0.8497)\n",
      "24213 Traning Loss: tensor(0.8497)\n",
      "24214 Traning Loss: tensor(0.8497)\n",
      "24215 Traning Loss: tensor(0.8497)\n",
      "24216 Traning Loss: tensor(0.8496)\n",
      "24217 Traning Loss: tensor(0.8496)\n",
      "24218 Traning Loss: tensor(0.8496)\n",
      "24219 Traning Loss: tensor(0.8496)\n",
      "24220 Traning Loss: tensor(0.8496)\n",
      "24221 Traning Loss: tensor(0.8496)\n",
      "24222 Traning Loss: tensor(0.8496)\n",
      "24223 Traning Loss: tensor(0.8496)\n",
      "24224 Traning Loss: tensor(0.8496)\n",
      "24225 Traning Loss: tensor(0.8496)\n",
      "24226 Traning Loss: tensor(0.8496)\n",
      "24227 Traning Loss: tensor(0.8496)\n",
      "24228 Traning Loss: tensor(0.8496)\n",
      "24229 Traning Loss: tensor(0.8496)\n",
      "24230 Traning Loss: tensor(0.8496)\n",
      "24231 Traning Loss: tensor(0.8496)\n",
      "24232 Traning Loss: tensor(0.8496)\n",
      "24233 Traning Loss: tensor(0.8496)\n",
      "24234 Traning Loss: tensor(0.8496)\n",
      "24235 Traning Loss: tensor(0.8496)\n",
      "24236 Traning Loss: tensor(0.8495)\n",
      "24237 Traning Loss: tensor(0.8495)\n",
      "24238 Traning Loss: tensor(0.8495)\n",
      "24239 Traning Loss: tensor(0.8495)\n",
      "24240 Traning Loss: tensor(0.8495)\n",
      "24241 Traning Loss: tensor(0.8495)\n",
      "24242 Traning Loss: tensor(0.8495)\n",
      "24243 Traning Loss: tensor(0.8495)\n",
      "24244 Traning Loss: tensor(0.8495)\n",
      "24245 Traning Loss: tensor(0.8495)\n",
      "24246 Traning Loss: tensor(0.8495)\n",
      "24247 Traning Loss: tensor(0.8495)\n",
      "24248 Traning Loss: tensor(0.8495)\n",
      "24249 Traning Loss: tensor(0.8495)\n",
      "24250 Traning Loss: tensor(0.8495)\n",
      "24251 Traning Loss: tensor(0.8495)\n",
      "24252 Traning Loss: tensor(0.8495)\n",
      "24253 Traning Loss: tensor(0.8495)\n",
      "24254 Traning Loss: tensor(0.8495)\n",
      "24255 Traning Loss: tensor(0.8495)\n",
      "24256 Traning Loss: tensor(0.8495)\n",
      "24257 Traning Loss: tensor(0.8495)\n",
      "24258 Traning Loss: tensor(0.8494)\n",
      "24259 Traning Loss: tensor(0.8494)\n",
      "24260 Traning Loss: tensor(0.8494)\n",
      "24261 Traning Loss: tensor(0.8494)\n",
      "24262 Traning Loss: tensor(0.8494)\n",
      "24263 Traning Loss: tensor(0.8494)\n",
      "24264 Traning Loss: tensor(0.8494)\n",
      "24265 Traning Loss: tensor(0.8494)\n",
      "24266 Traning Loss: tensor(0.8494)\n",
      "24267 Traning Loss: tensor(0.8494)\n",
      "24268 Traning Loss: tensor(0.8494)\n",
      "24269 Traning Loss: tensor(0.8494)\n",
      "24270 Traning Loss: tensor(0.8494)\n",
      "24271 Traning Loss: tensor(0.8494)\n",
      "24272 Traning Loss: tensor(0.8494)\n",
      "24273 Traning Loss: tensor(0.8494)\n",
      "24274 Traning Loss: tensor(0.8494)\n",
      "24275 Traning Loss: tensor(0.8494)\n",
      "24276 Traning Loss: tensor(0.8494)\n",
      "24277 Traning Loss: tensor(0.8494)\n",
      "24278 Traning Loss: tensor(0.8494)\n",
      "24279 Traning Loss: tensor(0.8494)\n",
      "24280 Traning Loss: tensor(0.8494)\n",
      "24281 Traning Loss: tensor(0.8494)\n",
      "24282 Traning Loss: tensor(0.8494)\n",
      "24283 Traning Loss: tensor(0.8494)\n",
      "24284 Traning Loss: tensor(0.8493)\n",
      "24285 Traning Loss: tensor(0.8493)\n",
      "24286 Traning Loss: tensor(0.8493)\n",
      "24287 Traning Loss: tensor(0.8493)\n",
      "24288 Traning Loss: tensor(0.8493)\n",
      "24289 Traning Loss: tensor(0.8493)\n",
      "24290 Traning Loss: tensor(0.8493)\n",
      "24291 Traning Loss: tensor(0.8493)\n",
      "24292 Traning Loss: tensor(0.8493)\n",
      "24293 Traning Loss: tensor(0.8493)\n",
      "24294 Traning Loss: tensor(0.8493)\n",
      "24295 Traning Loss: tensor(0.8493)\n",
      "24296 Traning Loss: tensor(0.8493)\n",
      "24297 Traning Loss: tensor(0.8493)\n",
      "24298 Traning Loss: tensor(0.8493)\n",
      "24299 Traning Loss: tensor(0.8493)\n",
      "24300 Traning Loss: tensor(0.8493)\n",
      "24301 Traning Loss: tensor(0.8493)\n",
      "24302 Traning Loss: tensor(0.8493)\n",
      "24303 Traning Loss: tensor(0.8493)\n",
      "24304 Traning Loss: tensor(0.8493)\n",
      "24305 Traning Loss: tensor(0.8493)\n",
      "24306 Traning Loss: tensor(0.8493)\n",
      "24307 Traning Loss: tensor(0.8493)\n",
      "24308 Traning Loss: tensor(0.8493)\n",
      "24309 Traning Loss: tensor(0.8493)\n",
      "24310 Traning Loss: tensor(0.8493)\n",
      "24311 Traning Loss: tensor(0.8493)\n",
      "24312 Traning Loss: tensor(0.8493)\n",
      "24313 Traning Loss: tensor(0.8493)\n",
      "24314 Traning Loss: tensor(0.8492)\n",
      "24315 Traning Loss: tensor(0.8492)\n",
      "24316 Traning Loss: tensor(0.8492)\n",
      "24317 Traning Loss: tensor(0.8492)\n",
      "24318 Traning Loss: tensor(0.8492)\n",
      "24319 Traning Loss: tensor(0.8492)\n",
      "24320 Traning Loss: tensor(0.8492)\n",
      "24321 Traning Loss: tensor(0.8492)\n",
      "24322 Traning Loss: tensor(0.8492)\n",
      "24323 Traning Loss: tensor(0.8492)\n",
      "24324 Traning Loss: tensor(0.8492)\n",
      "24325 Traning Loss: tensor(0.8492)\n",
      "24326 Traning Loss: tensor(0.8492)\n",
      "24327 Traning Loss: tensor(0.8492)\n",
      "24328 Traning Loss: tensor(0.8492)\n",
      "24329 Traning Loss: tensor(0.8492)\n",
      "24330 Traning Loss: tensor(0.8492)\n",
      "24331 Traning Loss: tensor(0.8492)\n",
      "24332 Traning Loss: tensor(0.8492)\n",
      "24333 Traning Loss: tensor(0.8492)\n",
      "24334 Traning Loss: tensor(0.8492)\n",
      "24335 Traning Loss: tensor(0.8492)\n",
      "24336 Traning Loss: tensor(0.8492)\n",
      "24337 Traning Loss: tensor(0.8492)\n",
      "24338 Traning Loss: tensor(0.8492)\n",
      "24339 Traning Loss: tensor(0.8492)\n",
      "24340 Traning Loss: tensor(0.8492)\n",
      "24341 Traning Loss: tensor(0.8492)\n",
      "24342 Traning Loss: tensor(0.8492)\n",
      "24343 Traning Loss: tensor(0.8492)\n",
      "24344 Traning Loss: tensor(0.8492)\n",
      "24345 Traning Loss: tensor(0.8492)\n",
      "24346 Traning Loss: tensor(0.8492)\n",
      "24347 Traning Loss: tensor(0.8492)\n",
      "24348 Traning Loss: tensor(0.8492)\n",
      "24349 Traning Loss: tensor(0.8492)\n",
      "24350 Traning Loss: tensor(0.8491)\n",
      "24351 Traning Loss: tensor(0.8491)\n",
      "24352 Traning Loss: tensor(0.8491)\n",
      "24353 Traning Loss: tensor(0.8491)\n",
      "24354 Traning Loss: tensor(0.8491)\n",
      "24355 Traning Loss: tensor(0.8491)\n",
      "24356 Traning Loss: tensor(0.8491)\n",
      "24357 Traning Loss: tensor(0.8491)\n",
      "24358 Traning Loss: tensor(0.8491)\n",
      "24359 Traning Loss: tensor(0.8491)\n",
      "24360 Traning Loss: tensor(0.8491)\n",
      "24361 Traning Loss: tensor(0.8491)\n",
      "24362 Traning Loss: tensor(0.8491)\n",
      "24363 Traning Loss: tensor(0.8491)\n",
      "24364 Traning Loss: tensor(0.8491)\n",
      "24365 Traning Loss: tensor(0.8491)\n",
      "24366 Traning Loss: tensor(0.8491)\n",
      "24367 Traning Loss: tensor(0.8491)\n",
      "24368 Traning Loss: tensor(0.8491)\n",
      "24369 Traning Loss: tensor(0.8491)\n",
      "24370 Traning Loss: tensor(0.8491)\n",
      "24371 Traning Loss: tensor(0.8491)\n",
      "24372 Traning Loss: tensor(0.8491)\n",
      "24373 Traning Loss: tensor(0.8491)\n",
      "24374 Traning Loss: tensor(0.8491)\n",
      "24375 Traning Loss: tensor(0.8491)\n",
      "24376 Traning Loss: tensor(0.8491)\n",
      "24377 Traning Loss: tensor(0.8491)\n",
      "24378 Traning Loss: tensor(0.8491)\n",
      "24379 Traning Loss: tensor(0.8491)\n",
      "24380 Traning Loss: tensor(0.8491)\n",
      "24381 Traning Loss: tensor(0.8491)\n",
      "24382 Traning Loss: tensor(0.8491)\n",
      "24383 Traning Loss: tensor(0.8491)\n",
      "24384 Traning Loss: tensor(0.8491)\n",
      "24385 Traning Loss: tensor(0.8491)\n",
      "24386 Traning Loss: tensor(0.8491)\n",
      "24387 Traning Loss: tensor(0.8491)\n",
      "24388 Traning Loss: tensor(0.8491)\n",
      "24389 Traning Loss: tensor(0.8491)\n",
      "24390 Traning Loss: tensor(0.8491)\n",
      "24391 Traning Loss: tensor(0.8491)\n",
      "24392 Traning Loss: tensor(0.8491)\n",
      "24393 Traning Loss: tensor(0.8491)\n",
      "24394 Traning Loss: tensor(0.8491)\n",
      "24395 Traning Loss: tensor(0.8491)\n",
      "24396 Traning Loss: tensor(0.8491)\n",
      "24397 Traning Loss: tensor(0.8490)\n",
      "24398 Traning Loss: tensor(0.8490)\n",
      "24399 Traning Loss: tensor(0.8490)\n",
      "24400 Traning Loss: tensor(0.8490)\n",
      "24401 Traning Loss: tensor(0.8490)\n",
      "24402 Traning Loss: tensor(0.8490)\n",
      "24403 Traning Loss: tensor(0.8490)\n",
      "24404 Traning Loss: tensor(0.8490)\n",
      "24405 Traning Loss: tensor(0.8490)\n",
      "24406 Traning Loss: tensor(0.8490)\n",
      "24407 Traning Loss: tensor(0.8490)\n",
      "24408 Traning Loss: tensor(0.8490)\n",
      "24409 Traning Loss: tensor(0.8490)\n",
      "24410 Traning Loss: tensor(0.8490)\n",
      "24411 Traning Loss: tensor(0.8490)\n",
      "24412 Traning Loss: tensor(0.8490)\n",
      "24413 Traning Loss: tensor(0.8490)\n",
      "24414 Traning Loss: tensor(0.8490)\n",
      "24415 Traning Loss: tensor(0.8490)\n",
      "24416 Traning Loss: tensor(0.8490)\n",
      "24417 Traning Loss: tensor(0.8490)\n",
      "24418 Traning Loss: tensor(0.8490)\n",
      "24419 Traning Loss: tensor(0.8490)\n",
      "24420 Traning Loss: tensor(0.8490)\n",
      "24421 Traning Loss: tensor(0.8490)\n",
      "24422 Traning Loss: tensor(0.8490)\n",
      "24423 Traning Loss: tensor(0.8490)\n",
      "24424 Traning Loss: tensor(0.8490)\n",
      "24425 Traning Loss: tensor(0.8490)\n",
      "24426 Traning Loss: tensor(0.8490)\n",
      "24427 Traning Loss: tensor(0.8490)\n",
      "24428 Traning Loss: tensor(0.8490)\n",
      "24429 Traning Loss: tensor(0.8490)\n",
      "24430 Traning Loss: tensor(0.8490)\n",
      "24431 Traning Loss: tensor(0.8490)\n",
      "24432 Traning Loss: tensor(0.8490)\n",
      "24433 Traning Loss: tensor(0.8490)\n",
      "24434 Traning Loss: tensor(0.8490)\n",
      "24435 Traning Loss: tensor(0.8490)\n",
      "24436 Traning Loss: tensor(0.8490)\n",
      "24437 Traning Loss: tensor(0.8490)\n",
      "24438 Traning Loss: tensor(0.8490)\n",
      "24439 Traning Loss: tensor(0.8490)\n",
      "24440 Traning Loss: tensor(0.8490)\n",
      "24441 Traning Loss: tensor(0.8490)\n",
      "24442 Traning Loss: tensor(0.8490)\n",
      "24443 Traning Loss: tensor(0.8490)\n",
      "24444 Traning Loss: tensor(0.8490)\n",
      "24445 Traning Loss: tensor(0.8490)\n",
      "24446 Traning Loss: tensor(0.8490)\n",
      "24447 Traning Loss: tensor(0.8490)\n",
      "24448 Traning Loss: tensor(0.8490)\n",
      "24449 Traning Loss: tensor(0.8490)\n",
      "24450 Traning Loss: tensor(0.8490)\n",
      "24451 Traning Loss: tensor(0.8490)\n",
      "24452 Traning Loss: tensor(0.8490)\n",
      "24453 Traning Loss: tensor(0.8490)\n",
      "24454 Traning Loss: tensor(0.8490)\n",
      "24455 Traning Loss: tensor(0.8490)\n",
      "24456 Traning Loss: tensor(0.8490)\n",
      "24457 Traning Loss: tensor(0.8490)\n",
      "24458 Traning Loss: tensor(0.8490)\n",
      "24459 Traning Loss: tensor(0.8490)\n",
      "24460 Traning Loss: tensor(0.8489)\n",
      "24461 Traning Loss: tensor(0.8489)\n",
      "24462 Traning Loss: tensor(0.8489)\n",
      "24463 Traning Loss: tensor(0.8489)\n",
      "24464 Traning Loss: tensor(0.8489)\n",
      "24465 Traning Loss: tensor(0.8489)\n",
      "24466 Traning Loss: tensor(0.8489)\n",
      "24467 Traning Loss: tensor(0.8489)\n",
      "24468 Traning Loss: tensor(0.8489)\n",
      "24469 Traning Loss: tensor(0.8489)\n",
      "24470 Traning Loss: tensor(0.8489)\n",
      "24471 Traning Loss: tensor(0.8489)\n",
      "24472 Traning Loss: tensor(0.8489)\n",
      "24473 Traning Loss: tensor(0.8489)\n",
      "24474 Traning Loss: tensor(0.8489)\n",
      "24475 Traning Loss: tensor(0.8489)\n",
      "24476 Traning Loss: tensor(0.8489)\n",
      "24477 Traning Loss: tensor(0.8489)\n",
      "24478 Traning Loss: tensor(0.8489)\n",
      "24479 Traning Loss: tensor(0.8489)\n",
      "24480 Traning Loss: tensor(0.8489)\n",
      "24481 Traning Loss: tensor(0.8489)\n",
      "24482 Traning Loss: tensor(0.8489)\n",
      "24483 Traning Loss: tensor(0.8489)\n",
      "24484 Traning Loss: tensor(0.8489)\n",
      "24485 Traning Loss: tensor(0.8489)\n",
      "24486 Traning Loss: tensor(0.8489)\n",
      "24487 Traning Loss: tensor(0.8489)\n",
      "24488 Traning Loss: tensor(0.8489)\n",
      "24489 Traning Loss: tensor(0.8489)\n",
      "24490 Traning Loss: tensor(0.8489)\n",
      "24491 Traning Loss: tensor(0.8489)\n",
      "24492 Traning Loss: tensor(0.8489)\n",
      "24493 Traning Loss: tensor(0.8489)\n",
      "24494 Traning Loss: tensor(0.8489)\n",
      "24495 Traning Loss: tensor(0.8489)\n",
      "24496 Traning Loss: tensor(0.8489)\n",
      "24497 Traning Loss: tensor(0.8489)\n",
      "24498 Traning Loss: tensor(0.8489)\n",
      "24499 Traning Loss: tensor(0.8489)\n",
      "24500 Traning Loss: tensor(0.8489)\n",
      "24501 Traning Loss: tensor(0.8489)\n",
      "24502 Traning Loss: tensor(0.8489)\n",
      "24503 Traning Loss: tensor(0.8489)\n",
      "24504 Traning Loss: tensor(0.8489)\n",
      "24505 Traning Loss: tensor(0.8489)\n",
      "24506 Traning Loss: tensor(0.8489)\n",
      "24507 Traning Loss: tensor(0.8489)\n",
      "24508 Traning Loss: tensor(0.8489)\n",
      "24509 Traning Loss: tensor(0.8489)\n",
      "24510 Traning Loss: tensor(0.8489)\n",
      "24511 Traning Loss: tensor(0.8489)\n",
      "24512 Traning Loss: tensor(0.8489)\n",
      "24513 Traning Loss: tensor(0.8489)\n",
      "24514 Traning Loss: tensor(0.8489)\n",
      "24515 Traning Loss: tensor(0.8489)\n",
      "24516 Traning Loss: tensor(0.8489)\n",
      "24517 Traning Loss: tensor(0.8489)\n",
      "24518 Traning Loss: tensor(0.8489)\n",
      "24519 Traning Loss: tensor(0.8489)\n",
      "24520 Traning Loss: tensor(0.8489)\n",
      "24521 Traning Loss: tensor(0.8489)\n",
      "24522 Traning Loss: tensor(0.8489)\n",
      "24523 Traning Loss: tensor(0.8489)\n",
      "24524 Traning Loss: tensor(0.8489)\n",
      "24525 Traning Loss: tensor(0.8489)\n",
      "24526 Traning Loss: tensor(0.8489)\n",
      "24527 Traning Loss: tensor(0.8489)\n",
      "24528 Traning Loss: tensor(0.8489)\n",
      "24529 Traning Loss: tensor(0.8489)\n",
      "24530 Traning Loss: tensor(0.8489)\n",
      "24531 Traning Loss: tensor(0.8489)\n",
      "24532 Traning Loss: tensor(0.8489)\n",
      "24533 Traning Loss: tensor(0.8489)\n",
      "24534 Traning Loss: tensor(0.8489)\n",
      "24535 Traning Loss: tensor(0.8489)\n",
      "24536 Traning Loss: tensor(0.8489)\n",
      "24537 Traning Loss: tensor(0.8489)\n",
      "24538 Traning Loss: tensor(0.8489)\n",
      "24539 Traning Loss: tensor(0.8489)\n",
      "24540 Traning Loss: tensor(0.8489)\n",
      "24541 Traning Loss: tensor(0.8489)\n",
      "24542 Traning Loss: tensor(0.8489)\n",
      "24543 Traning Loss: tensor(0.8489)\n",
      "24544 Traning Loss: tensor(0.8489)\n",
      "24545 Traning Loss: tensor(0.8489)\n",
      "24546 Traning Loss: tensor(0.8489)\n",
      "24547 Traning Loss: tensor(0.8489)\n",
      "24548 Traning Loss: tensor(0.8489)\n",
      "24549 Traning Loss: tensor(0.8489)\n",
      "24550 Traning Loss: tensor(0.8489)\n",
      "24551 Traning Loss: tensor(0.8489)\n",
      "24552 Traning Loss: tensor(0.8489)\n",
      "24553 Traning Loss: tensor(0.8489)\n",
      "24554 Traning Loss: tensor(0.8489)\n",
      "24555 Traning Loss: tensor(0.8489)\n",
      "24556 Traning Loss: tensor(0.8489)\n",
      "24557 Traning Loss: tensor(0.8489)\n",
      "24558 Traning Loss: tensor(0.8489)\n",
      "24559 Traning Loss: tensor(0.8489)\n",
      "24560 Traning Loss: tensor(0.8489)\n",
      "24561 Traning Loss: tensor(0.8489)\n",
      "24562 Traning Loss: tensor(0.8489)\n",
      "24563 Traning Loss: tensor(0.8489)\n",
      "24564 Traning Loss: tensor(0.8489)\n",
      "24565 Traning Loss: tensor(0.8488)\n",
      "24566 Traning Loss: tensor(0.8488)\n",
      "24567 Traning Loss: tensor(0.8488)\n",
      "24568 Traning Loss: tensor(0.8488)\n",
      "24569 Traning Loss: tensor(0.8488)\n",
      "24570 Traning Loss: tensor(0.8488)\n",
      "24571 Traning Loss: tensor(0.8488)\n",
      "24572 Traning Loss: tensor(0.8488)\n",
      "24573 Traning Loss: tensor(0.8488)\n",
      "24574 Traning Loss: tensor(0.8488)\n",
      "24575 Traning Loss: tensor(0.8488)\n",
      "24576 Traning Loss: tensor(0.8488)\n",
      "24577 Traning Loss: tensor(0.8488)\n",
      "24578 Traning Loss: tensor(0.8488)\n",
      "24579 Traning Loss: tensor(0.8488)\n",
      "24580 Traning Loss: tensor(0.8488)\n",
      "24581 Traning Loss: tensor(0.8488)\n",
      "24582 Traning Loss: tensor(0.8488)\n",
      "24583 Traning Loss: tensor(0.8488)\n",
      "24584 Traning Loss: tensor(0.8488)\n",
      "24585 Traning Loss: tensor(0.8488)\n",
      "24586 Traning Loss: tensor(0.8488)\n",
      "24587 Traning Loss: tensor(0.8488)\n",
      "24588 Traning Loss: tensor(0.8488)\n",
      "24589 Traning Loss: tensor(0.8488)\n",
      "24590 Traning Loss: tensor(0.8488)\n",
      "24591 Traning Loss: tensor(0.8488)\n",
      "24592 Traning Loss: tensor(0.8488)\n",
      "24593 Traning Loss: tensor(0.8488)\n",
      "24594 Traning Loss: tensor(0.8488)\n",
      "24595 Traning Loss: tensor(0.8488)\n",
      "24596 Traning Loss: tensor(0.8488)\n",
      "24597 Traning Loss: tensor(0.8488)\n",
      "24598 Traning Loss: tensor(0.8488)\n",
      "24599 Traning Loss: tensor(0.8488)\n",
      "24600 Traning Loss: tensor(0.8488)\n",
      "24601 Traning Loss: tensor(0.8488)\n",
      "24602 Traning Loss: tensor(0.8488)\n",
      "24603 Traning Loss: tensor(0.8488)\n",
      "24604 Traning Loss: tensor(0.8488)\n",
      "24605 Traning Loss: tensor(0.8488)\n",
      "24606 Traning Loss: tensor(0.8488)\n",
      "24607 Traning Loss: tensor(0.8488)\n",
      "24608 Traning Loss: tensor(0.8488)\n",
      "24609 Traning Loss: tensor(0.8488)\n",
      "24610 Traning Loss: tensor(0.8488)\n",
      "24611 Traning Loss: tensor(0.8488)\n",
      "24612 Traning Loss: tensor(0.8488)\n",
      "24613 Traning Loss: tensor(0.8488)\n",
      "24614 Traning Loss: tensor(0.8488)\n",
      "24615 Traning Loss: tensor(0.8488)\n",
      "24616 Traning Loss: tensor(0.8488)\n",
      "24617 Traning Loss: tensor(0.8488)\n",
      "24618 Traning Loss: tensor(0.8488)\n",
      "24619 Traning Loss: tensor(0.8488)\n",
      "24620 Traning Loss: tensor(0.8488)\n",
      "24621 Traning Loss: tensor(0.8488)\n",
      "24622 Traning Loss: tensor(0.8488)\n",
      "24623 Traning Loss: tensor(0.8488)\n",
      "24624 Traning Loss: tensor(0.8488)\n",
      "24625 Traning Loss: tensor(0.8488)\n",
      "24626 Traning Loss: tensor(0.8488)\n",
      "24627 Traning Loss: tensor(0.8488)\n",
      "24628 Traning Loss: tensor(0.8488)\n",
      "24629 Traning Loss: tensor(0.8488)\n",
      "24630 Traning Loss: tensor(0.8488)\n",
      "24631 Traning Loss: tensor(0.8488)\n",
      "24632 Traning Loss: tensor(0.8488)\n",
      "24633 Traning Loss: tensor(0.8488)\n",
      "24634 Traning Loss: tensor(0.8488)\n",
      "24635 Traning Loss: tensor(0.8488)\n",
      "24636 Traning Loss: tensor(0.8488)\n",
      "24637 Traning Loss: tensor(0.8488)\n",
      "24638 Traning Loss: tensor(0.8488)\n",
      "24639 Traning Loss: tensor(0.8488)\n",
      "24640 Traning Loss: tensor(0.8488)\n",
      "24641 Traning Loss: tensor(0.8488)\n",
      "24642 Traning Loss: tensor(0.8488)\n",
      "24643 Traning Loss: tensor(0.8488)\n",
      "24644 Traning Loss: tensor(0.8488)\n",
      "24645 Traning Loss: tensor(0.8488)\n",
      "24646 Traning Loss: tensor(0.8488)\n",
      "24647 Traning Loss: tensor(0.8488)\n",
      "24648 Traning Loss: tensor(0.8488)\n",
      "24649 Traning Loss: tensor(0.8488)\n",
      "24650 Traning Loss: tensor(0.8488)\n",
      "24651 Traning Loss: tensor(0.8488)\n",
      "24652 Traning Loss: tensor(0.8488)\n",
      "24653 Traning Loss: tensor(0.8488)\n",
      "24654 Traning Loss: tensor(0.8488)\n",
      "24655 Traning Loss: tensor(0.8488)\n",
      "24656 Traning Loss: tensor(0.8488)\n",
      "24657 Traning Loss: tensor(0.8488)\n",
      "24658 Traning Loss: tensor(0.8488)\n",
      "24659 Traning Loss: tensor(0.8488)\n",
      "24660 Traning Loss: tensor(0.8488)\n",
      "24661 Traning Loss: tensor(0.8488)\n",
      "24662 Traning Loss: tensor(0.8488)\n",
      "24663 Traning Loss: tensor(0.8488)\n",
      "24664 Traning Loss: tensor(0.8488)\n",
      "24665 Traning Loss: tensor(0.8488)\n",
      "24666 Traning Loss: tensor(0.8488)\n",
      "24667 Traning Loss: tensor(0.8488)\n",
      "24668 Traning Loss: tensor(0.8488)\n",
      "24669 Traning Loss: tensor(0.8488)\n",
      "24670 Traning Loss: tensor(0.8488)\n",
      "24671 Traning Loss: tensor(0.8488)\n",
      "24672 Traning Loss: tensor(0.8488)\n",
      "24673 Traning Loss: tensor(0.8488)\n",
      "24674 Traning Loss: tensor(0.8488)\n",
      "24675 Traning Loss: tensor(0.8488)\n",
      "24676 Traning Loss: tensor(0.8488)\n",
      "24677 Traning Loss: tensor(0.8488)\n",
      "24678 Traning Loss: tensor(0.8488)\n",
      "24679 Traning Loss: tensor(0.8488)\n",
      "24680 Traning Loss: tensor(0.8488)\n",
      "24681 Traning Loss: tensor(0.8488)\n",
      "24682 Traning Loss: tensor(0.8488)\n",
      "24683 Traning Loss: tensor(0.8488)\n",
      "24684 Traning Loss: tensor(0.8488)\n",
      "24685 Traning Loss: tensor(0.8488)\n",
      "24686 Traning Loss: tensor(0.8488)\n",
      "24687 Traning Loss: tensor(0.8488)\n",
      "24688 Traning Loss: tensor(0.8488)\n",
      "24689 Traning Loss: tensor(0.8488)\n",
      "24690 Traning Loss: tensor(0.8488)\n",
      "24691 Traning Loss: tensor(0.8488)\n",
      "24692 Traning Loss: tensor(0.8488)\n",
      "24693 Traning Loss: tensor(0.8488)\n",
      "24694 Traning Loss: tensor(0.8488)\n",
      "24695 Traning Loss: tensor(0.8488)\n",
      "24696 Traning Loss: tensor(0.8488)\n",
      "24697 Traning Loss: tensor(0.8488)\n",
      "24698 Traning Loss: tensor(0.8488)\n",
      "24699 Traning Loss: tensor(0.8488)\n",
      "24700 Traning Loss: tensor(0.8488)\n",
      "24701 Traning Loss: tensor(0.8488)\n",
      "24702 Traning Loss: tensor(0.8488)\n",
      "24703 Traning Loss: tensor(0.8488)\n",
      "24704 Traning Loss: tensor(0.8488)\n",
      "24705 Traning Loss: tensor(0.8488)\n",
      "24706 Traning Loss: tensor(0.8488)\n",
      "24707 Traning Loss: tensor(0.8488)\n",
      "24708 Traning Loss: tensor(0.8488)\n",
      "24709 Traning Loss: tensor(0.8488)\n",
      "24710 Traning Loss: tensor(0.8488)\n",
      "24711 Traning Loss: tensor(0.8488)\n",
      "24712 Traning Loss: tensor(0.8488)\n",
      "24713 Traning Loss: tensor(0.8488)\n",
      "24714 Traning Loss: tensor(0.8488)\n",
      "24715 Traning Loss: tensor(0.8488)\n",
      "24716 Traning Loss: tensor(0.8488)\n",
      "24717 Traning Loss: tensor(0.8488)\n",
      "24718 Traning Loss: tensor(0.8488)\n",
      "24719 Traning Loss: tensor(0.8488)\n",
      "24720 Traning Loss: tensor(0.8488)\n",
      "24721 Traning Loss: tensor(0.8488)\n",
      "24722 Traning Loss: tensor(0.8488)\n",
      "24723 Traning Loss: tensor(0.8488)\n",
      "24724 Traning Loss: tensor(0.8488)\n",
      "24725 Traning Loss: tensor(0.8488)\n",
      "24726 Traning Loss: tensor(0.8488)\n",
      "24727 Traning Loss: tensor(0.8488)\n",
      "24728 Traning Loss: tensor(0.8488)\n",
      "24729 Traning Loss: tensor(0.8488)\n",
      "24730 Traning Loss: tensor(0.8488)\n",
      "24731 Traning Loss: tensor(0.8488)\n",
      "24732 Traning Loss: tensor(0.8488)\n",
      "24733 Traning Loss: tensor(0.8488)\n",
      "24734 Traning Loss: tensor(0.8488)\n",
      "24735 Traning Loss: tensor(0.8488)\n",
      "24736 Traning Loss: tensor(0.8488)\n",
      "24737 Traning Loss: tensor(0.8488)\n",
      "24738 Traning Loss: tensor(0.8488)\n",
      "24739 Traning Loss: tensor(0.8488)\n",
      "24740 Traning Loss: tensor(0.8488)\n",
      "24741 Traning Loss: tensor(0.8488)\n",
      "24742 Traning Loss: tensor(0.8488)\n",
      "24743 Traning Loss: tensor(0.8488)\n",
      "24744 Traning Loss: tensor(0.8488)\n",
      "24745 Traning Loss: tensor(0.8488)\n",
      "24746 Traning Loss: tensor(0.8488)\n",
      "24747 Traning Loss: tensor(0.8488)\n",
      "24748 Traning Loss: tensor(0.8488)\n",
      "24749 Traning Loss: tensor(0.8488)\n",
      "24750 Traning Loss: tensor(0.8488)\n",
      "24751 Traning Loss: tensor(0.8488)\n",
      "24752 Traning Loss: tensor(0.8488)\n",
      "24753 Traning Loss: tensor(0.8488)\n",
      "24754 Traning Loss: tensor(0.8488)\n",
      "24755 Traning Loss: tensor(0.8488)\n",
      "24756 Traning Loss: tensor(0.8488)\n",
      "24757 Traning Loss: tensor(0.8488)\n",
      "24758 Traning Loss: tensor(0.8488)\n",
      "24759 Traning Loss: tensor(0.8488)\n",
      "24760 Traning Loss: tensor(0.8488)\n",
      "24761 Traning Loss: tensor(0.8488)\n",
      "24762 Traning Loss: tensor(0.8488)\n",
      "24763 Traning Loss: tensor(0.8488)\n",
      "24764 Traning Loss: tensor(0.8488)\n",
      "24765 Traning Loss: tensor(0.8488)\n",
      "24766 Traning Loss: tensor(0.8488)\n",
      "24767 Traning Loss: tensor(0.8488)\n",
      "24768 Traning Loss: tensor(0.8488)\n",
      "24769 Traning Loss: tensor(0.8488)\n",
      "24770 Traning Loss: tensor(0.8488)\n",
      "24771 Traning Loss: tensor(0.8488)\n",
      "24772 Traning Loss: tensor(0.8488)\n",
      "24773 Traning Loss: tensor(0.8488)\n",
      "24774 Traning Loss: tensor(0.8488)\n",
      "24775 Traning Loss: tensor(0.8488)\n",
      "24776 Traning Loss: tensor(0.8488)\n",
      "24777 Traning Loss: tensor(0.8488)\n",
      "24778 Traning Loss: tensor(0.8488)\n",
      "24779 Traning Loss: tensor(0.8488)\n",
      "24780 Traning Loss: tensor(0.8488)\n",
      "24781 Traning Loss: tensor(0.8488)\n",
      "24782 Traning Loss: tensor(0.8488)\n",
      "24783 Traning Loss: tensor(0.8488)\n",
      "24784 Traning Loss: tensor(0.8488)\n",
      "24785 Traning Loss: tensor(0.8488)\n",
      "24786 Traning Loss: tensor(0.8488)\n",
      "24787 Traning Loss: tensor(0.8488)\n",
      "24788 Traning Loss: tensor(0.8488)\n",
      "24789 Traning Loss: tensor(0.8488)\n",
      "24790 Traning Loss: tensor(0.8488)\n",
      "24791 Traning Loss: tensor(0.8488)\n",
      "24792 Traning Loss: tensor(0.8488)\n",
      "24793 Traning Loss: tensor(0.8488)\n",
      "24794 Traning Loss: tensor(0.8488)\n",
      "24795 Traning Loss: tensor(0.8488)\n",
      "24796 Traning Loss: tensor(0.8488)\n",
      "24797 Traning Loss: tensor(0.8488)\n",
      "24798 Traning Loss: tensor(0.8488)\n",
      "24799 Traning Loss: tensor(0.8488)\n",
      "24800 Traning Loss: tensor(0.8488)\n",
      "24801 Traning Loss: tensor(0.8488)\n",
      "24802 Traning Loss: tensor(0.8488)\n",
      "24803 Traning Loss: tensor(0.8488)\n",
      "24804 Traning Loss: tensor(0.8488)\n",
      "24805 Traning Loss: tensor(0.8488)\n",
      "24806 Traning Loss: tensor(0.8488)\n",
      "24807 Traning Loss: tensor(0.8488)\n",
      "24808 Traning Loss: tensor(0.8488)\n",
      "24809 Traning Loss: tensor(0.8488)\n",
      "24810 Traning Loss: tensor(0.8488)\n",
      "24811 Traning Loss: tensor(0.8488)\n",
      "24812 Traning Loss: tensor(0.8488)\n",
      "24813 Traning Loss: tensor(0.8488)\n",
      "24814 Traning Loss: tensor(0.8488)\n",
      "24815 Traning Loss: tensor(0.8488)\n",
      "24816 Traning Loss: tensor(0.8488)\n",
      "24817 Traning Loss: tensor(0.8488)\n",
      "24818 Traning Loss: tensor(0.8488)\n",
      "24819 Traning Loss: tensor(0.8488)\n",
      "24820 Traning Loss: tensor(0.8488)\n",
      "24821 Traning Loss: tensor(0.8488)\n",
      "24822 Traning Loss: tensor(0.8488)\n",
      "24823 Traning Loss: tensor(0.8488)\n",
      "24824 Traning Loss: tensor(0.8488)\n",
      "24825 Traning Loss: tensor(0.8488)\n",
      "24826 Traning Loss: tensor(0.8488)\n",
      "24827 Traning Loss: tensor(0.8488)\n",
      "24828 Traning Loss: tensor(0.8488)\n",
      "24829 Traning Loss: tensor(0.8488)\n",
      "24830 Traning Loss: tensor(0.8488)\n",
      "24831 Traning Loss: tensor(0.8488)\n",
      "24832 Traning Loss: tensor(0.8488)\n",
      "24833 Traning Loss: tensor(0.8488)\n",
      "24834 Traning Loss: tensor(0.8488)\n",
      "24835 Traning Loss: tensor(0.8488)\n",
      "24836 Traning Loss: tensor(0.8488)\n",
      "24837 Traning Loss: tensor(0.8488)\n",
      "24838 Traning Loss: tensor(0.8488)\n",
      "24839 Traning Loss: tensor(0.8488)\n",
      "24840 Traning Loss: tensor(0.8488)\n",
      "24841 Traning Loss: tensor(0.8488)\n",
      "24842 Traning Loss: tensor(0.8488)\n",
      "24843 Traning Loss: tensor(0.8488)\n",
      "24844 Traning Loss: tensor(0.8488)\n",
      "24845 Traning Loss: tensor(0.8488)\n",
      "24846 Traning Loss: tensor(0.8488)\n",
      "24847 Traning Loss: tensor(0.8488)\n",
      "24848 Traning Loss: tensor(0.8488)\n",
      "24849 Traning Loss: tensor(0.8488)\n",
      "24850 Traning Loss: tensor(0.8488)\n",
      "24851 Traning Loss: tensor(0.8488)\n",
      "24852 Traning Loss: tensor(0.8488)\n",
      "24853 Traning Loss: tensor(0.8488)\n",
      "24854 Traning Loss: tensor(0.8488)\n",
      "24855 Traning Loss: tensor(0.8488)\n",
      "24856 Traning Loss: tensor(0.8488)\n",
      "24857 Traning Loss: tensor(0.8488)\n",
      "24858 Traning Loss: tensor(0.8488)\n",
      "24859 Traning Loss: tensor(0.8488)\n",
      "24860 Traning Loss: tensor(0.8488)\n",
      "24861 Traning Loss: tensor(0.8488)\n",
      "24862 Traning Loss: tensor(0.8488)\n",
      "24863 Traning Loss: tensor(0.8488)\n",
      "24864 Traning Loss: tensor(0.8488)\n",
      "24865 Traning Loss: tensor(0.8488)\n",
      "24866 Traning Loss: tensor(0.8488)\n",
      "24867 Traning Loss: tensor(0.8488)\n",
      "24868 Traning Loss: tensor(0.8488)\n",
      "24869 Traning Loss: tensor(0.8488)\n",
      "24870 Traning Loss: tensor(0.8488)\n",
      "24871 Traning Loss: tensor(0.8488)\n",
      "24872 Traning Loss: tensor(0.8488)\n",
      "24873 Traning Loss: tensor(0.8488)\n",
      "24874 Traning Loss: tensor(0.8488)\n",
      "24875 Traning Loss: tensor(0.8488)\n",
      "24876 Traning Loss: tensor(0.8488)\n",
      "24877 Traning Loss: tensor(0.8488)\n",
      "24878 Traning Loss: tensor(0.8488)\n",
      "24879 Traning Loss: tensor(0.8488)\n",
      "24880 Traning Loss: tensor(0.8488)\n",
      "24881 Traning Loss: tensor(0.8488)\n",
      "24882 Traning Loss: tensor(0.8488)\n",
      "24883 Traning Loss: tensor(0.8488)\n",
      "24884 Traning Loss: tensor(0.8488)\n",
      "24885 Traning Loss: tensor(0.8488)\n",
      "24886 Traning Loss: tensor(0.8488)\n",
      "24887 Traning Loss: tensor(0.8488)\n",
      "24888 Traning Loss: tensor(0.8488)\n",
      "24889 Traning Loss: tensor(0.8488)\n",
      "24890 Traning Loss: tensor(0.8488)\n",
      "24891 Traning Loss: tensor(0.8488)\n",
      "24892 Traning Loss: tensor(0.8488)\n",
      "24893 Traning Loss: tensor(0.8488)\n",
      "24894 Traning Loss: tensor(0.8488)\n",
      "24895 Traning Loss: tensor(0.8488)\n",
      "24896 Traning Loss: tensor(0.8488)\n",
      "24897 Traning Loss: tensor(0.8488)\n",
      "24898 Traning Loss: tensor(0.8488)\n",
      "24899 Traning Loss: tensor(0.8488)\n",
      "24900 Traning Loss: tensor(0.8488)\n",
      "24901 Traning Loss: tensor(0.8488)\n",
      "24902 Traning Loss: tensor(0.8488)\n",
      "24903 Traning Loss: tensor(0.8488)\n",
      "24904 Traning Loss: tensor(0.8488)\n",
      "24905 Traning Loss: tensor(0.8488)\n",
      "24906 Traning Loss: tensor(0.8488)\n",
      "24907 Traning Loss: tensor(0.8488)\n",
      "24908 Traning Loss: tensor(0.8488)\n",
      "24909 Traning Loss: tensor(0.8488)\n",
      "24910 Traning Loss: tensor(0.8488)\n",
      "24911 Traning Loss: tensor(0.8488)\n",
      "24912 Traning Loss: tensor(0.8488)\n",
      "24913 Traning Loss: tensor(0.8488)\n",
      "24914 Traning Loss: tensor(0.8488)\n",
      "24915 Traning Loss: tensor(0.8488)\n",
      "24916 Traning Loss: tensor(0.8488)\n",
      "24917 Traning Loss: tensor(0.8488)\n",
      "24918 Traning Loss: tensor(0.8488)\n",
      "24919 Traning Loss: tensor(0.8488)\n",
      "24920 Traning Loss: tensor(0.8488)\n",
      "24921 Traning Loss: tensor(0.8488)\n",
      "24922 Traning Loss: tensor(0.8488)\n",
      "24923 Traning Loss: tensor(0.8488)\n",
      "24924 Traning Loss: tensor(0.8488)\n",
      "24925 Traning Loss: tensor(0.8488)\n",
      "24926 Traning Loss: tensor(0.8488)\n",
      "24927 Traning Loss: tensor(0.8488)\n",
      "24928 Traning Loss: tensor(0.8488)\n",
      "24929 Traning Loss: tensor(0.8488)\n",
      "24930 Traning Loss: tensor(0.8488)\n",
      "24931 Traning Loss: tensor(0.8488)\n",
      "24932 Traning Loss: tensor(0.8488)\n",
      "24933 Traning Loss: tensor(0.8488)\n",
      "24934 Traning Loss: tensor(0.8488)\n",
      "24935 Traning Loss: tensor(0.8488)\n",
      "24936 Traning Loss: tensor(0.8488)\n",
      "24937 Traning Loss: tensor(0.8488)\n",
      "24938 Traning Loss: tensor(0.8488)\n",
      "24939 Traning Loss: tensor(0.8488)\n",
      "24940 Traning Loss: tensor(0.8488)\n",
      "24941 Traning Loss: tensor(0.8488)\n",
      "24942 Traning Loss: tensor(0.8488)\n",
      "24943 Traning Loss: tensor(0.8488)\n",
      "24944 Traning Loss: tensor(0.8488)\n",
      "24945 Traning Loss: tensor(0.8488)\n",
      "24946 Traning Loss: tensor(0.8488)\n",
      "24947 Traning Loss: tensor(0.8488)\n",
      "24948 Traning Loss: tensor(0.8488)\n",
      "24949 Traning Loss: tensor(0.8488)\n",
      "24950 Traning Loss: tensor(0.8488)\n",
      "24951 Traning Loss: tensor(0.8488)\n",
      "24952 Traning Loss: tensor(0.8488)\n",
      "24953 Traning Loss: tensor(0.8488)\n",
      "24954 Traning Loss: tensor(0.8488)\n",
      "24955 Traning Loss: tensor(0.8488)\n",
      "24956 Traning Loss: tensor(0.8488)\n",
      "24957 Traning Loss: tensor(0.8488)\n",
      "24958 Traning Loss: tensor(0.8488)\n",
      "24959 Traning Loss: tensor(0.8488)\n",
      "24960 Traning Loss: tensor(0.8488)\n",
      "24961 Traning Loss: tensor(0.8488)\n",
      "24962 Traning Loss: tensor(0.8488)\n",
      "24963 Traning Loss: tensor(0.8488)\n",
      "24964 Traning Loss: tensor(0.8488)\n",
      "24965 Traning Loss: tensor(0.8488)\n",
      "24966 Traning Loss: tensor(0.8488)\n",
      "24967 Traning Loss: tensor(0.8488)\n",
      "24968 Traning Loss: tensor(0.8488)\n",
      "24969 Traning Loss: tensor(0.8488)\n",
      "24970 Traning Loss: tensor(0.8488)\n",
      "24971 Traning Loss: tensor(0.8488)\n",
      "24972 Traning Loss: tensor(0.8488)\n",
      "24973 Traning Loss: tensor(0.8488)\n",
      "24974 Traning Loss: tensor(0.8488)\n",
      "24975 Traning Loss: tensor(0.8488)\n",
      "24976 Traning Loss: tensor(0.8488)\n",
      "24977 Traning Loss: tensor(0.8488)\n",
      "24978 Traning Loss: tensor(0.8488)\n",
      "24979 Traning Loss: tensor(0.8488)\n",
      "24980 Traning Loss: tensor(0.8488)\n",
      "24981 Traning Loss: tensor(0.8488)\n",
      "24982 Traning Loss: tensor(0.8488)\n",
      "24983 Traning Loss: tensor(0.8488)\n",
      "24984 Traning Loss: tensor(0.8488)\n",
      "24985 Traning Loss: tensor(0.8488)\n",
      "24986 Traning Loss: tensor(0.8488)\n",
      "24987 Traning Loss: tensor(0.8488)\n",
      "24988 Traning Loss: tensor(0.8488)\n",
      "24989 Traning Loss: tensor(0.8488)\n",
      "24990 Traning Loss: tensor(0.8488)\n",
      "24991 Traning Loss: tensor(0.8488)\n",
      "24992 Traning Loss: tensor(0.8488)\n",
      "24993 Traning Loss: tensor(0.8488)\n",
      "24994 Traning Loss: tensor(0.8488)\n",
      "24995 Traning Loss: tensor(0.8488)\n",
      "24996 Traning Loss: tensor(0.8488)\n",
      "24997 Traning Loss: tensor(0.8488)\n",
      "24998 Traning Loss: tensor(0.8488)\n",
      "24999 Traning Loss: tensor(0.8488)\n",
      "25000 Traning Loss: tensor(0.8488)\n",
      "25001 Traning Loss: tensor(0.8488)\n",
      "25002 Traning Loss: tensor(0.8488)\n",
      "25003 Traning Loss: tensor(0.8488)\n",
      "25004 Traning Loss: tensor(0.8488)\n",
      "25005 Traning Loss: tensor(0.8488)\n",
      "25006 Traning Loss: tensor(0.8488)\n",
      "25007 Traning Loss: tensor(0.8488)\n",
      "25008 Traning Loss: tensor(0.8488)\n",
      "25009 Traning Loss: tensor(0.8488)\n",
      "25010 Traning Loss: tensor(0.8488)\n",
      "25011 Traning Loss: tensor(0.8488)\n",
      "25012 Traning Loss: tensor(0.8488)\n",
      "25013 Traning Loss: tensor(0.8488)\n",
      "25014 Traning Loss: tensor(0.8488)\n",
      "25015 Traning Loss: tensor(0.8488)\n",
      "25016 Traning Loss: tensor(0.8488)\n",
      "25017 Traning Loss: tensor(0.8488)\n",
      "25018 Traning Loss: tensor(0.8488)\n",
      "25019 Traning Loss: tensor(0.8488)\n",
      "25020 Traning Loss: tensor(0.8488)\n",
      "25021 Traning Loss: tensor(0.8488)\n",
      "25022 Traning Loss: tensor(0.8488)\n",
      "25023 Traning Loss: tensor(0.8488)\n",
      "25024 Traning Loss: tensor(0.8488)\n",
      "25025 Traning Loss: tensor(0.8488)\n",
      "25026 Traning Loss: tensor(0.8488)\n",
      "25027 Traning Loss: tensor(0.8488)\n",
      "25028 Traning Loss: tensor(0.8488)\n",
      "25029 Traning Loss: tensor(0.8488)\n",
      "25030 Traning Loss: tensor(0.8488)\n",
      "25031 Traning Loss: tensor(0.8488)\n",
      "25032 Traning Loss: tensor(0.8488)\n",
      "25033 Traning Loss: tensor(0.8488)\n",
      "25034 Traning Loss: tensor(0.8488)\n",
      "25035 Traning Loss: tensor(0.8488)\n",
      "25036 Traning Loss: tensor(0.8488)\n",
      "25037 Traning Loss: tensor(0.8488)\n",
      "25038 Traning Loss: tensor(0.8488)\n",
      "25039 Traning Loss: tensor(0.8488)\n",
      "25040 Traning Loss: tensor(0.8488)\n",
      "25041 Traning Loss: tensor(0.8488)\n",
      "25042 Traning Loss: tensor(0.8488)\n",
      "25043 Traning Loss: tensor(0.8488)\n",
      "25044 Traning Loss: tensor(0.8488)\n",
      "25045 Traning Loss: tensor(0.8487)\n",
      "25046 Traning Loss: tensor(0.8488)\n",
      "25047 Traning Loss: tensor(0.8488)\n",
      "25048 Traning Loss: tensor(0.8487)\n",
      "25049 Traning Loss: tensor(0.8488)\n",
      "25050 Traning Loss: tensor(0.8488)\n",
      "25051 Traning Loss: tensor(0.8487)\n",
      "25052 Traning Loss: tensor(0.8487)\n",
      "25053 Traning Loss: tensor(0.8487)\n",
      "25054 Traning Loss: tensor(0.8487)\n",
      "25055 Traning Loss: tensor(0.8487)\n",
      "25056 Traning Loss: tensor(0.8487)\n",
      "25057 Traning Loss: tensor(0.8487)\n",
      "25058 Traning Loss: tensor(0.8487)\n",
      "25059 Traning Loss: tensor(0.8487)\n",
      "25060 Traning Loss: tensor(0.8487)\n",
      "25061 Traning Loss: tensor(0.8487)\n",
      "25062 Traning Loss: tensor(0.8487)\n",
      "25063 Traning Loss: tensor(0.8487)\n",
      "25064 Traning Loss: tensor(0.8487)\n",
      "25065 Traning Loss: tensor(0.8487)\n",
      "25066 Traning Loss: tensor(0.8487)\n",
      "25067 Traning Loss: tensor(0.8487)\n",
      "25068 Traning Loss: tensor(0.8487)\n",
      "25069 Traning Loss: tensor(0.8487)\n",
      "25070 Traning Loss: tensor(0.8487)\n",
      "25071 Traning Loss: tensor(0.8487)\n",
      "25072 Traning Loss: tensor(0.8487)\n",
      "25073 Traning Loss: tensor(0.8487)\n",
      "25074 Traning Loss: tensor(0.8487)\n",
      "25075 Traning Loss: tensor(0.8487)\n",
      "25076 Traning Loss: tensor(0.8487)\n",
      "25077 Traning Loss: tensor(0.8487)\n",
      "25078 Traning Loss: tensor(0.8487)\n",
      "25079 Traning Loss: tensor(0.8487)\n",
      "25080 Traning Loss: tensor(0.8487)\n",
      "25081 Traning Loss: tensor(0.8487)\n",
      "25082 Traning Loss: tensor(0.8487)\n",
      "25083 Traning Loss: tensor(0.8487)\n",
      "25084 Traning Loss: tensor(0.8487)\n",
      "25085 Traning Loss: tensor(0.8487)\n",
      "25086 Traning Loss: tensor(0.8487)\n",
      "25087 Traning Loss: tensor(0.8487)\n",
      "25088 Traning Loss: tensor(0.8487)\n",
      "25089 Traning Loss: tensor(0.8487)\n",
      "25090 Traning Loss: tensor(0.8487)\n",
      "25091 Traning Loss: tensor(0.8487)\n",
      "25092 Traning Loss: tensor(0.8487)\n",
      "25093 Traning Loss: tensor(0.8487)\n",
      "25094 Traning Loss: tensor(0.8487)\n",
      "25095 Traning Loss: tensor(0.8487)\n",
      "25096 Traning Loss: tensor(0.8487)\n",
      "25097 Traning Loss: tensor(0.8487)\n",
      "25098 Traning Loss: tensor(0.8487)\n",
      "25099 Traning Loss: tensor(0.8487)\n",
      "25100 Traning Loss: tensor(0.8487)\n",
      "25101 Traning Loss: tensor(0.8487)\n",
      "25102 Traning Loss: tensor(0.8487)\n",
      "25103 Traning Loss: tensor(0.8487)\n",
      "25104 Traning Loss: tensor(0.8487)\n",
      "25105 Traning Loss: tensor(0.8487)\n",
      "25106 Traning Loss: tensor(0.8487)\n",
      "25107 Traning Loss: tensor(0.8487)\n",
      "25108 Traning Loss: tensor(0.8487)\n",
      "25109 Traning Loss: tensor(0.8487)\n",
      "25110 Traning Loss: tensor(0.8487)\n",
      "25111 Traning Loss: tensor(0.8487)\n",
      "25112 Traning Loss: tensor(0.8487)\n",
      "25113 Traning Loss: tensor(0.8487)\n",
      "25114 Traning Loss: tensor(0.8487)\n",
      "25115 Traning Loss: tensor(0.8487)\n",
      "25116 Traning Loss: tensor(0.8487)\n",
      "25117 Traning Loss: tensor(0.8487)\n",
      "25118 Traning Loss: tensor(0.8487)\n",
      "25119 Traning Loss: tensor(0.8487)\n",
      "25120 Traning Loss: tensor(0.8487)\n",
      "25121 Traning Loss: tensor(0.8487)\n",
      "25122 Traning Loss: tensor(0.8487)\n",
      "25123 Traning Loss: tensor(0.8487)\n",
      "25124 Traning Loss: tensor(0.8487)\n",
      "25125 Traning Loss: tensor(0.8487)\n",
      "25126 Traning Loss: tensor(0.8487)\n",
      "25127 Traning Loss: tensor(0.8487)\n",
      "25128 Traning Loss: tensor(0.8487)\n",
      "25129 Traning Loss: tensor(0.8487)\n",
      "25130 Traning Loss: tensor(0.8487)\n",
      "25131 Traning Loss: tensor(0.8487)\n",
      "25132 Traning Loss: tensor(0.8487)\n",
      "25133 Traning Loss: tensor(0.8487)\n",
      "25134 Traning Loss: tensor(0.8487)\n",
      "25135 Traning Loss: tensor(0.8487)\n",
      "25136 Traning Loss: tensor(0.8487)\n",
      "25137 Traning Loss: tensor(0.8487)\n",
      "25138 Traning Loss: tensor(0.8487)\n",
      "25139 Traning Loss: tensor(0.8487)\n",
      "25140 Traning Loss: tensor(0.8487)\n",
      "25141 Traning Loss: tensor(0.8487)\n",
      "25142 Traning Loss: tensor(0.8487)\n",
      "25143 Traning Loss: tensor(0.8487)\n",
      "25144 Traning Loss: tensor(0.8487)\n",
      "25145 Traning Loss: tensor(0.8487)\n",
      "25146 Traning Loss: tensor(0.8487)\n",
      "25147 Traning Loss: tensor(0.8487)\n",
      "25148 Traning Loss: tensor(0.8487)\n",
      "25149 Traning Loss: tensor(0.8487)\n",
      "25150 Traning Loss: tensor(0.8487)\n",
      "25151 Traning Loss: tensor(0.8487)\n",
      "25152 Traning Loss: tensor(0.8487)\n",
      "25153 Traning Loss: tensor(0.8487)\n",
      "25154 Traning Loss: tensor(0.8487)\n",
      "25155 Traning Loss: tensor(0.8487)\n",
      "25156 Traning Loss: tensor(0.8487)\n",
      "25157 Traning Loss: tensor(0.8487)\n",
      "25158 Traning Loss: tensor(0.8487)\n",
      "25159 Traning Loss: tensor(0.8487)\n",
      "25160 Traning Loss: tensor(0.8487)\n",
      "25161 Traning Loss: tensor(0.8487)\n",
      "25162 Traning Loss: tensor(0.8487)\n",
      "25163 Traning Loss: tensor(0.8487)\n",
      "25164 Traning Loss: tensor(0.8487)\n",
      "25165 Traning Loss: tensor(0.8487)\n",
      "25166 Traning Loss: tensor(0.8487)\n",
      "25167 Traning Loss: tensor(0.8487)\n",
      "25168 Traning Loss: tensor(0.8487)\n",
      "25169 Traning Loss: tensor(0.8487)\n",
      "25170 Traning Loss: tensor(0.8487)\n",
      "25171 Traning Loss: tensor(0.8487)\n",
      "25172 Traning Loss: tensor(0.8487)\n",
      "25173 Traning Loss: tensor(0.8487)\n",
      "25174 Traning Loss: tensor(0.8487)\n",
      "25175 Traning Loss: tensor(0.8487)\n",
      "25176 Traning Loss: tensor(0.8487)\n",
      "25177 Traning Loss: tensor(0.8487)\n",
      "25178 Traning Loss: tensor(0.8487)\n",
      "25179 Traning Loss: tensor(0.8487)\n",
      "25180 Traning Loss: tensor(0.8487)\n",
      "25181 Traning Loss: tensor(0.8487)\n",
      "25182 Traning Loss: tensor(0.8487)\n",
      "25183 Traning Loss: tensor(0.8487)\n",
      "25184 Traning Loss: tensor(0.8487)\n",
      "25185 Traning Loss: tensor(0.8487)\n",
      "25186 Traning Loss: tensor(0.8487)\n",
      "25187 Traning Loss: tensor(0.8487)\n",
      "25188 Traning Loss: tensor(0.8487)\n",
      "25189 Traning Loss: tensor(0.8487)\n",
      "25190 Traning Loss: tensor(0.8487)\n",
      "25191 Traning Loss: tensor(0.8487)\n",
      "25192 Traning Loss: tensor(0.8487)\n",
      "25193 Traning Loss: tensor(0.8487)\n",
      "25194 Traning Loss: tensor(0.8487)\n",
      "25195 Traning Loss: tensor(0.8487)\n",
      "25196 Traning Loss: tensor(0.8487)\n",
      "25197 Traning Loss: tensor(0.8487)\n",
      "25198 Traning Loss: tensor(0.8487)\n",
      "25199 Traning Loss: tensor(0.8487)\n",
      "25200 Traning Loss: tensor(0.8487)\n",
      "25201 Traning Loss: tensor(0.8487)\n",
      "25202 Traning Loss: tensor(0.8487)\n",
      "25203 Traning Loss: tensor(0.8487)\n",
      "25204 Traning Loss: tensor(0.8487)\n",
      "25205 Traning Loss: tensor(0.8487)\n",
      "25206 Traning Loss: tensor(0.8487)\n",
      "25207 Traning Loss: tensor(0.8487)\n",
      "25208 Traning Loss: tensor(0.8487)\n",
      "25209 Traning Loss: tensor(0.8487)\n",
      "25210 Traning Loss: tensor(0.8487)\n",
      "25211 Traning Loss: tensor(0.8487)\n",
      "25212 Traning Loss: tensor(0.8487)\n",
      "25213 Traning Loss: tensor(0.8487)\n",
      "25214 Traning Loss: tensor(0.8487)\n",
      "25215 Traning Loss: tensor(0.8487)\n",
      "25216 Traning Loss: tensor(0.8487)\n",
      "25217 Traning Loss: tensor(0.8487)\n",
      "25218 Traning Loss: tensor(0.8487)\n",
      "25219 Traning Loss: tensor(0.8487)\n",
      "25220 Traning Loss: tensor(0.8487)\n",
      "25221 Traning Loss: tensor(0.8487)\n",
      "25222 Traning Loss: tensor(0.8487)\n",
      "25223 Traning Loss: tensor(0.8487)\n",
      "25224 Traning Loss: tensor(0.8487)\n",
      "25225 Traning Loss: tensor(0.8487)\n",
      "25226 Traning Loss: tensor(0.8487)\n",
      "25227 Traning Loss: tensor(0.8487)\n",
      "25228 Traning Loss: tensor(0.8487)\n",
      "25229 Traning Loss: tensor(0.8487)\n",
      "25230 Traning Loss: tensor(0.8487)\n",
      "25231 Traning Loss: tensor(0.8487)\n",
      "25232 Traning Loss: tensor(0.8487)\n",
      "25233 Traning Loss: tensor(0.8487)\n",
      "25234 Traning Loss: tensor(0.8487)\n",
      "25235 Traning Loss: tensor(0.8487)\n",
      "25236 Traning Loss: tensor(0.8487)\n",
      "25237 Traning Loss: tensor(0.8487)\n",
      "25238 Traning Loss: tensor(0.8487)\n",
      "25239 Traning Loss: tensor(0.8487)\n",
      "25240 Traning Loss: tensor(0.8487)\n",
      "25241 Traning Loss: tensor(0.8487)\n",
      "25242 Traning Loss: tensor(0.8487)\n",
      "25243 Traning Loss: tensor(0.8487)\n",
      "25244 Traning Loss: tensor(0.8487)\n",
      "25245 Traning Loss: tensor(0.8487)\n",
      "25246 Traning Loss: tensor(0.8487)\n",
      "25247 Traning Loss: tensor(0.8487)\n",
      "25248 Traning Loss: tensor(0.8487)\n",
      "25249 Traning Loss: tensor(0.8487)\n",
      "25250 Traning Loss: tensor(0.8487)\n",
      "25251 Traning Loss: tensor(0.8487)\n",
      "25252 Traning Loss: tensor(0.8487)\n",
      "25253 Traning Loss: tensor(0.8487)\n",
      "25254 Traning Loss: tensor(0.8487)\n",
      "25255 Traning Loss: tensor(0.8487)\n",
      "25256 Traning Loss: tensor(0.8487)\n",
      "25257 Traning Loss: tensor(0.8487)\n",
      "25258 Traning Loss: tensor(0.8487)\n",
      "25259 Traning Loss: tensor(0.8487)\n",
      "25260 Traning Loss: tensor(0.8487)\n",
      "25261 Traning Loss: tensor(0.8487)\n",
      "25262 Traning Loss: tensor(0.8487)\n",
      "25263 Traning Loss: tensor(0.8487)\n",
      "25264 Traning Loss: tensor(0.8487)\n",
      "25265 Traning Loss: tensor(0.8487)\n",
      "25266 Traning Loss: tensor(0.8487)\n",
      "25267 Traning Loss: tensor(0.8487)\n",
      "25268 Traning Loss: tensor(0.8487)\n",
      "25269 Traning Loss: tensor(0.8487)\n",
      "25270 Traning Loss: tensor(0.8487)\n",
      "25271 Traning Loss: tensor(0.8487)\n",
      "25272 Traning Loss: tensor(0.8487)\n",
      "25273 Traning Loss: tensor(0.8487)\n",
      "25274 Traning Loss: tensor(0.8487)\n",
      "25275 Traning Loss: tensor(0.8487)\n",
      "25276 Traning Loss: tensor(0.8487)\n",
      "25277 Traning Loss: tensor(0.8487)\n",
      "25278 Traning Loss: tensor(0.8487)\n",
      "25279 Traning Loss: tensor(0.8487)\n",
      "25280 Traning Loss: tensor(0.8487)\n",
      "25281 Traning Loss: tensor(0.8487)\n",
      "25282 Traning Loss: tensor(0.8487)\n",
      "25283 Traning Loss: tensor(0.8487)\n",
      "25284 Traning Loss: tensor(0.8487)\n",
      "25285 Traning Loss: tensor(0.8487)\n",
      "25286 Traning Loss: tensor(0.8487)\n",
      "25287 Traning Loss: tensor(0.8487)\n",
      "25288 Traning Loss: tensor(0.8487)\n",
      "25289 Traning Loss: tensor(0.8487)\n",
      "25290 Traning Loss: tensor(0.8487)\n",
      "25291 Traning Loss: tensor(0.8487)\n",
      "25292 Traning Loss: tensor(0.8487)\n",
      "25293 Traning Loss: tensor(0.8487)\n",
      "25294 Traning Loss: tensor(0.8487)\n",
      "25295 Traning Loss: tensor(0.8487)\n",
      "25296 Traning Loss: tensor(0.8487)\n",
      "25297 Traning Loss: tensor(0.8487)\n",
      "25298 Traning Loss: tensor(0.8487)\n",
      "25299 Traning Loss: tensor(0.8487)\n",
      "25300 Traning Loss: tensor(0.8487)\n",
      "25301 Traning Loss: tensor(0.8487)\n",
      "25302 Traning Loss: tensor(0.8487)\n",
      "25303 Traning Loss: tensor(0.8487)\n",
      "25304 Traning Loss: tensor(0.8487)\n",
      "25305 Traning Loss: tensor(0.8487)\n",
      "25306 Traning Loss: tensor(0.8487)\n",
      "25307 Traning Loss: tensor(0.8487)\n",
      "25308 Traning Loss: tensor(0.8487)\n",
      "25309 Traning Loss: tensor(0.8487)\n",
      "25310 Traning Loss: tensor(0.8487)\n",
      "25311 Traning Loss: tensor(0.8487)\n",
      "25312 Traning Loss: tensor(0.8487)\n",
      "25313 Traning Loss: tensor(0.8487)\n",
      "25314 Traning Loss: tensor(0.8487)\n",
      "25315 Traning Loss: tensor(0.8487)\n",
      "25316 Traning Loss: tensor(0.8487)\n",
      "25317 Traning Loss: tensor(0.8487)\n",
      "25318 Traning Loss: tensor(0.8487)\n",
      "25319 Traning Loss: tensor(0.8487)\n",
      "25320 Traning Loss: tensor(0.8487)\n",
      "25321 Traning Loss: tensor(0.8487)\n",
      "25322 Traning Loss: tensor(0.8487)\n",
      "25323 Traning Loss: tensor(0.8487)\n",
      "25324 Traning Loss: tensor(0.8487)\n",
      "25325 Traning Loss: tensor(0.8487)\n",
      "25326 Traning Loss: tensor(0.8487)\n",
      "25327 Traning Loss: tensor(0.8487)\n",
      "25328 Traning Loss: tensor(0.8487)\n",
      "25329 Traning Loss: tensor(0.8487)\n",
      "25330 Traning Loss: tensor(0.8487)\n",
      "25331 Traning Loss: tensor(0.8487)\n",
      "25332 Traning Loss: tensor(0.8487)\n",
      "25333 Traning Loss: tensor(0.8487)\n",
      "25334 Traning Loss: tensor(0.8487)\n",
      "25335 Traning Loss: tensor(0.8487)\n",
      "25336 Traning Loss: tensor(0.8487)\n",
      "25337 Traning Loss: tensor(0.8487)\n",
      "25338 Traning Loss: tensor(0.8487)\n",
      "25339 Traning Loss: tensor(0.8487)\n",
      "25340 Traning Loss: tensor(0.8487)\n",
      "25341 Traning Loss: tensor(0.8487)\n",
      "25342 Traning Loss: tensor(0.8487)\n",
      "25343 Traning Loss: tensor(0.8487)\n",
      "25344 Traning Loss: tensor(0.8487)\n",
      "25345 Traning Loss: tensor(0.8487)\n",
      "25346 Traning Loss: tensor(0.8487)\n",
      "25347 Traning Loss: tensor(0.8487)\n",
      "25348 Traning Loss: tensor(0.8487)\n",
      "25349 Traning Loss: tensor(0.8487)\n",
      "25350 Traning Loss: tensor(0.8487)\n",
      "25351 Traning Loss: tensor(0.8487)\n",
      "25352 Traning Loss: tensor(0.8487)\n",
      "25353 Traning Loss: tensor(0.8487)\n",
      "25354 Traning Loss: tensor(0.8487)\n",
      "25355 Traning Loss: tensor(0.8487)\n",
      "25356 Traning Loss: tensor(0.8487)\n",
      "25357 Traning Loss: tensor(0.8487)\n",
      "25358 Traning Loss: tensor(0.8487)\n",
      "25359 Traning Loss: tensor(0.8487)\n",
      "25360 Traning Loss: tensor(0.8487)\n",
      "25361 Traning Loss: tensor(0.8487)\n",
      "25362 Traning Loss: tensor(0.8487)\n",
      "25363 Traning Loss: tensor(0.8487)\n",
      "25364 Traning Loss: tensor(0.8487)\n",
      "25365 Traning Loss: tensor(0.8487)\n",
      "25366 Traning Loss: tensor(0.8487)\n",
      "25367 Traning Loss: tensor(0.8487)\n",
      "25368 Traning Loss: tensor(0.8487)\n",
      "25369 Traning Loss: tensor(0.8487)\n",
      "25370 Traning Loss: tensor(0.8487)\n",
      "25371 Traning Loss: tensor(0.8487)\n",
      "25372 Traning Loss: tensor(0.8487)\n",
      "25373 Traning Loss: tensor(0.8487)\n",
      "25374 Traning Loss: tensor(0.8487)\n",
      "25375 Traning Loss: tensor(0.8487)\n",
      "25376 Traning Loss: tensor(0.8487)\n",
      "25377 Traning Loss: tensor(0.8487)\n",
      "25378 Traning Loss: tensor(0.8487)\n",
      "25379 Traning Loss: tensor(0.8487)\n",
      "25380 Traning Loss: tensor(0.8487)\n",
      "25381 Traning Loss: tensor(0.8487)\n",
      "25382 Traning Loss: tensor(0.8487)\n",
      "25383 Traning Loss: tensor(0.8487)\n",
      "25384 Traning Loss: tensor(0.8487)\n",
      "25385 Traning Loss: tensor(0.8487)\n",
      "25386 Traning Loss: tensor(0.8487)\n",
      "25387 Traning Loss: tensor(0.8487)\n",
      "25388 Traning Loss: tensor(0.8487)\n",
      "25389 Traning Loss: tensor(0.8487)\n",
      "25390 Traning Loss: tensor(0.8487)\n",
      "25391 Traning Loss: tensor(0.8487)\n",
      "25392 Traning Loss: tensor(0.8487)\n",
      "25393 Traning Loss: tensor(0.8487)\n",
      "25394 Traning Loss: tensor(0.8487)\n",
      "25395 Traning Loss: tensor(0.8487)\n",
      "25396 Traning Loss: tensor(0.8487)\n",
      "25397 Traning Loss: tensor(0.8487)\n",
      "25398 Traning Loss: tensor(0.8487)\n",
      "25399 Traning Loss: tensor(0.8487)\n",
      "25400 Traning Loss: tensor(0.8487)\n",
      "25401 Traning Loss: tensor(0.8487)\n",
      "25402 Traning Loss: tensor(0.8487)\n",
      "25403 Traning Loss: tensor(0.8487)\n",
      "25404 Traning Loss: tensor(0.8487)\n",
      "25405 Traning Loss: tensor(0.8487)\n",
      "25406 Traning Loss: tensor(0.8487)\n",
      "25407 Traning Loss: tensor(0.8487)\n",
      "25408 Traning Loss: tensor(0.8487)\n",
      "25409 Traning Loss: tensor(0.8487)\n",
      "25410 Traning Loss: tensor(0.8487)\n",
      "25411 Traning Loss: tensor(0.8487)\n",
      "25412 Traning Loss: tensor(0.8487)\n",
      "25413 Traning Loss: tensor(0.8487)\n",
      "25414 Traning Loss: tensor(0.8487)\n",
      "25415 Traning Loss: tensor(0.8487)\n",
      "25416 Traning Loss: tensor(0.8487)\n",
      "25417 Traning Loss: tensor(0.8487)\n",
      "25418 Traning Loss: tensor(0.8487)\n",
      "25419 Traning Loss: tensor(0.8487)\n",
      "25420 Traning Loss: tensor(0.8487)\n",
      "25421 Traning Loss: tensor(0.8487)\n",
      "25422 Traning Loss: tensor(0.8487)\n",
      "25423 Traning Loss: tensor(0.8487)\n",
      "25424 Traning Loss: tensor(0.8487)\n",
      "25425 Traning Loss: tensor(0.8487)\n",
      "25426 Traning Loss: tensor(0.8487)\n",
      "25427 Traning Loss: tensor(0.8487)\n",
      "25428 Traning Loss: tensor(0.8487)\n",
      "25429 Traning Loss: tensor(0.8487)\n",
      "25430 Traning Loss: tensor(0.8487)\n",
      "25431 Traning Loss: tensor(0.8487)\n",
      "25432 Traning Loss: tensor(0.8487)\n",
      "25433 Traning Loss: tensor(0.8487)\n",
      "25434 Traning Loss: tensor(0.8487)\n",
      "25435 Traning Loss: tensor(0.8487)\n",
      "25436 Traning Loss: tensor(0.8487)\n",
      "25437 Traning Loss: tensor(0.8487)\n",
      "25438 Traning Loss: tensor(0.8487)\n",
      "25439 Traning Loss: tensor(0.8487)\n",
      "25440 Traning Loss: tensor(0.8487)\n",
      "25441 Traning Loss: tensor(0.8487)\n",
      "25442 Traning Loss: tensor(0.8487)\n",
      "25443 Traning Loss: tensor(0.8487)\n",
      "25444 Traning Loss: tensor(0.8487)\n",
      "25445 Traning Loss: tensor(0.8487)\n",
      "25446 Traning Loss: tensor(0.8487)\n",
      "25447 Traning Loss: tensor(0.8487)\n",
      "25448 Traning Loss: tensor(0.8487)\n",
      "25449 Traning Loss: tensor(0.8487)\n",
      "25450 Traning Loss: tensor(0.8487)\n",
      "25451 Traning Loss: tensor(0.8487)\n",
      "25452 Traning Loss: tensor(0.8487)\n",
      "25453 Traning Loss: tensor(0.8487)\n",
      "25454 Traning Loss: tensor(0.8487)\n",
      "25455 Traning Loss: tensor(0.8487)\n",
      "25456 Traning Loss: tensor(0.8487)\n",
      "25457 Traning Loss: tensor(0.8487)\n",
      "25458 Traning Loss: tensor(0.8487)\n",
      "25459 Traning Loss: tensor(0.8487)\n",
      "25460 Traning Loss: tensor(0.8487)\n",
      "25461 Traning Loss: tensor(0.8487)\n",
      "25462 Traning Loss: tensor(0.8487)\n",
      "25463 Traning Loss: tensor(0.8487)\n",
      "25464 Traning Loss: tensor(0.8487)\n",
      "25465 Traning Loss: tensor(0.8487)\n",
      "25466 Traning Loss: tensor(0.8487)\n",
      "25467 Traning Loss: tensor(0.8487)\n",
      "25468 Traning Loss: tensor(0.8487)\n",
      "25469 Traning Loss: tensor(0.8487)\n",
      "25470 Traning Loss: tensor(0.8487)\n",
      "25471 Traning Loss: tensor(0.8487)\n",
      "25472 Traning Loss: tensor(0.8487)\n",
      "25473 Traning Loss: tensor(0.8487)\n",
      "25474 Traning Loss: tensor(0.8487)\n",
      "25475 Traning Loss: tensor(0.8487)\n",
      "25476 Traning Loss: tensor(0.8487)\n",
      "25477 Traning Loss: tensor(0.8487)\n",
      "25478 Traning Loss: tensor(0.8487)\n",
      "25479 Traning Loss: tensor(0.8487)\n",
      "25480 Traning Loss: tensor(0.8487)\n",
      "25481 Traning Loss: tensor(0.8487)\n",
      "25482 Traning Loss: tensor(0.8487)\n",
      "25483 Traning Loss: tensor(0.8487)\n",
      "25484 Traning Loss: tensor(0.8487)\n",
      "25485 Traning Loss: tensor(0.8487)\n",
      "25486 Traning Loss: tensor(0.8487)\n",
      "25487 Traning Loss: tensor(0.8487)\n",
      "25488 Traning Loss: tensor(0.8487)\n",
      "25489 Traning Loss: tensor(0.8487)\n",
      "25490 Traning Loss: tensor(0.8487)\n",
      "25491 Traning Loss: tensor(0.8487)\n",
      "25492 Traning Loss: tensor(0.8487)\n",
      "25493 Traning Loss: tensor(0.8487)\n",
      "25494 Traning Loss: tensor(0.8487)\n",
      "25495 Traning Loss: tensor(0.8487)\n",
      "25496 Traning Loss: tensor(0.8487)\n",
      "25497 Traning Loss: tensor(0.8487)\n",
      "25498 Traning Loss: tensor(0.8487)\n",
      "25499 Traning Loss: tensor(0.8487)\n",
      "25500 Traning Loss: tensor(0.8487)\n",
      "25501 Traning Loss: tensor(0.8487)\n",
      "25502 Traning Loss: tensor(0.8487)\n",
      "25503 Traning Loss: tensor(0.8487)\n",
      "25504 Traning Loss: tensor(0.8487)\n",
      "25505 Traning Loss: tensor(0.8487)\n",
      "25506 Traning Loss: tensor(0.8487)\n",
      "25507 Traning Loss: tensor(0.8487)\n",
      "25508 Traning Loss: tensor(0.8487)\n",
      "25509 Traning Loss: tensor(0.8487)\n",
      "25510 Traning Loss: tensor(0.8487)\n",
      "25511 Traning Loss: tensor(0.8487)\n",
      "25512 Traning Loss: tensor(0.8487)\n",
      "25513 Traning Loss: tensor(0.8487)\n",
      "25514 Traning Loss: tensor(0.8487)\n",
      "25515 Traning Loss: tensor(0.8487)\n",
      "25516 Traning Loss: tensor(0.8487)\n",
      "25517 Traning Loss: tensor(0.8487)\n",
      "25518 Traning Loss: tensor(0.8487)\n",
      "25519 Traning Loss: tensor(0.8487)\n",
      "25520 Traning Loss: tensor(0.8487)\n",
      "25521 Traning Loss: tensor(0.8487)\n",
      "25522 Traning Loss: tensor(0.8487)\n",
      "25523 Traning Loss: tensor(0.8487)\n",
      "25524 Traning Loss: tensor(0.8487)\n",
      "25525 Traning Loss: tensor(0.8487)\n",
      "25526 Traning Loss: tensor(0.8487)\n",
      "25527 Traning Loss: tensor(0.8487)\n",
      "25528 Traning Loss: tensor(0.8487)\n",
      "25529 Traning Loss: tensor(0.8487)\n",
      "25530 Traning Loss: tensor(0.8487)\n",
      "25531 Traning Loss: tensor(0.8487)\n",
      "25532 Traning Loss: tensor(0.8487)\n",
      "25533 Traning Loss: tensor(0.8487)\n",
      "25534 Traning Loss: tensor(0.8487)\n",
      "25535 Traning Loss: tensor(0.8487)\n",
      "25536 Traning Loss: tensor(0.8487)\n",
      "25537 Traning Loss: tensor(0.8487)\n",
      "25538 Traning Loss: tensor(0.8487)\n",
      "25539 Traning Loss: tensor(0.8487)\n",
      "25540 Traning Loss: tensor(0.8487)\n",
      "25541 Traning Loss: tensor(0.8487)\n",
      "25542 Traning Loss: tensor(0.8487)\n",
      "25543 Traning Loss: tensor(0.8487)\n",
      "25544 Traning Loss: tensor(0.8487)\n",
      "25545 Traning Loss: tensor(0.8487)\n",
      "25546 Traning Loss: tensor(0.8487)\n",
      "25547 Traning Loss: tensor(0.8487)\n",
      "25548 Traning Loss: tensor(0.8487)\n",
      "25549 Traning Loss: tensor(0.8487)\n",
      "25550 Traning Loss: tensor(0.8487)\n",
      "25551 Traning Loss: tensor(0.8487)\n",
      "25552 Traning Loss: tensor(0.8487)\n",
      "25553 Traning Loss: tensor(0.8487)\n",
      "25554 Traning Loss: tensor(0.8487)\n",
      "25555 Traning Loss: tensor(0.8487)\n",
      "25556 Traning Loss: tensor(0.8487)\n",
      "25557 Traning Loss: tensor(0.8487)\n",
      "25558 Traning Loss: tensor(0.8487)\n",
      "25559 Traning Loss: tensor(0.8487)\n",
      "25560 Traning Loss: tensor(0.8487)\n",
      "25561 Traning Loss: tensor(0.8487)\n",
      "25562 Traning Loss: tensor(0.8487)\n",
      "25563 Traning Loss: tensor(0.8487)\n",
      "25564 Traning Loss: tensor(0.8487)\n",
      "25565 Traning Loss: tensor(0.8487)\n",
      "25566 Traning Loss: tensor(0.8487)\n",
      "25567 Traning Loss: tensor(0.8487)\n",
      "25568 Traning Loss: tensor(0.8487)\n",
      "25569 Traning Loss: tensor(0.8487)\n",
      "25570 Traning Loss: tensor(0.8487)\n",
      "25571 Traning Loss: tensor(0.8487)\n",
      "25572 Traning Loss: tensor(0.8487)\n",
      "25573 Traning Loss: tensor(0.8487)\n",
      "25574 Traning Loss: tensor(0.8487)\n",
      "25575 Traning Loss: tensor(0.8487)\n",
      "25576 Traning Loss: tensor(0.8487)\n",
      "25577 Traning Loss: tensor(0.8487)\n",
      "25578 Traning Loss: tensor(0.8487)\n",
      "25579 Traning Loss: tensor(0.8487)\n",
      "25580 Traning Loss: tensor(0.8487)\n",
      "25581 Traning Loss: tensor(0.8487)\n",
      "25582 Traning Loss: tensor(0.8487)\n",
      "25583 Traning Loss: tensor(0.8487)\n",
      "25584 Traning Loss: tensor(0.8487)\n",
      "25585 Traning Loss: tensor(0.8487)\n",
      "25586 Traning Loss: tensor(0.8487)\n",
      "25587 Traning Loss: tensor(0.8487)\n",
      "25588 Traning Loss: tensor(0.8487)\n",
      "25589 Traning Loss: tensor(0.8487)\n",
      "25590 Traning Loss: tensor(0.8487)\n",
      "25591 Traning Loss: tensor(0.8487)\n",
      "25592 Traning Loss: tensor(0.8487)\n",
      "25593 Traning Loss: tensor(0.8487)\n",
      "25594 Traning Loss: tensor(0.8487)\n",
      "25595 Traning Loss: tensor(0.8487)\n",
      "25596 Traning Loss: tensor(0.8487)\n",
      "25597 Traning Loss: tensor(0.8487)\n",
      "25598 Traning Loss: tensor(0.8487)\n",
      "25599 Traning Loss: tensor(0.8487)\n",
      "25600 Traning Loss: tensor(0.8487)\n",
      "25601 Traning Loss: tensor(0.8487)\n",
      "25602 Traning Loss: tensor(0.8487)\n",
      "25603 Traning Loss: tensor(0.8487)\n",
      "25604 Traning Loss: tensor(0.8487)\n",
      "25605 Traning Loss: tensor(0.8487)\n",
      "25606 Traning Loss: tensor(0.8487)\n",
      "25607 Traning Loss: tensor(0.8487)\n",
      "25608 Traning Loss: tensor(0.8487)\n",
      "25609 Traning Loss: tensor(0.8487)\n",
      "25610 Traning Loss: tensor(0.8487)\n",
      "25611 Traning Loss: tensor(0.8487)\n",
      "25612 Traning Loss: tensor(0.8487)\n",
      "25613 Traning Loss: tensor(0.8487)\n",
      "25614 Traning Loss: tensor(0.8487)\n",
      "25615 Traning Loss: tensor(0.8487)\n",
      "25616 Traning Loss: tensor(0.8487)\n",
      "25617 Traning Loss: tensor(0.8487)\n",
      "25618 Traning Loss: tensor(0.8487)\n",
      "25619 Traning Loss: tensor(0.8487)\n",
      "25620 Traning Loss: tensor(0.8487)\n",
      "25621 Traning Loss: tensor(0.8487)\n",
      "25622 Traning Loss: tensor(0.8487)\n",
      "25623 Traning Loss: tensor(0.8487)\n",
      "25624 Traning Loss: tensor(0.8487)\n",
      "25625 Traning Loss: tensor(0.8487)\n",
      "25626 Traning Loss: tensor(0.8487)\n",
      "25627 Traning Loss: tensor(0.8487)\n",
      "25628 Traning Loss: tensor(0.8487)\n",
      "25629 Traning Loss: tensor(0.8487)\n",
      "25630 Traning Loss: tensor(0.8487)\n",
      "25631 Traning Loss: tensor(0.8487)\n",
      "25632 Traning Loss: tensor(0.8487)\n",
      "25633 Traning Loss: tensor(0.8487)\n",
      "25634 Traning Loss: tensor(0.8487)\n",
      "25635 Traning Loss: tensor(0.8487)\n",
      "25636 Traning Loss: tensor(0.8487)\n",
      "25637 Traning Loss: tensor(0.8487)\n",
      "25638 Traning Loss: tensor(0.8487)\n",
      "25639 Traning Loss: tensor(0.8487)\n",
      "25640 Traning Loss: tensor(0.8487)\n",
      "25641 Traning Loss: tensor(0.8487)\n",
      "25642 Traning Loss: tensor(0.8487)\n",
      "25643 Traning Loss: tensor(0.8487)\n",
      "25644 Traning Loss: tensor(0.8487)\n",
      "25645 Traning Loss: tensor(0.8487)\n",
      "25646 Traning Loss: tensor(0.8487)\n",
      "25647 Traning Loss: tensor(0.8487)\n",
      "25648 Traning Loss: tensor(0.8487)\n",
      "25649 Traning Loss: tensor(0.8487)\n",
      "25650 Traning Loss: tensor(0.8487)\n",
      "25651 Traning Loss: tensor(0.8487)\n",
      "25652 Traning Loss: tensor(0.8487)\n",
      "25653 Traning Loss: tensor(0.8487)\n",
      "25654 Traning Loss: tensor(0.8487)\n",
      "25655 Traning Loss: tensor(0.8487)\n",
      "25656 Traning Loss: tensor(0.8487)\n",
      "25657 Traning Loss: tensor(0.8487)\n",
      "25658 Traning Loss: tensor(0.8487)\n",
      "25659 Traning Loss: tensor(0.8487)\n",
      "25660 Traning Loss: tensor(0.8487)\n",
      "25661 Traning Loss: tensor(0.8487)\n",
      "25662 Traning Loss: tensor(0.8487)\n",
      "25663 Traning Loss: tensor(0.8487)\n",
      "25664 Traning Loss: tensor(0.8487)\n",
      "25665 Traning Loss: tensor(0.8487)\n",
      "25666 Traning Loss: tensor(0.8487)\n",
      "25667 Traning Loss: tensor(0.8487)\n",
      "25668 Traning Loss: tensor(0.8487)\n",
      "25669 Traning Loss: tensor(0.8487)\n",
      "25670 Traning Loss: tensor(0.8487)\n",
      "25671 Traning Loss: tensor(0.8487)\n",
      "25672 Traning Loss: tensor(0.8487)\n",
      "25673 Traning Loss: tensor(0.8487)\n",
      "25674 Traning Loss: tensor(0.8487)\n",
      "25675 Traning Loss: tensor(0.8487)\n",
      "25676 Traning Loss: tensor(0.8487)\n",
      "25677 Traning Loss: tensor(0.8487)\n",
      "25678 Traning Loss: tensor(0.8487)\n",
      "25679 Traning Loss: tensor(0.8487)\n",
      "25680 Traning Loss: tensor(0.8487)\n",
      "25681 Traning Loss: tensor(0.8487)\n",
      "25682 Traning Loss: tensor(0.8487)\n",
      "25683 Traning Loss: tensor(0.8487)\n",
      "25684 Traning Loss: tensor(0.8487)\n",
      "25685 Traning Loss: tensor(0.8487)\n",
      "25686 Traning Loss: tensor(0.8487)\n",
      "25687 Traning Loss: tensor(0.8487)\n",
      "25688 Traning Loss: tensor(0.8487)\n",
      "25689 Traning Loss: tensor(0.8487)\n",
      "25690 Traning Loss: tensor(0.8487)\n",
      "25691 Traning Loss: tensor(0.8487)\n",
      "25692 Traning Loss: tensor(0.8487)\n",
      "25693 Traning Loss: tensor(0.8487)\n",
      "25694 Traning Loss: tensor(0.8487)\n",
      "25695 Traning Loss: tensor(0.8487)\n",
      "25696 Traning Loss: tensor(0.8487)\n",
      "25697 Traning Loss: tensor(0.8487)\n",
      "25698 Traning Loss: tensor(0.8487)\n",
      "25699 Traning Loss: tensor(0.8487)\n",
      "25700 Traning Loss: tensor(0.8487)\n",
      "25701 Traning Loss: tensor(0.8487)\n",
      "25702 Traning Loss: tensor(0.8487)\n",
      "25703 Traning Loss: tensor(0.8487)\n",
      "25704 Traning Loss: tensor(0.8487)\n",
      "25705 Traning Loss: tensor(0.8487)\n",
      "25706 Traning Loss: tensor(0.8487)\n",
      "25707 Traning Loss: tensor(0.8487)\n",
      "25708 Traning Loss: tensor(0.8487)\n",
      "25709 Traning Loss: tensor(0.8487)\n",
      "25710 Traning Loss: tensor(0.8487)\n",
      "25711 Traning Loss: tensor(0.8487)\n",
      "25712 Traning Loss: tensor(0.8487)\n",
      "25713 Traning Loss: tensor(0.8487)\n",
      "25714 Traning Loss: tensor(0.8487)\n",
      "25715 Traning Loss: tensor(0.8487)\n",
      "25716 Traning Loss: tensor(0.8487)\n",
      "25717 Traning Loss: tensor(0.8487)\n",
      "25718 Traning Loss: tensor(0.8487)\n",
      "25719 Traning Loss: tensor(0.8487)\n",
      "25720 Traning Loss: tensor(0.8487)\n",
      "25721 Traning Loss: tensor(0.8487)\n",
      "25722 Traning Loss: tensor(0.8487)\n",
      "25723 Traning Loss: tensor(0.8487)\n",
      "25724 Traning Loss: tensor(0.8487)\n",
      "25725 Traning Loss: tensor(0.8487)\n",
      "25726 Traning Loss: tensor(0.8487)\n",
      "25727 Traning Loss: tensor(0.8487)\n",
      "25728 Traning Loss: tensor(0.8487)\n",
      "25729 Traning Loss: tensor(0.8487)\n",
      "25730 Traning Loss: tensor(0.8487)\n",
      "25731 Traning Loss: tensor(0.8487)\n",
      "25732 Traning Loss: tensor(0.8487)\n",
      "25733 Traning Loss: tensor(0.8487)\n",
      "25734 Traning Loss: tensor(0.8487)\n",
      "25735 Traning Loss: tensor(0.8487)\n",
      "25736 Traning Loss: tensor(0.8487)\n",
      "25737 Traning Loss: tensor(0.8487)\n",
      "25738 Traning Loss: tensor(0.8487)\n",
      "25739 Traning Loss: tensor(0.8487)\n",
      "25740 Traning Loss: tensor(0.8487)\n",
      "25741 Traning Loss: tensor(0.8487)\n",
      "25742 Traning Loss: tensor(0.8487)\n",
      "25743 Traning Loss: tensor(0.8487)\n",
      "25744 Traning Loss: tensor(0.8487)\n",
      "25745 Traning Loss: tensor(0.8487)\n",
      "25746 Traning Loss: tensor(0.8487)\n",
      "25747 Traning Loss: tensor(0.8487)\n",
      "25748 Traning Loss: tensor(0.8487)\n",
      "25749 Traning Loss: tensor(0.8487)\n",
      "25750 Traning Loss: tensor(0.8487)\n",
      "25751 Traning Loss: tensor(0.8487)\n",
      "25752 Traning Loss: tensor(0.8487)\n",
      "25753 Traning Loss: tensor(0.8487)\n",
      "25754 Traning Loss: tensor(0.8487)\n",
      "25755 Traning Loss: tensor(0.8487)\n",
      "25756 Traning Loss: tensor(0.8487)\n",
      "25757 Traning Loss: tensor(0.8487)\n",
      "25758 Traning Loss: tensor(0.8487)\n",
      "25759 Traning Loss: tensor(0.8487)\n",
      "25760 Traning Loss: tensor(0.8487)\n",
      "25761 Traning Loss: tensor(0.8487)\n",
      "25762 Traning Loss: tensor(0.8487)\n",
      "25763 Traning Loss: tensor(0.8487)\n",
      "25764 Traning Loss: tensor(0.8487)\n",
      "25765 Traning Loss: tensor(0.8487)\n",
      "25766 Traning Loss: tensor(0.8487)\n",
      "25767 Traning Loss: tensor(0.8487)\n",
      "25768 Traning Loss: tensor(0.8487)\n",
      "25769 Traning Loss: tensor(0.8487)\n",
      "25770 Traning Loss: tensor(0.8487)\n",
      "25771 Traning Loss: tensor(0.8487)\n",
      "25772 Traning Loss: tensor(0.8487)\n",
      "25773 Traning Loss: tensor(0.8487)\n",
      "25774 Traning Loss: tensor(0.8487)\n",
      "25775 Traning Loss: tensor(0.8487)\n",
      "25776 Traning Loss: tensor(0.8487)\n",
      "25777 Traning Loss: tensor(0.8487)\n",
      "25778 Traning Loss: tensor(0.8487)\n",
      "25779 Traning Loss: tensor(0.8487)\n",
      "25780 Traning Loss: tensor(0.8487)\n",
      "25781 Traning Loss: tensor(0.8487)\n",
      "25782 Traning Loss: tensor(0.8487)\n",
      "25783 Traning Loss: tensor(0.8487)\n",
      "25784 Traning Loss: tensor(0.8487)\n",
      "25785 Traning Loss: tensor(0.8487)\n",
      "25786 Traning Loss: tensor(0.8487)\n",
      "25787 Traning Loss: tensor(0.8487)\n",
      "25788 Traning Loss: tensor(0.8487)\n",
      "25789 Traning Loss: tensor(0.8487)\n",
      "25790 Traning Loss: tensor(0.8487)\n",
      "25791 Traning Loss: tensor(0.8487)\n",
      "25792 Traning Loss: tensor(0.8487)\n",
      "25793 Traning Loss: tensor(0.8487)\n",
      "25794 Traning Loss: tensor(0.8487)\n",
      "25795 Traning Loss: tensor(0.8487)\n",
      "25796 Traning Loss: tensor(0.8487)\n",
      "25797 Traning Loss: tensor(0.8487)\n",
      "25798 Traning Loss: tensor(0.8487)\n",
      "25799 Traning Loss: tensor(0.8487)\n",
      "25800 Traning Loss: tensor(0.8487)\n",
      "25801 Traning Loss: tensor(0.8487)\n",
      "25802 Traning Loss: tensor(0.8487)\n",
      "25803 Traning Loss: tensor(0.8487)\n",
      "25804 Traning Loss: tensor(0.8487)\n",
      "25805 Traning Loss: tensor(0.8487)\n",
      "25806 Traning Loss: tensor(0.8487)\n",
      "25807 Traning Loss: tensor(0.8487)\n",
      "25808 Traning Loss: tensor(0.8487)\n",
      "25809 Traning Loss: tensor(0.8487)\n",
      "25810 Traning Loss: tensor(0.8487)\n",
      "25811 Traning Loss: tensor(0.8487)\n",
      "25812 Traning Loss: tensor(0.8487)\n",
      "25813 Traning Loss: tensor(0.8487)\n",
      "25814 Traning Loss: tensor(0.8487)\n",
      "25815 Traning Loss: tensor(0.8487)\n",
      "25816 Traning Loss: tensor(0.8487)\n",
      "25817 Traning Loss: tensor(0.8487)\n",
      "25818 Traning Loss: tensor(0.8487)\n",
      "25819 Traning Loss: tensor(0.8487)\n",
      "25820 Traning Loss: tensor(0.8487)\n",
      "25821 Traning Loss: tensor(0.8487)\n",
      "25822 Traning Loss: tensor(0.8487)\n",
      "25823 Traning Loss: tensor(0.8487)\n",
      "25824 Traning Loss: tensor(0.8487)\n",
      "25825 Traning Loss: tensor(0.8487)\n",
      "25826 Traning Loss: tensor(0.8487)\n",
      "25827 Traning Loss: tensor(0.8487)\n",
      "25828 Traning Loss: tensor(0.8487)\n",
      "25829 Traning Loss: tensor(0.8487)\n",
      "25830 Traning Loss: tensor(0.8487)\n",
      "25831 Traning Loss: tensor(0.8487)\n",
      "25832 Traning Loss: tensor(0.8487)\n",
      "25833 Traning Loss: tensor(0.8487)\n",
      "25834 Traning Loss: tensor(0.8487)\n",
      "25835 Traning Loss: tensor(0.8487)\n",
      "25836 Traning Loss: tensor(0.8487)\n",
      "25837 Traning Loss: tensor(0.8487)\n",
      "25838 Traning Loss: tensor(0.8487)\n",
      "25839 Traning Loss: tensor(0.8487)\n",
      "25840 Traning Loss: tensor(0.8487)\n",
      "25841 Traning Loss: tensor(0.8487)\n",
      "25842 Traning Loss: tensor(0.8487)\n",
      "25843 Traning Loss: tensor(0.8487)\n",
      "25844 Traning Loss: tensor(0.8487)\n",
      "25845 Traning Loss: tensor(0.8487)\n",
      "25846 Traning Loss: tensor(0.8487)\n",
      "25847 Traning Loss: tensor(0.8487)\n",
      "25848 Traning Loss: tensor(0.8487)\n",
      "25849 Traning Loss: tensor(0.8487)\n",
      "25850 Traning Loss: tensor(0.8487)\n",
      "25851 Traning Loss: tensor(0.8487)\n",
      "25852 Traning Loss: tensor(0.8487)\n",
      "25853 Traning Loss: tensor(0.8487)\n",
      "25854 Traning Loss: tensor(0.8487)\n",
      "25855 Traning Loss: tensor(0.8487)\n",
      "25856 Traning Loss: tensor(0.8487)\n",
      "25857 Traning Loss: tensor(0.8487)\n",
      "25858 Traning Loss: tensor(0.8487)\n",
      "25859 Traning Loss: tensor(0.8487)\n",
      "25860 Traning Loss: tensor(0.8487)\n",
      "25861 Traning Loss: tensor(0.8487)\n",
      "25862 Traning Loss: tensor(0.8487)\n",
      "25863 Traning Loss: tensor(0.8487)\n",
      "25864 Traning Loss: tensor(0.8487)\n",
      "25865 Traning Loss: tensor(0.8487)\n",
      "25866 Traning Loss: tensor(0.8487)\n",
      "25867 Traning Loss: tensor(0.8487)\n",
      "25868 Traning Loss: tensor(0.8487)\n",
      "25869 Traning Loss: tensor(0.8487)\n",
      "25870 Traning Loss: tensor(0.8487)\n",
      "25871 Traning Loss: tensor(0.8487)\n",
      "25872 Traning Loss: tensor(0.8487)\n",
      "25873 Traning Loss: tensor(0.8487)\n",
      "25874 Traning Loss: tensor(0.8487)\n",
      "25875 Traning Loss: tensor(0.8487)\n",
      "25876 Traning Loss: tensor(0.8487)\n",
      "25877 Traning Loss: tensor(0.8487)\n",
      "25878 Traning Loss: tensor(0.8487)\n",
      "25879 Traning Loss: tensor(0.8487)\n",
      "25880 Traning Loss: tensor(0.8487)\n",
      "25881 Traning Loss: tensor(0.8487)\n",
      "25882 Traning Loss: tensor(0.8487)\n",
      "25883 Traning Loss: tensor(0.8487)\n",
      "25884 Traning Loss: tensor(0.8487)\n",
      "25885 Traning Loss: tensor(0.8487)\n",
      "25886 Traning Loss: tensor(0.8487)\n",
      "25887 Traning Loss: tensor(0.8487)\n",
      "25888 Traning Loss: tensor(0.8487)\n",
      "25889 Traning Loss: tensor(0.8487)\n",
      "25890 Traning Loss: tensor(0.8487)\n",
      "25891 Traning Loss: tensor(0.8487)\n",
      "25892 Traning Loss: tensor(0.8487)\n",
      "25893 Traning Loss: tensor(0.8487)\n",
      "25894 Traning Loss: tensor(0.8487)\n",
      "25895 Traning Loss: tensor(0.8487)\n",
      "25896 Traning Loss: tensor(0.8487)\n",
      "25897 Traning Loss: tensor(0.8487)\n",
      "25898 Traning Loss: tensor(0.8487)\n",
      "25899 Traning Loss: tensor(0.8487)\n",
      "25900 Traning Loss: tensor(0.8487)\n",
      "25901 Traning Loss: tensor(0.8487)\n",
      "25902 Traning Loss: tensor(0.8487)\n",
      "25903 Traning Loss: tensor(0.8487)\n",
      "25904 Traning Loss: tensor(0.8487)\n",
      "25905 Traning Loss: tensor(0.8487)\n",
      "25906 Traning Loss: tensor(0.8487)\n",
      "25907 Traning Loss: tensor(0.8487)\n",
      "25908 Traning Loss: tensor(0.8487)\n",
      "25909 Traning Loss: tensor(0.8487)\n",
      "25910 Traning Loss: tensor(0.8487)\n",
      "25911 Traning Loss: tensor(0.8487)\n",
      "25912 Traning Loss: tensor(0.8487)\n",
      "25913 Traning Loss: tensor(0.8487)\n",
      "25914 Traning Loss: tensor(0.8487)\n",
      "25915 Traning Loss: tensor(0.8487)\n",
      "25916 Traning Loss: tensor(0.8487)\n",
      "25917 Traning Loss: tensor(0.8487)\n",
      "25918 Traning Loss: tensor(0.8487)\n",
      "25919 Traning Loss: tensor(0.8487)\n",
      "25920 Traning Loss: tensor(0.8487)\n",
      "25921 Traning Loss: tensor(0.8487)\n",
      "25922 Traning Loss: tensor(0.8487)\n",
      "25923 Traning Loss: tensor(0.8487)\n",
      "25924 Traning Loss: tensor(0.8487)\n",
      "25925 Traning Loss: tensor(0.8487)\n",
      "25926 Traning Loss: tensor(0.8487)\n",
      "25927 Traning Loss: tensor(0.8487)\n",
      "25928 Traning Loss: tensor(0.8487)\n",
      "25929 Traning Loss: tensor(0.8487)\n",
      "25930 Traning Loss: tensor(0.8487)\n",
      "25931 Traning Loss: tensor(0.8487)\n",
      "25932 Traning Loss: tensor(0.8487)\n",
      "25933 Traning Loss: tensor(0.8487)\n",
      "25934 Traning Loss: tensor(0.8487)\n",
      "25935 Traning Loss: tensor(0.8487)\n",
      "25936 Traning Loss: tensor(0.8487)\n",
      "25937 Traning Loss: tensor(0.8487)\n",
      "25938 Traning Loss: tensor(0.8487)\n",
      "25939 Traning Loss: tensor(0.8487)\n",
      "25940 Traning Loss: tensor(0.8487)\n",
      "25941 Traning Loss: tensor(0.8487)\n",
      "25942 Traning Loss: tensor(0.8487)\n",
      "25943 Traning Loss: tensor(0.8487)\n",
      "25944 Traning Loss: tensor(0.8487)\n",
      "25945 Traning Loss: tensor(0.8487)\n",
      "25946 Traning Loss: tensor(0.8487)\n",
      "25947 Traning Loss: tensor(0.8487)\n",
      "25948 Traning Loss: tensor(0.8487)\n",
      "25949 Traning Loss: tensor(0.8487)\n",
      "25950 Traning Loss: tensor(0.8487)\n",
      "25951 Traning Loss: tensor(0.8487)\n",
      "25952 Traning Loss: tensor(0.8487)\n",
      "25953 Traning Loss: tensor(0.8487)\n",
      "25954 Traning Loss: tensor(0.8487)\n",
      "25955 Traning Loss: tensor(0.8487)\n",
      "25956 Traning Loss: tensor(0.8487)\n",
      "25957 Traning Loss: tensor(0.8487)\n",
      "25958 Traning Loss: tensor(0.8487)\n",
      "25959 Traning Loss: tensor(0.8487)\n",
      "25960 Traning Loss: tensor(0.8487)\n",
      "25961 Traning Loss: tensor(0.8487)\n",
      "25962 Traning Loss: tensor(0.8487)\n",
      "25963 Traning Loss: tensor(0.8487)\n",
      "25964 Traning Loss: tensor(0.8487)\n",
      "25965 Traning Loss: tensor(0.8487)\n",
      "25966 Traning Loss: tensor(0.8487)\n",
      "25967 Traning Loss: tensor(0.8487)\n",
      "25968 Traning Loss: tensor(0.8487)\n",
      "25969 Traning Loss: tensor(0.8487)\n",
      "25970 Traning Loss: tensor(0.8487)\n",
      "25971 Traning Loss: tensor(0.8487)\n",
      "25972 Traning Loss: tensor(0.8487)\n",
      "25973 Traning Loss: tensor(0.8487)\n",
      "25974 Traning Loss: tensor(0.8487)\n",
      "25975 Traning Loss: tensor(0.8487)\n",
      "25976 Traning Loss: tensor(0.8487)\n",
      "25977 Traning Loss: tensor(0.8487)\n",
      "25978 Traning Loss: tensor(0.8487)\n",
      "25979 Traning Loss: tensor(0.8487)\n",
      "25980 Traning Loss: tensor(0.8487)\n",
      "25981 Traning Loss: tensor(0.8487)\n",
      "25982 Traning Loss: tensor(0.8487)\n",
      "25983 Traning Loss: tensor(0.8487)\n",
      "25984 Traning Loss: tensor(0.8487)\n",
      "25985 Traning Loss: tensor(0.8487)\n",
      "25986 Traning Loss: tensor(0.8487)\n",
      "25987 Traning Loss: tensor(0.8487)\n",
      "25988 Traning Loss: tensor(0.8487)\n",
      "25989 Traning Loss: tensor(0.8487)\n",
      "25990 Traning Loss: tensor(0.8487)\n",
      "25991 Traning Loss: tensor(0.8487)\n",
      "25992 Traning Loss: tensor(0.8487)\n",
      "25993 Traning Loss: tensor(0.8487)\n",
      "25994 Traning Loss: tensor(0.8487)\n",
      "25995 Traning Loss: tensor(0.8487)\n",
      "25996 Traning Loss: tensor(0.8487)\n",
      "25997 Traning Loss: tensor(0.8487)\n",
      "25998 Traning Loss: tensor(0.8487)\n",
      "25999 Traning Loss: tensor(0.8487)\n",
      "26000 Traning Loss: tensor(0.8487)\n",
      "26001 Traning Loss: tensor(0.8487)\n",
      "26002 Traning Loss: tensor(0.8487)\n",
      "26003 Traning Loss: tensor(0.8487)\n",
      "26004 Traning Loss: tensor(0.8487)\n",
      "26005 Traning Loss: tensor(0.8487)\n",
      "26006 Traning Loss: tensor(0.8487)\n",
      "26007 Traning Loss: tensor(0.8487)\n",
      "26008 Traning Loss: tensor(0.8487)\n",
      "26009 Traning Loss: tensor(0.8487)\n",
      "26010 Traning Loss: tensor(0.8487)\n",
      "26011 Traning Loss: tensor(0.8487)\n",
      "26012 Traning Loss: tensor(0.8487)\n",
      "26013 Traning Loss: tensor(0.8487)\n",
      "26014 Traning Loss: tensor(0.8487)\n",
      "26015 Traning Loss: tensor(0.8487)\n",
      "26016 Traning Loss: tensor(0.8487)\n",
      "26017 Traning Loss: tensor(0.8487)\n",
      "26018 Traning Loss: tensor(0.8487)\n",
      "26019 Traning Loss: tensor(0.8487)\n",
      "26020 Traning Loss: tensor(0.8487)\n",
      "26021 Traning Loss: tensor(0.8487)\n",
      "26022 Traning Loss: tensor(0.8487)\n",
      "26023 Traning Loss: tensor(0.8487)\n",
      "26024 Traning Loss: tensor(0.8487)\n",
      "26025 Traning Loss: tensor(0.8487)\n",
      "26026 Traning Loss: tensor(0.8487)\n",
      "26027 Traning Loss: tensor(0.8487)\n",
      "26028 Traning Loss: tensor(0.8487)\n",
      "26029 Traning Loss: tensor(0.8487)\n",
      "26030 Traning Loss: tensor(0.8487)\n",
      "26031 Traning Loss: tensor(0.8487)\n",
      "26032 Traning Loss: tensor(0.8487)\n",
      "26033 Traning Loss: tensor(0.8487)\n",
      "26034 Traning Loss: tensor(0.8487)\n",
      "26035 Traning Loss: tensor(0.8487)\n",
      "26036 Traning Loss: tensor(0.8487)\n",
      "26037 Traning Loss: tensor(0.8487)\n",
      "26038 Traning Loss: tensor(0.8487)\n",
      "26039 Traning Loss: tensor(0.8487)\n",
      "26040 Traning Loss: tensor(0.8487)\n",
      "26041 Traning Loss: tensor(0.8487)\n",
      "26042 Traning Loss: tensor(0.8487)\n",
      "26043 Traning Loss: tensor(0.8487)\n",
      "26044 Traning Loss: tensor(0.8487)\n",
      "26045 Traning Loss: tensor(0.8487)\n",
      "26046 Traning Loss: tensor(0.8487)\n",
      "26047 Traning Loss: tensor(0.8487)\n",
      "26048 Traning Loss: tensor(0.8487)\n",
      "26049 Traning Loss: tensor(0.8487)\n",
      "26050 Traning Loss: tensor(0.8487)\n",
      "26051 Traning Loss: tensor(0.8487)\n",
      "26052 Traning Loss: tensor(0.8487)\n",
      "26053 Traning Loss: tensor(0.8487)\n",
      "26054 Traning Loss: tensor(0.8487)\n",
      "26055 Traning Loss: tensor(0.8487)\n",
      "26056 Traning Loss: tensor(0.8487)\n",
      "26057 Traning Loss: tensor(0.8487)\n",
      "26058 Traning Loss: tensor(0.8487)\n",
      "26059 Traning Loss: tensor(0.8487)\n",
      "26060 Traning Loss: tensor(0.8487)\n",
      "26061 Traning Loss: tensor(0.8487)\n",
      "26062 Traning Loss: tensor(0.8487)\n",
      "26063 Traning Loss: tensor(0.8487)\n",
      "26064 Traning Loss: tensor(0.8487)\n",
      "26065 Traning Loss: tensor(0.8487)\n",
      "26066 Traning Loss: tensor(0.8487)\n",
      "26067 Traning Loss: tensor(0.8487)\n",
      "26068 Traning Loss: tensor(0.8487)\n",
      "26069 Traning Loss: tensor(0.8487)\n",
      "26070 Traning Loss: tensor(0.8487)\n",
      "26071 Traning Loss: tensor(0.8487)\n",
      "26072 Traning Loss: tensor(0.8487)\n",
      "26073 Traning Loss: tensor(0.8487)\n",
      "26074 Traning Loss: tensor(0.8487)\n",
      "26075 Traning Loss: tensor(0.8487)\n",
      "26076 Traning Loss: tensor(0.8487)\n",
      "26077 Traning Loss: tensor(0.8487)\n",
      "26078 Traning Loss: tensor(0.8487)\n",
      "26079 Traning Loss: tensor(0.8487)\n",
      "26080 Traning Loss: tensor(0.8487)\n",
      "26081 Traning Loss: tensor(0.8487)\n",
      "26082 Traning Loss: tensor(0.8487)\n",
      "26083 Traning Loss: tensor(0.8487)\n",
      "26084 Traning Loss: tensor(0.8487)\n",
      "26085 Traning Loss: tensor(0.8487)\n",
      "26086 Traning Loss: tensor(0.8487)\n",
      "26087 Traning Loss: tensor(0.8487)\n",
      "26088 Traning Loss: tensor(0.8487)\n",
      "26089 Traning Loss: tensor(0.8487)\n",
      "26090 Traning Loss: tensor(0.8487)\n",
      "26091 Traning Loss: tensor(0.8487)\n",
      "26092 Traning Loss: tensor(0.8487)\n",
      "26093 Traning Loss: tensor(0.8487)\n",
      "26094 Traning Loss: tensor(0.8487)\n",
      "26095 Traning Loss: tensor(0.8487)\n",
      "26096 Traning Loss: tensor(0.8487)\n",
      "26097 Traning Loss: tensor(0.8487)\n",
      "26098 Traning Loss: tensor(0.8487)\n",
      "26099 Traning Loss: tensor(0.8487)\n",
      "26100 Traning Loss: tensor(0.8487)\n",
      "26101 Traning Loss: tensor(0.8487)\n",
      "26102 Traning Loss: tensor(0.8487)\n",
      "26103 Traning Loss: tensor(0.8487)\n",
      "26104 Traning Loss: tensor(0.8487)\n",
      "26105 Traning Loss: tensor(0.8487)\n",
      "26106 Traning Loss: tensor(0.8487)\n",
      "26107 Traning Loss: tensor(0.8487)\n",
      "26108 Traning Loss: tensor(0.8487)\n",
      "26109 Traning Loss: tensor(0.8487)\n",
      "26110 Traning Loss: tensor(0.8487)\n",
      "26111 Traning Loss: tensor(0.8487)\n",
      "26112 Traning Loss: tensor(0.8487)\n",
      "26113 Traning Loss: tensor(0.8487)\n",
      "26114 Traning Loss: tensor(0.8487)\n",
      "26115 Traning Loss: tensor(0.8487)\n",
      "26116 Traning Loss: tensor(0.8487)\n",
      "26117 Traning Loss: tensor(0.8487)\n",
      "26118 Traning Loss: tensor(0.8487)\n",
      "26119 Traning Loss: tensor(0.8487)\n",
      "26120 Traning Loss: tensor(0.8487)\n",
      "26121 Traning Loss: tensor(0.8487)\n",
      "26122 Traning Loss: tensor(0.8487)\n",
      "26123 Traning Loss: tensor(0.8487)\n",
      "26124 Traning Loss: tensor(0.8487)\n",
      "26125 Traning Loss: tensor(0.8487)\n",
      "26126 Traning Loss: tensor(0.8487)\n",
      "26127 Traning Loss: tensor(0.8487)\n",
      "26128 Traning Loss: tensor(0.8487)\n",
      "26129 Traning Loss: tensor(0.8487)\n",
      "26130 Traning Loss: tensor(0.8487)\n",
      "26131 Traning Loss: tensor(0.8487)\n",
      "26132 Traning Loss: tensor(0.8487)\n",
      "26133 Traning Loss: tensor(0.8487)\n",
      "26134 Traning Loss: tensor(0.8487)\n",
      "26135 Traning Loss: tensor(0.8487)\n",
      "26136 Traning Loss: tensor(0.8487)\n",
      "26137 Traning Loss: tensor(0.8487)\n",
      "26138 Traning Loss: tensor(0.8487)\n",
      "26139 Traning Loss: tensor(0.8487)\n",
      "26140 Traning Loss: tensor(0.8487)\n",
      "26141 Traning Loss: tensor(0.8487)\n",
      "26142 Traning Loss: tensor(0.8487)\n",
      "26143 Traning Loss: tensor(0.8487)\n",
      "26144 Traning Loss: tensor(0.8487)\n",
      "26145 Traning Loss: tensor(0.8487)\n",
      "26146 Traning Loss: tensor(0.8487)\n",
      "26147 Traning Loss: tensor(0.8487)\n",
      "26148 Traning Loss: tensor(0.8487)\n",
      "26149 Traning Loss: tensor(0.8487)\n",
      "26150 Traning Loss: tensor(0.8487)\n",
      "26151 Traning Loss: tensor(0.8487)\n",
      "26152 Traning Loss: tensor(0.8487)\n",
      "26153 Traning Loss: tensor(0.8487)\n",
      "26154 Traning Loss: tensor(0.8487)\n",
      "26155 Traning Loss: tensor(0.8487)\n",
      "26156 Traning Loss: tensor(0.8487)\n",
      "26157 Traning Loss: tensor(0.8487)\n",
      "26158 Traning Loss: tensor(0.8487)\n",
      "26159 Traning Loss: tensor(0.8487)\n",
      "26160 Traning Loss: tensor(0.8487)\n",
      "26161 Traning Loss: tensor(0.8487)\n",
      "26162 Traning Loss: tensor(0.8487)\n",
      "26163 Traning Loss: tensor(0.8487)\n",
      "26164 Traning Loss: tensor(0.8487)\n",
      "26165 Traning Loss: tensor(0.8487)\n",
      "26166 Traning Loss: tensor(0.8487)\n",
      "26167 Traning Loss: tensor(0.8487)\n",
      "26168 Traning Loss: tensor(0.8487)\n",
      "26169 Traning Loss: tensor(0.8487)\n",
      "26170 Traning Loss: tensor(0.8487)\n",
      "26171 Traning Loss: tensor(0.8487)\n",
      "26172 Traning Loss: tensor(0.8487)\n",
      "26173 Traning Loss: tensor(0.8487)\n",
      "26174 Traning Loss: tensor(0.8487)\n",
      "26175 Traning Loss: tensor(0.8487)\n",
      "26176 Traning Loss: tensor(0.8487)\n",
      "26177 Traning Loss: tensor(0.8487)\n",
      "26178 Traning Loss: tensor(0.8487)\n",
      "26179 Traning Loss: tensor(0.8487)\n",
      "26180 Traning Loss: tensor(0.8487)\n",
      "26181 Traning Loss: tensor(0.8487)\n",
      "26182 Traning Loss: tensor(0.8487)\n",
      "26183 Traning Loss: tensor(0.8487)\n",
      "26184 Traning Loss: tensor(0.8487)\n",
      "26185 Traning Loss: tensor(0.8487)\n",
      "26186 Traning Loss: tensor(0.8487)\n",
      "26187 Traning Loss: tensor(0.8487)\n",
      "26188 Traning Loss: tensor(0.8487)\n",
      "26189 Traning Loss: tensor(0.8487)\n",
      "26190 Traning Loss: tensor(0.8487)\n",
      "26191 Traning Loss: tensor(0.8487)\n",
      "26192 Traning Loss: tensor(0.8487)\n",
      "26193 Traning Loss: tensor(0.8487)\n",
      "26194 Traning Loss: tensor(0.8487)\n",
      "26195 Traning Loss: tensor(0.8487)\n",
      "26196 Traning Loss: tensor(0.8487)\n",
      "26197 Traning Loss: tensor(0.8487)\n",
      "26198 Traning Loss: tensor(0.8487)\n",
      "26199 Traning Loss: tensor(0.8487)\n",
      "26200 Traning Loss: tensor(0.8487)\n",
      "26201 Traning Loss: tensor(0.8487)\n",
      "26202 Traning Loss: tensor(0.8487)\n",
      "26203 Traning Loss: tensor(0.8487)\n",
      "26204 Traning Loss: tensor(0.8487)\n",
      "26205 Traning Loss: tensor(0.8487)\n",
      "26206 Traning Loss: tensor(0.8487)\n",
      "26207 Traning Loss: tensor(0.8487)\n",
      "26208 Traning Loss: tensor(0.8487)\n",
      "26209 Traning Loss: tensor(0.8487)\n",
      "26210 Traning Loss: tensor(0.8487)\n",
      "26211 Traning Loss: tensor(0.8487)\n",
      "26212 Traning Loss: tensor(0.8487)\n",
      "26213 Traning Loss: tensor(0.8487)\n",
      "26214 Traning Loss: tensor(0.8487)\n",
      "26215 Traning Loss: tensor(0.8487)\n",
      "26216 Traning Loss: tensor(0.8487)\n",
      "26217 Traning Loss: tensor(0.8487)\n",
      "26218 Traning Loss: tensor(0.8487)\n",
      "26219 Traning Loss: tensor(0.8487)\n",
      "26220 Traning Loss: tensor(0.8487)\n",
      "26221 Traning Loss: tensor(0.8487)\n",
      "26222 Traning Loss: tensor(0.8487)\n",
      "26223 Traning Loss: tensor(0.8487)\n",
      "26224 Traning Loss: tensor(0.8487)\n",
      "26225 Traning Loss: tensor(0.8487)\n",
      "26226 Traning Loss: tensor(0.8487)\n",
      "26227 Traning Loss: tensor(0.8487)\n",
      "26228 Traning Loss: tensor(0.8487)\n",
      "26229 Traning Loss: tensor(0.8487)\n",
      "26230 Traning Loss: tensor(0.8487)\n",
      "26231 Traning Loss: tensor(0.8487)\n",
      "26232 Traning Loss: tensor(0.8487)\n",
      "26233 Traning Loss: tensor(0.8487)\n",
      "26234 Traning Loss: tensor(0.8487)\n",
      "26235 Traning Loss: tensor(0.8487)\n",
      "26236 Traning Loss: tensor(0.8487)\n",
      "26237 Traning Loss: tensor(0.8487)\n",
      "26238 Traning Loss: tensor(0.8487)\n",
      "26239 Traning Loss: tensor(0.8487)\n",
      "26240 Traning Loss: tensor(0.8487)\n",
      "26241 Traning Loss: tensor(0.8487)\n",
      "26242 Traning Loss: tensor(0.8487)\n",
      "26243 Traning Loss: tensor(0.8487)\n",
      "26244 Traning Loss: tensor(0.8487)\n",
      "26245 Traning Loss: tensor(0.8487)\n",
      "26246 Traning Loss: tensor(0.8487)\n",
      "26247 Traning Loss: tensor(0.8487)\n",
      "26248 Traning Loss: tensor(0.8487)\n",
      "26249 Traning Loss: tensor(0.8487)\n",
      "26250 Traning Loss: tensor(0.8487)\n",
      "26251 Traning Loss: tensor(0.8487)\n",
      "26252 Traning Loss: tensor(0.8487)\n",
      "26253 Traning Loss: tensor(0.8487)\n",
      "26254 Traning Loss: tensor(0.8487)\n",
      "26255 Traning Loss: tensor(0.8487)\n",
      "26256 Traning Loss: tensor(0.8487)\n",
      "26257 Traning Loss: tensor(0.8487)\n",
      "26258 Traning Loss: tensor(0.8487)\n",
      "26259 Traning Loss: tensor(0.8487)\n",
      "26260 Traning Loss: tensor(0.8487)\n",
      "26261 Traning Loss: tensor(0.8487)\n",
      "26262 Traning Loss: tensor(0.8487)\n",
      "26263 Traning Loss: tensor(0.8487)\n",
      "26264 Traning Loss: tensor(0.8487)\n",
      "26265 Traning Loss: tensor(0.8487)\n",
      "26266 Traning Loss: tensor(0.8487)\n",
      "26267 Traning Loss: tensor(0.8487)\n",
      "26268 Traning Loss: tensor(0.8487)\n",
      "26269 Traning Loss: tensor(0.8487)\n",
      "26270 Traning Loss: tensor(0.8487)\n",
      "26271 Traning Loss: tensor(0.8487)\n",
      "26272 Traning Loss: tensor(0.8487)\n",
      "26273 Traning Loss: tensor(0.8487)\n",
      "26274 Traning Loss: tensor(0.8487)\n",
      "26275 Traning Loss: tensor(0.8487)\n",
      "26276 Traning Loss: tensor(0.8487)\n",
      "26277 Traning Loss: tensor(0.8487)\n",
      "26278 Traning Loss: tensor(0.8487)\n",
      "26279 Traning Loss: tensor(0.8487)\n",
      "26280 Traning Loss: tensor(0.8487)\n",
      "26281 Traning Loss: tensor(0.8487)\n",
      "26282 Traning Loss: tensor(0.8487)\n",
      "26283 Traning Loss: tensor(0.8487)\n",
      "26284 Traning Loss: tensor(0.8487)\n",
      "26285 Traning Loss: tensor(0.8487)\n",
      "26286 Traning Loss: tensor(0.8487)\n",
      "26287 Traning Loss: tensor(0.8487)\n",
      "26288 Traning Loss: tensor(0.8487)\n",
      "26289 Traning Loss: tensor(0.8487)\n",
      "26290 Traning Loss: tensor(0.8487)\n",
      "26291 Traning Loss: tensor(0.8487)\n",
      "26292 Traning Loss: tensor(0.8487)\n",
      "26293 Traning Loss: tensor(0.8487)\n",
      "26294 Traning Loss: tensor(0.8487)\n",
      "26295 Traning Loss: tensor(0.8487)\n",
      "26296 Traning Loss: tensor(0.8487)\n",
      "26297 Traning Loss: tensor(0.8487)\n",
      "26298 Traning Loss: tensor(0.8487)\n",
      "26299 Traning Loss: tensor(0.8487)\n",
      "26300 Traning Loss: tensor(0.8487)\n",
      "26301 Traning Loss: tensor(0.8487)\n",
      "26302 Traning Loss: tensor(0.8487)\n",
      "26303 Traning Loss: tensor(0.8487)\n",
      "26304 Traning Loss: tensor(0.8487)\n",
      "26305 Traning Loss: tensor(0.8487)\n",
      "26306 Traning Loss: tensor(0.8487)\n",
      "26307 Traning Loss: tensor(0.8487)\n",
      "26308 Traning Loss: tensor(0.8487)\n",
      "26309 Traning Loss: tensor(0.8487)\n",
      "26310 Traning Loss: tensor(0.8487)\n",
      "26311 Traning Loss: tensor(0.8487)\n",
      "26312 Traning Loss: tensor(0.8487)\n",
      "26313 Traning Loss: tensor(0.8487)\n",
      "26314 Traning Loss: tensor(0.8487)\n",
      "26315 Traning Loss: tensor(0.8487)\n",
      "26316 Traning Loss: tensor(0.8487)\n",
      "26317 Traning Loss: tensor(0.8487)\n",
      "26318 Traning Loss: tensor(0.8487)\n",
      "26319 Traning Loss: tensor(0.8487)\n",
      "26320 Traning Loss: tensor(0.8487)\n",
      "26321 Traning Loss: tensor(0.8487)\n",
      "26322 Traning Loss: tensor(0.8487)\n",
      "26323 Traning Loss: tensor(0.8487)\n",
      "26324 Traning Loss: tensor(0.8487)\n",
      "26325 Traning Loss: tensor(0.8487)\n",
      "26326 Traning Loss: tensor(0.8487)\n",
      "26327 Traning Loss: tensor(0.8487)\n",
      "26328 Traning Loss: tensor(0.8487)\n",
      "26329 Traning Loss: tensor(0.8487)\n",
      "26330 Traning Loss: tensor(0.8487)\n",
      "26331 Traning Loss: tensor(0.8487)\n",
      "26332 Traning Loss: tensor(0.8487)\n",
      "26333 Traning Loss: tensor(0.8487)\n",
      "26334 Traning Loss: tensor(0.8487)\n",
      "26335 Traning Loss: tensor(0.8487)\n",
      "26336 Traning Loss: tensor(0.8487)\n",
      "26337 Traning Loss: tensor(0.8487)\n",
      "26338 Traning Loss: tensor(0.8487)\n",
      "26339 Traning Loss: tensor(0.8487)\n",
      "26340 Traning Loss: tensor(0.8487)\n",
      "26341 Traning Loss: tensor(0.8487)\n",
      "26342 Traning Loss: tensor(0.8487)\n",
      "26343 Traning Loss: tensor(0.8487)\n",
      "26344 Traning Loss: tensor(0.8487)\n",
      "26345 Traning Loss: tensor(0.8487)\n",
      "26346 Traning Loss: tensor(0.8487)\n",
      "26347 Traning Loss: tensor(0.8487)\n",
      "26348 Traning Loss: tensor(0.8487)\n",
      "26349 Traning Loss: tensor(0.8487)\n",
      "26350 Traning Loss: tensor(0.8487)\n",
      "26351 Traning Loss: tensor(0.8487)\n",
      "26352 Traning Loss: tensor(0.8487)\n",
      "26353 Traning Loss: tensor(0.8487)\n",
      "26354 Traning Loss: tensor(0.8487)\n",
      "26355 Traning Loss: tensor(0.8487)\n",
      "26356 Traning Loss: tensor(0.8487)\n",
      "26357 Traning Loss: tensor(0.8487)\n",
      "26358 Traning Loss: tensor(0.8487)\n",
      "26359 Traning Loss: tensor(0.8487)\n",
      "26360 Traning Loss: tensor(0.8487)\n",
      "26361 Traning Loss: tensor(0.8487)\n",
      "26362 Traning Loss: tensor(0.8487)\n",
      "26363 Traning Loss: tensor(0.8487)\n",
      "26364 Traning Loss: tensor(0.8487)\n",
      "26365 Traning Loss: tensor(0.8487)\n",
      "26366 Traning Loss: tensor(0.8487)\n",
      "26367 Traning Loss: tensor(0.8487)\n",
      "26368 Traning Loss: tensor(0.8487)\n",
      "26369 Traning Loss: tensor(0.8487)\n",
      "26370 Traning Loss: tensor(0.8487)\n",
      "26371 Traning Loss: tensor(0.8487)\n",
      "26372 Traning Loss: tensor(0.8487)\n",
      "26373 Traning Loss: tensor(0.8487)\n",
      "26374 Traning Loss: tensor(0.8487)\n",
      "26375 Traning Loss: tensor(0.8487)\n",
      "26376 Traning Loss: tensor(0.8487)\n",
      "26377 Traning Loss: tensor(0.8487)\n",
      "26378 Traning Loss: tensor(0.8487)\n",
      "26379 Traning Loss: tensor(0.8487)\n",
      "26380 Traning Loss: tensor(0.8487)\n",
      "26381 Traning Loss: tensor(0.8487)\n",
      "26382 Traning Loss: tensor(0.8487)\n",
      "26383 Traning Loss: tensor(0.8487)\n",
      "26384 Traning Loss: tensor(0.8487)\n",
      "26385 Traning Loss: tensor(0.8487)\n",
      "26386 Traning Loss: tensor(0.8487)\n",
      "26387 Traning Loss: tensor(0.8487)\n",
      "26388 Traning Loss: tensor(0.8487)\n",
      "26389 Traning Loss: tensor(0.8487)\n",
      "26390 Traning Loss: tensor(0.8487)\n",
      "26391 Traning Loss: tensor(0.8487)\n",
      "26392 Traning Loss: tensor(0.8487)\n",
      "26393 Traning Loss: tensor(0.8487)\n",
      "26394 Traning Loss: tensor(0.8487)\n",
      "26395 Traning Loss: tensor(0.8487)\n",
      "26396 Traning Loss: tensor(0.8487)\n",
      "26397 Traning Loss: tensor(0.8487)\n",
      "26398 Traning Loss: tensor(0.8487)\n",
      "26399 Traning Loss: tensor(0.8487)\n",
      "26400 Traning Loss: tensor(0.8487)\n",
      "26401 Traning Loss: tensor(0.8487)\n",
      "26402 Traning Loss: tensor(0.8487)\n",
      "26403 Traning Loss: tensor(0.8487)\n",
      "26404 Traning Loss: tensor(0.8487)\n",
      "26405 Traning Loss: tensor(0.8487)\n",
      "26406 Traning Loss: tensor(0.8487)\n",
      "26407 Traning Loss: tensor(0.8487)\n",
      "26408 Traning Loss: tensor(0.8487)\n",
      "26409 Traning Loss: tensor(0.8487)\n",
      "26410 Traning Loss: tensor(0.8487)\n",
      "26411 Traning Loss: tensor(0.8487)\n",
      "26412 Traning Loss: tensor(0.8487)\n",
      "26413 Traning Loss: tensor(0.8487)\n",
      "26414 Traning Loss: tensor(0.8487)\n",
      "26415 Traning Loss: tensor(0.8487)\n",
      "26416 Traning Loss: tensor(0.8487)\n",
      "26417 Traning Loss: tensor(0.8487)\n",
      "26418 Traning Loss: tensor(0.8487)\n",
      "26419 Traning Loss: tensor(0.8487)\n",
      "26420 Traning Loss: tensor(0.8487)\n",
      "26421 Traning Loss: tensor(0.8487)\n",
      "26422 Traning Loss: tensor(0.8487)\n",
      "26423 Traning Loss: tensor(0.8487)\n",
      "26424 Traning Loss: tensor(0.8487)\n",
      "26425 Traning Loss: tensor(0.8487)\n",
      "26426 Traning Loss: tensor(0.8487)\n",
      "26427 Traning Loss: tensor(0.8487)\n",
      "26428 Traning Loss: tensor(0.8487)\n",
      "26429 Traning Loss: tensor(0.8487)\n",
      "26430 Traning Loss: tensor(0.8487)\n",
      "26431 Traning Loss: tensor(0.8487)\n",
      "26432 Traning Loss: tensor(0.8487)\n",
      "26433 Traning Loss: tensor(0.8487)\n",
      "26434 Traning Loss: tensor(0.8487)\n",
      "26435 Traning Loss: tensor(0.8487)\n",
      "26436 Traning Loss: tensor(0.8487)\n",
      "26437 Traning Loss: tensor(0.8487)\n",
      "26438 Traning Loss: tensor(0.8487)\n",
      "26439 Traning Loss: tensor(0.8487)\n",
      "26440 Traning Loss: tensor(0.8487)\n",
      "26441 Traning Loss: tensor(0.8487)\n",
      "26442 Traning Loss: tensor(0.8487)\n",
      "26443 Traning Loss: tensor(0.8487)\n",
      "26444 Traning Loss: tensor(0.8487)\n",
      "26445 Traning Loss: tensor(0.8487)\n",
      "26446 Traning Loss: tensor(0.8487)\n",
      "26447 Traning Loss: tensor(0.8487)\n",
      "26448 Traning Loss: tensor(0.8487)\n",
      "26449 Traning Loss: tensor(0.8487)\n",
      "26450 Traning Loss: tensor(0.8487)\n",
      "26451 Traning Loss: tensor(0.8487)\n",
      "26452 Traning Loss: tensor(0.8487)\n",
      "26453 Traning Loss: tensor(0.8487)\n",
      "26454 Traning Loss: tensor(0.8487)\n",
      "26455 Traning Loss: tensor(0.8487)\n",
      "26456 Traning Loss: tensor(0.8487)\n",
      "26457 Traning Loss: tensor(0.8487)\n",
      "26458 Traning Loss: tensor(0.8487)\n",
      "26459 Traning Loss: tensor(0.8487)\n",
      "26460 Traning Loss: tensor(0.8487)\n",
      "26461 Traning Loss: tensor(0.8487)\n",
      "26462 Traning Loss: tensor(0.8487)\n",
      "26463 Traning Loss: tensor(0.8487)\n",
      "26464 Traning Loss: tensor(0.8487)\n",
      "26465 Traning Loss: tensor(0.8487)\n",
      "26466 Traning Loss: tensor(0.8487)\n",
      "26467 Traning Loss: tensor(0.8487)\n",
      "26468 Traning Loss: tensor(0.8487)\n",
      "26469 Traning Loss: tensor(0.8487)\n",
      "26470 Traning Loss: tensor(0.8487)\n",
      "26471 Traning Loss: tensor(0.8487)\n",
      "26472 Traning Loss: tensor(0.8487)\n",
      "26473 Traning Loss: tensor(0.8487)\n",
      "26474 Traning Loss: tensor(0.8487)\n",
      "26475 Traning Loss: tensor(0.8487)\n",
      "26476 Traning Loss: tensor(0.8487)\n",
      "26477 Traning Loss: tensor(0.8487)\n",
      "26478 Traning Loss: tensor(0.8487)\n",
      "26479 Traning Loss: tensor(0.8487)\n",
      "26480 Traning Loss: tensor(0.8487)\n",
      "26481 Traning Loss: tensor(0.8487)\n",
      "26482 Traning Loss: tensor(0.8487)\n",
      "26483 Traning Loss: tensor(0.8487)\n",
      "26484 Traning Loss: tensor(0.8487)\n",
      "26485 Traning Loss: tensor(0.8487)\n",
      "26486 Traning Loss: tensor(0.8487)\n",
      "26487 Traning Loss: tensor(0.8487)\n",
      "26488 Traning Loss: tensor(0.8487)\n",
      "26489 Traning Loss: tensor(0.8487)\n",
      "26490 Traning Loss: tensor(0.8487)\n",
      "26491 Traning Loss: tensor(0.8487)\n",
      "26492 Traning Loss: tensor(0.8487)\n",
      "26493 Traning Loss: tensor(0.8487)\n",
      "26494 Traning Loss: tensor(0.8487)\n",
      "26495 Traning Loss: tensor(0.8487)\n",
      "26496 Traning Loss: tensor(0.8487)\n",
      "26497 Traning Loss: tensor(0.8487)\n",
      "26498 Traning Loss: tensor(0.8487)\n",
      "26499 Traning Loss: tensor(0.8487)\n",
      "26500 Traning Loss: tensor(0.8487)\n",
      "26501 Traning Loss: tensor(0.8487)\n",
      "26502 Traning Loss: tensor(0.8487)\n",
      "26503 Traning Loss: tensor(0.8487)\n",
      "26504 Traning Loss: tensor(0.8487)\n",
      "26505 Traning Loss: tensor(0.8487)\n",
      "26506 Traning Loss: tensor(0.8487)\n",
      "26507 Traning Loss: tensor(0.8487)\n",
      "26508 Traning Loss: tensor(0.8487)\n",
      "26509 Traning Loss: tensor(0.8487)\n",
      "26510 Traning Loss: tensor(0.8487)\n",
      "26511 Traning Loss: tensor(0.8487)\n",
      "26512 Traning Loss: tensor(0.8487)\n",
      "26513 Traning Loss: tensor(0.8487)\n",
      "26514 Traning Loss: tensor(0.8487)\n",
      "26515 Traning Loss: tensor(0.8487)\n",
      "26516 Traning Loss: tensor(0.8487)\n",
      "26517 Traning Loss: tensor(0.8487)\n",
      "26518 Traning Loss: tensor(0.8487)\n",
      "26519 Traning Loss: tensor(0.8487)\n",
      "26520 Traning Loss: tensor(0.8487)\n",
      "26521 Traning Loss: tensor(0.8487)\n",
      "26522 Traning Loss: tensor(0.8487)\n",
      "26523 Traning Loss: tensor(0.8487)\n",
      "26524 Traning Loss: tensor(0.8487)\n",
      "26525 Traning Loss: tensor(0.8487)\n",
      "26526 Traning Loss: tensor(0.8487)\n",
      "26527 Traning Loss: tensor(0.8487)\n",
      "26528 Traning Loss: tensor(0.8487)\n",
      "26529 Traning Loss: tensor(0.8487)\n",
      "26530 Traning Loss: tensor(0.8487)\n",
      "26531 Traning Loss: tensor(0.8487)\n",
      "26532 Traning Loss: tensor(0.8487)\n",
      "26533 Traning Loss: tensor(0.8487)\n",
      "26534 Traning Loss: tensor(0.8487)\n",
      "26535 Traning Loss: tensor(0.8487)\n",
      "26536 Traning Loss: tensor(0.8487)\n",
      "26537 Traning Loss: tensor(0.8487)\n",
      "26538 Traning Loss: tensor(0.8487)\n",
      "26539 Traning Loss: tensor(0.8487)\n",
      "26540 Traning Loss: tensor(0.8487)\n",
      "26541 Traning Loss: tensor(0.8487)\n",
      "26542 Traning Loss: tensor(0.8487)\n",
      "26543 Traning Loss: tensor(0.8487)\n",
      "26544 Traning Loss: tensor(0.8487)\n",
      "26545 Traning Loss: tensor(0.8487)\n",
      "26546 Traning Loss: tensor(0.8487)\n",
      "26547 Traning Loss: tensor(0.8487)\n",
      "26548 Traning Loss: tensor(0.8487)\n",
      "26549 Traning Loss: tensor(0.8487)\n",
      "26550 Traning Loss: tensor(0.8487)\n",
      "26551 Traning Loss: tensor(0.8487)\n",
      "26552 Traning Loss: tensor(0.8487)\n",
      "26553 Traning Loss: tensor(0.8487)\n",
      "26554 Traning Loss: tensor(0.8487)\n",
      "26555 Traning Loss: tensor(0.8487)\n",
      "26556 Traning Loss: tensor(0.8487)\n",
      "26557 Traning Loss: tensor(0.8487)\n",
      "26558 Traning Loss: tensor(0.8487)\n",
      "26559 Traning Loss: tensor(0.8487)\n",
      "26560 Traning Loss: tensor(0.8487)\n",
      "26561 Traning Loss: tensor(0.8487)\n",
      "26562 Traning Loss: tensor(0.8487)\n",
      "26563 Traning Loss: tensor(0.8487)\n",
      "26564 Traning Loss: tensor(0.8487)\n",
      "26565 Traning Loss: tensor(0.8487)\n",
      "26566 Traning Loss: tensor(0.8487)\n",
      "26567 Traning Loss: tensor(0.8487)\n",
      "26568 Traning Loss: tensor(0.8487)\n",
      "26569 Traning Loss: tensor(0.8487)\n",
      "26570 Traning Loss: tensor(0.8487)\n",
      "26571 Traning Loss: tensor(0.8487)\n",
      "26572 Traning Loss: tensor(0.8487)\n",
      "26573 Traning Loss: tensor(0.8487)\n",
      "26574 Traning Loss: tensor(0.8487)\n",
      "26575 Traning Loss: tensor(0.8487)\n",
      "26576 Traning Loss: tensor(0.8487)\n",
      "26577 Traning Loss: tensor(0.8487)\n",
      "26578 Traning Loss: tensor(0.8487)\n",
      "26579 Traning Loss: tensor(0.8487)\n",
      "26580 Traning Loss: tensor(0.8487)\n",
      "26581 Traning Loss: tensor(0.8487)\n",
      "26582 Traning Loss: tensor(0.8487)\n",
      "26583 Traning Loss: tensor(0.8487)\n",
      "26584 Traning Loss: tensor(0.8487)\n",
      "26585 Traning Loss: tensor(0.8487)\n",
      "26586 Traning Loss: tensor(0.8487)\n",
      "26587 Traning Loss: tensor(0.8487)\n",
      "26588 Traning Loss: tensor(0.8487)\n",
      "26589 Traning Loss: tensor(0.8487)\n",
      "26590 Traning Loss: tensor(0.8487)\n",
      "26591 Traning Loss: tensor(0.8487)\n",
      "26592 Traning Loss: tensor(0.8487)\n",
      "26593 Traning Loss: tensor(0.8487)\n",
      "26594 Traning Loss: tensor(0.8487)\n",
      "26595 Traning Loss: tensor(0.8487)\n",
      "26596 Traning Loss: tensor(0.8487)\n",
      "26597 Traning Loss: tensor(0.8487)\n",
      "26598 Traning Loss: tensor(0.8487)\n",
      "26599 Traning Loss: tensor(0.8487)\n",
      "26600 Traning Loss: tensor(0.8487)\n",
      "26601 Traning Loss: tensor(0.8487)\n",
      "26602 Traning Loss: tensor(0.8487)\n",
      "26603 Traning Loss: tensor(0.8487)\n",
      "26604 Traning Loss: tensor(0.8487)\n",
      "26605 Traning Loss: tensor(0.8487)\n",
      "26606 Traning Loss: tensor(0.8487)\n",
      "26607 Traning Loss: tensor(0.8487)\n",
      "26608 Traning Loss: tensor(0.8487)\n",
      "26609 Traning Loss: tensor(0.8487)\n",
      "26610 Traning Loss: tensor(0.8487)\n",
      "26611 Traning Loss: tensor(0.8487)\n",
      "26612 Traning Loss: tensor(0.8487)\n",
      "26613 Traning Loss: tensor(0.8487)\n",
      "26614 Traning Loss: tensor(0.8487)\n",
      "26615 Traning Loss: tensor(0.8487)\n",
      "26616 Traning Loss: tensor(0.8487)\n",
      "26617 Traning Loss: tensor(0.8487)\n",
      "26618 Traning Loss: tensor(0.8487)\n",
      "26619 Traning Loss: tensor(0.8487)\n",
      "26620 Traning Loss: tensor(0.8487)\n",
      "26621 Traning Loss: tensor(0.8487)\n",
      "26622 Traning Loss: tensor(0.8487)\n",
      "26623 Traning Loss: tensor(0.8487)\n",
      "26624 Traning Loss: tensor(0.8487)\n",
      "26625 Traning Loss: tensor(0.8487)\n",
      "26626 Traning Loss: tensor(0.8487)\n",
      "26627 Traning Loss: tensor(0.8487)\n",
      "26628 Traning Loss: tensor(0.8487)\n",
      "26629 Traning Loss: tensor(0.8487)\n",
      "26630 Traning Loss: tensor(0.8487)\n",
      "26631 Traning Loss: tensor(0.8487)\n",
      "26632 Traning Loss: tensor(0.8487)\n",
      "26633 Traning Loss: tensor(0.8487)\n",
      "26634 Traning Loss: tensor(0.8487)\n",
      "26635 Traning Loss: tensor(0.8487)\n",
      "26636 Traning Loss: tensor(0.8487)\n",
      "26637 Traning Loss: tensor(0.8487)\n",
      "26638 Traning Loss: tensor(0.8487)\n",
      "26639 Traning Loss: tensor(0.8487)\n",
      "26640 Traning Loss: tensor(0.8487)\n",
      "26641 Traning Loss: tensor(0.8487)\n",
      "26642 Traning Loss: tensor(0.8487)\n",
      "26643 Traning Loss: tensor(0.8487)\n",
      "26644 Traning Loss: tensor(0.8487)\n",
      "26645 Traning Loss: tensor(0.8487)\n",
      "26646 Traning Loss: tensor(0.8487)\n",
      "26647 Traning Loss: tensor(0.8487)\n",
      "26648 Traning Loss: tensor(0.8487)\n",
      "26649 Traning Loss: tensor(0.8487)\n",
      "26650 Traning Loss: tensor(0.8487)\n",
      "26651 Traning Loss: tensor(0.8487)\n",
      "26652 Traning Loss: tensor(0.8487)\n",
      "26653 Traning Loss: tensor(0.8487)\n",
      "26654 Traning Loss: tensor(0.8487)\n",
      "26655 Traning Loss: tensor(0.8487)\n",
      "26656 Traning Loss: tensor(0.8487)\n",
      "26657 Traning Loss: tensor(0.8487)\n",
      "26658 Traning Loss: tensor(0.8487)\n",
      "26659 Traning Loss: tensor(0.8487)\n",
      "26660 Traning Loss: tensor(0.8487)\n",
      "26661 Traning Loss: tensor(0.8487)\n",
      "26662 Traning Loss: tensor(0.8487)\n",
      "26663 Traning Loss: tensor(0.8487)\n",
      "26664 Traning Loss: tensor(0.8487)\n",
      "26665 Traning Loss: tensor(0.8487)\n",
      "26666 Traning Loss: tensor(0.8487)\n",
      "26667 Traning Loss: tensor(0.8487)\n",
      "26668 Traning Loss: tensor(0.8487)\n",
      "26669 Traning Loss: tensor(0.8487)\n",
      "26670 Traning Loss: tensor(0.8487)\n",
      "26671 Traning Loss: tensor(0.8487)\n",
      "26672 Traning Loss: tensor(0.8487)\n",
      "26673 Traning Loss: tensor(0.8487)\n",
      "26674 Traning Loss: tensor(0.8487)\n",
      "26675 Traning Loss: tensor(0.8487)\n",
      "26676 Traning Loss: tensor(0.8487)\n",
      "26677 Traning Loss: tensor(0.8487)\n",
      "26678 Traning Loss: tensor(0.8487)\n",
      "26679 Traning Loss: tensor(0.8487)\n",
      "26680 Traning Loss: tensor(0.8487)\n",
      "26681 Traning Loss: tensor(0.8487)\n",
      "26682 Traning Loss: tensor(0.8487)\n",
      "26683 Traning Loss: tensor(0.8487)\n",
      "26684 Traning Loss: tensor(0.8487)\n",
      "26685 Traning Loss: tensor(0.8487)\n",
      "26686 Traning Loss: tensor(0.8487)\n",
      "26687 Traning Loss: tensor(0.8487)\n",
      "26688 Traning Loss: tensor(0.8487)\n",
      "26689 Traning Loss: tensor(0.8487)\n",
      "26690 Traning Loss: tensor(0.8487)\n",
      "26691 Traning Loss: tensor(0.8487)\n",
      "26692 Traning Loss: tensor(0.8487)\n",
      "26693 Traning Loss: tensor(0.8487)\n",
      "26694 Traning Loss: tensor(0.8487)\n",
      "26695 Traning Loss: tensor(0.8487)\n",
      "26696 Traning Loss: tensor(0.8487)\n",
      "26697 Traning Loss: tensor(0.8487)\n",
      "26698 Traning Loss: tensor(0.8487)\n",
      "26699 Traning Loss: tensor(0.8487)\n",
      "26700 Traning Loss: tensor(0.8487)\n",
      "26701 Traning Loss: tensor(0.8487)\n",
      "26702 Traning Loss: tensor(0.8487)\n",
      "26703 Traning Loss: tensor(0.8487)\n",
      "26704 Traning Loss: tensor(0.8487)\n",
      "26705 Traning Loss: tensor(0.8487)\n",
      "26706 Traning Loss: tensor(0.8487)\n",
      "26707 Traning Loss: tensor(0.8487)\n",
      "26708 Traning Loss: tensor(0.8487)\n",
      "26709 Traning Loss: tensor(0.8487)\n",
      "26710 Traning Loss: tensor(0.8487)\n",
      "26711 Traning Loss: tensor(0.8487)\n",
      "26712 Traning Loss: tensor(0.8487)\n",
      "26713 Traning Loss: tensor(0.8487)\n",
      "26714 Traning Loss: tensor(0.8487)\n",
      "26715 Traning Loss: tensor(0.8487)\n",
      "26716 Traning Loss: tensor(0.8487)\n",
      "26717 Traning Loss: tensor(0.8487)\n",
      "26718 Traning Loss: tensor(0.8487)\n",
      "26719 Traning Loss: tensor(0.8487)\n",
      "26720 Traning Loss: tensor(0.8487)\n",
      "26721 Traning Loss: tensor(0.8487)\n",
      "26722 Traning Loss: tensor(0.8487)\n",
      "26723 Traning Loss: tensor(0.8487)\n",
      "26724 Traning Loss: tensor(0.8487)\n",
      "26725 Traning Loss: tensor(0.8487)\n",
      "26726 Traning Loss: tensor(0.8487)\n",
      "26727 Traning Loss: tensor(0.8487)\n",
      "26728 Traning Loss: tensor(0.8487)\n",
      "26729 Traning Loss: tensor(0.8487)\n",
      "26730 Traning Loss: tensor(0.8487)\n",
      "26731 Traning Loss: tensor(0.8487)\n",
      "26732 Traning Loss: tensor(0.8487)\n",
      "26733 Traning Loss: tensor(0.8487)\n",
      "26734 Traning Loss: tensor(0.8487)\n",
      "26735 Traning Loss: tensor(0.8487)\n",
      "26736 Traning Loss: tensor(0.8487)\n",
      "26737 Traning Loss: tensor(0.8487)\n",
      "26738 Traning Loss: tensor(0.8487)\n",
      "26739 Traning Loss: tensor(0.8487)\n",
      "26740 Traning Loss: tensor(0.8487)\n",
      "26741 Traning Loss: tensor(0.8487)\n",
      "26742 Traning Loss: tensor(0.8487)\n",
      "26743 Traning Loss: tensor(0.8487)\n",
      "26744 Traning Loss: tensor(0.8487)\n",
      "26745 Traning Loss: tensor(0.8487)\n",
      "26746 Traning Loss: tensor(0.8487)\n",
      "26747 Traning Loss: tensor(0.8487)\n",
      "26748 Traning Loss: tensor(0.8487)\n",
      "26749 Traning Loss: tensor(0.8487)\n",
      "26750 Traning Loss: tensor(0.8487)\n",
      "26751 Traning Loss: tensor(0.8487)\n",
      "26752 Traning Loss: tensor(0.8487)\n",
      "26753 Traning Loss: tensor(0.8487)\n",
      "26754 Traning Loss: tensor(0.8487)\n",
      "26755 Traning Loss: tensor(0.8487)\n",
      "26756 Traning Loss: tensor(0.8487)\n",
      "26757 Traning Loss: tensor(0.8487)\n",
      "26758 Traning Loss: tensor(0.8487)\n",
      "26759 Traning Loss: tensor(0.8487)\n",
      "26760 Traning Loss: tensor(0.8487)\n",
      "26761 Traning Loss: tensor(0.8487)\n",
      "26762 Traning Loss: tensor(0.8487)\n",
      "26763 Traning Loss: tensor(0.8487)\n",
      "26764 Traning Loss: tensor(0.8487)\n",
      "26765 Traning Loss: tensor(0.8487)\n",
      "26766 Traning Loss: tensor(0.8487)\n",
      "26767 Traning Loss: tensor(0.8487)\n",
      "26768 Traning Loss: tensor(0.8487)\n",
      "26769 Traning Loss: tensor(0.8487)\n",
      "26770 Traning Loss: tensor(0.8487)\n",
      "26771 Traning Loss: tensor(0.8487)\n",
      "26772 Traning Loss: tensor(0.8487)\n",
      "26773 Traning Loss: tensor(0.8487)\n",
      "26774 Traning Loss: tensor(0.8487)\n",
      "26775 Traning Loss: tensor(0.8487)\n",
      "26776 Traning Loss: tensor(0.8487)\n",
      "26777 Traning Loss: tensor(0.8487)\n",
      "26778 Traning Loss: tensor(0.8487)\n",
      "26779 Traning Loss: tensor(0.8487)\n",
      "26780 Traning Loss: tensor(0.8487)\n",
      "26781 Traning Loss: tensor(0.8487)\n",
      "26782 Traning Loss: tensor(0.8487)\n",
      "26783 Traning Loss: tensor(0.8487)\n",
      "26784 Traning Loss: tensor(0.8487)\n",
      "26785 Traning Loss: tensor(0.8487)\n",
      "26786 Traning Loss: tensor(0.8487)\n",
      "26787 Traning Loss: tensor(0.8487)\n",
      "26788 Traning Loss: tensor(0.8487)\n",
      "26789 Traning Loss: tensor(0.8487)\n",
      "26790 Traning Loss: tensor(0.8487)\n",
      "26791 Traning Loss: tensor(0.8487)\n",
      "26792 Traning Loss: tensor(0.8487)\n",
      "26793 Traning Loss: tensor(0.8487)\n",
      "26794 Traning Loss: tensor(0.8487)\n",
      "26795 Traning Loss: tensor(0.8487)\n",
      "26796 Traning Loss: tensor(0.8487)\n",
      "26797 Traning Loss: tensor(0.8487)\n",
      "26798 Traning Loss: tensor(0.8487)\n",
      "26799 Traning Loss: tensor(0.8487)\n",
      "26800 Traning Loss: tensor(0.8487)\n",
      "26801 Traning Loss: tensor(0.8487)\n",
      "26802 Traning Loss: tensor(0.8487)\n",
      "26803 Traning Loss: tensor(0.8487)\n",
      "26804 Traning Loss: tensor(0.8487)\n",
      "26805 Traning Loss: tensor(0.8487)\n",
      "26806 Traning Loss: tensor(0.8487)\n",
      "26807 Traning Loss: tensor(0.8487)\n",
      "26808 Traning Loss: tensor(0.8487)\n",
      "26809 Traning Loss: tensor(0.8487)\n",
      "26810 Traning Loss: tensor(0.8487)\n",
      "26811 Traning Loss: tensor(0.8487)\n",
      "26812 Traning Loss: tensor(0.8487)\n",
      "26813 Traning Loss: tensor(0.8487)\n",
      "26814 Traning Loss: tensor(0.8487)\n",
      "26815 Traning Loss: tensor(0.8487)\n",
      "26816 Traning Loss: tensor(0.8487)\n",
      "26817 Traning Loss: tensor(0.8487)\n",
      "26818 Traning Loss: tensor(0.8487)\n",
      "26819 Traning Loss: tensor(0.8487)\n",
      "26820 Traning Loss: tensor(0.8487)\n",
      "26821 Traning Loss: tensor(0.8487)\n",
      "26822 Traning Loss: tensor(0.8487)\n",
      "26823 Traning Loss: tensor(0.8487)\n",
      "26824 Traning Loss: tensor(0.8487)\n",
      "26825 Traning Loss: tensor(0.8487)\n",
      "26826 Traning Loss: tensor(0.8487)\n",
      "26827 Traning Loss: tensor(0.8487)\n",
      "26828 Traning Loss: tensor(0.8487)\n",
      "26829 Traning Loss: tensor(0.8487)\n",
      "26830 Traning Loss: tensor(0.8487)\n",
      "26831 Traning Loss: tensor(0.8487)\n",
      "26832 Traning Loss: tensor(0.8487)\n",
      "26833 Traning Loss: tensor(0.8487)\n",
      "26834 Traning Loss: tensor(0.8487)\n",
      "26835 Traning Loss: tensor(0.8487)\n",
      "26836 Traning Loss: tensor(0.8487)\n",
      "26837 Traning Loss: tensor(0.8487)\n",
      "26838 Traning Loss: tensor(0.8487)\n",
      "26839 Traning Loss: tensor(0.8487)\n",
      "26840 Traning Loss: tensor(0.8487)\n",
      "26841 Traning Loss: tensor(0.8487)\n",
      "26842 Traning Loss: tensor(0.8487)\n",
      "26843 Traning Loss: tensor(0.8487)\n",
      "26844 Traning Loss: tensor(0.8487)\n",
      "26845 Traning Loss: tensor(0.8487)\n",
      "26846 Traning Loss: tensor(0.8487)\n",
      "26847 Traning Loss: tensor(0.8487)\n",
      "26848 Traning Loss: tensor(0.8487)\n",
      "26849 Traning Loss: tensor(0.8487)\n",
      "26850 Traning Loss: tensor(0.8487)\n",
      "26851 Traning Loss: tensor(0.8487)\n",
      "26852 Traning Loss: tensor(0.8487)\n",
      "26853 Traning Loss: tensor(0.8487)\n",
      "26854 Traning Loss: tensor(0.8487)\n",
      "26855 Traning Loss: tensor(0.8487)\n",
      "26856 Traning Loss: tensor(0.8487)\n",
      "26857 Traning Loss: tensor(0.8487)\n",
      "26858 Traning Loss: tensor(0.8487)\n",
      "26859 Traning Loss: tensor(0.8487)\n",
      "26860 Traning Loss: tensor(0.8487)\n",
      "26861 Traning Loss: tensor(0.8487)\n",
      "26862 Traning Loss: tensor(0.8487)\n",
      "26863 Traning Loss: tensor(0.8487)\n",
      "26864 Traning Loss: tensor(0.8487)\n",
      "26865 Traning Loss: tensor(0.8487)\n",
      "26866 Traning Loss: tensor(0.8487)\n",
      "26867 Traning Loss: tensor(0.8487)\n",
      "26868 Traning Loss: tensor(0.8487)\n",
      "26869 Traning Loss: tensor(0.8487)\n",
      "26870 Traning Loss: tensor(0.8487)\n",
      "26871 Traning Loss: tensor(0.8487)\n",
      "26872 Traning Loss: tensor(0.8487)\n",
      "26873 Traning Loss: tensor(0.8487)\n",
      "26874 Traning Loss: tensor(0.8487)\n",
      "26875 Traning Loss: tensor(0.8487)\n",
      "26876 Traning Loss: tensor(0.8487)\n",
      "26877 Traning Loss: tensor(0.8487)\n",
      "26878 Traning Loss: tensor(0.8487)\n",
      "26879 Traning Loss: tensor(0.8487)\n",
      "26880 Traning Loss: tensor(0.8487)\n",
      "26881 Traning Loss: tensor(0.8487)\n",
      "26882 Traning Loss: tensor(0.8487)\n",
      "26883 Traning Loss: tensor(0.8487)\n",
      "26884 Traning Loss: tensor(0.8487)\n",
      "26885 Traning Loss: tensor(0.8487)\n",
      "26886 Traning Loss: tensor(0.8487)\n",
      "26887 Traning Loss: tensor(0.8487)\n",
      "26888 Traning Loss: tensor(0.8487)\n",
      "26889 Traning Loss: tensor(0.8487)\n",
      "26890 Traning Loss: tensor(0.8487)\n",
      "26891 Traning Loss: tensor(0.8487)\n",
      "26892 Traning Loss: tensor(0.8487)\n",
      "26893 Traning Loss: tensor(0.8487)\n",
      "26894 Traning Loss: tensor(0.8487)\n",
      "26895 Traning Loss: tensor(0.8487)\n",
      "26896 Traning Loss: tensor(0.8487)\n",
      "26897 Traning Loss: tensor(0.8487)\n",
      "26898 Traning Loss: tensor(0.8487)\n",
      "26899 Traning Loss: tensor(0.8487)\n",
      "26900 Traning Loss: tensor(0.8487)\n",
      "26901 Traning Loss: tensor(0.8487)\n",
      "26902 Traning Loss: tensor(0.8487)\n",
      "26903 Traning Loss: tensor(0.8487)\n",
      "26904 Traning Loss: tensor(0.8487)\n",
      "26905 Traning Loss: tensor(0.8487)\n",
      "26906 Traning Loss: tensor(0.8487)\n",
      "26907 Traning Loss: tensor(0.8487)\n",
      "26908 Traning Loss: tensor(0.8487)\n",
      "26909 Traning Loss: tensor(0.8487)\n",
      "26910 Traning Loss: tensor(0.8487)\n",
      "26911 Traning Loss: tensor(0.8487)\n",
      "26912 Traning Loss: tensor(0.8487)\n",
      "26913 Traning Loss: tensor(0.8487)\n",
      "26914 Traning Loss: tensor(0.8487)\n",
      "26915 Traning Loss: tensor(0.8487)\n",
      "26916 Traning Loss: tensor(0.8487)\n",
      "26917 Traning Loss: tensor(0.8487)\n",
      "26918 Traning Loss: tensor(0.8487)\n",
      "26919 Traning Loss: tensor(0.8487)\n",
      "26920 Traning Loss: tensor(0.8487)\n",
      "26921 Traning Loss: tensor(0.8487)\n",
      "26922 Traning Loss: tensor(0.8487)\n",
      "26923 Traning Loss: tensor(0.8487)\n",
      "26924 Traning Loss: tensor(0.8487)\n",
      "26925 Traning Loss: tensor(0.8487)\n",
      "26926 Traning Loss: tensor(0.8487)\n",
      "26927 Traning Loss: tensor(0.8487)\n",
      "26928 Traning Loss: tensor(0.8487)\n",
      "26929 Traning Loss: tensor(0.8487)\n",
      "26930 Traning Loss: tensor(0.8487)\n",
      "26931 Traning Loss: tensor(0.8487)\n",
      "26932 Traning Loss: tensor(0.8487)\n",
      "26933 Traning Loss: tensor(0.8487)\n",
      "26934 Traning Loss: tensor(0.8487)\n",
      "26935 Traning Loss: tensor(0.8487)\n",
      "26936 Traning Loss: tensor(0.8487)\n",
      "26937 Traning Loss: tensor(0.8487)\n",
      "26938 Traning Loss: tensor(0.8487)\n",
      "26939 Traning Loss: tensor(0.8487)\n",
      "26940 Traning Loss: tensor(0.8487)\n",
      "26941 Traning Loss: tensor(0.8487)\n",
      "26942 Traning Loss: tensor(0.8487)\n",
      "26943 Traning Loss: tensor(0.8487)\n",
      "26944 Traning Loss: tensor(0.8487)\n",
      "26945 Traning Loss: tensor(0.8487)\n",
      "26946 Traning Loss: tensor(0.8487)\n",
      "26947 Traning Loss: tensor(0.8487)\n",
      "26948 Traning Loss: tensor(0.8487)\n",
      "26949 Traning Loss: tensor(0.8487)\n",
      "26950 Traning Loss: tensor(0.8487)\n",
      "26951 Traning Loss: tensor(0.8487)\n",
      "26952 Traning Loss: tensor(0.8487)\n",
      "26953 Traning Loss: tensor(0.8487)\n",
      "26954 Traning Loss: tensor(0.8487)\n",
      "26955 Traning Loss: tensor(0.8487)\n",
      "26956 Traning Loss: tensor(0.8487)\n",
      "26957 Traning Loss: tensor(0.8487)\n",
      "26958 Traning Loss: tensor(0.8487)\n",
      "26959 Traning Loss: tensor(0.8487)\n",
      "26960 Traning Loss: tensor(0.8487)\n",
      "26961 Traning Loss: tensor(0.8487)\n",
      "26962 Traning Loss: tensor(0.8487)\n",
      "26963 Traning Loss: tensor(0.8487)\n",
      "26964 Traning Loss: tensor(0.8487)\n",
      "26965 Traning Loss: tensor(0.8487)\n",
      "26966 Traning Loss: tensor(0.8487)\n",
      "26967 Traning Loss: tensor(0.8487)\n",
      "26968 Traning Loss: tensor(0.8487)\n",
      "26969 Traning Loss: tensor(0.8487)\n",
      "26970 Traning Loss: tensor(0.8487)\n",
      "26971 Traning Loss: tensor(0.8487)\n",
      "26972 Traning Loss: tensor(0.8487)\n",
      "26973 Traning Loss: tensor(0.8487)\n",
      "26974 Traning Loss: tensor(0.8487)\n",
      "26975 Traning Loss: tensor(0.8487)\n",
      "26976 Traning Loss: tensor(0.8487)\n",
      "26977 Traning Loss: tensor(0.8487)\n",
      "26978 Traning Loss: tensor(0.8487)\n",
      "26979 Traning Loss: tensor(0.8487)\n",
      "26980 Traning Loss: tensor(0.8487)\n",
      "26981 Traning Loss: tensor(0.8487)\n",
      "26982 Traning Loss: tensor(0.8487)\n",
      "26983 Traning Loss: tensor(0.8487)\n",
      "26984 Traning Loss: tensor(0.8487)\n",
      "26985 Traning Loss: tensor(0.8487)\n",
      "26986 Traning Loss: tensor(0.8487)\n",
      "26987 Traning Loss: tensor(0.8487)\n",
      "26988 Traning Loss: tensor(0.8487)\n",
      "26989 Traning Loss: tensor(0.8487)\n",
      "26990 Traning Loss: tensor(0.8487)\n",
      "26991 Traning Loss: tensor(0.8487)\n",
      "26992 Traning Loss: tensor(0.8487)\n",
      "26993 Traning Loss: tensor(0.8487)\n",
      "26994 Traning Loss: tensor(0.8487)\n",
      "26995 Traning Loss: tensor(0.8487)\n",
      "26996 Traning Loss: tensor(0.8487)\n",
      "26997 Traning Loss: tensor(0.8487)\n",
      "26998 Traning Loss: tensor(0.8487)\n",
      "26999 Traning Loss: tensor(0.8487)\n",
      "27000 Traning Loss: tensor(0.8487)\n",
      "27001 Traning Loss: tensor(0.8487)\n",
      "27002 Traning Loss: tensor(0.8487)\n",
      "27003 Traning Loss: tensor(0.8487)\n",
      "27004 Traning Loss: tensor(0.8487)\n",
      "27005 Traning Loss: tensor(0.8487)\n",
      "27006 Traning Loss: tensor(0.8487)\n",
      "27007 Traning Loss: tensor(0.8487)\n",
      "27008 Traning Loss: tensor(0.8487)\n",
      "27009 Traning Loss: tensor(0.8487)\n",
      "27010 Traning Loss: tensor(0.8487)\n",
      "27011 Traning Loss: tensor(0.8487)\n",
      "27012 Traning Loss: tensor(0.8487)\n",
      "27013 Traning Loss: tensor(0.8487)\n",
      "27014 Traning Loss: tensor(0.8487)\n",
      "27015 Traning Loss: tensor(0.8487)\n",
      "27016 Traning Loss: tensor(0.8487)\n",
      "27017 Traning Loss: tensor(0.8487)\n",
      "27018 Traning Loss: tensor(0.8487)\n",
      "27019 Traning Loss: tensor(0.8487)\n",
      "27020 Traning Loss: tensor(0.8487)\n",
      "27021 Traning Loss: tensor(0.8487)\n",
      "27022 Traning Loss: tensor(0.8487)\n",
      "27023 Traning Loss: tensor(0.8487)\n",
      "27024 Traning Loss: tensor(0.8487)\n",
      "27025 Traning Loss: tensor(0.8487)\n",
      "27026 Traning Loss: tensor(0.8487)\n",
      "27027 Traning Loss: tensor(0.8487)\n",
      "27028 Traning Loss: tensor(0.8487)\n",
      "27029 Traning Loss: tensor(0.8487)\n",
      "27030 Traning Loss: tensor(0.8487)\n",
      "27031 Traning Loss: tensor(0.8487)\n",
      "27032 Traning Loss: tensor(0.8487)\n",
      "27033 Traning Loss: tensor(0.8487)\n",
      "27034 Traning Loss: tensor(0.8487)\n",
      "27035 Traning Loss: tensor(0.8487)\n",
      "27036 Traning Loss: tensor(0.8487)\n",
      "27037 Traning Loss: tensor(0.8487)\n",
      "27038 Traning Loss: tensor(0.8487)\n",
      "27039 Traning Loss: tensor(0.8487)\n",
      "27040 Traning Loss: tensor(0.8487)\n",
      "27041 Traning Loss: tensor(0.8487)\n",
      "27042 Traning Loss: tensor(0.8487)\n",
      "27043 Traning Loss: tensor(0.8487)\n",
      "27044 Traning Loss: tensor(0.8487)\n",
      "27045 Traning Loss: tensor(0.8487)\n",
      "27046 Traning Loss: tensor(0.8487)\n",
      "27047 Traning Loss: tensor(0.8487)\n",
      "27048 Traning Loss: tensor(0.8487)\n",
      "27049 Traning Loss: tensor(0.8487)\n",
      "27050 Traning Loss: tensor(0.8487)\n",
      "27051 Traning Loss: tensor(0.8487)\n",
      "27052 Traning Loss: tensor(0.8487)\n",
      "27053 Traning Loss: tensor(0.8487)\n",
      "27054 Traning Loss: tensor(0.8487)\n",
      "27055 Traning Loss: tensor(0.8487)\n",
      "27056 Traning Loss: tensor(0.8487)\n",
      "27057 Traning Loss: tensor(0.8487)\n",
      "27058 Traning Loss: tensor(0.8487)\n",
      "27059 Traning Loss: tensor(0.8487)\n",
      "27060 Traning Loss: tensor(0.8487)\n",
      "27061 Traning Loss: tensor(0.8487)\n",
      "27062 Traning Loss: tensor(0.8487)\n",
      "27063 Traning Loss: tensor(0.8487)\n",
      "27064 Traning Loss: tensor(0.8487)\n",
      "27065 Traning Loss: tensor(0.8487)\n",
      "27066 Traning Loss: tensor(0.8487)\n",
      "27067 Traning Loss: tensor(0.8487)\n",
      "27068 Traning Loss: tensor(0.8487)\n",
      "27069 Traning Loss: tensor(0.8487)\n",
      "27070 Traning Loss: tensor(0.8487)\n",
      "27071 Traning Loss: tensor(0.8487)\n",
      "27072 Traning Loss: tensor(0.8487)\n",
      "27073 Traning Loss: tensor(0.8487)\n",
      "27074 Traning Loss: tensor(0.8487)\n",
      "27075 Traning Loss: tensor(0.8487)\n",
      "27076 Traning Loss: tensor(0.8487)\n",
      "27077 Traning Loss: tensor(0.8487)\n",
      "27078 Traning Loss: tensor(0.8487)\n",
      "27079 Traning Loss: tensor(0.8487)\n",
      "27080 Traning Loss: tensor(0.8487)\n",
      "27081 Traning Loss: tensor(0.8487)\n",
      "27082 Traning Loss: tensor(0.8487)\n",
      "27083 Traning Loss: tensor(0.8487)\n",
      "27084 Traning Loss: tensor(0.8487)\n",
      "27085 Traning Loss: tensor(0.8487)\n",
      "27086 Traning Loss: tensor(0.8487)\n",
      "27087 Traning Loss: tensor(0.8487)\n",
      "27088 Traning Loss: tensor(0.8487)\n",
      "27089 Traning Loss: tensor(0.8487)\n",
      "27090 Traning Loss: tensor(0.8487)\n",
      "27091 Traning Loss: tensor(0.8487)\n",
      "27092 Traning Loss: tensor(0.8487)\n",
      "27093 Traning Loss: tensor(0.8487)\n",
      "27094 Traning Loss: tensor(0.8487)\n",
      "27095 Traning Loss: tensor(0.8487)\n",
      "27096 Traning Loss: tensor(0.8487)\n",
      "27097 Traning Loss: tensor(0.8487)\n",
      "27098 Traning Loss: tensor(0.8487)\n",
      "27099 Traning Loss: tensor(0.8487)\n",
      "27100 Traning Loss: tensor(0.8487)\n",
      "27101 Traning Loss: tensor(0.8487)\n",
      "27102 Traning Loss: tensor(0.8487)\n",
      "27103 Traning Loss: tensor(0.8487)\n",
      "27104 Traning Loss: tensor(0.8487)\n",
      "27105 Traning Loss: tensor(0.8487)\n",
      "27106 Traning Loss: tensor(0.8487)\n",
      "27107 Traning Loss: tensor(0.8487)\n",
      "27108 Traning Loss: tensor(0.8487)\n",
      "27109 Traning Loss: tensor(0.8487)\n",
      "27110 Traning Loss: tensor(0.8487)\n",
      "27111 Traning Loss: tensor(0.8487)\n",
      "27112 Traning Loss: tensor(0.8487)\n",
      "27113 Traning Loss: tensor(0.8487)\n",
      "27114 Traning Loss: tensor(0.8487)\n",
      "27115 Traning Loss: tensor(0.8487)\n",
      "27116 Traning Loss: tensor(0.8487)\n",
      "27117 Traning Loss: tensor(0.8487)\n",
      "27118 Traning Loss: tensor(0.8487)\n",
      "27119 Traning Loss: tensor(0.8487)\n",
      "27120 Traning Loss: tensor(0.8487)\n",
      "27121 Traning Loss: tensor(0.8487)\n",
      "27122 Traning Loss: tensor(0.8487)\n",
      "27123 Traning Loss: tensor(0.8487)\n",
      "27124 Traning Loss: tensor(0.8487)\n",
      "27125 Traning Loss: tensor(0.8487)\n",
      "27126 Traning Loss: tensor(0.8487)\n",
      "27127 Traning Loss: tensor(0.8487)\n",
      "27128 Traning Loss: tensor(0.8487)\n",
      "27129 Traning Loss: tensor(0.8487)\n",
      "27130 Traning Loss: tensor(0.8487)\n",
      "27131 Traning Loss: tensor(0.8487)\n",
      "27132 Traning Loss: tensor(0.8487)\n",
      "27133 Traning Loss: tensor(0.8487)\n",
      "27134 Traning Loss: tensor(0.8487)\n",
      "27135 Traning Loss: tensor(0.8487)\n",
      "27136 Traning Loss: tensor(0.8487)\n",
      "27137 Traning Loss: tensor(0.8487)\n",
      "27138 Traning Loss: tensor(0.8487)\n",
      "27139 Traning Loss: tensor(0.8487)\n",
      "27140 Traning Loss: tensor(0.8487)\n",
      "27141 Traning Loss: tensor(0.8487)\n",
      "27142 Traning Loss: tensor(0.8487)\n",
      "27143 Traning Loss: tensor(0.8487)\n",
      "27144 Traning Loss: tensor(0.8487)\n",
      "27145 Traning Loss: tensor(0.8487)\n",
      "27146 Traning Loss: tensor(0.8487)\n",
      "27147 Traning Loss: tensor(0.8487)\n",
      "27148 Traning Loss: tensor(0.8487)\n",
      "27149 Traning Loss: tensor(0.8487)\n",
      "27150 Traning Loss: tensor(0.8487)\n",
      "27151 Traning Loss: tensor(0.8487)\n",
      "27152 Traning Loss: tensor(0.8487)\n",
      "27153 Traning Loss: tensor(0.8487)\n",
      "27154 Traning Loss: tensor(0.8487)\n",
      "27155 Traning Loss: tensor(0.8487)\n",
      "27156 Traning Loss: tensor(0.8487)\n",
      "27157 Traning Loss: tensor(0.8487)\n",
      "27158 Traning Loss: tensor(0.8487)\n",
      "27159 Traning Loss: tensor(0.8487)\n",
      "27160 Traning Loss: tensor(0.8487)\n",
      "27161 Traning Loss: tensor(0.8487)\n",
      "27162 Traning Loss: tensor(0.8487)\n",
      "27163 Traning Loss: tensor(0.8487)\n",
      "27164 Traning Loss: tensor(0.8487)\n",
      "27165 Traning Loss: tensor(0.8487)\n",
      "27166 Traning Loss: tensor(0.8487)\n",
      "27167 Traning Loss: tensor(0.8487)\n",
      "27168 Traning Loss: tensor(0.8487)\n",
      "27169 Traning Loss: tensor(0.8487)\n",
      "27170 Traning Loss: tensor(0.8487)\n",
      "27171 Traning Loss: tensor(0.8487)\n",
      "27172 Traning Loss: tensor(0.8487)\n",
      "27173 Traning Loss: tensor(0.8487)\n",
      "27174 Traning Loss: tensor(0.8487)\n",
      "27175 Traning Loss: tensor(0.8487)\n",
      "27176 Traning Loss: tensor(0.8487)\n",
      "27177 Traning Loss: tensor(0.8487)\n",
      "27178 Traning Loss: tensor(0.8487)\n",
      "27179 Traning Loss: tensor(0.8487)\n",
      "27180 Traning Loss: tensor(0.8487)\n",
      "27181 Traning Loss: tensor(0.8487)\n",
      "27182 Traning Loss: tensor(0.8487)\n",
      "27183 Traning Loss: tensor(0.8487)\n",
      "27184 Traning Loss: tensor(0.8487)\n",
      "27185 Traning Loss: tensor(0.8487)\n",
      "27186 Traning Loss: tensor(0.8487)\n",
      "27187 Traning Loss: tensor(0.8487)\n",
      "27188 Traning Loss: tensor(0.8487)\n",
      "27189 Traning Loss: tensor(0.8487)\n",
      "27190 Traning Loss: tensor(0.8487)\n",
      "27191 Traning Loss: tensor(0.8487)\n",
      "27192 Traning Loss: tensor(0.8487)\n",
      "27193 Traning Loss: tensor(0.8487)\n",
      "27194 Traning Loss: tensor(0.8487)\n",
      "27195 Traning Loss: tensor(0.8487)\n",
      "27196 Traning Loss: tensor(0.8487)\n",
      "27197 Traning Loss: tensor(0.8487)\n",
      "27198 Traning Loss: tensor(0.8487)\n",
      "27199 Traning Loss: tensor(0.8487)\n",
      "27200 Traning Loss: tensor(0.8487)\n",
      "27201 Traning Loss: tensor(0.8487)\n",
      "27202 Traning Loss: tensor(0.8487)\n",
      "27203 Traning Loss: tensor(0.8487)\n",
      "27204 Traning Loss: tensor(0.8487)\n",
      "27205 Traning Loss: tensor(0.8487)\n",
      "27206 Traning Loss: tensor(0.8487)\n",
      "27207 Traning Loss: tensor(0.8487)\n",
      "27208 Traning Loss: tensor(0.8487)\n",
      "27209 Traning Loss: tensor(0.8487)\n",
      "27210 Traning Loss: tensor(0.8487)\n",
      "27211 Traning Loss: tensor(0.8487)\n",
      "27212 Traning Loss: tensor(0.8487)\n",
      "27213 Traning Loss: tensor(0.8487)\n",
      "27214 Traning Loss: tensor(0.8487)\n",
      "27215 Traning Loss: tensor(0.8487)\n",
      "27216 Traning Loss: tensor(0.8487)\n",
      "27217 Traning Loss: tensor(0.8487)\n",
      "27218 Traning Loss: tensor(0.8487)\n",
      "27219 Traning Loss: tensor(0.8487)\n",
      "27220 Traning Loss: tensor(0.8487)\n",
      "27221 Traning Loss: tensor(0.8487)\n",
      "27222 Traning Loss: tensor(0.8487)\n",
      "27223 Traning Loss: tensor(0.8487)\n",
      "27224 Traning Loss: tensor(0.8488)\n",
      "27225 Traning Loss: tensor(0.8488)\n",
      "27226 Traning Loss: tensor(0.8488)\n",
      "27227 Traning Loss: tensor(0.8488)\n",
      "27228 Traning Loss: tensor(0.8488)\n",
      "27229 Traning Loss: tensor(0.8487)\n",
      "27230 Traning Loss: tensor(0.8487)\n",
      "27231 Traning Loss: tensor(0.8487)\n",
      "27232 Traning Loss: tensor(0.8487)\n",
      "27233 Traning Loss: tensor(0.8487)\n",
      "27234 Traning Loss: tensor(0.8487)\n",
      "27235 Traning Loss: tensor(0.8487)\n",
      "27236 Traning Loss: tensor(0.8487)\n",
      "27237 Traning Loss: tensor(0.8487)\n",
      "27238 Traning Loss: tensor(0.8487)\n",
      "27239 Traning Loss: tensor(0.8487)\n",
      "27240 Traning Loss: tensor(0.8487)\n",
      "27241 Traning Loss: tensor(0.8487)\n",
      "27242 Traning Loss: tensor(0.8487)\n",
      "27243 Traning Loss: tensor(0.8487)\n",
      "27244 Traning Loss: tensor(0.8487)\n",
      "27245 Traning Loss: tensor(0.8487)\n",
      "27246 Traning Loss: tensor(0.8487)\n",
      "27247 Traning Loss: tensor(0.8487)\n",
      "27248 Traning Loss: tensor(0.8487)\n",
      "27249 Traning Loss: tensor(0.8487)\n",
      "27250 Traning Loss: tensor(0.8487)\n",
      "27251 Traning Loss: tensor(0.8487)\n",
      "27252 Traning Loss: tensor(0.8487)\n",
      "27253 Traning Loss: tensor(0.8487)\n",
      "27254 Traning Loss: tensor(0.8487)\n",
      "27255 Traning Loss: tensor(0.8487)\n",
      "27256 Traning Loss: tensor(0.8487)\n",
      "27257 Traning Loss: tensor(0.8487)\n",
      "27258 Traning Loss: tensor(0.8487)\n",
      "27259 Traning Loss: tensor(0.8487)\n",
      "27260 Traning Loss: tensor(0.8487)\n",
      "27261 Traning Loss: tensor(0.8487)\n",
      "27262 Traning Loss: tensor(0.8487)\n",
      "27263 Traning Loss: tensor(0.8487)\n",
      "27264 Traning Loss: tensor(0.8487)\n",
      "27265 Traning Loss: tensor(0.8487)\n",
      "27266 Traning Loss: tensor(0.8487)\n",
      "27267 Traning Loss: tensor(0.8487)\n",
      "27268 Traning Loss: tensor(0.8487)\n",
      "27269 Traning Loss: tensor(0.8487)\n",
      "27270 Traning Loss: tensor(0.8487)\n",
      "27271 Traning Loss: tensor(0.8487)\n",
      "27272 Traning Loss: tensor(0.8487)\n",
      "27273 Traning Loss: tensor(0.8487)\n",
      "27274 Traning Loss: tensor(0.8487)\n",
      "27275 Traning Loss: tensor(0.8487)\n",
      "27276 Traning Loss: tensor(0.8487)\n",
      "27277 Traning Loss: tensor(0.8487)\n",
      "27278 Traning Loss: tensor(0.8487)\n",
      "27279 Traning Loss: tensor(0.8487)\n",
      "27280 Traning Loss: tensor(0.8487)\n",
      "27281 Traning Loss: tensor(0.8487)\n",
      "27282 Traning Loss: tensor(0.8487)\n",
      "27283 Traning Loss: tensor(0.8487)\n",
      "27284 Traning Loss: tensor(0.8487)\n",
      "27285 Traning Loss: tensor(0.8487)\n",
      "27286 Traning Loss: tensor(0.8487)\n",
      "27287 Traning Loss: tensor(0.8487)\n",
      "27288 Traning Loss: tensor(0.8487)\n",
      "27289 Traning Loss: tensor(0.8487)\n",
      "27290 Traning Loss: tensor(0.8487)\n",
      "27291 Traning Loss: tensor(0.8487)\n",
      "27292 Traning Loss: tensor(0.8487)\n",
      "27293 Traning Loss: tensor(0.8487)\n",
      "27294 Traning Loss: tensor(0.8487)\n",
      "27295 Traning Loss: tensor(0.8487)\n",
      "27296 Traning Loss: tensor(0.8487)\n",
      "27297 Traning Loss: tensor(0.8487)\n",
      "27298 Traning Loss: tensor(0.8487)\n",
      "27299 Traning Loss: tensor(0.8487)\n",
      "27300 Traning Loss: tensor(0.8487)\n",
      "27301 Traning Loss: tensor(0.8487)\n",
      "27302 Traning Loss: tensor(0.8487)\n",
      "27303 Traning Loss: tensor(0.8487)\n",
      "27304 Traning Loss: tensor(0.8487)\n",
      "27305 Traning Loss: tensor(0.8487)\n",
      "27306 Traning Loss: tensor(0.8487)\n",
      "27307 Traning Loss: tensor(0.8487)\n",
      "27308 Traning Loss: tensor(0.8487)\n",
      "27309 Traning Loss: tensor(0.8487)\n",
      "27310 Traning Loss: tensor(0.8487)\n",
      "27311 Traning Loss: tensor(0.8487)\n",
      "27312 Traning Loss: tensor(0.8487)\n",
      "27313 Traning Loss: tensor(0.8487)\n",
      "27314 Traning Loss: tensor(0.8487)\n",
      "27315 Traning Loss: tensor(0.8487)\n",
      "27316 Traning Loss: tensor(0.8487)\n",
      "27317 Traning Loss: tensor(0.8487)\n",
      "27318 Traning Loss: tensor(0.8487)\n",
      "27319 Traning Loss: tensor(0.8487)\n",
      "27320 Traning Loss: tensor(0.8487)\n",
      "27321 Traning Loss: tensor(0.8487)\n",
      "27322 Traning Loss: tensor(0.8487)\n",
      "27323 Traning Loss: tensor(0.8487)\n",
      "27324 Traning Loss: tensor(0.8487)\n",
      "27325 Traning Loss: tensor(0.8487)\n",
      "27326 Traning Loss: tensor(0.8487)\n",
      "27327 Traning Loss: tensor(0.8487)\n",
      "27328 Traning Loss: tensor(0.8487)\n",
      "27329 Traning Loss: tensor(0.8487)\n",
      "27330 Traning Loss: tensor(0.8487)\n",
      "27331 Traning Loss: tensor(0.8487)\n",
      "27332 Traning Loss: tensor(0.8487)\n",
      "27333 Traning Loss: tensor(0.8487)\n",
      "27334 Traning Loss: tensor(0.8487)\n",
      "27335 Traning Loss: tensor(0.8487)\n",
      "27336 Traning Loss: tensor(0.8487)\n",
      "27337 Traning Loss: tensor(0.8487)\n",
      "27338 Traning Loss: tensor(0.8487)\n",
      "27339 Traning Loss: tensor(0.8487)\n",
      "27340 Traning Loss: tensor(0.8487)\n",
      "27341 Traning Loss: tensor(0.8487)\n",
      "27342 Traning Loss: tensor(0.8487)\n",
      "27343 Traning Loss: tensor(0.8487)\n",
      "27344 Traning Loss: tensor(0.8487)\n",
      "27345 Traning Loss: tensor(0.8487)\n",
      "27346 Traning Loss: tensor(0.8487)\n",
      "27347 Traning Loss: tensor(0.8487)\n",
      "27348 Traning Loss: tensor(0.8487)\n",
      "27349 Traning Loss: tensor(0.8487)\n",
      "27350 Traning Loss: tensor(0.8487)\n",
      "27351 Traning Loss: tensor(0.8487)\n",
      "27352 Traning Loss: tensor(0.8487)\n",
      "27353 Traning Loss: tensor(0.8487)\n",
      "27354 Traning Loss: tensor(0.8487)\n",
      "27355 Traning Loss: tensor(0.8487)\n",
      "27356 Traning Loss: tensor(0.8487)\n",
      "27357 Traning Loss: tensor(0.8487)\n",
      "27358 Traning Loss: tensor(0.8487)\n",
      "27359 Traning Loss: tensor(0.8487)\n",
      "27360 Traning Loss: tensor(0.8487)\n",
      "27361 Traning Loss: tensor(0.8487)\n",
      "27362 Traning Loss: tensor(0.8487)\n",
      "27363 Traning Loss: tensor(0.8487)\n",
      "27364 Traning Loss: tensor(0.8487)\n",
      "27365 Traning Loss: tensor(0.8487)\n",
      "27366 Traning Loss: tensor(0.8487)\n",
      "27367 Traning Loss: tensor(0.8487)\n",
      "27368 Traning Loss: tensor(0.8487)\n",
      "27369 Traning Loss: tensor(0.8487)\n",
      "27370 Traning Loss: tensor(0.8487)\n",
      "27371 Traning Loss: tensor(0.8487)\n",
      "27372 Traning Loss: tensor(0.8487)\n",
      "27373 Traning Loss: tensor(0.8487)\n",
      "27374 Traning Loss: tensor(0.8487)\n",
      "27375 Traning Loss: tensor(0.8487)\n",
      "27376 Traning Loss: tensor(0.8487)\n",
      "27377 Traning Loss: tensor(0.8487)\n",
      "27378 Traning Loss: tensor(0.8487)\n",
      "27379 Traning Loss: tensor(0.8487)\n",
      "27380 Traning Loss: tensor(0.8487)\n",
      "27381 Traning Loss: tensor(0.8487)\n",
      "27382 Traning Loss: tensor(0.8487)\n",
      "27383 Traning Loss: tensor(0.8487)\n",
      "27384 Traning Loss: tensor(0.8487)\n",
      "27385 Traning Loss: tensor(0.8487)\n",
      "27386 Traning Loss: tensor(0.8487)\n",
      "27387 Traning Loss: tensor(0.8487)\n",
      "27388 Traning Loss: tensor(0.8487)\n",
      "27389 Traning Loss: tensor(0.8487)\n",
      "27390 Traning Loss: tensor(0.8487)\n",
      "27391 Traning Loss: tensor(0.8487)\n",
      "27392 Traning Loss: tensor(0.8487)\n",
      "27393 Traning Loss: tensor(0.8487)\n",
      "27394 Traning Loss: tensor(0.8487)\n",
      "27395 Traning Loss: tensor(0.8487)\n",
      "27396 Traning Loss: tensor(0.8487)\n",
      "27397 Traning Loss: tensor(0.8487)\n",
      "27398 Traning Loss: tensor(0.8487)\n",
      "27399 Traning Loss: tensor(0.8487)\n",
      "27400 Traning Loss: tensor(0.8487)\n",
      "27401 Traning Loss: tensor(0.8487)\n",
      "27402 Traning Loss: tensor(0.8487)\n",
      "27403 Traning Loss: tensor(0.8487)\n",
      "27404 Traning Loss: tensor(0.8487)\n",
      "27405 Traning Loss: tensor(0.8487)\n",
      "27406 Traning Loss: tensor(0.8487)\n",
      "27407 Traning Loss: tensor(0.8487)\n",
      "27408 Traning Loss: tensor(0.8487)\n",
      "27409 Traning Loss: tensor(0.8487)\n",
      "27410 Traning Loss: tensor(0.8487)\n",
      "27411 Traning Loss: tensor(0.8487)\n",
      "27412 Traning Loss: tensor(0.8487)\n",
      "27413 Traning Loss: tensor(0.8487)\n",
      "27414 Traning Loss: tensor(0.8487)\n",
      "27415 Traning Loss: tensor(0.8487)\n",
      "27416 Traning Loss: tensor(0.8487)\n",
      "27417 Traning Loss: tensor(0.8487)\n",
      "27418 Traning Loss: tensor(0.8487)\n",
      "27419 Traning Loss: tensor(0.8487)\n",
      "27420 Traning Loss: tensor(0.8487)\n",
      "27421 Traning Loss: tensor(0.8487)\n",
      "27422 Traning Loss: tensor(0.8487)\n",
      "27423 Traning Loss: tensor(0.8487)\n",
      "27424 Traning Loss: tensor(0.8487)\n",
      "27425 Traning Loss: tensor(0.8487)\n",
      "27426 Traning Loss: tensor(0.8487)\n",
      "27427 Traning Loss: tensor(0.8487)\n",
      "27428 Traning Loss: tensor(0.8487)\n",
      "27429 Traning Loss: tensor(0.8487)\n",
      "27430 Traning Loss: tensor(0.8487)\n",
      "27431 Traning Loss: tensor(0.8487)\n",
      "27432 Traning Loss: tensor(0.8487)\n",
      "27433 Traning Loss: tensor(0.8487)\n",
      "27434 Traning Loss: tensor(0.8487)\n",
      "27435 Traning Loss: tensor(0.8487)\n",
      "27436 Traning Loss: tensor(0.8487)\n",
      "27437 Traning Loss: tensor(0.8487)\n",
      "27438 Traning Loss: tensor(0.8487)\n",
      "27439 Traning Loss: tensor(0.8487)\n",
      "27440 Traning Loss: tensor(0.8487)\n",
      "27441 Traning Loss: tensor(0.8487)\n",
      "27442 Traning Loss: tensor(0.8487)\n",
      "27443 Traning Loss: tensor(0.8487)\n",
      "27444 Traning Loss: tensor(0.8487)\n",
      "27445 Traning Loss: tensor(0.8487)\n",
      "27446 Traning Loss: tensor(0.8487)\n",
      "27447 Traning Loss: tensor(0.8487)\n",
      "27448 Traning Loss: tensor(0.8487)\n",
      "27449 Traning Loss: tensor(0.8487)\n",
      "27450 Traning Loss: tensor(0.8487)\n",
      "27451 Traning Loss: tensor(0.8487)\n",
      "27452 Traning Loss: tensor(0.8487)\n",
      "27453 Traning Loss: tensor(0.8487)\n",
      "27454 Traning Loss: tensor(0.8487)\n",
      "27455 Traning Loss: tensor(0.8487)\n",
      "27456 Traning Loss: tensor(0.8487)\n",
      "27457 Traning Loss: tensor(0.8487)\n",
      "27458 Traning Loss: tensor(0.8487)\n",
      "27459 Traning Loss: tensor(0.8487)\n",
      "27460 Traning Loss: tensor(0.8487)\n",
      "27461 Traning Loss: tensor(0.8487)\n",
      "27462 Traning Loss: tensor(0.8487)\n",
      "27463 Traning Loss: tensor(0.8487)\n",
      "27464 Traning Loss: tensor(0.8487)\n",
      "27465 Traning Loss: tensor(0.8487)\n",
      "27466 Traning Loss: tensor(0.8487)\n",
      "27467 Traning Loss: tensor(0.8487)\n",
      "27468 Traning Loss: tensor(0.8487)\n",
      "27469 Traning Loss: tensor(0.8487)\n",
      "27470 Traning Loss: tensor(0.8487)\n",
      "27471 Traning Loss: tensor(0.8487)\n",
      "27472 Traning Loss: tensor(0.8487)\n",
      "27473 Traning Loss: tensor(0.8487)\n",
      "27474 Traning Loss: tensor(0.8487)\n",
      "27475 Traning Loss: tensor(0.8487)\n",
      "27476 Traning Loss: tensor(0.8487)\n",
      "27477 Traning Loss: tensor(0.8487)\n",
      "27478 Traning Loss: tensor(0.8487)\n",
      "27479 Traning Loss: tensor(0.8487)\n",
      "27480 Traning Loss: tensor(0.8487)\n",
      "27481 Traning Loss: tensor(0.8487)\n",
      "27482 Traning Loss: tensor(0.8487)\n",
      "27483 Traning Loss: tensor(0.8487)\n",
      "27484 Traning Loss: tensor(0.8487)\n",
      "27485 Traning Loss: tensor(0.8487)\n",
      "27486 Traning Loss: tensor(0.8487)\n",
      "27487 Traning Loss: tensor(0.8487)\n",
      "27488 Traning Loss: tensor(0.8487)\n",
      "27489 Traning Loss: tensor(0.8487)\n",
      "27490 Traning Loss: tensor(0.8487)\n",
      "27491 Traning Loss: tensor(0.8487)\n",
      "27492 Traning Loss: tensor(0.8487)\n",
      "27493 Traning Loss: tensor(0.8487)\n",
      "27494 Traning Loss: tensor(0.8487)\n",
      "27495 Traning Loss: tensor(0.8487)\n",
      "27496 Traning Loss: tensor(0.8487)\n",
      "27497 Traning Loss: tensor(0.8487)\n",
      "27498 Traning Loss: tensor(0.8487)\n",
      "27499 Traning Loss: tensor(0.8487)\n",
      "27500 Traning Loss: tensor(0.8487)\n",
      "27501 Traning Loss: tensor(0.8487)\n",
      "27502 Traning Loss: tensor(0.8487)\n",
      "27503 Traning Loss: tensor(0.8487)\n",
      "27504 Traning Loss: tensor(0.8487)\n",
      "27505 Traning Loss: tensor(0.8487)\n",
      "27506 Traning Loss: tensor(0.8488)\n",
      "27507 Traning Loss: tensor(0.8488)\n",
      "27508 Traning Loss: tensor(0.8488)\n",
      "27509 Traning Loss: tensor(0.8488)\n",
      "27510 Traning Loss: tensor(0.8487)\n",
      "27511 Traning Loss: tensor(0.8487)\n",
      "27512 Traning Loss: tensor(0.8487)\n",
      "27513 Traning Loss: tensor(0.8487)\n",
      "27514 Traning Loss: tensor(0.8487)\n",
      "27515 Traning Loss: tensor(0.8487)\n",
      "27516 Traning Loss: tensor(0.8487)\n",
      "27517 Traning Loss: tensor(0.8487)\n",
      "27518 Traning Loss: tensor(0.8487)\n",
      "27519 Traning Loss: tensor(0.8487)\n",
      "27520 Traning Loss: tensor(0.8487)\n",
      "27521 Traning Loss: tensor(0.8487)\n",
      "27522 Traning Loss: tensor(0.8487)\n",
      "27523 Traning Loss: tensor(0.8487)\n",
      "27524 Traning Loss: tensor(0.8487)\n",
      "27525 Traning Loss: tensor(0.8487)\n",
      "27526 Traning Loss: tensor(0.8487)\n",
      "27527 Traning Loss: tensor(0.8487)\n",
      "27528 Traning Loss: tensor(0.8487)\n",
      "27529 Traning Loss: tensor(0.8487)\n",
      "27530 Traning Loss: tensor(0.8487)\n",
      "27531 Traning Loss: tensor(0.8487)\n",
      "27532 Traning Loss: tensor(0.8487)\n",
      "27533 Traning Loss: tensor(0.8487)\n",
      "27534 Traning Loss: tensor(0.8487)\n",
      "27535 Traning Loss: tensor(0.8487)\n",
      "27536 Traning Loss: tensor(0.8487)\n",
      "27537 Traning Loss: tensor(0.8487)\n",
      "27538 Traning Loss: tensor(0.8487)\n",
      "27539 Traning Loss: tensor(0.8487)\n",
      "27540 Traning Loss: tensor(0.8487)\n",
      "27541 Traning Loss: tensor(0.8487)\n",
      "27542 Traning Loss: tensor(0.8487)\n",
      "27543 Traning Loss: tensor(0.8487)\n",
      "27544 Traning Loss: tensor(0.8487)\n",
      "27545 Traning Loss: tensor(0.8487)\n",
      "27546 Traning Loss: tensor(0.8487)\n",
      "27547 Traning Loss: tensor(0.8487)\n",
      "27548 Traning Loss: tensor(0.8487)\n",
      "27549 Traning Loss: tensor(0.8487)\n",
      "27550 Traning Loss: tensor(0.8487)\n",
      "27551 Traning Loss: tensor(0.8487)\n",
      "27552 Traning Loss: tensor(0.8487)\n",
      "27553 Traning Loss: tensor(0.8487)\n",
      "27554 Traning Loss: tensor(0.8487)\n",
      "27555 Traning Loss: tensor(0.8487)\n",
      "27556 Traning Loss: tensor(0.8487)\n",
      "27557 Traning Loss: tensor(0.8487)\n",
      "27558 Traning Loss: tensor(0.8487)\n",
      "27559 Traning Loss: tensor(0.8487)\n",
      "27560 Traning Loss: tensor(0.8487)\n",
      "27561 Traning Loss: tensor(0.8487)\n",
      "27562 Traning Loss: tensor(0.8487)\n",
      "27563 Traning Loss: tensor(0.8487)\n",
      "27564 Traning Loss: tensor(0.8487)\n",
      "27565 Traning Loss: tensor(0.8487)\n",
      "27566 Traning Loss: tensor(0.8487)\n",
      "27567 Traning Loss: tensor(0.8487)\n",
      "27568 Traning Loss: tensor(0.8487)\n",
      "27569 Traning Loss: tensor(0.8487)\n",
      "27570 Traning Loss: tensor(0.8487)\n",
      "27571 Traning Loss: tensor(0.8487)\n",
      "27572 Traning Loss: tensor(0.8487)\n",
      "27573 Traning Loss: tensor(0.8487)\n",
      "27574 Traning Loss: tensor(0.8487)\n",
      "27575 Traning Loss: tensor(0.8487)\n",
      "27576 Traning Loss: tensor(0.8487)\n",
      "27577 Traning Loss: tensor(0.8487)\n",
      "27578 Traning Loss: tensor(0.8487)\n",
      "27579 Traning Loss: tensor(0.8487)\n",
      "27580 Traning Loss: tensor(0.8487)\n",
      "27581 Traning Loss: tensor(0.8487)\n",
      "27582 Traning Loss: tensor(0.8487)\n",
      "27583 Traning Loss: tensor(0.8487)\n",
      "27584 Traning Loss: tensor(0.8487)\n",
      "27585 Traning Loss: tensor(0.8487)\n",
      "27586 Traning Loss: tensor(0.8487)\n",
      "27587 Traning Loss: tensor(0.8487)\n",
      "27588 Traning Loss: tensor(0.8487)\n",
      "27589 Traning Loss: tensor(0.8487)\n",
      "27590 Traning Loss: tensor(0.8487)\n",
      "27591 Traning Loss: tensor(0.8487)\n",
      "27592 Traning Loss: tensor(0.8487)\n",
      "27593 Traning Loss: tensor(0.8487)\n",
      "27594 Traning Loss: tensor(0.8487)\n",
      "27595 Traning Loss: tensor(0.8487)\n",
      "27596 Traning Loss: tensor(0.8487)\n",
      "27597 Traning Loss: tensor(0.8487)\n",
      "27598 Traning Loss: tensor(0.8487)\n",
      "27599 Traning Loss: tensor(0.8487)\n",
      "27600 Traning Loss: tensor(0.8487)\n",
      "27601 Traning Loss: tensor(0.8487)\n",
      "27602 Traning Loss: tensor(0.8487)\n",
      "27603 Traning Loss: tensor(0.8487)\n",
      "27604 Traning Loss: tensor(0.8487)\n",
      "27605 Traning Loss: tensor(0.8487)\n",
      "27606 Traning Loss: tensor(0.8487)\n",
      "27607 Traning Loss: tensor(0.8487)\n",
      "27608 Traning Loss: tensor(0.8487)\n",
      "27609 Traning Loss: tensor(0.8487)\n",
      "27610 Traning Loss: tensor(0.8487)\n",
      "27611 Traning Loss: tensor(0.8487)\n",
      "27612 Traning Loss: tensor(0.8487)\n",
      "27613 Traning Loss: tensor(0.8487)\n",
      "27614 Traning Loss: tensor(0.8487)\n",
      "27615 Traning Loss: tensor(0.8487)\n",
      "27616 Traning Loss: tensor(0.8487)\n",
      "27617 Traning Loss: tensor(0.8487)\n",
      "27618 Traning Loss: tensor(0.8487)\n",
      "27619 Traning Loss: tensor(0.8487)\n",
      "27620 Traning Loss: tensor(0.8487)\n",
      "27621 Traning Loss: tensor(0.8487)\n",
      "27622 Traning Loss: tensor(0.8487)\n",
      "27623 Traning Loss: tensor(0.8487)\n",
      "27624 Traning Loss: tensor(0.8487)\n",
      "27625 Traning Loss: tensor(0.8487)\n",
      "27626 Traning Loss: tensor(0.8487)\n",
      "27627 Traning Loss: tensor(0.8487)\n",
      "27628 Traning Loss: tensor(0.8487)\n",
      "27629 Traning Loss: tensor(0.8487)\n",
      "27630 Traning Loss: tensor(0.8487)\n",
      "27631 Traning Loss: tensor(0.8487)\n",
      "27632 Traning Loss: tensor(0.8487)\n",
      "27633 Traning Loss: tensor(0.8487)\n",
      "27634 Traning Loss: tensor(0.8487)\n",
      "27635 Traning Loss: tensor(0.8487)\n",
      "27636 Traning Loss: tensor(0.8487)\n",
      "27637 Traning Loss: tensor(0.8487)\n",
      "27638 Traning Loss: tensor(0.8487)\n",
      "27639 Traning Loss: tensor(0.8487)\n",
      "27640 Traning Loss: tensor(0.8487)\n",
      "27641 Traning Loss: tensor(0.8487)\n",
      "27642 Traning Loss: tensor(0.8487)\n",
      "27643 Traning Loss: tensor(0.8487)\n",
      "27644 Traning Loss: tensor(0.8487)\n",
      "27645 Traning Loss: tensor(0.8487)\n",
      "27646 Traning Loss: tensor(0.8487)\n",
      "27647 Traning Loss: tensor(0.8487)\n",
      "27648 Traning Loss: tensor(0.8487)\n",
      "27649 Traning Loss: tensor(0.8487)\n",
      "27650 Traning Loss: tensor(0.8487)\n",
      "27651 Traning Loss: tensor(0.8487)\n",
      "27652 Traning Loss: tensor(0.8487)\n",
      "27653 Traning Loss: tensor(0.8487)\n",
      "27654 Traning Loss: tensor(0.8487)\n",
      "27655 Traning Loss: tensor(0.8487)\n",
      "27656 Traning Loss: tensor(0.8487)\n",
      "27657 Traning Loss: tensor(0.8487)\n",
      "27658 Traning Loss: tensor(0.8487)\n",
      "27659 Traning Loss: tensor(0.8487)\n",
      "27660 Traning Loss: tensor(0.8487)\n",
      "27661 Traning Loss: tensor(0.8487)\n",
      "27662 Traning Loss: tensor(0.8487)\n",
      "27663 Traning Loss: tensor(0.8487)\n",
      "27664 Traning Loss: tensor(0.8487)\n",
      "27665 Traning Loss: tensor(0.8487)\n",
      "27666 Traning Loss: tensor(0.8487)\n",
      "27667 Traning Loss: tensor(0.8487)\n",
      "27668 Traning Loss: tensor(0.8487)\n",
      "27669 Traning Loss: tensor(0.8487)\n",
      "27670 Traning Loss: tensor(0.8487)\n",
      "27671 Traning Loss: tensor(0.8487)\n",
      "27672 Traning Loss: tensor(0.8487)\n",
      "27673 Traning Loss: tensor(0.8487)\n",
      "27674 Traning Loss: tensor(0.8487)\n",
      "27675 Traning Loss: tensor(0.8487)\n",
      "27676 Traning Loss: tensor(0.8487)\n",
      "27677 Traning Loss: tensor(0.8487)\n",
      "27678 Traning Loss: tensor(0.8487)\n",
      "27679 Traning Loss: tensor(0.8487)\n",
      "27680 Traning Loss: tensor(0.8487)\n",
      "27681 Traning Loss: tensor(0.8487)\n",
      "27682 Traning Loss: tensor(0.8487)\n",
      "27683 Traning Loss: tensor(0.8487)\n",
      "27684 Traning Loss: tensor(0.8487)\n",
      "27685 Traning Loss: tensor(0.8487)\n",
      "27686 Traning Loss: tensor(0.8487)\n",
      "27687 Traning Loss: tensor(0.8487)\n",
      "27688 Traning Loss: tensor(0.8487)\n",
      "27689 Traning Loss: tensor(0.8487)\n",
      "27690 Traning Loss: tensor(0.8487)\n",
      "27691 Traning Loss: tensor(0.8487)\n",
      "27692 Traning Loss: tensor(0.8487)\n",
      "27693 Traning Loss: tensor(0.8487)\n",
      "27694 Traning Loss: tensor(0.8487)\n",
      "27695 Traning Loss: tensor(0.8487)\n",
      "27696 Traning Loss: tensor(0.8487)\n",
      "27697 Traning Loss: tensor(0.8487)\n",
      "27698 Traning Loss: tensor(0.8487)\n",
      "27699 Traning Loss: tensor(0.8487)\n",
      "27700 Traning Loss: tensor(0.8487)\n",
      "27701 Traning Loss: tensor(0.8487)\n",
      "27702 Traning Loss: tensor(0.8487)\n",
      "27703 Traning Loss: tensor(0.8487)\n",
      "27704 Traning Loss: tensor(0.8487)\n",
      "27705 Traning Loss: tensor(0.8487)\n",
      "27706 Traning Loss: tensor(0.8487)\n",
      "27707 Traning Loss: tensor(0.8487)\n",
      "27708 Traning Loss: tensor(0.8487)\n",
      "27709 Traning Loss: tensor(0.8487)\n",
      "27710 Traning Loss: tensor(0.8487)\n",
      "27711 Traning Loss: tensor(0.8487)\n",
      "27712 Traning Loss: tensor(0.8487)\n",
      "27713 Traning Loss: tensor(0.8487)\n",
      "27714 Traning Loss: tensor(0.8487)\n",
      "27715 Traning Loss: tensor(0.8487)\n",
      "27716 Traning Loss: tensor(0.8487)\n",
      "27717 Traning Loss: tensor(0.8487)\n",
      "27718 Traning Loss: tensor(0.8487)\n",
      "27719 Traning Loss: tensor(0.8487)\n",
      "27720 Traning Loss: tensor(0.8487)\n",
      "27721 Traning Loss: tensor(0.8487)\n",
      "27722 Traning Loss: tensor(0.8487)\n",
      "27723 Traning Loss: tensor(0.8487)\n",
      "27724 Traning Loss: tensor(0.8487)\n",
      "27725 Traning Loss: tensor(0.8487)\n",
      "27726 Traning Loss: tensor(0.8487)\n",
      "27727 Traning Loss: tensor(0.8487)\n",
      "27728 Traning Loss: tensor(0.8487)\n",
      "27729 Traning Loss: tensor(0.8487)\n",
      "27730 Traning Loss: tensor(0.8487)\n",
      "27731 Traning Loss: tensor(0.8487)\n",
      "27732 Traning Loss: tensor(0.8487)\n",
      "27733 Traning Loss: tensor(0.8487)\n",
      "27734 Traning Loss: tensor(0.8487)\n",
      "27735 Traning Loss: tensor(0.8487)\n",
      "27736 Traning Loss: tensor(0.8487)\n",
      "27737 Traning Loss: tensor(0.8487)\n",
      "27738 Traning Loss: tensor(0.8487)\n",
      "27739 Traning Loss: tensor(0.8487)\n",
      "27740 Traning Loss: tensor(0.8487)\n",
      "27741 Traning Loss: tensor(0.8487)\n",
      "27742 Traning Loss: tensor(0.8487)\n",
      "27743 Traning Loss: tensor(0.8487)\n",
      "27744 Traning Loss: tensor(0.8487)\n",
      "27745 Traning Loss: tensor(0.8487)\n",
      "27746 Traning Loss: tensor(0.8487)\n",
      "27747 Traning Loss: tensor(0.8487)\n",
      "27748 Traning Loss: tensor(0.8487)\n",
      "27749 Traning Loss: tensor(0.8487)\n",
      "27750 Traning Loss: tensor(0.8487)\n",
      "27751 Traning Loss: tensor(0.8487)\n",
      "27752 Traning Loss: tensor(0.8487)\n",
      "27753 Traning Loss: tensor(0.8487)\n",
      "27754 Traning Loss: tensor(0.8487)\n",
      "27755 Traning Loss: tensor(0.8487)\n",
      "27756 Traning Loss: tensor(0.8487)\n",
      "27757 Traning Loss: tensor(0.8487)\n",
      "27758 Traning Loss: tensor(0.8487)\n",
      "27759 Traning Loss: tensor(0.8487)\n",
      "27760 Traning Loss: tensor(0.8487)\n",
      "27761 Traning Loss: tensor(0.8487)\n",
      "27762 Traning Loss: tensor(0.8487)\n",
      "27763 Traning Loss: tensor(0.8487)\n",
      "27764 Traning Loss: tensor(0.8487)\n",
      "27765 Traning Loss: tensor(0.8487)\n",
      "27766 Traning Loss: tensor(0.8487)\n",
      "27767 Traning Loss: tensor(0.8487)\n",
      "27768 Traning Loss: tensor(0.8487)\n",
      "27769 Traning Loss: tensor(0.8487)\n",
      "27770 Traning Loss: tensor(0.8487)\n",
      "27771 Traning Loss: tensor(0.8487)\n",
      "27772 Traning Loss: tensor(0.8487)\n",
      "27773 Traning Loss: tensor(0.8487)\n",
      "27774 Traning Loss: tensor(0.8487)\n",
      "27775 Traning Loss: tensor(0.8487)\n",
      "27776 Traning Loss: tensor(0.8487)\n",
      "27777 Traning Loss: tensor(0.8487)\n",
      "27778 Traning Loss: tensor(0.8487)\n",
      "27779 Traning Loss: tensor(0.8488)\n",
      "27780 Traning Loss: tensor(0.8488)\n",
      "27781 Traning Loss: tensor(0.8488)\n",
      "27782 Traning Loss: tensor(0.8488)\n",
      "27783 Traning Loss: tensor(0.8488)\n",
      "27784 Traning Loss: tensor(0.8487)\n",
      "27785 Traning Loss: tensor(0.8487)\n",
      "27786 Traning Loss: tensor(0.8487)\n",
      "27787 Traning Loss: tensor(0.8487)\n",
      "27788 Traning Loss: tensor(0.8487)\n",
      "27789 Traning Loss: tensor(0.8487)\n",
      "27790 Traning Loss: tensor(0.8487)\n",
      "27791 Traning Loss: tensor(0.8487)\n",
      "27792 Traning Loss: tensor(0.8487)\n",
      "27793 Traning Loss: tensor(0.8487)\n",
      "27794 Traning Loss: tensor(0.8487)\n",
      "27795 Traning Loss: tensor(0.8487)\n",
      "27796 Traning Loss: tensor(0.8487)\n",
      "27797 Traning Loss: tensor(0.8487)\n",
      "27798 Traning Loss: tensor(0.8487)\n",
      "27799 Traning Loss: tensor(0.8487)\n",
      "27800 Traning Loss: tensor(0.8487)\n",
      "27801 Traning Loss: tensor(0.8487)\n",
      "27802 Traning Loss: tensor(0.8487)\n",
      "27803 Traning Loss: tensor(0.8487)\n",
      "27804 Traning Loss: tensor(0.8487)\n",
      "27805 Traning Loss: tensor(0.8487)\n",
      "27806 Traning Loss: tensor(0.8487)\n",
      "27807 Traning Loss: tensor(0.8487)\n",
      "27808 Traning Loss: tensor(0.8487)\n",
      "27809 Traning Loss: tensor(0.8487)\n",
      "27810 Traning Loss: tensor(0.8487)\n",
      "27811 Traning Loss: tensor(0.8487)\n",
      "27812 Traning Loss: tensor(0.8487)\n",
      "27813 Traning Loss: tensor(0.8487)\n",
      "27814 Traning Loss: tensor(0.8487)\n",
      "27815 Traning Loss: tensor(0.8487)\n",
      "27816 Traning Loss: tensor(0.8487)\n",
      "27817 Traning Loss: tensor(0.8487)\n",
      "27818 Traning Loss: tensor(0.8487)\n",
      "27819 Traning Loss: tensor(0.8487)\n",
      "27820 Traning Loss: tensor(0.8487)\n",
      "27821 Traning Loss: tensor(0.8487)\n",
      "27822 Traning Loss: tensor(0.8487)\n",
      "27823 Traning Loss: tensor(0.8487)\n",
      "27824 Traning Loss: tensor(0.8487)\n",
      "27825 Traning Loss: tensor(0.8487)\n",
      "27826 Traning Loss: tensor(0.8487)\n",
      "27827 Traning Loss: tensor(0.8487)\n",
      "27828 Traning Loss: tensor(0.8487)\n",
      "27829 Traning Loss: tensor(0.8487)\n",
      "27830 Traning Loss: tensor(0.8487)\n",
      "27831 Traning Loss: tensor(0.8487)\n",
      "27832 Traning Loss: tensor(0.8487)\n",
      "27833 Traning Loss: tensor(0.8487)\n",
      "27834 Traning Loss: tensor(0.8487)\n",
      "27835 Traning Loss: tensor(0.8487)\n",
      "27836 Traning Loss: tensor(0.8487)\n",
      "27837 Traning Loss: tensor(0.8487)\n",
      "27838 Traning Loss: tensor(0.8487)\n",
      "27839 Traning Loss: tensor(0.8487)\n",
      "27840 Traning Loss: tensor(0.8487)\n",
      "27841 Traning Loss: tensor(0.8487)\n",
      "27842 Traning Loss: tensor(0.8487)\n",
      "27843 Traning Loss: tensor(0.8487)\n",
      "27844 Traning Loss: tensor(0.8487)\n",
      "27845 Traning Loss: tensor(0.8487)\n",
      "27846 Traning Loss: tensor(0.8487)\n",
      "27847 Traning Loss: tensor(0.8487)\n",
      "27848 Traning Loss: tensor(0.8487)\n",
      "27849 Traning Loss: tensor(0.8487)\n",
      "27850 Traning Loss: tensor(0.8487)\n",
      "27851 Traning Loss: tensor(0.8487)\n",
      "27852 Traning Loss: tensor(0.8487)\n",
      "27853 Traning Loss: tensor(0.8487)\n",
      "27854 Traning Loss: tensor(0.8487)\n",
      "27855 Traning Loss: tensor(0.8487)\n",
      "27856 Traning Loss: tensor(0.8487)\n",
      "27857 Traning Loss: tensor(0.8487)\n",
      "27858 Traning Loss: tensor(0.8487)\n",
      "27859 Traning Loss: tensor(0.8487)\n",
      "27860 Traning Loss: tensor(0.8487)\n",
      "27861 Traning Loss: tensor(0.8487)\n",
      "27862 Traning Loss: tensor(0.8487)\n",
      "27863 Traning Loss: tensor(0.8487)\n",
      "27864 Traning Loss: tensor(0.8487)\n",
      "27865 Traning Loss: tensor(0.8487)\n",
      "27866 Traning Loss: tensor(0.8487)\n",
      "27867 Traning Loss: tensor(0.8487)\n",
      "27868 Traning Loss: tensor(0.8487)\n",
      "27869 Traning Loss: tensor(0.8487)\n",
      "27870 Traning Loss: tensor(0.8487)\n",
      "27871 Traning Loss: tensor(0.8487)\n",
      "27872 Traning Loss: tensor(0.8487)\n",
      "27873 Traning Loss: tensor(0.8487)\n",
      "27874 Traning Loss: tensor(0.8487)\n",
      "27875 Traning Loss: tensor(0.8487)\n",
      "27876 Traning Loss: tensor(0.8487)\n",
      "27877 Traning Loss: tensor(0.8487)\n",
      "27878 Traning Loss: tensor(0.8487)\n",
      "27879 Traning Loss: tensor(0.8487)\n",
      "27880 Traning Loss: tensor(0.8487)\n",
      "27881 Traning Loss: tensor(0.8487)\n",
      "27882 Traning Loss: tensor(0.8487)\n",
      "27883 Traning Loss: tensor(0.8487)\n",
      "27884 Traning Loss: tensor(0.8487)\n",
      "27885 Traning Loss: tensor(0.8487)\n",
      "27886 Traning Loss: tensor(0.8487)\n",
      "27887 Traning Loss: tensor(0.8487)\n",
      "27888 Traning Loss: tensor(0.8487)\n",
      "27889 Traning Loss: tensor(0.8487)\n",
      "27890 Traning Loss: tensor(0.8487)\n",
      "27891 Traning Loss: tensor(0.8487)\n",
      "27892 Traning Loss: tensor(0.8487)\n",
      "27893 Traning Loss: tensor(0.8487)\n",
      "27894 Traning Loss: tensor(0.8487)\n",
      "27895 Traning Loss: tensor(0.8487)\n",
      "27896 Traning Loss: tensor(0.8487)\n",
      "27897 Traning Loss: tensor(0.8487)\n",
      "27898 Traning Loss: tensor(0.8487)\n",
      "27899 Traning Loss: tensor(0.8487)\n",
      "27900 Traning Loss: tensor(0.8487)\n",
      "27901 Traning Loss: tensor(0.8487)\n",
      "27902 Traning Loss: tensor(0.8487)\n",
      "27903 Traning Loss: tensor(0.8487)\n",
      "27904 Traning Loss: tensor(0.8487)\n",
      "27905 Traning Loss: tensor(0.8487)\n",
      "27906 Traning Loss: tensor(0.8487)\n",
      "27907 Traning Loss: tensor(0.8487)\n",
      "27908 Traning Loss: tensor(0.8487)\n",
      "27909 Traning Loss: tensor(0.8487)\n",
      "27910 Traning Loss: tensor(0.8487)\n",
      "27911 Traning Loss: tensor(0.8487)\n",
      "27912 Traning Loss: tensor(0.8487)\n",
      "27913 Traning Loss: tensor(0.8487)\n",
      "27914 Traning Loss: tensor(0.8487)\n",
      "27915 Traning Loss: tensor(0.8487)\n",
      "27916 Traning Loss: tensor(0.8487)\n",
      "27917 Traning Loss: tensor(0.8487)\n",
      "27918 Traning Loss: tensor(0.8487)\n",
      "27919 Traning Loss: tensor(0.8487)\n",
      "27920 Traning Loss: tensor(0.8487)\n",
      "27921 Traning Loss: tensor(0.8487)\n",
      "27922 Traning Loss: tensor(0.8487)\n",
      "27923 Traning Loss: tensor(0.8487)\n",
      "27924 Traning Loss: tensor(0.8487)\n",
      "27925 Traning Loss: tensor(0.8487)\n",
      "27926 Traning Loss: tensor(0.8487)\n",
      "27927 Traning Loss: tensor(0.8487)\n",
      "27928 Traning Loss: tensor(0.8487)\n",
      "27929 Traning Loss: tensor(0.8487)\n",
      "27930 Traning Loss: tensor(0.8487)\n",
      "27931 Traning Loss: tensor(0.8487)\n",
      "27932 Traning Loss: tensor(0.8487)\n",
      "27933 Traning Loss: tensor(0.8487)\n",
      "27934 Traning Loss: tensor(0.8487)\n",
      "27935 Traning Loss: tensor(0.8487)\n",
      "27936 Traning Loss: tensor(0.8487)\n",
      "27937 Traning Loss: tensor(0.8487)\n",
      "27938 Traning Loss: tensor(0.8487)\n",
      "27939 Traning Loss: tensor(0.8487)\n",
      "27940 Traning Loss: tensor(0.8487)\n",
      "27941 Traning Loss: tensor(0.8487)\n",
      "27942 Traning Loss: tensor(0.8487)\n",
      "27943 Traning Loss: tensor(0.8487)\n",
      "27944 Traning Loss: tensor(0.8487)\n",
      "27945 Traning Loss: tensor(0.8487)\n",
      "27946 Traning Loss: tensor(0.8487)\n",
      "27947 Traning Loss: tensor(0.8487)\n",
      "27948 Traning Loss: tensor(0.8487)\n",
      "27949 Traning Loss: tensor(0.8487)\n",
      "27950 Traning Loss: tensor(0.8487)\n",
      "27951 Traning Loss: tensor(0.8487)\n",
      "27952 Traning Loss: tensor(0.8487)\n",
      "27953 Traning Loss: tensor(0.8487)\n",
      "27954 Traning Loss: tensor(0.8487)\n",
      "27955 Traning Loss: tensor(0.8487)\n",
      "27956 Traning Loss: tensor(0.8487)\n",
      "27957 Traning Loss: tensor(0.8487)\n",
      "27958 Traning Loss: tensor(0.8487)\n",
      "27959 Traning Loss: tensor(0.8487)\n",
      "27960 Traning Loss: tensor(0.8487)\n",
      "27961 Traning Loss: tensor(0.8487)\n",
      "27962 Traning Loss: tensor(0.8487)\n",
      "27963 Traning Loss: tensor(0.8487)\n",
      "27964 Traning Loss: tensor(0.8487)\n",
      "27965 Traning Loss: tensor(0.8487)\n",
      "27966 Traning Loss: tensor(0.8487)\n",
      "27967 Traning Loss: tensor(0.8487)\n",
      "27968 Traning Loss: tensor(0.8487)\n",
      "27969 Traning Loss: tensor(0.8487)\n",
      "27970 Traning Loss: tensor(0.8487)\n",
      "27971 Traning Loss: tensor(0.8487)\n",
      "27972 Traning Loss: tensor(0.8487)\n",
      "27973 Traning Loss: tensor(0.8487)\n",
      "27974 Traning Loss: tensor(0.8487)\n",
      "27975 Traning Loss: tensor(0.8487)\n",
      "27976 Traning Loss: tensor(0.8487)\n",
      "27977 Traning Loss: tensor(0.8487)\n",
      "27978 Traning Loss: tensor(0.8487)\n",
      "27979 Traning Loss: tensor(0.8487)\n",
      "27980 Traning Loss: tensor(0.8487)\n",
      "27981 Traning Loss: tensor(0.8487)\n",
      "27982 Traning Loss: tensor(0.8487)\n",
      "27983 Traning Loss: tensor(0.8487)\n",
      "27984 Traning Loss: tensor(0.8487)\n",
      "27985 Traning Loss: tensor(0.8487)\n",
      "27986 Traning Loss: tensor(0.8487)\n",
      "27987 Traning Loss: tensor(0.8487)\n",
      "27988 Traning Loss: tensor(0.8487)\n",
      "27989 Traning Loss: tensor(0.8487)\n",
      "27990 Traning Loss: tensor(0.8487)\n",
      "27991 Traning Loss: tensor(0.8487)\n",
      "27992 Traning Loss: tensor(0.8487)\n",
      "27993 Traning Loss: tensor(0.8487)\n",
      "27994 Traning Loss: tensor(0.8487)\n",
      "27995 Traning Loss: tensor(0.8487)\n",
      "27996 Traning Loss: tensor(0.8487)\n",
      "27997 Traning Loss: tensor(0.8487)\n",
      "27998 Traning Loss: tensor(0.8487)\n",
      "27999 Traning Loss: tensor(0.8487)\n",
      "28000 Traning Loss: tensor(0.8487)\n",
      "28001 Traning Loss: tensor(0.8487)\n",
      "28002 Traning Loss: tensor(0.8487)\n",
      "28003 Traning Loss: tensor(0.8487)\n",
      "28004 Traning Loss: tensor(0.8487)\n",
      "28005 Traning Loss: tensor(0.8487)\n",
      "28006 Traning Loss: tensor(0.8487)\n",
      "28007 Traning Loss: tensor(0.8487)\n",
      "28008 Traning Loss: tensor(0.8487)\n",
      "28009 Traning Loss: tensor(0.8487)\n",
      "28010 Traning Loss: tensor(0.8487)\n",
      "28011 Traning Loss: tensor(0.8487)\n",
      "28012 Traning Loss: tensor(0.8487)\n",
      "28013 Traning Loss: tensor(0.8487)\n",
      "28014 Traning Loss: tensor(0.8487)\n",
      "28015 Traning Loss: tensor(0.8487)\n",
      "28016 Traning Loss: tensor(0.8487)\n",
      "28017 Traning Loss: tensor(0.8487)\n",
      "28018 Traning Loss: tensor(0.8487)\n",
      "28019 Traning Loss: tensor(0.8487)\n",
      "28020 Traning Loss: tensor(0.8487)\n",
      "28021 Traning Loss: tensor(0.8487)\n",
      "28022 Traning Loss: tensor(0.8487)\n",
      "28023 Traning Loss: tensor(0.8487)\n",
      "28024 Traning Loss: tensor(0.8487)\n",
      "28025 Traning Loss: tensor(0.8487)\n",
      "28026 Traning Loss: tensor(0.8487)\n",
      "28027 Traning Loss: tensor(0.8487)\n",
      "28028 Traning Loss: tensor(0.8487)\n",
      "28029 Traning Loss: tensor(0.8487)\n",
      "28030 Traning Loss: tensor(0.8487)\n",
      "28031 Traning Loss: tensor(0.8487)\n",
      "28032 Traning Loss: tensor(0.8487)\n",
      "28033 Traning Loss: tensor(0.8487)\n",
      "28034 Traning Loss: tensor(0.8487)\n",
      "28035 Traning Loss: tensor(0.8487)\n",
      "28036 Traning Loss: tensor(0.8487)\n",
      "28037 Traning Loss: tensor(0.8487)\n",
      "28038 Traning Loss: tensor(0.8487)\n",
      "28039 Traning Loss: tensor(0.8487)\n",
      "28040 Traning Loss: tensor(0.8487)\n",
      "28041 Traning Loss: tensor(0.8487)\n",
      "28042 Traning Loss: tensor(0.8487)\n",
      "28043 Traning Loss: tensor(0.8487)\n",
      "28044 Traning Loss: tensor(0.8487)\n",
      "28045 Traning Loss: tensor(0.8487)\n",
      "28046 Traning Loss: tensor(0.8487)\n",
      "28047 Traning Loss: tensor(0.8487)\n",
      "28048 Traning Loss: tensor(0.8487)\n",
      "28049 Traning Loss: tensor(0.8487)\n",
      "28050 Traning Loss: tensor(0.8487)\n",
      "28051 Traning Loss: tensor(0.8487)\n",
      "28052 Traning Loss: tensor(0.8487)\n",
      "28053 Traning Loss: tensor(0.8487)\n",
      "28054 Traning Loss: tensor(0.8487)\n",
      "28055 Traning Loss: tensor(0.8487)\n",
      "28056 Traning Loss: tensor(0.8487)\n",
      "28057 Traning Loss: tensor(0.8487)\n",
      "28058 Traning Loss: tensor(0.8487)\n",
      "28059 Traning Loss: tensor(0.8487)\n",
      "28060 Traning Loss: tensor(0.8487)\n",
      "28061 Traning Loss: tensor(0.8487)\n",
      "28062 Traning Loss: tensor(0.8487)\n",
      "28063 Traning Loss: tensor(0.8487)\n",
      "28064 Traning Loss: tensor(0.8487)\n",
      "28065 Traning Loss: tensor(0.8487)\n",
      "28066 Traning Loss: tensor(0.8487)\n",
      "28067 Traning Loss: tensor(0.8487)\n",
      "28068 Traning Loss: tensor(0.8487)\n",
      "28069 Traning Loss: tensor(0.8487)\n",
      "28070 Traning Loss: tensor(0.8487)\n",
      "28071 Traning Loss: tensor(0.8488)\n",
      "28072 Traning Loss: tensor(0.8488)\n",
      "28073 Traning Loss: tensor(0.8488)\n",
      "28074 Traning Loss: tensor(0.8487)\n",
      "28075 Traning Loss: tensor(0.8487)\n",
      "28076 Traning Loss: tensor(0.8487)\n",
      "28077 Traning Loss: tensor(0.8487)\n",
      "28078 Traning Loss: tensor(0.8487)\n",
      "28079 Traning Loss: tensor(0.8487)\n",
      "28080 Traning Loss: tensor(0.8487)\n",
      "28081 Traning Loss: tensor(0.8487)\n",
      "28082 Traning Loss: tensor(0.8487)\n",
      "28083 Traning Loss: tensor(0.8487)\n",
      "28084 Traning Loss: tensor(0.8487)\n",
      "28085 Traning Loss: tensor(0.8487)\n",
      "28086 Traning Loss: tensor(0.8487)\n",
      "28087 Traning Loss: tensor(0.8487)\n",
      "28088 Traning Loss: tensor(0.8487)\n",
      "28089 Traning Loss: tensor(0.8487)\n",
      "28090 Traning Loss: tensor(0.8487)\n",
      "28091 Traning Loss: tensor(0.8487)\n",
      "28092 Traning Loss: tensor(0.8487)\n",
      "28093 Traning Loss: tensor(0.8487)\n",
      "28094 Traning Loss: tensor(0.8487)\n",
      "28095 Traning Loss: tensor(0.8487)\n",
      "28096 Traning Loss: tensor(0.8487)\n",
      "28097 Traning Loss: tensor(0.8487)\n",
      "28098 Traning Loss: tensor(0.8487)\n",
      "28099 Traning Loss: tensor(0.8487)\n",
      "28100 Traning Loss: tensor(0.8487)\n",
      "28101 Traning Loss: tensor(0.8487)\n",
      "28102 Traning Loss: tensor(0.8487)\n",
      "28103 Traning Loss: tensor(0.8487)\n",
      "28104 Traning Loss: tensor(0.8487)\n",
      "28105 Traning Loss: tensor(0.8487)\n",
      "28106 Traning Loss: tensor(0.8487)\n",
      "28107 Traning Loss: tensor(0.8487)\n",
      "28108 Traning Loss: tensor(0.8487)\n",
      "28109 Traning Loss: tensor(0.8487)\n",
      "28110 Traning Loss: tensor(0.8487)\n",
      "28111 Traning Loss: tensor(0.8487)\n",
      "28112 Traning Loss: tensor(0.8487)\n",
      "28113 Traning Loss: tensor(0.8487)\n",
      "28114 Traning Loss: tensor(0.8487)\n",
      "28115 Traning Loss: tensor(0.8487)\n",
      "28116 Traning Loss: tensor(0.8487)\n",
      "28117 Traning Loss: tensor(0.8487)\n",
      "28118 Traning Loss: tensor(0.8487)\n",
      "28119 Traning Loss: tensor(0.8487)\n",
      "28120 Traning Loss: tensor(0.8487)\n",
      "28121 Traning Loss: tensor(0.8487)\n",
      "28122 Traning Loss: tensor(0.8487)\n",
      "28123 Traning Loss: tensor(0.8487)\n",
      "28124 Traning Loss: tensor(0.8487)\n",
      "28125 Traning Loss: tensor(0.8487)\n",
      "28126 Traning Loss: tensor(0.8487)\n",
      "28127 Traning Loss: tensor(0.8487)\n",
      "28128 Traning Loss: tensor(0.8487)\n",
      "28129 Traning Loss: tensor(0.8487)\n",
      "28130 Traning Loss: tensor(0.8487)\n",
      "28131 Traning Loss: tensor(0.8487)\n",
      "28132 Traning Loss: tensor(0.8487)\n",
      "28133 Traning Loss: tensor(0.8487)\n",
      "28134 Traning Loss: tensor(0.8487)\n",
      "28135 Traning Loss: tensor(0.8487)\n",
      "28136 Traning Loss: tensor(0.8487)\n",
      "28137 Traning Loss: tensor(0.8487)\n",
      "28138 Traning Loss: tensor(0.8487)\n",
      "28139 Traning Loss: tensor(0.8487)\n",
      "28140 Traning Loss: tensor(0.8487)\n",
      "28141 Traning Loss: tensor(0.8487)\n",
      "28142 Traning Loss: tensor(0.8487)\n",
      "28143 Traning Loss: tensor(0.8487)\n",
      "28144 Traning Loss: tensor(0.8487)\n",
      "28145 Traning Loss: tensor(0.8487)\n",
      "28146 Traning Loss: tensor(0.8487)\n",
      "28147 Traning Loss: tensor(0.8487)\n",
      "28148 Traning Loss: tensor(0.8487)\n",
      "28149 Traning Loss: tensor(0.8487)\n",
      "28150 Traning Loss: tensor(0.8487)\n",
      "28151 Traning Loss: tensor(0.8487)\n",
      "28152 Traning Loss: tensor(0.8487)\n",
      "28153 Traning Loss: tensor(0.8487)\n",
      "28154 Traning Loss: tensor(0.8487)\n",
      "28155 Traning Loss: tensor(0.8487)\n",
      "28156 Traning Loss: tensor(0.8487)\n",
      "28157 Traning Loss: tensor(0.8487)\n",
      "28158 Traning Loss: tensor(0.8487)\n",
      "28159 Traning Loss: tensor(0.8487)\n",
      "28160 Traning Loss: tensor(0.8487)\n",
      "28161 Traning Loss: tensor(0.8487)\n",
      "28162 Traning Loss: tensor(0.8487)\n",
      "28163 Traning Loss: tensor(0.8487)\n",
      "28164 Traning Loss: tensor(0.8487)\n",
      "28165 Traning Loss: tensor(0.8487)\n",
      "28166 Traning Loss: tensor(0.8487)\n",
      "28167 Traning Loss: tensor(0.8487)\n",
      "28168 Traning Loss: tensor(0.8487)\n",
      "28169 Traning Loss: tensor(0.8487)\n",
      "28170 Traning Loss: tensor(0.8487)\n",
      "28171 Traning Loss: tensor(0.8487)\n",
      "28172 Traning Loss: tensor(0.8487)\n",
      "28173 Traning Loss: tensor(0.8487)\n",
      "28174 Traning Loss: tensor(0.8487)\n",
      "28175 Traning Loss: tensor(0.8487)\n",
      "28176 Traning Loss: tensor(0.8487)\n",
      "28177 Traning Loss: tensor(0.8487)\n",
      "28178 Traning Loss: tensor(0.8487)\n",
      "28179 Traning Loss: tensor(0.8487)\n",
      "28180 Traning Loss: tensor(0.8487)\n",
      "28181 Traning Loss: tensor(0.8487)\n",
      "28182 Traning Loss: tensor(0.8487)\n",
      "28183 Traning Loss: tensor(0.8487)\n",
      "28184 Traning Loss: tensor(0.8487)\n",
      "28185 Traning Loss: tensor(0.8487)\n",
      "28186 Traning Loss: tensor(0.8487)\n",
      "28187 Traning Loss: tensor(0.8487)\n",
      "28188 Traning Loss: tensor(0.8487)\n",
      "28189 Traning Loss: tensor(0.8487)\n",
      "28190 Traning Loss: tensor(0.8487)\n",
      "28191 Traning Loss: tensor(0.8487)\n",
      "28192 Traning Loss: tensor(0.8487)\n",
      "28193 Traning Loss: tensor(0.8487)\n",
      "28194 Traning Loss: tensor(0.8487)\n",
      "28195 Traning Loss: tensor(0.8487)\n",
      "28196 Traning Loss: tensor(0.8487)\n",
      "28197 Traning Loss: tensor(0.8487)\n",
      "28198 Traning Loss: tensor(0.8487)\n",
      "28199 Traning Loss: tensor(0.8487)\n",
      "28200 Traning Loss: tensor(0.8487)\n",
      "28201 Traning Loss: tensor(0.8487)\n",
      "28202 Traning Loss: tensor(0.8487)\n",
      "28203 Traning Loss: tensor(0.8487)\n",
      "28204 Traning Loss: tensor(0.8487)\n",
      "28205 Traning Loss: tensor(0.8487)\n",
      "28206 Traning Loss: tensor(0.8487)\n",
      "28207 Traning Loss: tensor(0.8487)\n",
      "28208 Traning Loss: tensor(0.8487)\n",
      "28209 Traning Loss: tensor(0.8487)\n",
      "28210 Traning Loss: tensor(0.8487)\n",
      "28211 Traning Loss: tensor(0.8487)\n",
      "28212 Traning Loss: tensor(0.8487)\n",
      "28213 Traning Loss: tensor(0.8487)\n",
      "28214 Traning Loss: tensor(0.8487)\n",
      "28215 Traning Loss: tensor(0.8487)\n",
      "28216 Traning Loss: tensor(0.8487)\n",
      "28217 Traning Loss: tensor(0.8487)\n",
      "28218 Traning Loss: tensor(0.8487)\n",
      "28219 Traning Loss: tensor(0.8487)\n",
      "28220 Traning Loss: tensor(0.8487)\n",
      "28221 Traning Loss: tensor(0.8487)\n",
      "28222 Traning Loss: tensor(0.8487)\n",
      "28223 Traning Loss: tensor(0.8487)\n",
      "28224 Traning Loss: tensor(0.8487)\n",
      "28225 Traning Loss: tensor(0.8487)\n",
      "28226 Traning Loss: tensor(0.8487)\n",
      "28227 Traning Loss: tensor(0.8487)\n",
      "28228 Traning Loss: tensor(0.8487)\n",
      "28229 Traning Loss: tensor(0.8487)\n",
      "28230 Traning Loss: tensor(0.8487)\n",
      "28231 Traning Loss: tensor(0.8487)\n",
      "28232 Traning Loss: tensor(0.8487)\n",
      "28233 Traning Loss: tensor(0.8487)\n",
      "28234 Traning Loss: tensor(0.8487)\n",
      "28235 Traning Loss: tensor(0.8487)\n",
      "28236 Traning Loss: tensor(0.8487)\n",
      "28237 Traning Loss: tensor(0.8487)\n",
      "28238 Traning Loss: tensor(0.8487)\n",
      "28239 Traning Loss: tensor(0.8487)\n",
      "28240 Traning Loss: tensor(0.8487)\n",
      "28241 Traning Loss: tensor(0.8487)\n",
      "28242 Traning Loss: tensor(0.8487)\n",
      "28243 Traning Loss: tensor(0.8487)\n",
      "28244 Traning Loss: tensor(0.8487)\n",
      "28245 Traning Loss: tensor(0.8487)\n",
      "28246 Traning Loss: tensor(0.8487)\n",
      "28247 Traning Loss: tensor(0.8487)\n",
      "28248 Traning Loss: tensor(0.8487)\n",
      "28249 Traning Loss: tensor(0.8487)\n",
      "28250 Traning Loss: tensor(0.8487)\n",
      "28251 Traning Loss: tensor(0.8487)\n",
      "28252 Traning Loss: tensor(0.8487)\n",
      "28253 Traning Loss: tensor(0.8487)\n",
      "28254 Traning Loss: tensor(0.8487)\n",
      "28255 Traning Loss: tensor(0.8487)\n",
      "28256 Traning Loss: tensor(0.8487)\n",
      "28257 Traning Loss: tensor(0.8487)\n",
      "28258 Traning Loss: tensor(0.8487)\n",
      "28259 Traning Loss: tensor(0.8487)\n",
      "28260 Traning Loss: tensor(0.8487)\n",
      "28261 Traning Loss: tensor(0.8487)\n",
      "28262 Traning Loss: tensor(0.8487)\n",
      "28263 Traning Loss: tensor(0.8487)\n",
      "28264 Traning Loss: tensor(0.8487)\n",
      "28265 Traning Loss: tensor(0.8487)\n",
      "28266 Traning Loss: tensor(0.8487)\n",
      "28267 Traning Loss: tensor(0.8487)\n",
      "28268 Traning Loss: tensor(0.8487)\n",
      "28269 Traning Loss: tensor(0.8487)\n",
      "28270 Traning Loss: tensor(0.8487)\n",
      "28271 Traning Loss: tensor(0.8487)\n",
      "28272 Traning Loss: tensor(0.8487)\n",
      "28273 Traning Loss: tensor(0.8487)\n",
      "28274 Traning Loss: tensor(0.8487)\n",
      "28275 Traning Loss: tensor(0.8487)\n",
      "28276 Traning Loss: tensor(0.8487)\n",
      "28277 Traning Loss: tensor(0.8487)\n",
      "28278 Traning Loss: tensor(0.8487)\n",
      "28279 Traning Loss: tensor(0.8487)\n",
      "28280 Traning Loss: tensor(0.8487)\n",
      "28281 Traning Loss: tensor(0.8487)\n",
      "28282 Traning Loss: tensor(0.8487)\n",
      "28283 Traning Loss: tensor(0.8488)\n",
      "28284 Traning Loss: tensor(0.8488)\n",
      "28285 Traning Loss: tensor(0.8488)\n",
      "28286 Traning Loss: tensor(0.8488)\n",
      "28287 Traning Loss: tensor(0.8487)\n",
      "28288 Traning Loss: tensor(0.8487)\n",
      "28289 Traning Loss: tensor(0.8487)\n",
      "28290 Traning Loss: tensor(0.8487)\n",
      "28291 Traning Loss: tensor(0.8487)\n",
      "28292 Traning Loss: tensor(0.8487)\n",
      "28293 Traning Loss: tensor(0.8487)\n",
      "28294 Traning Loss: tensor(0.8487)\n",
      "28295 Traning Loss: tensor(0.8487)\n",
      "28296 Traning Loss: tensor(0.8487)\n",
      "28297 Traning Loss: tensor(0.8487)\n",
      "28298 Traning Loss: tensor(0.8487)\n",
      "28299 Traning Loss: tensor(0.8487)\n",
      "28300 Traning Loss: tensor(0.8487)\n",
      "28301 Traning Loss: tensor(0.8487)\n",
      "28302 Traning Loss: tensor(0.8487)\n",
      "28303 Traning Loss: tensor(0.8487)\n",
      "28304 Traning Loss: tensor(0.8487)\n",
      "28305 Traning Loss: tensor(0.8487)\n",
      "28306 Traning Loss: tensor(0.8487)\n",
      "28307 Traning Loss: tensor(0.8487)\n",
      "28308 Traning Loss: tensor(0.8487)\n",
      "28309 Traning Loss: tensor(0.8487)\n",
      "28310 Traning Loss: tensor(0.8487)\n",
      "28311 Traning Loss: tensor(0.8487)\n",
      "28312 Traning Loss: tensor(0.8487)\n",
      "28313 Traning Loss: tensor(0.8487)\n",
      "28314 Traning Loss: tensor(0.8487)\n",
      "28315 Traning Loss: tensor(0.8487)\n",
      "28316 Traning Loss: tensor(0.8487)\n",
      "28317 Traning Loss: tensor(0.8487)\n",
      "28318 Traning Loss: tensor(0.8487)\n",
      "28319 Traning Loss: tensor(0.8487)\n",
      "28320 Traning Loss: tensor(0.8487)\n",
      "28321 Traning Loss: tensor(0.8487)\n",
      "28322 Traning Loss: tensor(0.8487)\n",
      "28323 Traning Loss: tensor(0.8487)\n",
      "28324 Traning Loss: tensor(0.8487)\n",
      "28325 Traning Loss: tensor(0.8487)\n",
      "28326 Traning Loss: tensor(0.8487)\n",
      "28327 Traning Loss: tensor(0.8487)\n",
      "28328 Traning Loss: tensor(0.8487)\n",
      "28329 Traning Loss: tensor(0.8487)\n",
      "28330 Traning Loss: tensor(0.8487)\n",
      "28331 Traning Loss: tensor(0.8487)\n",
      "28332 Traning Loss: tensor(0.8487)\n",
      "28333 Traning Loss: tensor(0.8487)\n",
      "28334 Traning Loss: tensor(0.8487)\n",
      "28335 Traning Loss: tensor(0.8487)\n",
      "28336 Traning Loss: tensor(0.8487)\n",
      "28337 Traning Loss: tensor(0.8487)\n",
      "28338 Traning Loss: tensor(0.8487)\n",
      "28339 Traning Loss: tensor(0.8487)\n",
      "28340 Traning Loss: tensor(0.8487)\n",
      "28341 Traning Loss: tensor(0.8487)\n",
      "28342 Traning Loss: tensor(0.8487)\n",
      "28343 Traning Loss: tensor(0.8487)\n",
      "28344 Traning Loss: tensor(0.8487)\n",
      "28345 Traning Loss: tensor(0.8487)\n",
      "28346 Traning Loss: tensor(0.8487)\n",
      "28347 Traning Loss: tensor(0.8487)\n",
      "28348 Traning Loss: tensor(0.8487)\n",
      "28349 Traning Loss: tensor(0.8487)\n",
      "28350 Traning Loss: tensor(0.8487)\n",
      "28351 Traning Loss: tensor(0.8487)\n",
      "28352 Traning Loss: tensor(0.8487)\n",
      "28353 Traning Loss: tensor(0.8487)\n",
      "28354 Traning Loss: tensor(0.8487)\n",
      "28355 Traning Loss: tensor(0.8487)\n",
      "28356 Traning Loss: tensor(0.8487)\n",
      "28357 Traning Loss: tensor(0.8487)\n",
      "28358 Traning Loss: tensor(0.8487)\n",
      "28359 Traning Loss: tensor(0.8487)\n",
      "28360 Traning Loss: tensor(0.8487)\n",
      "28361 Traning Loss: tensor(0.8487)\n",
      "28362 Traning Loss: tensor(0.8487)\n",
      "28363 Traning Loss: tensor(0.8487)\n",
      "28364 Traning Loss: tensor(0.8487)\n",
      "28365 Traning Loss: tensor(0.8487)\n",
      "28366 Traning Loss: tensor(0.8487)\n",
      "28367 Traning Loss: tensor(0.8487)\n",
      "28368 Traning Loss: tensor(0.8487)\n",
      "28369 Traning Loss: tensor(0.8487)\n",
      "28370 Traning Loss: tensor(0.8487)\n",
      "28371 Traning Loss: tensor(0.8487)\n",
      "28372 Traning Loss: tensor(0.8487)\n",
      "28373 Traning Loss: tensor(0.8487)\n",
      "28374 Traning Loss: tensor(0.8487)\n",
      "28375 Traning Loss: tensor(0.8487)\n",
      "28376 Traning Loss: tensor(0.8487)\n",
      "28377 Traning Loss: tensor(0.8487)\n",
      "28378 Traning Loss: tensor(0.8487)\n",
      "28379 Traning Loss: tensor(0.8487)\n",
      "28380 Traning Loss: tensor(0.8487)\n",
      "28381 Traning Loss: tensor(0.8487)\n",
      "28382 Traning Loss: tensor(0.8487)\n",
      "28383 Traning Loss: tensor(0.8487)\n",
      "28384 Traning Loss: tensor(0.8487)\n",
      "28385 Traning Loss: tensor(0.8487)\n",
      "28386 Traning Loss: tensor(0.8487)\n",
      "28387 Traning Loss: tensor(0.8487)\n",
      "28388 Traning Loss: tensor(0.8487)\n",
      "28389 Traning Loss: tensor(0.8487)\n",
      "28390 Traning Loss: tensor(0.8487)\n",
      "28391 Traning Loss: tensor(0.8487)\n",
      "28392 Traning Loss: tensor(0.8487)\n",
      "28393 Traning Loss: tensor(0.8487)\n",
      "28394 Traning Loss: tensor(0.8487)\n",
      "28395 Traning Loss: tensor(0.8487)\n",
      "28396 Traning Loss: tensor(0.8487)\n",
      "28397 Traning Loss: tensor(0.8487)\n",
      "28398 Traning Loss: tensor(0.8487)\n",
      "28399 Traning Loss: tensor(0.8487)\n",
      "28400 Traning Loss: tensor(0.8487)\n",
      "28401 Traning Loss: tensor(0.8487)\n",
      "28402 Traning Loss: tensor(0.8487)\n",
      "28403 Traning Loss: tensor(0.8487)\n",
      "28404 Traning Loss: tensor(0.8487)\n",
      "28405 Traning Loss: tensor(0.8487)\n",
      "28406 Traning Loss: tensor(0.8487)\n",
      "28407 Traning Loss: tensor(0.8487)\n",
      "28408 Traning Loss: tensor(0.8487)\n",
      "28409 Traning Loss: tensor(0.8487)\n",
      "28410 Traning Loss: tensor(0.8487)\n",
      "28411 Traning Loss: tensor(0.8487)\n",
      "28412 Traning Loss: tensor(0.8487)\n",
      "28413 Traning Loss: tensor(0.8487)\n",
      "28414 Traning Loss: tensor(0.8487)\n",
      "28415 Traning Loss: tensor(0.8487)\n",
      "28416 Traning Loss: tensor(0.8487)\n",
      "28417 Traning Loss: tensor(0.8487)\n",
      "28418 Traning Loss: tensor(0.8487)\n",
      "28419 Traning Loss: tensor(0.8487)\n",
      "28420 Traning Loss: tensor(0.8487)\n",
      "28421 Traning Loss: tensor(0.8487)\n",
      "28422 Traning Loss: tensor(0.8487)\n",
      "28423 Traning Loss: tensor(0.8487)\n",
      "28424 Traning Loss: tensor(0.8487)\n",
      "28425 Traning Loss: tensor(0.8487)\n",
      "28426 Traning Loss: tensor(0.8487)\n",
      "28427 Traning Loss: tensor(0.8487)\n",
      "28428 Traning Loss: tensor(0.8487)\n",
      "28429 Traning Loss: tensor(0.8487)\n",
      "28430 Traning Loss: tensor(0.8487)\n",
      "28431 Traning Loss: tensor(0.8487)\n",
      "28432 Traning Loss: tensor(0.8487)\n",
      "28433 Traning Loss: tensor(0.8487)\n",
      "28434 Traning Loss: tensor(0.8487)\n",
      "28435 Traning Loss: tensor(0.8487)\n",
      "28436 Traning Loss: tensor(0.8487)\n",
      "28437 Traning Loss: tensor(0.8487)\n",
      "28438 Traning Loss: tensor(0.8487)\n",
      "28439 Traning Loss: tensor(0.8487)\n",
      "28440 Traning Loss: tensor(0.8487)\n",
      "28441 Traning Loss: tensor(0.8487)\n",
      "28442 Traning Loss: tensor(0.8487)\n",
      "28443 Traning Loss: tensor(0.8487)\n",
      "28444 Traning Loss: tensor(0.8487)\n",
      "28445 Traning Loss: tensor(0.8487)\n",
      "28446 Traning Loss: tensor(0.8487)\n",
      "28447 Traning Loss: tensor(0.8487)\n",
      "28448 Traning Loss: tensor(0.8487)\n",
      "28449 Traning Loss: tensor(0.8487)\n",
      "28450 Traning Loss: tensor(0.8487)\n",
      "28451 Traning Loss: tensor(0.8487)\n",
      "28452 Traning Loss: tensor(0.8487)\n",
      "28453 Traning Loss: tensor(0.8487)\n",
      "28454 Traning Loss: tensor(0.8487)\n",
      "28455 Traning Loss: tensor(0.8487)\n",
      "28456 Traning Loss: tensor(0.8487)\n",
      "28457 Traning Loss: tensor(0.8487)\n",
      "28458 Traning Loss: tensor(0.8487)\n",
      "28459 Traning Loss: tensor(0.8487)\n",
      "28460 Traning Loss: tensor(0.8487)\n",
      "28461 Traning Loss: tensor(0.8487)\n",
      "28462 Traning Loss: tensor(0.8487)\n",
      "28463 Traning Loss: tensor(0.8487)\n",
      "28464 Traning Loss: tensor(0.8487)\n",
      "28465 Traning Loss: tensor(0.8487)\n",
      "28466 Traning Loss: tensor(0.8487)\n",
      "28467 Traning Loss: tensor(0.8487)\n",
      "28468 Traning Loss: tensor(0.8487)\n",
      "28469 Traning Loss: tensor(0.8487)\n",
      "28470 Traning Loss: tensor(0.8487)\n",
      "28471 Traning Loss: tensor(0.8487)\n",
      "28472 Traning Loss: tensor(0.8487)\n",
      "28473 Traning Loss: tensor(0.8487)\n",
      "28474 Traning Loss: tensor(0.8487)\n",
      "28475 Traning Loss: tensor(0.8487)\n",
      "28476 Traning Loss: tensor(0.8487)\n",
      "28477 Traning Loss: tensor(0.8487)\n",
      "28478 Traning Loss: tensor(0.8487)\n",
      "28479 Traning Loss: tensor(0.8487)\n",
      "28480 Traning Loss: tensor(0.8487)\n",
      "28481 Traning Loss: tensor(0.8487)\n",
      "28482 Traning Loss: tensor(0.8487)\n",
      "28483 Traning Loss: tensor(0.8487)\n",
      "28484 Traning Loss: tensor(0.8487)\n",
      "28485 Traning Loss: tensor(0.8487)\n",
      "28486 Traning Loss: tensor(0.8487)\n",
      "28487 Traning Loss: tensor(0.8487)\n",
      "28488 Traning Loss: tensor(0.8487)\n",
      "28489 Traning Loss: tensor(0.8487)\n",
      "28490 Traning Loss: tensor(0.8487)\n",
      "28491 Traning Loss: tensor(0.8487)\n",
      "28492 Traning Loss: tensor(0.8487)\n",
      "28493 Traning Loss: tensor(0.8487)\n",
      "28494 Traning Loss: tensor(0.8487)\n",
      "28495 Traning Loss: tensor(0.8487)\n",
      "28496 Traning Loss: tensor(0.8487)\n",
      "28497 Traning Loss: tensor(0.8487)\n",
      "28498 Traning Loss: tensor(0.8487)\n",
      "28499 Traning Loss: tensor(0.8487)\n",
      "28500 Traning Loss: tensor(0.8487)\n",
      "28501 Traning Loss: tensor(0.8487)\n",
      "28502 Traning Loss: tensor(0.8487)\n",
      "28503 Traning Loss: tensor(0.8487)\n",
      "28504 Traning Loss: tensor(0.8487)\n",
      "28505 Traning Loss: tensor(0.8487)\n",
      "28506 Traning Loss: tensor(0.8487)\n",
      "28507 Traning Loss: tensor(0.8487)\n",
      "28508 Traning Loss: tensor(0.8487)\n",
      "28509 Traning Loss: tensor(0.8487)\n",
      "28510 Traning Loss: tensor(0.8487)\n",
      "28511 Traning Loss: tensor(0.8487)\n",
      "28512 Traning Loss: tensor(0.8487)\n",
      "28513 Traning Loss: tensor(0.8487)\n",
      "28514 Traning Loss: tensor(0.8487)\n",
      "28515 Traning Loss: tensor(0.8487)\n",
      "28516 Traning Loss: tensor(0.8487)\n",
      "28517 Traning Loss: tensor(0.8487)\n",
      "28518 Traning Loss: tensor(0.8487)\n",
      "28519 Traning Loss: tensor(0.8487)\n",
      "28520 Traning Loss: tensor(0.8487)\n",
      "28521 Traning Loss: tensor(0.8487)\n",
      "28522 Traning Loss: tensor(0.8487)\n",
      "28523 Traning Loss: tensor(0.8487)\n",
      "28524 Traning Loss: tensor(0.8487)\n",
      "28525 Traning Loss: tensor(0.8487)\n",
      "28526 Traning Loss: tensor(0.8488)\n",
      "28527 Traning Loss: tensor(0.8488)\n",
      "28528 Traning Loss: tensor(0.8488)\n",
      "28529 Traning Loss: tensor(0.8488)\n",
      "28530 Traning Loss: tensor(0.8487)\n",
      "28531 Traning Loss: tensor(0.8487)\n",
      "28532 Traning Loss: tensor(0.8487)\n",
      "28533 Traning Loss: tensor(0.8487)\n",
      "28534 Traning Loss: tensor(0.8487)\n",
      "28535 Traning Loss: tensor(0.8487)\n",
      "28536 Traning Loss: tensor(0.8487)\n",
      "28537 Traning Loss: tensor(0.8487)\n",
      "28538 Traning Loss: tensor(0.8487)\n",
      "28539 Traning Loss: tensor(0.8487)\n",
      "28540 Traning Loss: tensor(0.8487)\n",
      "28541 Traning Loss: tensor(0.8487)\n",
      "28542 Traning Loss: tensor(0.8487)\n",
      "28543 Traning Loss: tensor(0.8487)\n",
      "28544 Traning Loss: tensor(0.8487)\n",
      "28545 Traning Loss: tensor(0.8487)\n",
      "28546 Traning Loss: tensor(0.8487)\n",
      "28547 Traning Loss: tensor(0.8487)\n",
      "28548 Traning Loss: tensor(0.8487)\n",
      "28549 Traning Loss: tensor(0.8487)\n",
      "28550 Traning Loss: tensor(0.8487)\n",
      "28551 Traning Loss: tensor(0.8487)\n",
      "28552 Traning Loss: tensor(0.8487)\n",
      "28553 Traning Loss: tensor(0.8487)\n",
      "28554 Traning Loss: tensor(0.8487)\n",
      "28555 Traning Loss: tensor(0.8487)\n",
      "28556 Traning Loss: tensor(0.8487)\n",
      "28557 Traning Loss: tensor(0.8487)\n",
      "28558 Traning Loss: tensor(0.8487)\n",
      "28559 Traning Loss: tensor(0.8487)\n",
      "28560 Traning Loss: tensor(0.8487)\n",
      "28561 Traning Loss: tensor(0.8487)\n",
      "28562 Traning Loss: tensor(0.8487)\n",
      "28563 Traning Loss: tensor(0.8487)\n",
      "28564 Traning Loss: tensor(0.8487)\n",
      "28565 Traning Loss: tensor(0.8487)\n",
      "28566 Traning Loss: tensor(0.8487)\n",
      "28567 Traning Loss: tensor(0.8487)\n",
      "28568 Traning Loss: tensor(0.8487)\n",
      "28569 Traning Loss: tensor(0.8487)\n",
      "28570 Traning Loss: tensor(0.8487)\n",
      "28571 Traning Loss: tensor(0.8487)\n",
      "28572 Traning Loss: tensor(0.8487)\n",
      "28573 Traning Loss: tensor(0.8487)\n",
      "28574 Traning Loss: tensor(0.8487)\n",
      "28575 Traning Loss: tensor(0.8487)\n",
      "28576 Traning Loss: tensor(0.8487)\n",
      "28577 Traning Loss: tensor(0.8487)\n",
      "28578 Traning Loss: tensor(0.8487)\n",
      "28579 Traning Loss: tensor(0.8487)\n",
      "28580 Traning Loss: tensor(0.8487)\n",
      "28581 Traning Loss: tensor(0.8487)\n",
      "28582 Traning Loss: tensor(0.8487)\n",
      "28583 Traning Loss: tensor(0.8487)\n",
      "28584 Traning Loss: tensor(0.8487)\n",
      "28585 Traning Loss: tensor(0.8487)\n",
      "28586 Traning Loss: tensor(0.8487)\n",
      "28587 Traning Loss: tensor(0.8487)\n",
      "28588 Traning Loss: tensor(0.8487)\n",
      "28589 Traning Loss: tensor(0.8487)\n",
      "28590 Traning Loss: tensor(0.8487)\n",
      "28591 Traning Loss: tensor(0.8487)\n",
      "28592 Traning Loss: tensor(0.8487)\n",
      "28593 Traning Loss: tensor(0.8487)\n",
      "28594 Traning Loss: tensor(0.8487)\n",
      "28595 Traning Loss: tensor(0.8487)\n",
      "28596 Traning Loss: tensor(0.8487)\n",
      "28597 Traning Loss: tensor(0.8487)\n",
      "28598 Traning Loss: tensor(0.8487)\n",
      "28599 Traning Loss: tensor(0.8487)\n",
      "28600 Traning Loss: tensor(0.8487)\n",
      "28601 Traning Loss: tensor(0.8487)\n",
      "28602 Traning Loss: tensor(0.8487)\n",
      "28603 Traning Loss: tensor(0.8487)\n",
      "28604 Traning Loss: tensor(0.8487)\n",
      "28605 Traning Loss: tensor(0.8487)\n",
      "28606 Traning Loss: tensor(0.8487)\n",
      "28607 Traning Loss: tensor(0.8487)\n",
      "28608 Traning Loss: tensor(0.8487)\n",
      "28609 Traning Loss: tensor(0.8487)\n",
      "28610 Traning Loss: tensor(0.8487)\n",
      "28611 Traning Loss: tensor(0.8487)\n",
      "28612 Traning Loss: tensor(0.8487)\n",
      "28613 Traning Loss: tensor(0.8487)\n",
      "28614 Traning Loss: tensor(0.8487)\n",
      "28615 Traning Loss: tensor(0.8487)\n",
      "28616 Traning Loss: tensor(0.8487)\n",
      "28617 Traning Loss: tensor(0.8487)\n",
      "28618 Traning Loss: tensor(0.8487)\n",
      "28619 Traning Loss: tensor(0.8487)\n",
      "28620 Traning Loss: tensor(0.8487)\n",
      "28621 Traning Loss: tensor(0.8487)\n",
      "28622 Traning Loss: tensor(0.8487)\n",
      "28623 Traning Loss: tensor(0.8487)\n",
      "28624 Traning Loss: tensor(0.8487)\n",
      "28625 Traning Loss: tensor(0.8487)\n",
      "28626 Traning Loss: tensor(0.8487)\n",
      "28627 Traning Loss: tensor(0.8487)\n",
      "28628 Traning Loss: tensor(0.8487)\n",
      "28629 Traning Loss: tensor(0.8487)\n",
      "28630 Traning Loss: tensor(0.8487)\n",
      "28631 Traning Loss: tensor(0.8487)\n",
      "28632 Traning Loss: tensor(0.8487)\n",
      "28633 Traning Loss: tensor(0.8487)\n",
      "28634 Traning Loss: tensor(0.8487)\n",
      "28635 Traning Loss: tensor(0.8487)\n",
      "28636 Traning Loss: tensor(0.8487)\n",
      "28637 Traning Loss: tensor(0.8487)\n",
      "28638 Traning Loss: tensor(0.8487)\n",
      "28639 Traning Loss: tensor(0.8487)\n",
      "28640 Traning Loss: tensor(0.8487)\n",
      "28641 Traning Loss: tensor(0.8487)\n",
      "28642 Traning Loss: tensor(0.8487)\n",
      "28643 Traning Loss: tensor(0.8487)\n",
      "28644 Traning Loss: tensor(0.8487)\n",
      "28645 Traning Loss: tensor(0.8487)\n",
      "28646 Traning Loss: tensor(0.8487)\n",
      "28647 Traning Loss: tensor(0.8487)\n",
      "28648 Traning Loss: tensor(0.8487)\n",
      "28649 Traning Loss: tensor(0.8487)\n",
      "28650 Traning Loss: tensor(0.8487)\n",
      "28651 Traning Loss: tensor(0.8487)\n",
      "28652 Traning Loss: tensor(0.8487)\n",
      "28653 Traning Loss: tensor(0.8487)\n",
      "28654 Traning Loss: tensor(0.8487)\n",
      "28655 Traning Loss: tensor(0.8487)\n",
      "28656 Traning Loss: tensor(0.8487)\n",
      "28657 Traning Loss: tensor(0.8487)\n",
      "28658 Traning Loss: tensor(0.8487)\n",
      "28659 Traning Loss: tensor(0.8487)\n",
      "28660 Traning Loss: tensor(0.8487)\n",
      "28661 Traning Loss: tensor(0.8487)\n",
      "28662 Traning Loss: tensor(0.8487)\n",
      "28663 Traning Loss: tensor(0.8487)\n",
      "28664 Traning Loss: tensor(0.8487)\n",
      "28665 Traning Loss: tensor(0.8487)\n",
      "28666 Traning Loss: tensor(0.8487)\n",
      "28667 Traning Loss: tensor(0.8487)\n",
      "28668 Traning Loss: tensor(0.8487)\n",
      "28669 Traning Loss: tensor(0.8487)\n",
      "28670 Traning Loss: tensor(0.8487)\n",
      "28671 Traning Loss: tensor(0.8487)\n",
      "28672 Traning Loss: tensor(0.8487)\n",
      "28673 Traning Loss: tensor(0.8487)\n",
      "28674 Traning Loss: tensor(0.8487)\n",
      "28675 Traning Loss: tensor(0.8487)\n",
      "28676 Traning Loss: tensor(0.8487)\n",
      "28677 Traning Loss: tensor(0.8487)\n",
      "28678 Traning Loss: tensor(0.8487)\n",
      "28679 Traning Loss: tensor(0.8487)\n",
      "28680 Traning Loss: tensor(0.8487)\n",
      "28681 Traning Loss: tensor(0.8487)\n",
      "28682 Traning Loss: tensor(0.8487)\n",
      "28683 Traning Loss: tensor(0.8487)\n",
      "28684 Traning Loss: tensor(0.8487)\n",
      "28685 Traning Loss: tensor(0.8487)\n",
      "28686 Traning Loss: tensor(0.8487)\n",
      "28687 Traning Loss: tensor(0.8487)\n",
      "28688 Traning Loss: tensor(0.8487)\n",
      "28689 Traning Loss: tensor(0.8487)\n",
      "28690 Traning Loss: tensor(0.8487)\n",
      "28691 Traning Loss: tensor(0.8487)\n",
      "28692 Traning Loss: tensor(0.8487)\n",
      "28693 Traning Loss: tensor(0.8487)\n",
      "28694 Traning Loss: tensor(0.8487)\n",
      "28695 Traning Loss: tensor(0.8487)\n",
      "28696 Traning Loss: tensor(0.8487)\n",
      "28697 Traning Loss: tensor(0.8487)\n",
      "28698 Traning Loss: tensor(0.8487)\n",
      "28699 Traning Loss: tensor(0.8487)\n",
      "28700 Traning Loss: tensor(0.8487)\n",
      "28701 Traning Loss: tensor(0.8487)\n",
      "28702 Traning Loss: tensor(0.8487)\n",
      "28703 Traning Loss: tensor(0.8487)\n",
      "28704 Traning Loss: tensor(0.8487)\n",
      "28705 Traning Loss: tensor(0.8487)\n",
      "28706 Traning Loss: tensor(0.8487)\n",
      "28707 Traning Loss: tensor(0.8487)\n",
      "28708 Traning Loss: tensor(0.8487)\n",
      "28709 Traning Loss: tensor(0.8487)\n",
      "28710 Traning Loss: tensor(0.8487)\n",
      "28711 Traning Loss: tensor(0.8487)\n",
      "28712 Traning Loss: tensor(0.8487)\n",
      "28713 Traning Loss: tensor(0.8487)\n",
      "28714 Traning Loss: tensor(0.8487)\n",
      "28715 Traning Loss: tensor(0.8487)\n",
      "28716 Traning Loss: tensor(0.8487)\n",
      "28717 Traning Loss: tensor(0.8487)\n",
      "28718 Traning Loss: tensor(0.8487)\n",
      "28719 Traning Loss: tensor(0.8487)\n",
      "28720 Traning Loss: tensor(0.8487)\n",
      "28721 Traning Loss: tensor(0.8487)\n",
      "28722 Traning Loss: tensor(0.8487)\n",
      "28723 Traning Loss: tensor(0.8487)\n",
      "28724 Traning Loss: tensor(0.8487)\n",
      "28725 Traning Loss: tensor(0.8487)\n",
      "28726 Traning Loss: tensor(0.8487)\n",
      "28727 Traning Loss: tensor(0.8487)\n",
      "28728 Traning Loss: tensor(0.8487)\n",
      "28729 Traning Loss: tensor(0.8487)\n",
      "28730 Traning Loss: tensor(0.8487)\n",
      "28731 Traning Loss: tensor(0.8487)\n",
      "28732 Traning Loss: tensor(0.8487)\n",
      "28733 Traning Loss: tensor(0.8487)\n",
      "28734 Traning Loss: tensor(0.8487)\n",
      "28735 Traning Loss: tensor(0.8487)\n",
      "28736 Traning Loss: tensor(0.8487)\n",
      "28737 Traning Loss: tensor(0.8487)\n",
      "28738 Traning Loss: tensor(0.8487)\n",
      "28739 Traning Loss: tensor(0.8487)\n",
      "28740 Traning Loss: tensor(0.8487)\n",
      "28741 Traning Loss: tensor(0.8487)\n",
      "28742 Traning Loss: tensor(0.8487)\n",
      "28743 Traning Loss: tensor(0.8487)\n",
      "28744 Traning Loss: tensor(0.8487)\n",
      "28745 Traning Loss: tensor(0.8487)\n",
      "28746 Traning Loss: tensor(0.8487)\n",
      "28747 Traning Loss: tensor(0.8487)\n",
      "28748 Traning Loss: tensor(0.8487)\n",
      "28749 Traning Loss: tensor(0.8487)\n",
      "28750 Traning Loss: tensor(0.8487)\n",
      "28751 Traning Loss: tensor(0.8487)\n",
      "28752 Traning Loss: tensor(0.8487)\n",
      "28753 Traning Loss: tensor(0.8487)\n",
      "28754 Traning Loss: tensor(0.8487)\n",
      "28755 Traning Loss: tensor(0.8487)\n",
      "28756 Traning Loss: tensor(0.8487)\n",
      "28757 Traning Loss: tensor(0.8487)\n",
      "28758 Traning Loss: tensor(0.8487)\n",
      "28759 Traning Loss: tensor(0.8487)\n",
      "28760 Traning Loss: tensor(0.8487)\n",
      "28761 Traning Loss: tensor(0.8487)\n",
      "28762 Traning Loss: tensor(0.8487)\n",
      "28763 Traning Loss: tensor(0.8487)\n",
      "28764 Traning Loss: tensor(0.8487)\n",
      "28765 Traning Loss: tensor(0.8487)\n",
      "28766 Traning Loss: tensor(0.8487)\n",
      "28767 Traning Loss: tensor(0.8487)\n",
      "28768 Traning Loss: tensor(0.8487)\n",
      "28769 Traning Loss: tensor(0.8487)\n",
      "28770 Traning Loss: tensor(0.8487)\n",
      "28771 Traning Loss: tensor(0.8487)\n",
      "28772 Traning Loss: tensor(0.8487)\n",
      "28773 Traning Loss: tensor(0.8487)\n",
      "28774 Traning Loss: tensor(0.8487)\n",
      "28775 Traning Loss: tensor(0.8487)\n",
      "28776 Traning Loss: tensor(0.8487)\n",
      "28777 Traning Loss: tensor(0.8487)\n",
      "28778 Traning Loss: tensor(0.8487)\n",
      "28779 Traning Loss: tensor(0.8487)\n",
      "28780 Traning Loss: tensor(0.8487)\n",
      "28781 Traning Loss: tensor(0.8487)\n",
      "28782 Traning Loss: tensor(0.8487)\n",
      "28783 Traning Loss: tensor(0.8487)\n",
      "28784 Traning Loss: tensor(0.8487)\n",
      "28785 Traning Loss: tensor(0.8487)\n",
      "28786 Traning Loss: tensor(0.8487)\n",
      "28787 Traning Loss: tensor(0.8487)\n",
      "28788 Traning Loss: tensor(0.8487)\n",
      "28789 Traning Loss: tensor(0.8487)\n",
      "28790 Traning Loss: tensor(0.8487)\n",
      "28791 Traning Loss: tensor(0.8487)\n",
      "28792 Traning Loss: tensor(0.8488)\n",
      "28793 Traning Loss: tensor(0.8488)\n",
      "28794 Traning Loss: tensor(0.8488)\n",
      "28795 Traning Loss: tensor(0.8488)\n",
      "28796 Traning Loss: tensor(0.8488)\n",
      "28797 Traning Loss: tensor(0.8487)\n",
      "28798 Traning Loss: tensor(0.8487)\n",
      "28799 Traning Loss: tensor(0.8487)\n",
      "28800 Traning Loss: tensor(0.8487)\n",
      "28801 Traning Loss: tensor(0.8487)\n",
      "28802 Traning Loss: tensor(0.8487)\n",
      "28803 Traning Loss: tensor(0.8487)\n",
      "28804 Traning Loss: tensor(0.8487)\n",
      "28805 Traning Loss: tensor(0.8487)\n",
      "28806 Traning Loss: tensor(0.8487)\n",
      "28807 Traning Loss: tensor(0.8487)\n",
      "28808 Traning Loss: tensor(0.8487)\n",
      "28809 Traning Loss: tensor(0.8487)\n",
      "28810 Traning Loss: tensor(0.8487)\n",
      "28811 Traning Loss: tensor(0.8487)\n",
      "28812 Traning Loss: tensor(0.8487)\n",
      "28813 Traning Loss: tensor(0.8487)\n",
      "28814 Traning Loss: tensor(0.8487)\n",
      "28815 Traning Loss: tensor(0.8487)\n",
      "28816 Traning Loss: tensor(0.8487)\n",
      "28817 Traning Loss: tensor(0.8487)\n",
      "28818 Traning Loss: tensor(0.8487)\n",
      "28819 Traning Loss: tensor(0.8487)\n",
      "28820 Traning Loss: tensor(0.8487)\n",
      "28821 Traning Loss: tensor(0.8487)\n",
      "28822 Traning Loss: tensor(0.8487)\n",
      "28823 Traning Loss: tensor(0.8487)\n",
      "28824 Traning Loss: tensor(0.8487)\n",
      "28825 Traning Loss: tensor(0.8487)\n",
      "28826 Traning Loss: tensor(0.8487)\n",
      "28827 Traning Loss: tensor(0.8487)\n",
      "28828 Traning Loss: tensor(0.8487)\n",
      "28829 Traning Loss: tensor(0.8487)\n",
      "28830 Traning Loss: tensor(0.8487)\n",
      "28831 Traning Loss: tensor(0.8487)\n",
      "28832 Traning Loss: tensor(0.8487)\n",
      "28833 Traning Loss: tensor(0.8487)\n",
      "28834 Traning Loss: tensor(0.8487)\n",
      "28835 Traning Loss: tensor(0.8487)\n",
      "28836 Traning Loss: tensor(0.8487)\n",
      "28837 Traning Loss: tensor(0.8487)\n",
      "28838 Traning Loss: tensor(0.8487)\n",
      "28839 Traning Loss: tensor(0.8487)\n",
      "28840 Traning Loss: tensor(0.8487)\n",
      "28841 Traning Loss: tensor(0.8487)\n",
      "28842 Traning Loss: tensor(0.8487)\n",
      "28843 Traning Loss: tensor(0.8487)\n",
      "28844 Traning Loss: tensor(0.8487)\n",
      "28845 Traning Loss: tensor(0.8487)\n",
      "28846 Traning Loss: tensor(0.8487)\n",
      "28847 Traning Loss: tensor(0.8487)\n",
      "28848 Traning Loss: tensor(0.8487)\n",
      "28849 Traning Loss: tensor(0.8487)\n",
      "28850 Traning Loss: tensor(0.8487)\n",
      "28851 Traning Loss: tensor(0.8487)\n",
      "28852 Traning Loss: tensor(0.8487)\n",
      "28853 Traning Loss: tensor(0.8487)\n",
      "28854 Traning Loss: tensor(0.8487)\n",
      "28855 Traning Loss: tensor(0.8487)\n",
      "28856 Traning Loss: tensor(0.8487)\n",
      "28857 Traning Loss: tensor(0.8487)\n",
      "28858 Traning Loss: tensor(0.8487)\n",
      "28859 Traning Loss: tensor(0.8487)\n",
      "28860 Traning Loss: tensor(0.8487)\n",
      "28861 Traning Loss: tensor(0.8487)\n",
      "28862 Traning Loss: tensor(0.8487)\n",
      "28863 Traning Loss: tensor(0.8487)\n",
      "28864 Traning Loss: tensor(0.8487)\n",
      "28865 Traning Loss: tensor(0.8487)\n",
      "28866 Traning Loss: tensor(0.8487)\n",
      "28867 Traning Loss: tensor(0.8487)\n",
      "28868 Traning Loss: tensor(0.8487)\n",
      "28869 Traning Loss: tensor(0.8487)\n",
      "28870 Traning Loss: tensor(0.8487)\n",
      "28871 Traning Loss: tensor(0.8487)\n",
      "28872 Traning Loss: tensor(0.8487)\n",
      "28873 Traning Loss: tensor(0.8487)\n",
      "28874 Traning Loss: tensor(0.8487)\n",
      "28875 Traning Loss: tensor(0.8487)\n",
      "28876 Traning Loss: tensor(0.8487)\n",
      "28877 Traning Loss: tensor(0.8487)\n",
      "28878 Traning Loss: tensor(0.8487)\n",
      "28879 Traning Loss: tensor(0.8487)\n",
      "28880 Traning Loss: tensor(0.8487)\n",
      "28881 Traning Loss: tensor(0.8487)\n",
      "28882 Traning Loss: tensor(0.8487)\n",
      "28883 Traning Loss: tensor(0.8487)\n",
      "28884 Traning Loss: tensor(0.8487)\n",
      "28885 Traning Loss: tensor(0.8487)\n",
      "28886 Traning Loss: tensor(0.8487)\n",
      "28887 Traning Loss: tensor(0.8487)\n",
      "28888 Traning Loss: tensor(0.8487)\n",
      "28889 Traning Loss: tensor(0.8487)\n",
      "28890 Traning Loss: tensor(0.8487)\n",
      "28891 Traning Loss: tensor(0.8487)\n",
      "28892 Traning Loss: tensor(0.8487)\n",
      "28893 Traning Loss: tensor(0.8487)\n",
      "28894 Traning Loss: tensor(0.8487)\n",
      "28895 Traning Loss: tensor(0.8487)\n",
      "28896 Traning Loss: tensor(0.8487)\n",
      "28897 Traning Loss: tensor(0.8487)\n",
      "28898 Traning Loss: tensor(0.8487)\n",
      "28899 Traning Loss: tensor(0.8487)\n",
      "28900 Traning Loss: tensor(0.8487)\n",
      "28901 Traning Loss: tensor(0.8487)\n",
      "28902 Traning Loss: tensor(0.8487)\n",
      "28903 Traning Loss: tensor(0.8487)\n",
      "28904 Traning Loss: tensor(0.8487)\n",
      "28905 Traning Loss: tensor(0.8487)\n",
      "28906 Traning Loss: tensor(0.8487)\n",
      "28907 Traning Loss: tensor(0.8487)\n",
      "28908 Traning Loss: tensor(0.8487)\n",
      "28909 Traning Loss: tensor(0.8487)\n",
      "28910 Traning Loss: tensor(0.8487)\n",
      "28911 Traning Loss: tensor(0.8487)\n",
      "28912 Traning Loss: tensor(0.8487)\n",
      "28913 Traning Loss: tensor(0.8487)\n",
      "28914 Traning Loss: tensor(0.8487)\n",
      "28915 Traning Loss: tensor(0.8487)\n",
      "28916 Traning Loss: tensor(0.8487)\n",
      "28917 Traning Loss: tensor(0.8487)\n",
      "28918 Traning Loss: tensor(0.8487)\n",
      "28919 Traning Loss: tensor(0.8487)\n",
      "28920 Traning Loss: tensor(0.8487)\n",
      "28921 Traning Loss: tensor(0.8487)\n",
      "28922 Traning Loss: tensor(0.8487)\n",
      "28923 Traning Loss: tensor(0.8487)\n",
      "28924 Traning Loss: tensor(0.8487)\n",
      "28925 Traning Loss: tensor(0.8487)\n",
      "28926 Traning Loss: tensor(0.8487)\n",
      "28927 Traning Loss: tensor(0.8487)\n",
      "28928 Traning Loss: tensor(0.8487)\n",
      "28929 Traning Loss: tensor(0.8487)\n",
      "28930 Traning Loss: tensor(0.8487)\n",
      "28931 Traning Loss: tensor(0.8487)\n",
      "28932 Traning Loss: tensor(0.8487)\n",
      "28933 Traning Loss: tensor(0.8487)\n",
      "28934 Traning Loss: tensor(0.8487)\n",
      "28935 Traning Loss: tensor(0.8487)\n",
      "28936 Traning Loss: tensor(0.8487)\n",
      "28937 Traning Loss: tensor(0.8487)\n",
      "28938 Traning Loss: tensor(0.8487)\n",
      "28939 Traning Loss: tensor(0.8487)\n",
      "28940 Traning Loss: tensor(0.8487)\n",
      "28941 Traning Loss: tensor(0.8487)\n",
      "28942 Traning Loss: tensor(0.8487)\n",
      "28943 Traning Loss: tensor(0.8487)\n",
      "28944 Traning Loss: tensor(0.8487)\n",
      "28945 Traning Loss: tensor(0.8487)\n",
      "28946 Traning Loss: tensor(0.8487)\n",
      "28947 Traning Loss: tensor(0.8487)\n",
      "28948 Traning Loss: tensor(0.8487)\n",
      "28949 Traning Loss: tensor(0.8487)\n",
      "28950 Traning Loss: tensor(0.8487)\n",
      "28951 Traning Loss: tensor(0.8487)\n",
      "28952 Traning Loss: tensor(0.8487)\n",
      "28953 Traning Loss: tensor(0.8487)\n",
      "28954 Traning Loss: tensor(0.8487)\n",
      "28955 Traning Loss: tensor(0.8487)\n",
      "28956 Traning Loss: tensor(0.8487)\n",
      "28957 Traning Loss: tensor(0.8487)\n",
      "28958 Traning Loss: tensor(0.8487)\n",
      "28959 Traning Loss: tensor(0.8487)\n",
      "28960 Traning Loss: tensor(0.8487)\n",
      "28961 Traning Loss: tensor(0.8487)\n",
      "28962 Traning Loss: tensor(0.8487)\n",
      "28963 Traning Loss: tensor(0.8487)\n",
      "28964 Traning Loss: tensor(0.8487)\n",
      "28965 Traning Loss: tensor(0.8487)\n",
      "28966 Traning Loss: tensor(0.8487)\n",
      "28967 Traning Loss: tensor(0.8487)\n",
      "28968 Traning Loss: tensor(0.8487)\n",
      "28969 Traning Loss: tensor(0.8487)\n",
      "28970 Traning Loss: tensor(0.8487)\n",
      "28971 Traning Loss: tensor(0.8487)\n",
      "28972 Traning Loss: tensor(0.8487)\n",
      "28973 Traning Loss: tensor(0.8487)\n",
      "28974 Traning Loss: tensor(0.8487)\n",
      "28975 Traning Loss: tensor(0.8487)\n",
      "28976 Traning Loss: tensor(0.8487)\n",
      "28977 Traning Loss: tensor(0.8487)\n",
      "28978 Traning Loss: tensor(0.8487)\n",
      "28979 Traning Loss: tensor(0.8487)\n",
      "28980 Traning Loss: tensor(0.8487)\n",
      "28981 Traning Loss: tensor(0.8487)\n",
      "28982 Traning Loss: tensor(0.8487)\n",
      "28983 Traning Loss: tensor(0.8487)\n",
      "28984 Traning Loss: tensor(0.8487)\n",
      "28985 Traning Loss: tensor(0.8487)\n",
      "28986 Traning Loss: tensor(0.8487)\n",
      "28987 Traning Loss: tensor(0.8487)\n",
      "28988 Traning Loss: tensor(0.8487)\n",
      "28989 Traning Loss: tensor(0.8487)\n",
      "28990 Traning Loss: tensor(0.8487)\n",
      "28991 Traning Loss: tensor(0.8487)\n",
      "28992 Traning Loss: tensor(0.8487)\n",
      "28993 Traning Loss: tensor(0.8487)\n",
      "28994 Traning Loss: tensor(0.8487)\n",
      "28995 Traning Loss: tensor(0.8487)\n",
      "28996 Traning Loss: tensor(0.8487)\n",
      "28997 Traning Loss: tensor(0.8487)\n",
      "28998 Traning Loss: tensor(0.8487)\n",
      "28999 Traning Loss: tensor(0.8487)\n",
      "29000 Traning Loss: tensor(0.8487)\n",
      "29001 Traning Loss: tensor(0.8487)\n",
      "29002 Traning Loss: tensor(0.8487)\n",
      "29003 Traning Loss: tensor(0.8487)\n",
      "29004 Traning Loss: tensor(0.8487)\n",
      "29005 Traning Loss: tensor(0.8487)\n",
      "29006 Traning Loss: tensor(0.8487)\n",
      "29007 Traning Loss: tensor(0.8487)\n",
      "29008 Traning Loss: tensor(0.8487)\n",
      "29009 Traning Loss: tensor(0.8487)\n",
      "29010 Traning Loss: tensor(0.8487)\n",
      "29011 Traning Loss: tensor(0.8487)\n",
      "29012 Traning Loss: tensor(0.8487)\n",
      "29013 Traning Loss: tensor(0.8487)\n",
      "29014 Traning Loss: tensor(0.8487)\n",
      "29015 Traning Loss: tensor(0.8487)\n",
      "29016 Traning Loss: tensor(0.8487)\n",
      "29017 Traning Loss: tensor(0.8487)\n",
      "29018 Traning Loss: tensor(0.8487)\n",
      "29019 Traning Loss: tensor(0.8487)\n",
      "29020 Traning Loss: tensor(0.8487)\n",
      "29021 Traning Loss: tensor(0.8487)\n",
      "29022 Traning Loss: tensor(0.8487)\n",
      "29023 Traning Loss: tensor(0.8487)\n",
      "29024 Traning Loss: tensor(0.8487)\n",
      "29025 Traning Loss: tensor(0.8487)\n",
      "29026 Traning Loss: tensor(0.8487)\n",
      "29027 Traning Loss: tensor(0.8487)\n",
      "29028 Traning Loss: tensor(0.8487)\n",
      "29029 Traning Loss: tensor(0.8487)\n",
      "29030 Traning Loss: tensor(0.8487)\n",
      "29031 Traning Loss: tensor(0.8487)\n",
      "29032 Traning Loss: tensor(0.8487)\n",
      "29033 Traning Loss: tensor(0.8487)\n",
      "29034 Traning Loss: tensor(0.8487)\n",
      "29035 Traning Loss: tensor(0.8487)\n",
      "29036 Traning Loss: tensor(0.8487)\n",
      "29037 Traning Loss: tensor(0.8487)\n",
      "29038 Traning Loss: tensor(0.8487)\n",
      "29039 Traning Loss: tensor(0.8487)\n",
      "29040 Traning Loss: tensor(0.8487)\n",
      "29041 Traning Loss: tensor(0.8487)\n",
      "29042 Traning Loss: tensor(0.8487)\n",
      "29043 Traning Loss: tensor(0.8487)\n",
      "29044 Traning Loss: tensor(0.8487)\n",
      "29045 Traning Loss: tensor(0.8487)\n",
      "29046 Traning Loss: tensor(0.8487)\n",
      "29047 Traning Loss: tensor(0.8487)\n",
      "29048 Traning Loss: tensor(0.8487)\n",
      "29049 Traning Loss: tensor(0.8487)\n",
      "29050 Traning Loss: tensor(0.8487)\n",
      "29051 Traning Loss: tensor(0.8487)\n",
      "29052 Traning Loss: tensor(0.8487)\n",
      "29053 Traning Loss: tensor(0.8487)\n",
      "29054 Traning Loss: tensor(0.8487)\n",
      "29055 Traning Loss: tensor(0.8487)\n",
      "29056 Traning Loss: tensor(0.8487)\n",
      "29057 Traning Loss: tensor(0.8487)\n",
      "29058 Traning Loss: tensor(0.8487)\n",
      "29059 Traning Loss: tensor(0.8487)\n",
      "29060 Traning Loss: tensor(0.8487)\n",
      "29061 Traning Loss: tensor(0.8487)\n",
      "29062 Traning Loss: tensor(0.8487)\n",
      "29063 Traning Loss: tensor(0.8487)\n",
      "29064 Traning Loss: tensor(0.8487)\n",
      "29065 Traning Loss: tensor(0.8487)\n",
      "29066 Traning Loss: tensor(0.8487)\n",
      "29067 Traning Loss: tensor(0.8487)\n",
      "29068 Traning Loss: tensor(0.8487)\n",
      "29069 Traning Loss: tensor(0.8487)\n",
      "29070 Traning Loss: tensor(0.8487)\n",
      "29071 Traning Loss: tensor(0.8487)\n",
      "29072 Traning Loss: tensor(0.8487)\n",
      "29073 Traning Loss: tensor(0.8487)\n",
      "29074 Traning Loss: tensor(0.8487)\n",
      "29075 Traning Loss: tensor(0.8487)\n",
      "29076 Traning Loss: tensor(0.8487)\n",
      "29077 Traning Loss: tensor(0.8487)\n",
      "29078 Traning Loss: tensor(0.8487)\n",
      "29079 Traning Loss: tensor(0.8487)\n",
      "29080 Traning Loss: tensor(0.8488)\n",
      "29081 Traning Loss: tensor(0.8488)\n",
      "29082 Traning Loss: tensor(0.8488)\n",
      "29083 Traning Loss: tensor(0.8488)\n",
      "29084 Traning Loss: tensor(0.8488)\n",
      "29085 Traning Loss: tensor(0.8487)\n",
      "29086 Traning Loss: tensor(0.8487)\n",
      "29087 Traning Loss: tensor(0.8487)\n",
      "29088 Traning Loss: tensor(0.8487)\n",
      "29089 Traning Loss: tensor(0.8487)\n",
      "29090 Traning Loss: tensor(0.8487)\n",
      "29091 Traning Loss: tensor(0.8487)\n",
      "29092 Traning Loss: tensor(0.8487)\n",
      "29093 Traning Loss: tensor(0.8487)\n",
      "29094 Traning Loss: tensor(0.8487)\n",
      "29095 Traning Loss: tensor(0.8487)\n",
      "29096 Traning Loss: tensor(0.8487)\n",
      "29097 Traning Loss: tensor(0.8487)\n",
      "29098 Traning Loss: tensor(0.8487)\n",
      "29099 Traning Loss: tensor(0.8487)\n",
      "29100 Traning Loss: tensor(0.8487)\n",
      "29101 Traning Loss: tensor(0.8487)\n",
      "29102 Traning Loss: tensor(0.8487)\n",
      "29103 Traning Loss: tensor(0.8487)\n",
      "29104 Traning Loss: tensor(0.8487)\n",
      "29105 Traning Loss: tensor(0.8487)\n",
      "29106 Traning Loss: tensor(0.8487)\n",
      "29107 Traning Loss: tensor(0.8487)\n",
      "29108 Traning Loss: tensor(0.8487)\n",
      "29109 Traning Loss: tensor(0.8487)\n",
      "29110 Traning Loss: tensor(0.8487)\n",
      "29111 Traning Loss: tensor(0.8487)\n",
      "29112 Traning Loss: tensor(0.8487)\n",
      "29113 Traning Loss: tensor(0.8487)\n",
      "29114 Traning Loss: tensor(0.8487)\n",
      "29115 Traning Loss: tensor(0.8487)\n",
      "29116 Traning Loss: tensor(0.8487)\n",
      "29117 Traning Loss: tensor(0.8487)\n",
      "29118 Traning Loss: tensor(0.8487)\n",
      "29119 Traning Loss: tensor(0.8487)\n",
      "29120 Traning Loss: tensor(0.8487)\n",
      "29121 Traning Loss: tensor(0.8487)\n",
      "29122 Traning Loss: tensor(0.8487)\n",
      "29123 Traning Loss: tensor(0.8487)\n",
      "29124 Traning Loss: tensor(0.8487)\n",
      "29125 Traning Loss: tensor(0.8487)\n",
      "29126 Traning Loss: tensor(0.8487)\n",
      "29127 Traning Loss: tensor(0.8487)\n",
      "29128 Traning Loss: tensor(0.8487)\n",
      "29129 Traning Loss: tensor(0.8487)\n",
      "29130 Traning Loss: tensor(0.8487)\n",
      "29131 Traning Loss: tensor(0.8487)\n",
      "29132 Traning Loss: tensor(0.8487)\n",
      "29133 Traning Loss: tensor(0.8487)\n",
      "29134 Traning Loss: tensor(0.8487)\n",
      "29135 Traning Loss: tensor(0.8487)\n",
      "29136 Traning Loss: tensor(0.8487)\n",
      "29137 Traning Loss: tensor(0.8487)\n",
      "29138 Traning Loss: tensor(0.8487)\n",
      "29139 Traning Loss: tensor(0.8487)\n",
      "29140 Traning Loss: tensor(0.8487)\n",
      "29141 Traning Loss: tensor(0.8487)\n",
      "29142 Traning Loss: tensor(0.8487)\n",
      "29143 Traning Loss: tensor(0.8487)\n",
      "29144 Traning Loss: tensor(0.8487)\n",
      "29145 Traning Loss: tensor(0.8487)\n",
      "29146 Traning Loss: tensor(0.8487)\n",
      "29147 Traning Loss: tensor(0.8487)\n",
      "29148 Traning Loss: tensor(0.8487)\n",
      "29149 Traning Loss: tensor(0.8487)\n",
      "29150 Traning Loss: tensor(0.8487)\n",
      "29151 Traning Loss: tensor(0.8487)\n",
      "29152 Traning Loss: tensor(0.8487)\n",
      "29153 Traning Loss: tensor(0.8487)\n",
      "29154 Traning Loss: tensor(0.8487)\n",
      "29155 Traning Loss: tensor(0.8487)\n",
      "29156 Traning Loss: tensor(0.8487)\n",
      "29157 Traning Loss: tensor(0.8487)\n",
      "29158 Traning Loss: tensor(0.8487)\n",
      "29159 Traning Loss: tensor(0.8487)\n",
      "29160 Traning Loss: tensor(0.8487)\n",
      "29161 Traning Loss: tensor(0.8487)\n",
      "29162 Traning Loss: tensor(0.8487)\n",
      "29163 Traning Loss: tensor(0.8487)\n",
      "29164 Traning Loss: tensor(0.8487)\n",
      "29165 Traning Loss: tensor(0.8487)\n",
      "29166 Traning Loss: tensor(0.8487)\n",
      "29167 Traning Loss: tensor(0.8487)\n",
      "29168 Traning Loss: tensor(0.8487)\n",
      "29169 Traning Loss: tensor(0.8487)\n",
      "29170 Traning Loss: tensor(0.8487)\n",
      "29171 Traning Loss: tensor(0.8487)\n",
      "29172 Traning Loss: tensor(0.8487)\n",
      "29173 Traning Loss: tensor(0.8487)\n",
      "29174 Traning Loss: tensor(0.8487)\n",
      "29175 Traning Loss: tensor(0.8487)\n",
      "29176 Traning Loss: tensor(0.8487)\n",
      "29177 Traning Loss: tensor(0.8487)\n",
      "29178 Traning Loss: tensor(0.8487)\n",
      "29179 Traning Loss: tensor(0.8487)\n",
      "29180 Traning Loss: tensor(0.8487)\n",
      "29181 Traning Loss: tensor(0.8487)\n",
      "29182 Traning Loss: tensor(0.8487)\n",
      "29183 Traning Loss: tensor(0.8487)\n",
      "29184 Traning Loss: tensor(0.8487)\n",
      "29185 Traning Loss: tensor(0.8487)\n",
      "29186 Traning Loss: tensor(0.8487)\n",
      "29187 Traning Loss: tensor(0.8487)\n",
      "29188 Traning Loss: tensor(0.8487)\n",
      "29189 Traning Loss: tensor(0.8487)\n",
      "29190 Traning Loss: tensor(0.8487)\n",
      "29191 Traning Loss: tensor(0.8487)\n",
      "29192 Traning Loss: tensor(0.8487)\n",
      "29193 Traning Loss: tensor(0.8487)\n",
      "29194 Traning Loss: tensor(0.8487)\n",
      "29195 Traning Loss: tensor(0.8487)\n",
      "29196 Traning Loss: tensor(0.8487)\n",
      "29197 Traning Loss: tensor(0.8487)\n",
      "29198 Traning Loss: tensor(0.8487)\n",
      "29199 Traning Loss: tensor(0.8487)\n",
      "29200 Traning Loss: tensor(0.8487)\n",
      "29201 Traning Loss: tensor(0.8487)\n",
      "29202 Traning Loss: tensor(0.8487)\n",
      "29203 Traning Loss: tensor(0.8487)\n",
      "29204 Traning Loss: tensor(0.8487)\n",
      "29205 Traning Loss: tensor(0.8487)\n",
      "29206 Traning Loss: tensor(0.8487)\n",
      "29207 Traning Loss: tensor(0.8487)\n",
      "29208 Traning Loss: tensor(0.8487)\n",
      "29209 Traning Loss: tensor(0.8487)\n",
      "29210 Traning Loss: tensor(0.8487)\n",
      "29211 Traning Loss: tensor(0.8487)\n",
      "29212 Traning Loss: tensor(0.8487)\n",
      "29213 Traning Loss: tensor(0.8487)\n",
      "29214 Traning Loss: tensor(0.8487)\n",
      "29215 Traning Loss: tensor(0.8487)\n",
      "29216 Traning Loss: tensor(0.8487)\n",
      "29217 Traning Loss: tensor(0.8487)\n",
      "29218 Traning Loss: tensor(0.8487)\n",
      "29219 Traning Loss: tensor(0.8487)\n",
      "29220 Traning Loss: tensor(0.8487)\n",
      "29221 Traning Loss: tensor(0.8487)\n",
      "29222 Traning Loss: tensor(0.8487)\n",
      "29223 Traning Loss: tensor(0.8487)\n",
      "29224 Traning Loss: tensor(0.8487)\n",
      "29225 Traning Loss: tensor(0.8487)\n",
      "29226 Traning Loss: tensor(0.8487)\n",
      "29227 Traning Loss: tensor(0.8487)\n",
      "29228 Traning Loss: tensor(0.8487)\n",
      "29229 Traning Loss: tensor(0.8487)\n",
      "29230 Traning Loss: tensor(0.8487)\n",
      "29231 Traning Loss: tensor(0.8487)\n",
      "29232 Traning Loss: tensor(0.8487)\n",
      "29233 Traning Loss: tensor(0.8487)\n",
      "29234 Traning Loss: tensor(0.8487)\n",
      "29235 Traning Loss: tensor(0.8487)\n",
      "29236 Traning Loss: tensor(0.8487)\n",
      "29237 Traning Loss: tensor(0.8487)\n",
      "29238 Traning Loss: tensor(0.8487)\n",
      "29239 Traning Loss: tensor(0.8487)\n",
      "29240 Traning Loss: tensor(0.8487)\n",
      "29241 Traning Loss: tensor(0.8487)\n",
      "29242 Traning Loss: tensor(0.8487)\n",
      "29243 Traning Loss: tensor(0.8487)\n",
      "29244 Traning Loss: tensor(0.8487)\n",
      "29245 Traning Loss: tensor(0.8487)\n",
      "29246 Traning Loss: tensor(0.8487)\n",
      "29247 Traning Loss: tensor(0.8487)\n",
      "29248 Traning Loss: tensor(0.8487)\n",
      "29249 Traning Loss: tensor(0.8487)\n",
      "29250 Traning Loss: tensor(0.8487)\n",
      "29251 Traning Loss: tensor(0.8487)\n",
      "29252 Traning Loss: tensor(0.8487)\n",
      "29253 Traning Loss: tensor(0.8487)\n",
      "29254 Traning Loss: tensor(0.8487)\n",
      "29255 Traning Loss: tensor(0.8487)\n",
      "29256 Traning Loss: tensor(0.8487)\n",
      "29257 Traning Loss: tensor(0.8487)\n",
      "29258 Traning Loss: tensor(0.8487)\n",
      "29259 Traning Loss: tensor(0.8487)\n",
      "29260 Traning Loss: tensor(0.8487)\n",
      "29261 Traning Loss: tensor(0.8487)\n",
      "29262 Traning Loss: tensor(0.8487)\n",
      "29263 Traning Loss: tensor(0.8487)\n",
      "29264 Traning Loss: tensor(0.8487)\n",
      "29265 Traning Loss: tensor(0.8487)\n",
      "29266 Traning Loss: tensor(0.8487)\n",
      "29267 Traning Loss: tensor(0.8487)\n",
      "29268 Traning Loss: tensor(0.8487)\n",
      "29269 Traning Loss: tensor(0.8487)\n",
      "29270 Traning Loss: tensor(0.8487)\n",
      "29271 Traning Loss: tensor(0.8487)\n",
      "29272 Traning Loss: tensor(0.8487)\n",
      "29273 Traning Loss: tensor(0.8487)\n",
      "29274 Traning Loss: tensor(0.8487)\n",
      "29275 Traning Loss: tensor(0.8487)\n",
      "29276 Traning Loss: tensor(0.8487)\n",
      "29277 Traning Loss: tensor(0.8487)\n",
      "29278 Traning Loss: tensor(0.8487)\n",
      "29279 Traning Loss: tensor(0.8487)\n",
      "29280 Traning Loss: tensor(0.8487)\n",
      "29281 Traning Loss: tensor(0.8487)\n",
      "29282 Traning Loss: tensor(0.8487)\n",
      "29283 Traning Loss: tensor(0.8487)\n",
      "29284 Traning Loss: tensor(0.8487)\n",
      "29285 Traning Loss: tensor(0.8487)\n",
      "29286 Traning Loss: tensor(0.8487)\n",
      "29287 Traning Loss: tensor(0.8487)\n",
      "29288 Traning Loss: tensor(0.8487)\n",
      "29289 Traning Loss: tensor(0.8487)\n",
      "29290 Traning Loss: tensor(0.8487)\n",
      "29291 Traning Loss: tensor(0.8487)\n",
      "29292 Traning Loss: tensor(0.8487)\n",
      "29293 Traning Loss: tensor(0.8487)\n",
      "29294 Traning Loss: tensor(0.8487)\n",
      "29295 Traning Loss: tensor(0.8487)\n",
      "29296 Traning Loss: tensor(0.8487)\n",
      "29297 Traning Loss: tensor(0.8487)\n",
      "29298 Traning Loss: tensor(0.8487)\n",
      "29299 Traning Loss: tensor(0.8487)\n",
      "29300 Traning Loss: tensor(0.8487)\n",
      "29301 Traning Loss: tensor(0.8487)\n",
      "29302 Traning Loss: tensor(0.8487)\n",
      "29303 Traning Loss: tensor(0.8487)\n",
      "29304 Traning Loss: tensor(0.8487)\n",
      "29305 Traning Loss: tensor(0.8487)\n",
      "29306 Traning Loss: tensor(0.8487)\n",
      "29307 Traning Loss: tensor(0.8487)\n",
      "29308 Traning Loss: tensor(0.8487)\n",
      "29309 Traning Loss: tensor(0.8487)\n",
      "29310 Traning Loss: tensor(0.8487)\n",
      "29311 Traning Loss: tensor(0.8487)\n",
      "29312 Traning Loss: tensor(0.8487)\n",
      "29313 Traning Loss: tensor(0.8487)\n",
      "29314 Traning Loss: tensor(0.8487)\n",
      "29315 Traning Loss: tensor(0.8487)\n",
      "29316 Traning Loss: tensor(0.8487)\n",
      "29317 Traning Loss: tensor(0.8487)\n",
      "29318 Traning Loss: tensor(0.8487)\n",
      "29319 Traning Loss: tensor(0.8487)\n",
      "29320 Traning Loss: tensor(0.8487)\n",
      "29321 Traning Loss: tensor(0.8487)\n",
      "29322 Traning Loss: tensor(0.8487)\n",
      "29323 Traning Loss: tensor(0.8487)\n",
      "29324 Traning Loss: tensor(0.8487)\n",
      "29325 Traning Loss: tensor(0.8487)\n",
      "29326 Traning Loss: tensor(0.8487)\n",
      "29327 Traning Loss: tensor(0.8487)\n",
      "29328 Traning Loss: tensor(0.8487)\n",
      "29329 Traning Loss: tensor(0.8487)\n",
      "29330 Traning Loss: tensor(0.8487)\n",
      "29331 Traning Loss: tensor(0.8487)\n",
      "29332 Traning Loss: tensor(0.8487)\n",
      "29333 Traning Loss: tensor(0.8487)\n",
      "29334 Traning Loss: tensor(0.8487)\n",
      "29335 Traning Loss: tensor(0.8487)\n",
      "29336 Traning Loss: tensor(0.8487)\n",
      "29337 Traning Loss: tensor(0.8487)\n",
      "29338 Traning Loss: tensor(0.8487)\n",
      "29339 Traning Loss: tensor(0.8487)\n",
      "29340 Traning Loss: tensor(0.8487)\n",
      "29341 Traning Loss: tensor(0.8487)\n",
      "29342 Traning Loss: tensor(0.8487)\n",
      "29343 Traning Loss: tensor(0.8487)\n",
      "29344 Traning Loss: tensor(0.8487)\n",
      "29345 Traning Loss: tensor(0.8487)\n",
      "29346 Traning Loss: tensor(0.8487)\n",
      "29347 Traning Loss: tensor(0.8487)\n",
      "29348 Traning Loss: tensor(0.8487)\n",
      "29349 Traning Loss: tensor(0.8487)\n",
      "29350 Traning Loss: tensor(0.8487)\n",
      "29351 Traning Loss: tensor(0.8487)\n",
      "29352 Traning Loss: tensor(0.8487)\n",
      "29353 Traning Loss: tensor(0.8487)\n",
      "29354 Traning Loss: tensor(0.8487)\n",
      "29355 Traning Loss: tensor(0.8487)\n",
      "29356 Traning Loss: tensor(0.8487)\n",
      "29357 Traning Loss: tensor(0.8487)\n",
      "29358 Traning Loss: tensor(0.8487)\n",
      "29359 Traning Loss: tensor(0.8487)\n",
      "29360 Traning Loss: tensor(0.8487)\n",
      "29361 Traning Loss: tensor(0.8488)\n",
      "29362 Traning Loss: tensor(0.8488)\n",
      "29363 Traning Loss: tensor(0.8488)\n",
      "29364 Traning Loss: tensor(0.8488)\n",
      "29365 Traning Loss: tensor(0.8488)\n",
      "29366 Traning Loss: tensor(0.8487)\n",
      "29367 Traning Loss: tensor(0.8487)\n",
      "29368 Traning Loss: tensor(0.8487)\n",
      "29369 Traning Loss: tensor(0.8487)\n",
      "29370 Traning Loss: tensor(0.8488)\n",
      "29371 Traning Loss: tensor(0.8487)\n",
      "29372 Traning Loss: tensor(0.8487)\n",
      "29373 Traning Loss: tensor(0.8487)\n",
      "29374 Traning Loss: tensor(0.8487)\n",
      "29375 Traning Loss: tensor(0.8487)\n",
      "29376 Traning Loss: tensor(0.8487)\n",
      "29377 Traning Loss: tensor(0.8487)\n",
      "29378 Traning Loss: tensor(0.8487)\n",
      "29379 Traning Loss: tensor(0.8487)\n",
      "29380 Traning Loss: tensor(0.8487)\n",
      "29381 Traning Loss: tensor(0.8487)\n",
      "29382 Traning Loss: tensor(0.8487)\n",
      "29383 Traning Loss: tensor(0.8487)\n",
      "29384 Traning Loss: tensor(0.8487)\n",
      "29385 Traning Loss: tensor(0.8487)\n",
      "29386 Traning Loss: tensor(0.8487)\n",
      "29387 Traning Loss: tensor(0.8487)\n",
      "29388 Traning Loss: tensor(0.8487)\n",
      "29389 Traning Loss: tensor(0.8487)\n",
      "29390 Traning Loss: tensor(0.8487)\n",
      "29391 Traning Loss: tensor(0.8487)\n",
      "29392 Traning Loss: tensor(0.8487)\n",
      "29393 Traning Loss: tensor(0.8487)\n",
      "29394 Traning Loss: tensor(0.8487)\n",
      "29395 Traning Loss: tensor(0.8487)\n",
      "29396 Traning Loss: tensor(0.8487)\n",
      "29397 Traning Loss: tensor(0.8487)\n",
      "29398 Traning Loss: tensor(0.8487)\n",
      "29399 Traning Loss: tensor(0.8487)\n",
      "29400 Traning Loss: tensor(0.8487)\n",
      "29401 Traning Loss: tensor(0.8487)\n",
      "29402 Traning Loss: tensor(0.8487)\n",
      "29403 Traning Loss: tensor(0.8487)\n",
      "29404 Traning Loss: tensor(0.8487)\n",
      "29405 Traning Loss: tensor(0.8487)\n",
      "29406 Traning Loss: tensor(0.8487)\n",
      "29407 Traning Loss: tensor(0.8487)\n",
      "29408 Traning Loss: tensor(0.8487)\n",
      "29409 Traning Loss: tensor(0.8487)\n",
      "29410 Traning Loss: tensor(0.8487)\n",
      "29411 Traning Loss: tensor(0.8487)\n",
      "29412 Traning Loss: tensor(0.8487)\n",
      "29413 Traning Loss: tensor(0.8487)\n",
      "29414 Traning Loss: tensor(0.8487)\n",
      "29415 Traning Loss: tensor(0.8487)\n",
      "29416 Traning Loss: tensor(0.8487)\n",
      "29417 Traning Loss: tensor(0.8487)\n",
      "29418 Traning Loss: tensor(0.8487)\n",
      "29419 Traning Loss: tensor(0.8487)\n",
      "29420 Traning Loss: tensor(0.8487)\n",
      "29421 Traning Loss: tensor(0.8487)\n",
      "29422 Traning Loss: tensor(0.8487)\n",
      "29423 Traning Loss: tensor(0.8487)\n",
      "29424 Traning Loss: tensor(0.8487)\n",
      "29425 Traning Loss: tensor(0.8487)\n",
      "29426 Traning Loss: tensor(0.8487)\n",
      "29427 Traning Loss: tensor(0.8487)\n",
      "29428 Traning Loss: tensor(0.8487)\n",
      "29429 Traning Loss: tensor(0.8487)\n",
      "29430 Traning Loss: tensor(0.8487)\n",
      "29431 Traning Loss: tensor(0.8487)\n",
      "29432 Traning Loss: tensor(0.8487)\n",
      "29433 Traning Loss: tensor(0.8487)\n",
      "29434 Traning Loss: tensor(0.8487)\n",
      "29435 Traning Loss: tensor(0.8487)\n",
      "29436 Traning Loss: tensor(0.8487)\n",
      "29437 Traning Loss: tensor(0.8487)\n",
      "29438 Traning Loss: tensor(0.8487)\n",
      "29439 Traning Loss: tensor(0.8487)\n",
      "29440 Traning Loss: tensor(0.8487)\n",
      "29441 Traning Loss: tensor(0.8487)\n",
      "29442 Traning Loss: tensor(0.8487)\n",
      "29443 Traning Loss: tensor(0.8487)\n",
      "29444 Traning Loss: tensor(0.8487)\n",
      "29445 Traning Loss: tensor(0.8487)\n",
      "29446 Traning Loss: tensor(0.8487)\n",
      "29447 Traning Loss: tensor(0.8487)\n",
      "29448 Traning Loss: tensor(0.8487)\n",
      "29449 Traning Loss: tensor(0.8487)\n",
      "29450 Traning Loss: tensor(0.8487)\n",
      "29451 Traning Loss: tensor(0.8487)\n",
      "29452 Traning Loss: tensor(0.8487)\n",
      "29453 Traning Loss: tensor(0.8487)\n",
      "29454 Traning Loss: tensor(0.8487)\n",
      "29455 Traning Loss: tensor(0.8487)\n",
      "29456 Traning Loss: tensor(0.8487)\n",
      "29457 Traning Loss: tensor(0.8487)\n",
      "29458 Traning Loss: tensor(0.8487)\n",
      "29459 Traning Loss: tensor(0.8487)\n",
      "29460 Traning Loss: tensor(0.8487)\n",
      "29461 Traning Loss: tensor(0.8487)\n",
      "29462 Traning Loss: tensor(0.8487)\n",
      "29463 Traning Loss: tensor(0.8487)\n",
      "29464 Traning Loss: tensor(0.8487)\n",
      "29465 Traning Loss: tensor(0.8487)\n",
      "29466 Traning Loss: tensor(0.8487)\n",
      "29467 Traning Loss: tensor(0.8487)\n",
      "29468 Traning Loss: tensor(0.8487)\n",
      "29469 Traning Loss: tensor(0.8487)\n",
      "29470 Traning Loss: tensor(0.8487)\n",
      "29471 Traning Loss: tensor(0.8487)\n",
      "29472 Traning Loss: tensor(0.8487)\n",
      "29473 Traning Loss: tensor(0.8487)\n",
      "29474 Traning Loss: tensor(0.8487)\n",
      "29475 Traning Loss: tensor(0.8487)\n",
      "29476 Traning Loss: tensor(0.8487)\n",
      "29477 Traning Loss: tensor(0.8487)\n",
      "29478 Traning Loss: tensor(0.8487)\n",
      "29479 Traning Loss: tensor(0.8487)\n",
      "29480 Traning Loss: tensor(0.8487)\n",
      "29481 Traning Loss: tensor(0.8487)\n",
      "29482 Traning Loss: tensor(0.8487)\n",
      "29483 Traning Loss: tensor(0.8487)\n",
      "29484 Traning Loss: tensor(0.8487)\n",
      "29485 Traning Loss: tensor(0.8487)\n",
      "29486 Traning Loss: tensor(0.8487)\n",
      "29487 Traning Loss: tensor(0.8487)\n",
      "29488 Traning Loss: tensor(0.8487)\n",
      "29489 Traning Loss: tensor(0.8487)\n",
      "29490 Traning Loss: tensor(0.8487)\n",
      "29491 Traning Loss: tensor(0.8487)\n",
      "29492 Traning Loss: tensor(0.8487)\n",
      "29493 Traning Loss: tensor(0.8487)\n",
      "29494 Traning Loss: tensor(0.8487)\n",
      "29495 Traning Loss: tensor(0.8487)\n",
      "29496 Traning Loss: tensor(0.8487)\n",
      "29497 Traning Loss: tensor(0.8487)\n",
      "29498 Traning Loss: tensor(0.8487)\n",
      "29499 Traning Loss: tensor(0.8487)\n",
      "29500 Traning Loss: tensor(0.8487)\n",
      "29501 Traning Loss: tensor(0.8487)\n",
      "29502 Traning Loss: tensor(0.8487)\n",
      "29503 Traning Loss: tensor(0.8487)\n",
      "29504 Traning Loss: tensor(0.8487)\n",
      "29505 Traning Loss: tensor(0.8487)\n",
      "29506 Traning Loss: tensor(0.8487)\n",
      "29507 Traning Loss: tensor(0.8487)\n",
      "29508 Traning Loss: tensor(0.8487)\n",
      "29509 Traning Loss: tensor(0.8487)\n",
      "29510 Traning Loss: tensor(0.8487)\n",
      "29511 Traning Loss: tensor(0.8487)\n",
      "29512 Traning Loss: tensor(0.8487)\n",
      "29513 Traning Loss: tensor(0.8487)\n",
      "29514 Traning Loss: tensor(0.8487)\n",
      "29515 Traning Loss: tensor(0.8487)\n",
      "29516 Traning Loss: tensor(0.8487)\n",
      "29517 Traning Loss: tensor(0.8487)\n",
      "29518 Traning Loss: tensor(0.8487)\n",
      "29519 Traning Loss: tensor(0.8487)\n",
      "29520 Traning Loss: tensor(0.8487)\n",
      "29521 Traning Loss: tensor(0.8487)\n",
      "29522 Traning Loss: tensor(0.8487)\n",
      "29523 Traning Loss: tensor(0.8487)\n",
      "29524 Traning Loss: tensor(0.8487)\n",
      "29525 Traning Loss: tensor(0.8487)\n",
      "29526 Traning Loss: tensor(0.8487)\n",
      "29527 Traning Loss: tensor(0.8487)\n",
      "29528 Traning Loss: tensor(0.8487)\n",
      "29529 Traning Loss: tensor(0.8487)\n",
      "29530 Traning Loss: tensor(0.8487)\n",
      "29531 Traning Loss: tensor(0.8487)\n",
      "29532 Traning Loss: tensor(0.8487)\n",
      "29533 Traning Loss: tensor(0.8487)\n",
      "29534 Traning Loss: tensor(0.8487)\n",
      "29535 Traning Loss: tensor(0.8487)\n",
      "29536 Traning Loss: tensor(0.8487)\n",
      "29537 Traning Loss: tensor(0.8487)\n",
      "29538 Traning Loss: tensor(0.8487)\n",
      "29539 Traning Loss: tensor(0.8487)\n",
      "29540 Traning Loss: tensor(0.8487)\n",
      "29541 Traning Loss: tensor(0.8487)\n",
      "29542 Traning Loss: tensor(0.8487)\n",
      "29543 Traning Loss: tensor(0.8487)\n",
      "29544 Traning Loss: tensor(0.8487)\n",
      "29545 Traning Loss: tensor(0.8487)\n",
      "29546 Traning Loss: tensor(0.8487)\n",
      "29547 Traning Loss: tensor(0.8487)\n",
      "29548 Traning Loss: tensor(0.8487)\n",
      "29549 Traning Loss: tensor(0.8487)\n",
      "29550 Traning Loss: tensor(0.8487)\n",
      "29551 Traning Loss: tensor(0.8487)\n",
      "29552 Traning Loss: tensor(0.8487)\n",
      "29553 Traning Loss: tensor(0.8487)\n",
      "29554 Traning Loss: tensor(0.8487)\n",
      "29555 Traning Loss: tensor(0.8487)\n",
      "29556 Traning Loss: tensor(0.8487)\n",
      "29557 Traning Loss: tensor(0.8487)\n",
      "29558 Traning Loss: tensor(0.8487)\n",
      "29559 Traning Loss: tensor(0.8487)\n",
      "29560 Traning Loss: tensor(0.8487)\n",
      "29561 Traning Loss: tensor(0.8487)\n",
      "29562 Traning Loss: tensor(0.8487)\n",
      "29563 Traning Loss: tensor(0.8487)\n",
      "29564 Traning Loss: tensor(0.8487)\n",
      "29565 Traning Loss: tensor(0.8487)\n",
      "29566 Traning Loss: tensor(0.8487)\n",
      "29567 Traning Loss: tensor(0.8487)\n",
      "29568 Traning Loss: tensor(0.8487)\n",
      "29569 Traning Loss: tensor(0.8487)\n",
      "29570 Traning Loss: tensor(0.8487)\n",
      "29571 Traning Loss: tensor(0.8487)\n",
      "29572 Traning Loss: tensor(0.8487)\n",
      "29573 Traning Loss: tensor(0.8487)\n",
      "29574 Traning Loss: tensor(0.8487)\n",
      "29575 Traning Loss: tensor(0.8487)\n",
      "29576 Traning Loss: tensor(0.8487)\n",
      "29577 Traning Loss: tensor(0.8487)\n",
      "29578 Traning Loss: tensor(0.8487)\n",
      "29579 Traning Loss: tensor(0.8487)\n",
      "29580 Traning Loss: tensor(0.8487)\n",
      "29581 Traning Loss: tensor(0.8487)\n",
      "29582 Traning Loss: tensor(0.8487)\n",
      "29583 Traning Loss: tensor(0.8487)\n",
      "29584 Traning Loss: tensor(0.8487)\n",
      "29585 Traning Loss: tensor(0.8487)\n",
      "29586 Traning Loss: tensor(0.8487)\n",
      "29587 Traning Loss: tensor(0.8487)\n",
      "29588 Traning Loss: tensor(0.8487)\n",
      "29589 Traning Loss: tensor(0.8487)\n",
      "29590 Traning Loss: tensor(0.8487)\n",
      "29591 Traning Loss: tensor(0.8487)\n",
      "29592 Traning Loss: tensor(0.8487)\n",
      "29593 Traning Loss: tensor(0.8487)\n",
      "29594 Traning Loss: tensor(0.8487)\n",
      "29595 Traning Loss: tensor(0.8487)\n",
      "29596 Traning Loss: tensor(0.8487)\n",
      "29597 Traning Loss: tensor(0.8487)\n",
      "29598 Traning Loss: tensor(0.8487)\n",
      "29599 Traning Loss: tensor(0.8487)\n",
      "29600 Traning Loss: tensor(0.8487)\n",
      "29601 Traning Loss: tensor(0.8487)\n",
      "29602 Traning Loss: tensor(0.8487)\n",
      "29603 Traning Loss: tensor(0.8487)\n",
      "29604 Traning Loss: tensor(0.8487)\n",
      "29605 Traning Loss: tensor(0.8487)\n",
      "29606 Traning Loss: tensor(0.8487)\n",
      "29607 Traning Loss: tensor(0.8487)\n",
      "29608 Traning Loss: tensor(0.8487)\n",
      "29609 Traning Loss: tensor(0.8487)\n",
      "29610 Traning Loss: tensor(0.8487)\n",
      "29611 Traning Loss: tensor(0.8487)\n",
      "29612 Traning Loss: tensor(0.8487)\n",
      "29613 Traning Loss: tensor(0.8487)\n",
      "29614 Traning Loss: tensor(0.8487)\n",
      "29615 Traning Loss: tensor(0.8487)\n",
      "29616 Traning Loss: tensor(0.8487)\n",
      "29617 Traning Loss: tensor(0.8487)\n",
      "29618 Traning Loss: tensor(0.8487)\n",
      "29619 Traning Loss: tensor(0.8487)\n",
      "29620 Traning Loss: tensor(0.8487)\n",
      "29621 Traning Loss: tensor(0.8487)\n",
      "29622 Traning Loss: tensor(0.8487)\n",
      "29623 Traning Loss: tensor(0.8487)\n",
      "29624 Traning Loss: tensor(0.8487)\n",
      "29625 Traning Loss: tensor(0.8487)\n",
      "29626 Traning Loss: tensor(0.8487)\n",
      "29627 Traning Loss: tensor(0.8487)\n",
      "29628 Traning Loss: tensor(0.8487)\n",
      "29629 Traning Loss: tensor(0.8487)\n",
      "29630 Traning Loss: tensor(0.8487)\n",
      "29631 Traning Loss: tensor(0.8487)\n",
      "29632 Traning Loss: tensor(0.8487)\n",
      "29633 Traning Loss: tensor(0.8487)\n",
      "29634 Traning Loss: tensor(0.8487)\n",
      "29635 Traning Loss: tensor(0.8487)\n",
      "29636 Traning Loss: tensor(0.8487)\n",
      "29637 Traning Loss: tensor(0.8487)\n",
      "29638 Traning Loss: tensor(0.8487)\n",
      "29639 Traning Loss: tensor(0.8487)\n",
      "29640 Traning Loss: tensor(0.8487)\n",
      "29641 Traning Loss: tensor(0.8487)\n",
      "29642 Traning Loss: tensor(0.8487)\n",
      "29643 Traning Loss: tensor(0.8487)\n",
      "29644 Traning Loss: tensor(0.8487)\n",
      "29645 Traning Loss: tensor(0.8487)\n",
      "29646 Traning Loss: tensor(0.8487)\n",
      "29647 Traning Loss: tensor(0.8487)\n",
      "29648 Traning Loss: tensor(0.8487)\n",
      "29649 Traning Loss: tensor(0.8487)\n",
      "29650 Traning Loss: tensor(0.8487)\n",
      "29651 Traning Loss: tensor(0.8487)\n",
      "29652 Traning Loss: tensor(0.8487)\n",
      "29653 Traning Loss: tensor(0.8487)\n",
      "29654 Traning Loss: tensor(0.8487)\n",
      "29655 Traning Loss: tensor(0.8487)\n",
      "29656 Traning Loss: tensor(0.8487)\n",
      "29657 Traning Loss: tensor(0.8487)\n",
      "29658 Traning Loss: tensor(0.8487)\n",
      "29659 Traning Loss: tensor(0.8487)\n",
      "29660 Traning Loss: tensor(0.8487)\n",
      "29661 Traning Loss: tensor(0.8487)\n",
      "29662 Traning Loss: tensor(0.8487)\n",
      "29663 Traning Loss: tensor(0.8487)\n",
      "29664 Traning Loss: tensor(0.8487)\n",
      "29665 Traning Loss: tensor(0.8487)\n",
      "29666 Traning Loss: tensor(0.8487)\n",
      "29667 Traning Loss: tensor(0.8487)\n",
      "29668 Traning Loss: tensor(0.8487)\n",
      "29669 Traning Loss: tensor(0.8487)\n",
      "29670 Traning Loss: tensor(0.8487)\n",
      "29671 Traning Loss: tensor(0.8487)\n",
      "29672 Traning Loss: tensor(0.8487)\n",
      "29673 Traning Loss: tensor(0.8487)\n",
      "29674 Traning Loss: tensor(0.8487)\n",
      "29675 Traning Loss: tensor(0.8488)\n",
      "29676 Traning Loss: tensor(0.8488)\n",
      "29677 Traning Loss: tensor(0.8488)\n",
      "29678 Traning Loss: tensor(0.8488)\n",
      "29679 Traning Loss: tensor(0.8488)\n",
      "29680 Traning Loss: tensor(0.8487)\n",
      "29681 Traning Loss: tensor(0.8487)\n",
      "29682 Traning Loss: tensor(0.8487)\n",
      "29683 Traning Loss: tensor(0.8487)\n",
      "29684 Traning Loss: tensor(0.8487)\n",
      "29685 Traning Loss: tensor(0.8487)\n",
      "29686 Traning Loss: tensor(0.8487)\n",
      "29687 Traning Loss: tensor(0.8487)\n",
      "29688 Traning Loss: tensor(0.8487)\n",
      "29689 Traning Loss: tensor(0.8487)\n",
      "29690 Traning Loss: tensor(0.8487)\n",
      "29691 Traning Loss: tensor(0.8487)\n",
      "29692 Traning Loss: tensor(0.8487)\n",
      "29693 Traning Loss: tensor(0.8487)\n",
      "29694 Traning Loss: tensor(0.8487)\n",
      "29695 Traning Loss: tensor(0.8487)\n",
      "29696 Traning Loss: tensor(0.8487)\n",
      "29697 Traning Loss: tensor(0.8487)\n",
      "29698 Traning Loss: tensor(0.8487)\n",
      "29699 Traning Loss: tensor(0.8487)\n",
      "29700 Traning Loss: tensor(0.8487)\n",
      "29701 Traning Loss: tensor(0.8487)\n",
      "29702 Traning Loss: tensor(0.8487)\n",
      "29703 Traning Loss: tensor(0.8487)\n",
      "29704 Traning Loss: tensor(0.8487)\n",
      "29705 Traning Loss: tensor(0.8487)\n",
      "29706 Traning Loss: tensor(0.8487)\n",
      "29707 Traning Loss: tensor(0.8487)\n",
      "29708 Traning Loss: tensor(0.8487)\n",
      "29709 Traning Loss: tensor(0.8487)\n",
      "29710 Traning Loss: tensor(0.8487)\n",
      "29711 Traning Loss: tensor(0.8487)\n",
      "29712 Traning Loss: tensor(0.8487)\n",
      "29713 Traning Loss: tensor(0.8487)\n",
      "29714 Traning Loss: tensor(0.8487)\n",
      "29715 Traning Loss: tensor(0.8487)\n",
      "29716 Traning Loss: tensor(0.8487)\n",
      "29717 Traning Loss: tensor(0.8487)\n",
      "29718 Traning Loss: tensor(0.8487)\n",
      "29719 Traning Loss: tensor(0.8487)\n",
      "29720 Traning Loss: tensor(0.8487)\n",
      "29721 Traning Loss: tensor(0.8487)\n",
      "29722 Traning Loss: tensor(0.8487)\n",
      "29723 Traning Loss: tensor(0.8487)\n",
      "29724 Traning Loss: tensor(0.8487)\n",
      "29725 Traning Loss: tensor(0.8487)\n",
      "29726 Traning Loss: tensor(0.8487)\n",
      "29727 Traning Loss: tensor(0.8487)\n",
      "29728 Traning Loss: tensor(0.8487)\n",
      "29729 Traning Loss: tensor(0.8487)\n",
      "29730 Traning Loss: tensor(0.8487)\n",
      "29731 Traning Loss: tensor(0.8487)\n",
      "29732 Traning Loss: tensor(0.8487)\n",
      "29733 Traning Loss: tensor(0.8487)\n",
      "29734 Traning Loss: tensor(0.8487)\n",
      "29735 Traning Loss: tensor(0.8487)\n",
      "29736 Traning Loss: tensor(0.8487)\n",
      "29737 Traning Loss: tensor(0.8487)\n",
      "29738 Traning Loss: tensor(0.8487)\n",
      "29739 Traning Loss: tensor(0.8487)\n",
      "29740 Traning Loss: tensor(0.8487)\n",
      "29741 Traning Loss: tensor(0.8487)\n",
      "29742 Traning Loss: tensor(0.8487)\n",
      "29743 Traning Loss: tensor(0.8487)\n",
      "29744 Traning Loss: tensor(0.8487)\n",
      "29745 Traning Loss: tensor(0.8487)\n",
      "29746 Traning Loss: tensor(0.8487)\n",
      "29747 Traning Loss: tensor(0.8487)\n",
      "29748 Traning Loss: tensor(0.8487)\n",
      "29749 Traning Loss: tensor(0.8487)\n",
      "29750 Traning Loss: tensor(0.8487)\n",
      "29751 Traning Loss: tensor(0.8487)\n",
      "29752 Traning Loss: tensor(0.8487)\n",
      "29753 Traning Loss: tensor(0.8487)\n",
      "29754 Traning Loss: tensor(0.8487)\n",
      "29755 Traning Loss: tensor(0.8487)\n",
      "29756 Traning Loss: tensor(0.8487)\n",
      "29757 Traning Loss: tensor(0.8487)\n",
      "29758 Traning Loss: tensor(0.8487)\n",
      "29759 Traning Loss: tensor(0.8487)\n",
      "29760 Traning Loss: tensor(0.8487)\n",
      "29761 Traning Loss: tensor(0.8487)\n",
      "29762 Traning Loss: tensor(0.8487)\n",
      "29763 Traning Loss: tensor(0.8487)\n",
      "29764 Traning Loss: tensor(0.8487)\n",
      "29765 Traning Loss: tensor(0.8487)\n",
      "29766 Traning Loss: tensor(0.8487)\n",
      "29767 Traning Loss: tensor(0.8487)\n",
      "29768 Traning Loss: tensor(0.8487)\n",
      "29769 Traning Loss: tensor(0.8487)\n",
      "29770 Traning Loss: tensor(0.8487)\n",
      "29771 Traning Loss: tensor(0.8487)\n",
      "29772 Traning Loss: tensor(0.8487)\n",
      "29773 Traning Loss: tensor(0.8487)\n",
      "29774 Traning Loss: tensor(0.8487)\n",
      "29775 Traning Loss: tensor(0.8487)\n",
      "29776 Traning Loss: tensor(0.8487)\n",
      "29777 Traning Loss: tensor(0.8487)\n",
      "29778 Traning Loss: tensor(0.8487)\n",
      "29779 Traning Loss: tensor(0.8487)\n",
      "29780 Traning Loss: tensor(0.8487)\n",
      "29781 Traning Loss: tensor(0.8487)\n",
      "29782 Traning Loss: tensor(0.8487)\n",
      "29783 Traning Loss: tensor(0.8487)\n",
      "29784 Traning Loss: tensor(0.8487)\n",
      "29785 Traning Loss: tensor(0.8487)\n",
      "29786 Traning Loss: tensor(0.8487)\n",
      "29787 Traning Loss: tensor(0.8487)\n",
      "29788 Traning Loss: tensor(0.8487)\n",
      "29789 Traning Loss: tensor(0.8487)\n",
      "29790 Traning Loss: tensor(0.8487)\n",
      "29791 Traning Loss: tensor(0.8487)\n",
      "29792 Traning Loss: tensor(0.8487)\n",
      "29793 Traning Loss: tensor(0.8487)\n",
      "29794 Traning Loss: tensor(0.8487)\n",
      "29795 Traning Loss: tensor(0.8487)\n",
      "29796 Traning Loss: tensor(0.8487)\n",
      "29797 Traning Loss: tensor(0.8487)\n",
      "29798 Traning Loss: tensor(0.8487)\n",
      "29799 Traning Loss: tensor(0.8487)\n",
      "29800 Traning Loss: tensor(0.8487)\n",
      "29801 Traning Loss: tensor(0.8487)\n",
      "29802 Traning Loss: tensor(0.8487)\n",
      "29803 Traning Loss: tensor(0.8487)\n",
      "29804 Traning Loss: tensor(0.8487)\n",
      "29805 Traning Loss: tensor(0.8487)\n",
      "29806 Traning Loss: tensor(0.8487)\n",
      "29807 Traning Loss: tensor(0.8487)\n",
      "29808 Traning Loss: tensor(0.8487)\n",
      "29809 Traning Loss: tensor(0.8487)\n",
      "29810 Traning Loss: tensor(0.8487)\n",
      "29811 Traning Loss: tensor(0.8487)\n",
      "29812 Traning Loss: tensor(0.8487)\n",
      "29813 Traning Loss: tensor(0.8487)\n",
      "29814 Traning Loss: tensor(0.8487)\n",
      "29815 Traning Loss: tensor(0.8487)\n",
      "29816 Traning Loss: tensor(0.8487)\n",
      "29817 Traning Loss: tensor(0.8487)\n",
      "29818 Traning Loss: tensor(0.8487)\n",
      "29819 Traning Loss: tensor(0.8487)\n",
      "29820 Traning Loss: tensor(0.8487)\n",
      "29821 Traning Loss: tensor(0.8487)\n",
      "29822 Traning Loss: tensor(0.8487)\n",
      "29823 Traning Loss: tensor(0.8487)\n",
      "29824 Traning Loss: tensor(0.8487)\n",
      "29825 Traning Loss: tensor(0.8487)\n",
      "29826 Traning Loss: tensor(0.8487)\n",
      "29827 Traning Loss: tensor(0.8487)\n",
      "29828 Traning Loss: tensor(0.8487)\n",
      "29829 Traning Loss: tensor(0.8487)\n",
      "29830 Traning Loss: tensor(0.8487)\n",
      "29831 Traning Loss: tensor(0.8487)\n",
      "29832 Traning Loss: tensor(0.8487)\n",
      "29833 Traning Loss: tensor(0.8487)\n",
      "29834 Traning Loss: tensor(0.8487)\n",
      "29835 Traning Loss: tensor(0.8487)\n",
      "29836 Traning Loss: tensor(0.8487)\n",
      "29837 Traning Loss: tensor(0.8487)\n",
      "29838 Traning Loss: tensor(0.8487)\n",
      "29839 Traning Loss: tensor(0.8487)\n",
      "29840 Traning Loss: tensor(0.8487)\n",
      "29841 Traning Loss: tensor(0.8487)\n",
      "29842 Traning Loss: tensor(0.8487)\n",
      "29843 Traning Loss: tensor(0.8487)\n",
      "29844 Traning Loss: tensor(0.8487)\n",
      "29845 Traning Loss: tensor(0.8487)\n",
      "29846 Traning Loss: tensor(0.8487)\n",
      "29847 Traning Loss: tensor(0.8487)\n",
      "29848 Traning Loss: tensor(0.8487)\n",
      "29849 Traning Loss: tensor(0.8487)\n",
      "29850 Traning Loss: tensor(0.8487)\n",
      "29851 Traning Loss: tensor(0.8487)\n",
      "29852 Traning Loss: tensor(0.8487)\n",
      "29853 Traning Loss: tensor(0.8487)\n",
      "29854 Traning Loss: tensor(0.8487)\n",
      "29855 Traning Loss: tensor(0.8487)\n",
      "29856 Traning Loss: tensor(0.8487)\n",
      "29857 Traning Loss: tensor(0.8487)\n",
      "29858 Traning Loss: tensor(0.8487)\n",
      "29859 Traning Loss: tensor(0.8487)\n",
      "29860 Traning Loss: tensor(0.8487)\n",
      "29861 Traning Loss: tensor(0.8487)\n",
      "29862 Traning Loss: tensor(0.8487)\n",
      "29863 Traning Loss: tensor(0.8487)\n",
      "29864 Traning Loss: tensor(0.8487)\n",
      "29865 Traning Loss: tensor(0.8487)\n",
      "29866 Traning Loss: tensor(0.8487)\n",
      "29867 Traning Loss: tensor(0.8487)\n",
      "29868 Traning Loss: tensor(0.8487)\n",
      "29869 Traning Loss: tensor(0.8487)\n",
      "29870 Traning Loss: tensor(0.8487)\n",
      "29871 Traning Loss: tensor(0.8487)\n",
      "29872 Traning Loss: tensor(0.8487)\n",
      "29873 Traning Loss: tensor(0.8487)\n",
      "29874 Traning Loss: tensor(0.8487)\n",
      "29875 Traning Loss: tensor(0.8487)\n",
      "29876 Traning Loss: tensor(0.8487)\n",
      "29877 Traning Loss: tensor(0.8487)\n",
      "29878 Traning Loss: tensor(0.8487)\n",
      "29879 Traning Loss: tensor(0.8487)\n",
      "29880 Traning Loss: tensor(0.8487)\n",
      "29881 Traning Loss: tensor(0.8487)\n",
      "29882 Traning Loss: tensor(0.8487)\n",
      "29883 Traning Loss: tensor(0.8487)\n",
      "29884 Traning Loss: tensor(0.8487)\n",
      "29885 Traning Loss: tensor(0.8487)\n",
      "29886 Traning Loss: tensor(0.8487)\n",
      "29887 Traning Loss: tensor(0.8487)\n",
      "29888 Traning Loss: tensor(0.8487)\n",
      "29889 Traning Loss: tensor(0.8487)\n",
      "29890 Traning Loss: tensor(0.8487)\n",
      "29891 Traning Loss: tensor(0.8487)\n",
      "29892 Traning Loss: tensor(0.8487)\n",
      "29893 Traning Loss: tensor(0.8487)\n",
      "29894 Traning Loss: tensor(0.8487)\n",
      "29895 Traning Loss: tensor(0.8487)\n",
      "29896 Traning Loss: tensor(0.8487)\n",
      "29897 Traning Loss: tensor(0.8487)\n",
      "29898 Traning Loss: tensor(0.8487)\n",
      "29899 Traning Loss: tensor(0.8487)\n",
      "29900 Traning Loss: tensor(0.8487)\n",
      "29901 Traning Loss: tensor(0.8487)\n",
      "29902 Traning Loss: tensor(0.8487)\n",
      "29903 Traning Loss: tensor(0.8487)\n",
      "29904 Traning Loss: tensor(0.8487)\n",
      "29905 Traning Loss: tensor(0.8487)\n",
      "29906 Traning Loss: tensor(0.8487)\n",
      "29907 Traning Loss: tensor(0.8487)\n",
      "29908 Traning Loss: tensor(0.8487)\n",
      "29909 Traning Loss: tensor(0.8487)\n",
      "29910 Traning Loss: tensor(0.8487)\n",
      "29911 Traning Loss: tensor(0.8487)\n",
      "29912 Traning Loss: tensor(0.8487)\n",
      "29913 Traning Loss: tensor(0.8487)\n",
      "29914 Traning Loss: tensor(0.8487)\n",
      "29915 Traning Loss: tensor(0.8487)\n",
      "29916 Traning Loss: tensor(0.8487)\n",
      "29917 Traning Loss: tensor(0.8487)\n",
      "29918 Traning Loss: tensor(0.8487)\n",
      "29919 Traning Loss: tensor(0.8487)\n",
      "29920 Traning Loss: tensor(0.8487)\n",
      "29921 Traning Loss: tensor(0.8487)\n",
      "29922 Traning Loss: tensor(0.8487)\n",
      "29923 Traning Loss: tensor(0.8487)\n",
      "29924 Traning Loss: tensor(0.8487)\n",
      "29925 Traning Loss: tensor(0.8487)\n",
      "29926 Traning Loss: tensor(0.8487)\n",
      "29927 Traning Loss: tensor(0.8487)\n",
      "29928 Traning Loss: tensor(0.8487)\n",
      "29929 Traning Loss: tensor(0.8487)\n",
      "29930 Traning Loss: tensor(0.8487)\n",
      "29931 Traning Loss: tensor(0.8487)\n",
      "29932 Traning Loss: tensor(0.8487)\n",
      "29933 Traning Loss: tensor(0.8487)\n",
      "29934 Traning Loss: tensor(0.8487)\n",
      "29935 Traning Loss: tensor(0.8487)\n",
      "29936 Traning Loss: tensor(0.8487)\n",
      "29937 Traning Loss: tensor(0.8487)\n",
      "29938 Traning Loss: tensor(0.8487)\n",
      "29939 Traning Loss: tensor(0.8487)\n",
      "29940 Traning Loss: tensor(0.8487)\n",
      "29941 Traning Loss: tensor(0.8487)\n",
      "29942 Traning Loss: tensor(0.8487)\n",
      "29943 Traning Loss: tensor(0.8487)\n",
      "29944 Traning Loss: tensor(0.8487)\n",
      "29945 Traning Loss: tensor(0.8487)\n",
      "29946 Traning Loss: tensor(0.8487)\n",
      "29947 Traning Loss: tensor(0.8487)\n",
      "29948 Traning Loss: tensor(0.8487)\n",
      "29949 Traning Loss: tensor(0.8487)\n",
      "29950 Traning Loss: tensor(0.8487)\n",
      "29951 Traning Loss: tensor(0.8487)\n",
      "29952 Traning Loss: tensor(0.8487)\n",
      "29953 Traning Loss: tensor(0.8487)\n",
      "29954 Traning Loss: tensor(0.8487)\n",
      "29955 Traning Loss: tensor(0.8487)\n",
      "29956 Traning Loss: tensor(0.8487)\n",
      "29957 Traning Loss: tensor(0.8487)\n",
      "29958 Traning Loss: tensor(0.8487)\n",
      "29959 Traning Loss: tensor(0.8487)\n",
      "29960 Traning Loss: tensor(0.8487)\n",
      "29961 Traning Loss: tensor(0.8488)\n",
      "29962 Traning Loss: tensor(0.8488)\n",
      "29963 Traning Loss: tensor(0.8488)\n",
      "29964 Traning Loss: tensor(0.8488)\n",
      "29965 Traning Loss: tensor(0.8488)\n",
      "29966 Traning Loss: tensor(0.8488)\n",
      "29967 Traning Loss: tensor(0.8487)\n",
      "29968 Traning Loss: tensor(0.8487)\n",
      "29969 Traning Loss: tensor(0.8487)\n",
      "29970 Traning Loss: tensor(0.8488)\n",
      "29971 Traning Loss: tensor(0.8487)\n",
      "29972 Traning Loss: tensor(0.8487)\n",
      "29973 Traning Loss: tensor(0.8487)\n",
      "29974 Traning Loss: tensor(0.8487)\n",
      "29975 Traning Loss: tensor(0.8487)\n",
      "29976 Traning Loss: tensor(0.8487)\n",
      "29977 Traning Loss: tensor(0.8487)\n",
      "29978 Traning Loss: tensor(0.8487)\n",
      "29979 Traning Loss: tensor(0.8487)\n",
      "29980 Traning Loss: tensor(0.8487)\n",
      "29981 Traning Loss: tensor(0.8487)\n",
      "29982 Traning Loss: tensor(0.8487)\n",
      "29983 Traning Loss: tensor(0.8487)\n",
      "29984 Traning Loss: tensor(0.8487)\n",
      "29985 Traning Loss: tensor(0.8487)\n",
      "29986 Traning Loss: tensor(0.8487)\n",
      "29987 Traning Loss: tensor(0.8487)\n",
      "29988 Traning Loss: tensor(0.8487)\n",
      "29989 Traning Loss: tensor(0.8487)\n",
      "29990 Traning Loss: tensor(0.8487)\n",
      "29991 Traning Loss: tensor(0.8487)\n",
      "29992 Traning Loss: tensor(0.8487)\n",
      "29993 Traning Loss: tensor(0.8487)\n",
      "29994 Traning Loss: tensor(0.8487)\n",
      "29995 Traning Loss: tensor(0.8487)\n",
      "29996 Traning Loss: tensor(0.8487)\n",
      "29997 Traning Loss: tensor(0.8487)\n",
      "29998 Traning Loss: tensor(0.8487)\n",
      "29999 Traning Loss: tensor(0.8487)\n",
      "30000 Traning Loss: tensor(0.8487)\n",
      "30001 Traning Loss: tensor(0.8487)\n",
      "30002 Traning Loss: tensor(0.8487)\n",
      "30003 Traning Loss: tensor(0.8487)\n",
      "30004 Traning Loss: tensor(0.8487)\n",
      "30005 Traning Loss: tensor(0.8487)\n",
      "30006 Traning Loss: tensor(0.8487)\n",
      "30007 Traning Loss: tensor(0.8487)\n",
      "30008 Traning Loss: tensor(0.8487)\n",
      "30009 Traning Loss: tensor(0.8487)\n",
      "30010 Traning Loss: tensor(0.8487)\n",
      "30011 Traning Loss: tensor(0.8487)\n",
      "30012 Traning Loss: tensor(0.8487)\n",
      "30013 Traning Loss: tensor(0.8487)\n",
      "30014 Traning Loss: tensor(0.8487)\n",
      "30015 Traning Loss: tensor(0.8487)\n",
      "30016 Traning Loss: tensor(0.8487)\n",
      "30017 Traning Loss: tensor(0.8487)\n",
      "30018 Traning Loss: tensor(0.8487)\n",
      "30019 Traning Loss: tensor(0.8487)\n",
      "30020 Traning Loss: tensor(0.8487)\n",
      "30021 Traning Loss: tensor(0.8487)\n",
      "30022 Traning Loss: tensor(0.8487)\n",
      "30023 Traning Loss: tensor(0.8487)\n",
      "30024 Traning Loss: tensor(0.8487)\n",
      "30025 Traning Loss: tensor(0.8487)\n",
      "30026 Traning Loss: tensor(0.8487)\n",
      "30027 Traning Loss: tensor(0.8487)\n",
      "30028 Traning Loss: tensor(0.8487)\n",
      "30029 Traning Loss: tensor(0.8487)\n",
      "30030 Traning Loss: tensor(0.8487)\n",
      "30031 Traning Loss: tensor(0.8487)\n",
      "30032 Traning Loss: tensor(0.8487)\n",
      "30033 Traning Loss: tensor(0.8487)\n",
      "30034 Traning Loss: tensor(0.8487)\n",
      "30035 Traning Loss: tensor(0.8487)\n",
      "30036 Traning Loss: tensor(0.8487)\n",
      "30037 Traning Loss: tensor(0.8487)\n",
      "30038 Traning Loss: tensor(0.8487)\n",
      "30039 Traning Loss: tensor(0.8487)\n",
      "30040 Traning Loss: tensor(0.8487)\n",
      "30041 Traning Loss: tensor(0.8487)\n",
      "30042 Traning Loss: tensor(0.8487)\n",
      "30043 Traning Loss: tensor(0.8487)\n",
      "30044 Traning Loss: tensor(0.8487)\n",
      "30045 Traning Loss: tensor(0.8487)\n",
      "30046 Traning Loss: tensor(0.8487)\n",
      "30047 Traning Loss: tensor(0.8487)\n",
      "30048 Traning Loss: tensor(0.8487)\n",
      "30049 Traning Loss: tensor(0.8487)\n",
      "30050 Traning Loss: tensor(0.8487)\n",
      "30051 Traning Loss: tensor(0.8487)\n",
      "30052 Traning Loss: tensor(0.8487)\n",
      "30053 Traning Loss: tensor(0.8487)\n",
      "30054 Traning Loss: tensor(0.8487)\n",
      "30055 Traning Loss: tensor(0.8487)\n",
      "30056 Traning Loss: tensor(0.8487)\n",
      "30057 Traning Loss: tensor(0.8487)\n",
      "30058 Traning Loss: tensor(0.8487)\n",
      "30059 Traning Loss: tensor(0.8487)\n",
      "30060 Traning Loss: tensor(0.8487)\n",
      "30061 Traning Loss: tensor(0.8487)\n",
      "30062 Traning Loss: tensor(0.8487)\n",
      "30063 Traning Loss: tensor(0.8487)\n",
      "30064 Traning Loss: tensor(0.8487)\n",
      "30065 Traning Loss: tensor(0.8487)\n",
      "30066 Traning Loss: tensor(0.8487)\n",
      "30067 Traning Loss: tensor(0.8487)\n",
      "30068 Traning Loss: tensor(0.8487)\n",
      "30069 Traning Loss: tensor(0.8487)\n",
      "30070 Traning Loss: tensor(0.8487)\n",
      "30071 Traning Loss: tensor(0.8487)\n",
      "30072 Traning Loss: tensor(0.8487)\n",
      "30073 Traning Loss: tensor(0.8487)\n",
      "30074 Traning Loss: tensor(0.8487)\n",
      "30075 Traning Loss: tensor(0.8487)\n",
      "30076 Traning Loss: tensor(0.8487)\n",
      "30077 Traning Loss: tensor(0.8487)\n",
      "30078 Traning Loss: tensor(0.8487)\n",
      "30079 Traning Loss: tensor(0.8487)\n",
      "30080 Traning Loss: tensor(0.8487)\n",
      "30081 Traning Loss: tensor(0.8487)\n",
      "30082 Traning Loss: tensor(0.8487)\n",
      "30083 Traning Loss: tensor(0.8487)\n",
      "30084 Traning Loss: tensor(0.8487)\n",
      "30085 Traning Loss: tensor(0.8487)\n",
      "30086 Traning Loss: tensor(0.8487)\n",
      "30087 Traning Loss: tensor(0.8487)\n",
      "30088 Traning Loss: tensor(0.8487)\n",
      "30089 Traning Loss: tensor(0.8487)\n",
      "30090 Traning Loss: tensor(0.8487)\n",
      "30091 Traning Loss: tensor(0.8487)\n",
      "30092 Traning Loss: tensor(0.8487)\n",
      "30093 Traning Loss: tensor(0.8487)\n",
      "30094 Traning Loss: tensor(0.8487)\n",
      "30095 Traning Loss: tensor(0.8487)\n",
      "30096 Traning Loss: tensor(0.8487)\n",
      "30097 Traning Loss: tensor(0.8487)\n",
      "30098 Traning Loss: tensor(0.8487)\n",
      "30099 Traning Loss: tensor(0.8487)\n",
      "30100 Traning Loss: tensor(0.8487)\n",
      "30101 Traning Loss: tensor(0.8487)\n",
      "30102 Traning Loss: tensor(0.8487)\n",
      "30103 Traning Loss: tensor(0.8487)\n",
      "30104 Traning Loss: tensor(0.8487)\n",
      "30105 Traning Loss: tensor(0.8487)\n",
      "30106 Traning Loss: tensor(0.8487)\n",
      "30107 Traning Loss: tensor(0.8487)\n",
      "30108 Traning Loss: tensor(0.8487)\n",
      "30109 Traning Loss: tensor(0.8487)\n",
      "30110 Traning Loss: tensor(0.8487)\n",
      "30111 Traning Loss: tensor(0.8487)\n",
      "30112 Traning Loss: tensor(0.8487)\n",
      "30113 Traning Loss: tensor(0.8487)\n",
      "30114 Traning Loss: tensor(0.8487)\n",
      "30115 Traning Loss: tensor(0.8487)\n",
      "30116 Traning Loss: tensor(0.8487)\n",
      "30117 Traning Loss: tensor(0.8487)\n",
      "30118 Traning Loss: tensor(0.8487)\n",
      "30119 Traning Loss: tensor(0.8487)\n",
      "30120 Traning Loss: tensor(0.8487)\n",
      "30121 Traning Loss: tensor(0.8487)\n",
      "30122 Traning Loss: tensor(0.8487)\n",
      "30123 Traning Loss: tensor(0.8487)\n",
      "30124 Traning Loss: tensor(0.8487)\n",
      "30125 Traning Loss: tensor(0.8487)\n",
      "30126 Traning Loss: tensor(0.8487)\n",
      "30127 Traning Loss: tensor(0.8487)\n",
      "30128 Traning Loss: tensor(0.8487)\n",
      "30129 Traning Loss: tensor(0.8487)\n",
      "30130 Traning Loss: tensor(0.8487)\n",
      "30131 Traning Loss: tensor(0.8487)\n",
      "30132 Traning Loss: tensor(0.8487)\n",
      "30133 Traning Loss: tensor(0.8487)\n",
      "30134 Traning Loss: tensor(0.8487)\n",
      "30135 Traning Loss: tensor(0.8487)\n",
      "30136 Traning Loss: tensor(0.8487)\n",
      "30137 Traning Loss: tensor(0.8487)\n",
      "30138 Traning Loss: tensor(0.8487)\n",
      "30139 Traning Loss: tensor(0.8487)\n",
      "30140 Traning Loss: tensor(0.8487)\n",
      "30141 Traning Loss: tensor(0.8487)\n",
      "30142 Traning Loss: tensor(0.8487)\n",
      "30143 Traning Loss: tensor(0.8487)\n",
      "30144 Traning Loss: tensor(0.8487)\n",
      "30145 Traning Loss: tensor(0.8487)\n",
      "30146 Traning Loss: tensor(0.8487)\n",
      "30147 Traning Loss: tensor(0.8487)\n",
      "30148 Traning Loss: tensor(0.8487)\n",
      "30149 Traning Loss: tensor(0.8487)\n",
      "30150 Traning Loss: tensor(0.8487)\n",
      "30151 Traning Loss: tensor(0.8487)\n",
      "30152 Traning Loss: tensor(0.8487)\n",
      "30153 Traning Loss: tensor(0.8487)\n",
      "30154 Traning Loss: tensor(0.8487)\n",
      "30155 Traning Loss: tensor(0.8487)\n",
      "30156 Traning Loss: tensor(0.8487)\n",
      "30157 Traning Loss: tensor(0.8487)\n",
      "30158 Traning Loss: tensor(0.8487)\n",
      "30159 Traning Loss: tensor(0.8487)\n",
      "30160 Traning Loss: tensor(0.8487)\n",
      "30161 Traning Loss: tensor(0.8487)\n",
      "30162 Traning Loss: tensor(0.8487)\n",
      "30163 Traning Loss: tensor(0.8487)\n",
      "30164 Traning Loss: tensor(0.8487)\n",
      "30165 Traning Loss: tensor(0.8487)\n",
      "30166 Traning Loss: tensor(0.8487)\n",
      "30167 Traning Loss: tensor(0.8487)\n",
      "30168 Traning Loss: tensor(0.8487)\n",
      "30169 Traning Loss: tensor(0.8487)\n",
      "30170 Traning Loss: tensor(0.8487)\n",
      "30171 Traning Loss: tensor(0.8487)\n",
      "30172 Traning Loss: tensor(0.8487)\n",
      "30173 Traning Loss: tensor(0.8487)\n",
      "30174 Traning Loss: tensor(0.8487)\n",
      "30175 Traning Loss: tensor(0.8487)\n",
      "30176 Traning Loss: tensor(0.8487)\n",
      "30177 Traning Loss: tensor(0.8487)\n",
      "30178 Traning Loss: tensor(0.8487)\n",
      "30179 Traning Loss: tensor(0.8487)\n",
      "30180 Traning Loss: tensor(0.8487)\n",
      "30181 Traning Loss: tensor(0.8487)\n",
      "30182 Traning Loss: tensor(0.8487)\n",
      "30183 Traning Loss: tensor(0.8487)\n",
      "30184 Traning Loss: tensor(0.8487)\n",
      "30185 Traning Loss: tensor(0.8487)\n",
      "30186 Traning Loss: tensor(0.8487)\n",
      "30187 Traning Loss: tensor(0.8487)\n",
      "30188 Traning Loss: tensor(0.8487)\n",
      "30189 Traning Loss: tensor(0.8487)\n",
      "30190 Traning Loss: tensor(0.8487)\n",
      "30191 Traning Loss: tensor(0.8487)\n",
      "30192 Traning Loss: tensor(0.8487)\n",
      "30193 Traning Loss: tensor(0.8487)\n",
      "30194 Traning Loss: tensor(0.8487)\n",
      "30195 Traning Loss: tensor(0.8487)\n",
      "30196 Traning Loss: tensor(0.8487)\n",
      "30197 Traning Loss: tensor(0.8487)\n",
      "30198 Traning Loss: tensor(0.8487)\n",
      "30199 Traning Loss: tensor(0.8487)\n",
      "30200 Traning Loss: tensor(0.8487)\n",
      "30201 Traning Loss: tensor(0.8487)\n",
      "30202 Traning Loss: tensor(0.8487)\n",
      "30203 Traning Loss: tensor(0.8487)\n",
      "30204 Traning Loss: tensor(0.8487)\n",
      "30205 Traning Loss: tensor(0.8487)\n",
      "30206 Traning Loss: tensor(0.8487)\n",
      "30207 Traning Loss: tensor(0.8487)\n",
      "30208 Traning Loss: tensor(0.8487)\n",
      "30209 Traning Loss: tensor(0.8487)\n",
      "30210 Traning Loss: tensor(0.8487)\n",
      "30211 Traning Loss: tensor(0.8487)\n",
      "30212 Traning Loss: tensor(0.8487)\n",
      "30213 Traning Loss: tensor(0.8487)\n",
      "30214 Traning Loss: tensor(0.8487)\n",
      "30215 Traning Loss: tensor(0.8487)\n",
      "30216 Traning Loss: tensor(0.8487)\n",
      "30217 Traning Loss: tensor(0.8487)\n",
      "30218 Traning Loss: tensor(0.8487)\n",
      "30219 Traning Loss: tensor(0.8487)\n",
      "30220 Traning Loss: tensor(0.8487)\n",
      "30221 Traning Loss: tensor(0.8487)\n",
      "30222 Traning Loss: tensor(0.8487)\n",
      "30223 Traning Loss: tensor(0.8487)\n",
      "30224 Traning Loss: tensor(0.8487)\n",
      "30225 Traning Loss: tensor(0.8487)\n",
      "30226 Traning Loss: tensor(0.8487)\n",
      "30227 Traning Loss: tensor(0.8487)\n",
      "30228 Traning Loss: tensor(0.8487)\n",
      "30229 Traning Loss: tensor(0.8487)\n",
      "30230 Traning Loss: tensor(0.8487)\n",
      "30231 Traning Loss: tensor(0.8487)\n",
      "30232 Traning Loss: tensor(0.8487)\n",
      "30233 Traning Loss: tensor(0.8487)\n",
      "30234 Traning Loss: tensor(0.8487)\n",
      "30235 Traning Loss: tensor(0.8487)\n",
      "30236 Traning Loss: tensor(0.8487)\n",
      "30237 Traning Loss: tensor(0.8487)\n",
      "30238 Traning Loss: tensor(0.8487)\n",
      "30239 Traning Loss: tensor(0.8487)\n",
      "30240 Traning Loss: tensor(0.8487)\n",
      "30241 Traning Loss: tensor(0.8487)\n",
      "30242 Traning Loss: tensor(0.8487)\n",
      "30243 Traning Loss: tensor(0.8487)\n",
      "30244 Traning Loss: tensor(0.8487)\n",
      "30245 Traning Loss: tensor(0.8487)\n",
      "30246 Traning Loss: tensor(0.8487)\n",
      "30247 Traning Loss: tensor(0.8487)\n",
      "30248 Traning Loss: tensor(0.8487)\n",
      "30249 Traning Loss: tensor(0.8487)\n",
      "30250 Traning Loss: tensor(0.8487)\n",
      "30251 Traning Loss: tensor(0.8487)\n",
      "30252 Traning Loss: tensor(0.8487)\n",
      "30253 Traning Loss: tensor(0.8487)\n",
      "30254 Traning Loss: tensor(0.8487)\n",
      "30255 Traning Loss: tensor(0.8487)\n",
      "30256 Traning Loss: tensor(0.8487)\n",
      "30257 Traning Loss: tensor(0.8487)\n",
      "30258 Traning Loss: tensor(0.8487)\n",
      "30259 Traning Loss: tensor(0.8487)\n",
      "30260 Traning Loss: tensor(0.8487)\n",
      "30261 Traning Loss: tensor(0.8487)\n",
      "30262 Traning Loss: tensor(0.8488)\n",
      "30263 Traning Loss: tensor(0.8488)\n",
      "30264 Traning Loss: tensor(0.8488)\n",
      "30265 Traning Loss: tensor(0.8488)\n",
      "30266 Traning Loss: tensor(0.8488)\n",
      "30267 Traning Loss: tensor(0.8487)\n",
      "30268 Traning Loss: tensor(0.8487)\n",
      "30269 Traning Loss: tensor(0.8487)\n",
      "30270 Traning Loss: tensor(0.8487)\n",
      "30271 Traning Loss: tensor(0.8487)\n",
      "30272 Traning Loss: tensor(0.8487)\n",
      "30273 Traning Loss: tensor(0.8487)\n",
      "30274 Traning Loss: tensor(0.8487)\n",
      "30275 Traning Loss: tensor(0.8487)\n",
      "30276 Traning Loss: tensor(0.8487)\n",
      "30277 Traning Loss: tensor(0.8487)\n",
      "30278 Traning Loss: tensor(0.8487)\n",
      "30279 Traning Loss: tensor(0.8487)\n",
      "30280 Traning Loss: tensor(0.8487)\n",
      "30281 Traning Loss: tensor(0.8487)\n",
      "30282 Traning Loss: tensor(0.8487)\n",
      "30283 Traning Loss: tensor(0.8487)\n",
      "30284 Traning Loss: tensor(0.8487)\n",
      "30285 Traning Loss: tensor(0.8487)\n",
      "30286 Traning Loss: tensor(0.8487)\n",
      "30287 Traning Loss: tensor(0.8487)\n",
      "30288 Traning Loss: tensor(0.8487)\n",
      "30289 Traning Loss: tensor(0.8487)\n",
      "30290 Traning Loss: tensor(0.8487)\n",
      "30291 Traning Loss: tensor(0.8487)\n",
      "30292 Traning Loss: tensor(0.8487)\n",
      "30293 Traning Loss: tensor(0.8487)\n",
      "30294 Traning Loss: tensor(0.8487)\n",
      "30295 Traning Loss: tensor(0.8487)\n",
      "30296 Traning Loss: tensor(0.8487)\n",
      "30297 Traning Loss: tensor(0.8487)\n",
      "30298 Traning Loss: tensor(0.8487)\n",
      "30299 Traning Loss: tensor(0.8487)\n",
      "30300 Traning Loss: tensor(0.8487)\n",
      "30301 Traning Loss: tensor(0.8487)\n",
      "30302 Traning Loss: tensor(0.8487)\n",
      "30303 Traning Loss: tensor(0.8487)\n",
      "30304 Traning Loss: tensor(0.8487)\n",
      "30305 Traning Loss: tensor(0.8487)\n",
      "30306 Traning Loss: tensor(0.8487)\n",
      "30307 Traning Loss: tensor(0.8487)\n",
      "30308 Traning Loss: tensor(0.8487)\n",
      "30309 Traning Loss: tensor(0.8487)\n",
      "30310 Traning Loss: tensor(0.8487)\n",
      "30311 Traning Loss: tensor(0.8487)\n",
      "30312 Traning Loss: tensor(0.8487)\n",
      "30313 Traning Loss: tensor(0.8487)\n",
      "30314 Traning Loss: tensor(0.8487)\n",
      "30315 Traning Loss: tensor(0.8487)\n",
      "30316 Traning Loss: tensor(0.8487)\n",
      "30317 Traning Loss: tensor(0.8487)\n",
      "30318 Traning Loss: tensor(0.8487)\n",
      "30319 Traning Loss: tensor(0.8487)\n",
      "30320 Traning Loss: tensor(0.8487)\n",
      "30321 Traning Loss: tensor(0.8487)\n",
      "30322 Traning Loss: tensor(0.8487)\n",
      "30323 Traning Loss: tensor(0.8487)\n",
      "30324 Traning Loss: tensor(0.8487)\n",
      "30325 Traning Loss: tensor(0.8487)\n",
      "30326 Traning Loss: tensor(0.8487)\n",
      "30327 Traning Loss: tensor(0.8487)\n",
      "30328 Traning Loss: tensor(0.8487)\n",
      "30329 Traning Loss: tensor(0.8487)\n",
      "30330 Traning Loss: tensor(0.8487)\n",
      "30331 Traning Loss: tensor(0.8487)\n",
      "30332 Traning Loss: tensor(0.8487)\n",
      "30333 Traning Loss: tensor(0.8487)\n",
      "30334 Traning Loss: tensor(0.8487)\n",
      "30335 Traning Loss: tensor(0.8487)\n",
      "30336 Traning Loss: tensor(0.8487)\n",
      "30337 Traning Loss: tensor(0.8487)\n",
      "30338 Traning Loss: tensor(0.8487)\n",
      "30339 Traning Loss: tensor(0.8487)\n",
      "30340 Traning Loss: tensor(0.8487)\n",
      "30341 Traning Loss: tensor(0.8487)\n",
      "30342 Traning Loss: tensor(0.8487)\n",
      "30343 Traning Loss: tensor(0.8487)\n",
      "30344 Traning Loss: tensor(0.8487)\n",
      "30345 Traning Loss: tensor(0.8487)\n",
      "30346 Traning Loss: tensor(0.8487)\n",
      "30347 Traning Loss: tensor(0.8487)\n",
      "30348 Traning Loss: tensor(0.8487)\n",
      "30349 Traning Loss: tensor(0.8487)\n",
      "30350 Traning Loss: tensor(0.8487)\n",
      "30351 Traning Loss: tensor(0.8487)\n",
      "30352 Traning Loss: tensor(0.8487)\n",
      "30353 Traning Loss: tensor(0.8487)\n",
      "30354 Traning Loss: tensor(0.8487)\n",
      "30355 Traning Loss: tensor(0.8487)\n",
      "30356 Traning Loss: tensor(0.8487)\n",
      "30357 Traning Loss: tensor(0.8487)\n",
      "30358 Traning Loss: tensor(0.8487)\n",
      "30359 Traning Loss: tensor(0.8487)\n",
      "30360 Traning Loss: tensor(0.8487)\n",
      "30361 Traning Loss: tensor(0.8487)\n",
      "30362 Traning Loss: tensor(0.8487)\n",
      "30363 Traning Loss: tensor(0.8487)\n",
      "30364 Traning Loss: tensor(0.8487)\n",
      "30365 Traning Loss: tensor(0.8487)\n",
      "30366 Traning Loss: tensor(0.8487)\n",
      "30367 Traning Loss: tensor(0.8487)\n",
      "30368 Traning Loss: tensor(0.8487)\n",
      "30369 Traning Loss: tensor(0.8487)\n",
      "30370 Traning Loss: tensor(0.8487)\n",
      "30371 Traning Loss: tensor(0.8487)\n",
      "30372 Traning Loss: tensor(0.8487)\n",
      "30373 Traning Loss: tensor(0.8487)\n",
      "30374 Traning Loss: tensor(0.8487)\n",
      "30375 Traning Loss: tensor(0.8487)\n",
      "30376 Traning Loss: tensor(0.8487)\n",
      "30377 Traning Loss: tensor(0.8487)\n",
      "30378 Traning Loss: tensor(0.8487)\n",
      "30379 Traning Loss: tensor(0.8487)\n",
      "30380 Traning Loss: tensor(0.8487)\n",
      "30381 Traning Loss: tensor(0.8487)\n",
      "30382 Traning Loss: tensor(0.8487)\n",
      "30383 Traning Loss: tensor(0.8487)\n",
      "30384 Traning Loss: tensor(0.8487)\n",
      "30385 Traning Loss: tensor(0.8487)\n",
      "30386 Traning Loss: tensor(0.8487)\n",
      "30387 Traning Loss: tensor(0.8487)\n",
      "30388 Traning Loss: tensor(0.8487)\n",
      "30389 Traning Loss: tensor(0.8487)\n",
      "30390 Traning Loss: tensor(0.8487)\n",
      "30391 Traning Loss: tensor(0.8487)\n",
      "30392 Traning Loss: tensor(0.8487)\n",
      "30393 Traning Loss: tensor(0.8487)\n",
      "30394 Traning Loss: tensor(0.8487)\n",
      "30395 Traning Loss: tensor(0.8487)\n",
      "30396 Traning Loss: tensor(0.8487)\n",
      "30397 Traning Loss: tensor(0.8487)\n",
      "30398 Traning Loss: tensor(0.8487)\n",
      "30399 Traning Loss: tensor(0.8487)\n",
      "30400 Traning Loss: tensor(0.8487)\n",
      "30401 Traning Loss: tensor(0.8487)\n",
      "30402 Traning Loss: tensor(0.8487)\n",
      "30403 Traning Loss: tensor(0.8487)\n",
      "30404 Traning Loss: tensor(0.8487)\n",
      "30405 Traning Loss: tensor(0.8487)\n",
      "30406 Traning Loss: tensor(0.8487)\n",
      "30407 Traning Loss: tensor(0.8487)\n",
      "30408 Traning Loss: tensor(0.8487)\n",
      "30409 Traning Loss: tensor(0.8487)\n",
      "30410 Traning Loss: tensor(0.8487)\n",
      "30411 Traning Loss: tensor(0.8487)\n",
      "30412 Traning Loss: tensor(0.8487)\n",
      "30413 Traning Loss: tensor(0.8487)\n",
      "30414 Traning Loss: tensor(0.8487)\n",
      "30415 Traning Loss: tensor(0.8487)\n",
      "30416 Traning Loss: tensor(0.8487)\n",
      "30417 Traning Loss: tensor(0.8487)\n",
      "30418 Traning Loss: tensor(0.8487)\n",
      "30419 Traning Loss: tensor(0.8487)\n",
      "30420 Traning Loss: tensor(0.8487)\n",
      "30421 Traning Loss: tensor(0.8487)\n",
      "30422 Traning Loss: tensor(0.8487)\n",
      "30423 Traning Loss: tensor(0.8487)\n",
      "30424 Traning Loss: tensor(0.8487)\n",
      "30425 Traning Loss: tensor(0.8487)\n",
      "30426 Traning Loss: tensor(0.8487)\n",
      "30427 Traning Loss: tensor(0.8487)\n",
      "30428 Traning Loss: tensor(0.8487)\n",
      "30429 Traning Loss: tensor(0.8487)\n",
      "30430 Traning Loss: tensor(0.8487)\n",
      "30431 Traning Loss: tensor(0.8487)\n",
      "30432 Traning Loss: tensor(0.8487)\n",
      "30433 Traning Loss: tensor(0.8487)\n",
      "30434 Traning Loss: tensor(0.8487)\n",
      "30435 Traning Loss: tensor(0.8487)\n",
      "30436 Traning Loss: tensor(0.8487)\n",
      "30437 Traning Loss: tensor(0.8487)\n",
      "30438 Traning Loss: tensor(0.8487)\n",
      "30439 Traning Loss: tensor(0.8487)\n",
      "30440 Traning Loss: tensor(0.8487)\n",
      "30441 Traning Loss: tensor(0.8487)\n",
      "30442 Traning Loss: tensor(0.8487)\n",
      "30443 Traning Loss: tensor(0.8487)\n",
      "30444 Traning Loss: tensor(0.8487)\n",
      "30445 Traning Loss: tensor(0.8487)\n",
      "30446 Traning Loss: tensor(0.8487)\n",
      "30447 Traning Loss: tensor(0.8487)\n",
      "30448 Traning Loss: tensor(0.8487)\n",
      "30449 Traning Loss: tensor(0.8487)\n",
      "30450 Traning Loss: tensor(0.8487)\n",
      "30451 Traning Loss: tensor(0.8487)\n",
      "30452 Traning Loss: tensor(0.8487)\n",
      "30453 Traning Loss: tensor(0.8487)\n",
      "30454 Traning Loss: tensor(0.8487)\n",
      "30455 Traning Loss: tensor(0.8487)\n",
      "30456 Traning Loss: tensor(0.8487)\n",
      "30457 Traning Loss: tensor(0.8487)\n",
      "30458 Traning Loss: tensor(0.8487)\n",
      "30459 Traning Loss: tensor(0.8487)\n",
      "30460 Traning Loss: tensor(0.8487)\n",
      "30461 Traning Loss: tensor(0.8487)\n",
      "30462 Traning Loss: tensor(0.8487)\n",
      "30463 Traning Loss: tensor(0.8487)\n",
      "30464 Traning Loss: tensor(0.8487)\n",
      "30465 Traning Loss: tensor(0.8487)\n",
      "30466 Traning Loss: tensor(0.8487)\n",
      "30467 Traning Loss: tensor(0.8487)\n",
      "30468 Traning Loss: tensor(0.8487)\n",
      "30469 Traning Loss: tensor(0.8487)\n",
      "30470 Traning Loss: tensor(0.8487)\n",
      "30471 Traning Loss: tensor(0.8487)\n",
      "30472 Traning Loss: tensor(0.8487)\n",
      "30473 Traning Loss: tensor(0.8487)\n",
      "30474 Traning Loss: tensor(0.8487)\n",
      "30475 Traning Loss: tensor(0.8487)\n",
      "30476 Traning Loss: tensor(0.8487)\n",
      "30477 Traning Loss: tensor(0.8487)\n",
      "30478 Traning Loss: tensor(0.8487)\n",
      "30479 Traning Loss: tensor(0.8487)\n",
      "30480 Traning Loss: tensor(0.8488)\n",
      "30481 Traning Loss: tensor(0.8488)\n",
      "30482 Traning Loss: tensor(0.8488)\n",
      "30483 Traning Loss: tensor(0.8488)\n",
      "30484 Traning Loss: tensor(0.8488)\n",
      "30485 Traning Loss: tensor(0.8487)\n",
      "30486 Traning Loss: tensor(0.8487)\n",
      "30487 Traning Loss: tensor(0.8487)\n",
      "30488 Traning Loss: tensor(0.8487)\n",
      "30489 Traning Loss: tensor(0.8487)\n",
      "30490 Traning Loss: tensor(0.8487)\n",
      "30491 Traning Loss: tensor(0.8487)\n",
      "30492 Traning Loss: tensor(0.8487)\n",
      "30493 Traning Loss: tensor(0.8487)\n",
      "30494 Traning Loss: tensor(0.8487)\n",
      "30495 Traning Loss: tensor(0.8487)\n",
      "30496 Traning Loss: tensor(0.8487)\n",
      "30497 Traning Loss: tensor(0.8487)\n",
      "30498 Traning Loss: tensor(0.8487)\n",
      "30499 Traning Loss: tensor(0.8487)\n",
      "30500 Traning Loss: tensor(0.8487)\n",
      "30501 Traning Loss: tensor(0.8487)\n",
      "30502 Traning Loss: tensor(0.8487)\n",
      "30503 Traning Loss: tensor(0.8487)\n",
      "30504 Traning Loss: tensor(0.8487)\n",
      "30505 Traning Loss: tensor(0.8487)\n",
      "30506 Traning Loss: tensor(0.8487)\n",
      "30507 Traning Loss: tensor(0.8487)\n",
      "30508 Traning Loss: tensor(0.8487)\n",
      "30509 Traning Loss: tensor(0.8487)\n",
      "30510 Traning Loss: tensor(0.8487)\n",
      "30511 Traning Loss: tensor(0.8487)\n",
      "30512 Traning Loss: tensor(0.8487)\n",
      "30513 Traning Loss: tensor(0.8487)\n",
      "30514 Traning Loss: tensor(0.8487)\n",
      "30515 Traning Loss: tensor(0.8487)\n",
      "30516 Traning Loss: tensor(0.8487)\n",
      "30517 Traning Loss: tensor(0.8487)\n",
      "30518 Traning Loss: tensor(0.8487)\n",
      "30519 Traning Loss: tensor(0.8487)\n",
      "30520 Traning Loss: tensor(0.8487)\n",
      "30521 Traning Loss: tensor(0.8487)\n",
      "30522 Traning Loss: tensor(0.8487)\n",
      "30523 Traning Loss: tensor(0.8487)\n",
      "30524 Traning Loss: tensor(0.8487)\n",
      "30525 Traning Loss: tensor(0.8487)\n",
      "30526 Traning Loss: tensor(0.8487)\n",
      "30527 Traning Loss: tensor(0.8487)\n",
      "30528 Traning Loss: tensor(0.8487)\n",
      "30529 Traning Loss: tensor(0.8487)\n",
      "30530 Traning Loss: tensor(0.8487)\n",
      "30531 Traning Loss: tensor(0.8487)\n",
      "30532 Traning Loss: tensor(0.8487)\n",
      "30533 Traning Loss: tensor(0.8487)\n",
      "30534 Traning Loss: tensor(0.8487)\n",
      "30535 Traning Loss: tensor(0.8487)\n",
      "30536 Traning Loss: tensor(0.8487)\n",
      "30537 Traning Loss: tensor(0.8487)\n",
      "30538 Traning Loss: tensor(0.8487)\n",
      "30539 Traning Loss: tensor(0.8487)\n",
      "30540 Traning Loss: tensor(0.8487)\n",
      "30541 Traning Loss: tensor(0.8487)\n",
      "30542 Traning Loss: tensor(0.8487)\n",
      "30543 Traning Loss: tensor(0.8487)\n",
      "30544 Traning Loss: tensor(0.8487)\n",
      "30545 Traning Loss: tensor(0.8487)\n",
      "30546 Traning Loss: tensor(0.8487)\n",
      "30547 Traning Loss: tensor(0.8487)\n",
      "30548 Traning Loss: tensor(0.8487)\n",
      "30549 Traning Loss: tensor(0.8487)\n",
      "30550 Traning Loss: tensor(0.8487)\n",
      "30551 Traning Loss: tensor(0.8487)\n",
      "30552 Traning Loss: tensor(0.8487)\n",
      "30553 Traning Loss: tensor(0.8487)\n",
      "30554 Traning Loss: tensor(0.8487)\n",
      "30555 Traning Loss: tensor(0.8487)\n",
      "30556 Traning Loss: tensor(0.8487)\n",
      "30557 Traning Loss: tensor(0.8487)\n",
      "30558 Traning Loss: tensor(0.8487)\n",
      "30559 Traning Loss: tensor(0.8487)\n",
      "30560 Traning Loss: tensor(0.8487)\n",
      "30561 Traning Loss: tensor(0.8487)\n",
      "30562 Traning Loss: tensor(0.8487)\n",
      "30563 Traning Loss: tensor(0.8487)\n",
      "30564 Traning Loss: tensor(0.8487)\n",
      "30565 Traning Loss: tensor(0.8487)\n",
      "30566 Traning Loss: tensor(0.8487)\n",
      "30567 Traning Loss: tensor(0.8487)\n",
      "30568 Traning Loss: tensor(0.8487)\n",
      "30569 Traning Loss: tensor(0.8487)\n",
      "30570 Traning Loss: tensor(0.8487)\n",
      "30571 Traning Loss: tensor(0.8487)\n",
      "30572 Traning Loss: tensor(0.8487)\n",
      "30573 Traning Loss: tensor(0.8487)\n",
      "30574 Traning Loss: tensor(0.8487)\n",
      "30575 Traning Loss: tensor(0.8487)\n",
      "30576 Traning Loss: tensor(0.8487)\n",
      "30577 Traning Loss: tensor(0.8487)\n",
      "30578 Traning Loss: tensor(0.8487)\n",
      "30579 Traning Loss: tensor(0.8487)\n",
      "30580 Traning Loss: tensor(0.8487)\n",
      "30581 Traning Loss: tensor(0.8487)\n",
      "30582 Traning Loss: tensor(0.8487)\n",
      "30583 Traning Loss: tensor(0.8487)\n",
      "30584 Traning Loss: tensor(0.8487)\n",
      "30585 Traning Loss: tensor(0.8487)\n",
      "30586 Traning Loss: tensor(0.8487)\n",
      "30587 Traning Loss: tensor(0.8487)\n",
      "30588 Traning Loss: tensor(0.8487)\n",
      "30589 Traning Loss: tensor(0.8487)\n",
      "30590 Traning Loss: tensor(0.8487)\n",
      "30591 Traning Loss: tensor(0.8487)\n",
      "30592 Traning Loss: tensor(0.8487)\n",
      "30593 Traning Loss: tensor(0.8487)\n",
      "30594 Traning Loss: tensor(0.8487)\n",
      "30595 Traning Loss: tensor(0.8487)\n",
      "30596 Traning Loss: tensor(0.8487)\n",
      "30597 Traning Loss: tensor(0.8487)\n",
      "30598 Traning Loss: tensor(0.8487)\n",
      "30599 Traning Loss: tensor(0.8487)\n",
      "30600 Traning Loss: tensor(0.8487)\n",
      "30601 Traning Loss: tensor(0.8487)\n",
      "30602 Traning Loss: tensor(0.8487)\n",
      "30603 Traning Loss: tensor(0.8487)\n",
      "30604 Traning Loss: tensor(0.8487)\n",
      "30605 Traning Loss: tensor(0.8487)\n",
      "30606 Traning Loss: tensor(0.8487)\n",
      "30607 Traning Loss: tensor(0.8487)\n",
      "30608 Traning Loss: tensor(0.8487)\n",
      "30609 Traning Loss: tensor(0.8487)\n",
      "30610 Traning Loss: tensor(0.8487)\n",
      "30611 Traning Loss: tensor(0.8487)\n",
      "30612 Traning Loss: tensor(0.8487)\n",
      "30613 Traning Loss: tensor(0.8487)\n",
      "30614 Traning Loss: tensor(0.8487)\n",
      "30615 Traning Loss: tensor(0.8487)\n",
      "30616 Traning Loss: tensor(0.8487)\n",
      "30617 Traning Loss: tensor(0.8487)\n",
      "30618 Traning Loss: tensor(0.8487)\n",
      "30619 Traning Loss: tensor(0.8487)\n",
      "30620 Traning Loss: tensor(0.8487)\n",
      "30621 Traning Loss: tensor(0.8487)\n",
      "30622 Traning Loss: tensor(0.8487)\n",
      "30623 Traning Loss: tensor(0.8487)\n",
      "30624 Traning Loss: tensor(0.8487)\n",
      "30625 Traning Loss: tensor(0.8487)\n",
      "30626 Traning Loss: tensor(0.8487)\n",
      "30627 Traning Loss: tensor(0.8487)\n",
      "30628 Traning Loss: tensor(0.8487)\n",
      "30629 Traning Loss: tensor(0.8487)\n",
      "30630 Traning Loss: tensor(0.8487)\n",
      "30631 Traning Loss: tensor(0.8487)\n",
      "30632 Traning Loss: tensor(0.8487)\n",
      "30633 Traning Loss: tensor(0.8487)\n",
      "30634 Traning Loss: tensor(0.8487)\n",
      "30635 Traning Loss: tensor(0.8487)\n",
      "30636 Traning Loss: tensor(0.8487)\n",
      "30637 Traning Loss: tensor(0.8487)\n",
      "30638 Traning Loss: tensor(0.8487)\n",
      "30639 Traning Loss: tensor(0.8487)\n",
      "30640 Traning Loss: tensor(0.8487)\n",
      "30641 Traning Loss: tensor(0.8487)\n",
      "30642 Traning Loss: tensor(0.8487)\n",
      "30643 Traning Loss: tensor(0.8487)\n",
      "30644 Traning Loss: tensor(0.8487)\n",
      "30645 Traning Loss: tensor(0.8487)\n",
      "30646 Traning Loss: tensor(0.8487)\n",
      "30647 Traning Loss: tensor(0.8487)\n",
      "30648 Traning Loss: tensor(0.8487)\n",
      "30649 Traning Loss: tensor(0.8487)\n",
      "30650 Traning Loss: tensor(0.8487)\n",
      "30651 Traning Loss: tensor(0.8487)\n",
      "30652 Traning Loss: tensor(0.8487)\n",
      "30653 Traning Loss: tensor(0.8487)\n",
      "30654 Traning Loss: tensor(0.8487)\n",
      "30655 Traning Loss: tensor(0.8487)\n",
      "30656 Traning Loss: tensor(0.8487)\n",
      "30657 Traning Loss: tensor(0.8487)\n",
      "30658 Traning Loss: tensor(0.8487)\n",
      "30659 Traning Loss: tensor(0.8487)\n",
      "30660 Traning Loss: tensor(0.8487)\n",
      "30661 Traning Loss: tensor(0.8487)\n",
      "30662 Traning Loss: tensor(0.8487)\n",
      "30663 Traning Loss: tensor(0.8487)\n",
      "30664 Traning Loss: tensor(0.8487)\n",
      "30665 Traning Loss: tensor(0.8487)\n",
      "30666 Traning Loss: tensor(0.8487)\n",
      "30667 Traning Loss: tensor(0.8487)\n",
      "30668 Traning Loss: tensor(0.8487)\n",
      "30669 Traning Loss: tensor(0.8487)\n",
      "30670 Traning Loss: tensor(0.8487)\n",
      "30671 Traning Loss: tensor(0.8487)\n",
      "30672 Traning Loss: tensor(0.8487)\n",
      "30673 Traning Loss: tensor(0.8487)\n",
      "30674 Traning Loss: tensor(0.8487)\n",
      "30675 Traning Loss: tensor(0.8487)\n",
      "30676 Traning Loss: tensor(0.8487)\n",
      "30677 Traning Loss: tensor(0.8487)\n",
      "30678 Traning Loss: tensor(0.8487)\n",
      "30679 Traning Loss: tensor(0.8487)\n",
      "30680 Traning Loss: tensor(0.8487)\n",
      "30681 Traning Loss: tensor(0.8487)\n",
      "30682 Traning Loss: tensor(0.8487)\n",
      "30683 Traning Loss: tensor(0.8487)\n",
      "30684 Traning Loss: tensor(0.8487)\n",
      "30685 Traning Loss: tensor(0.8487)\n",
      "30686 Traning Loss: tensor(0.8487)\n",
      "30687 Traning Loss: tensor(0.8487)\n",
      "30688 Traning Loss: tensor(0.8487)\n",
      "30689 Traning Loss: tensor(0.8487)\n",
      "30690 Traning Loss: tensor(0.8487)\n",
      "30691 Traning Loss: tensor(0.8487)\n",
      "30692 Traning Loss: tensor(0.8487)\n",
      "30693 Traning Loss: tensor(0.8487)\n",
      "30694 Traning Loss: tensor(0.8487)\n",
      "30695 Traning Loss: tensor(0.8487)\n",
      "30696 Traning Loss: tensor(0.8487)\n",
      "30697 Traning Loss: tensor(0.8487)\n",
      "30698 Traning Loss: tensor(0.8487)\n",
      "30699 Traning Loss: tensor(0.8487)\n",
      "30700 Traning Loss: tensor(0.8487)\n",
      "30701 Traning Loss: tensor(0.8487)\n",
      "30702 Traning Loss: tensor(0.8487)\n",
      "30703 Traning Loss: tensor(0.8487)\n",
      "30704 Traning Loss: tensor(0.8487)\n",
      "30705 Traning Loss: tensor(0.8487)\n",
      "30706 Traning Loss: tensor(0.8487)\n",
      "30707 Traning Loss: tensor(0.8487)\n",
      "30708 Traning Loss: tensor(0.8487)\n",
      "30709 Traning Loss: tensor(0.8487)\n",
      "30710 Traning Loss: tensor(0.8487)\n",
      "30711 Traning Loss: tensor(0.8487)\n",
      "30712 Traning Loss: tensor(0.8487)\n",
      "30713 Traning Loss: tensor(0.8487)\n",
      "30714 Traning Loss: tensor(0.8487)\n",
      "30715 Traning Loss: tensor(0.8487)\n",
      "30716 Traning Loss: tensor(0.8488)\n",
      "30717 Traning Loss: tensor(0.8488)\n",
      "30718 Traning Loss: tensor(0.8488)\n",
      "30719 Traning Loss: tensor(0.8488)\n",
      "30720 Traning Loss: tensor(0.8487)\n",
      "30721 Traning Loss: tensor(0.8487)\n",
      "30722 Traning Loss: tensor(0.8487)\n",
      "30723 Traning Loss: tensor(0.8487)\n",
      "30724 Traning Loss: tensor(0.8487)\n",
      "30725 Traning Loss: tensor(0.8487)\n",
      "30726 Traning Loss: tensor(0.8487)\n",
      "30727 Traning Loss: tensor(0.8487)\n",
      "30728 Traning Loss: tensor(0.8487)\n",
      "30729 Traning Loss: tensor(0.8487)\n",
      "30730 Traning Loss: tensor(0.8487)\n",
      "30731 Traning Loss: tensor(0.8487)\n",
      "30732 Traning Loss: tensor(0.8487)\n",
      "30733 Traning Loss: tensor(0.8487)\n",
      "30734 Traning Loss: tensor(0.8487)\n",
      "30735 Traning Loss: tensor(0.8487)\n",
      "30736 Traning Loss: tensor(0.8487)\n",
      "30737 Traning Loss: tensor(0.8487)\n",
      "30738 Traning Loss: tensor(0.8487)\n",
      "30739 Traning Loss: tensor(0.8487)\n",
      "30740 Traning Loss: tensor(0.8487)\n",
      "30741 Traning Loss: tensor(0.8487)\n",
      "30742 Traning Loss: tensor(0.8487)\n",
      "30743 Traning Loss: tensor(0.8487)\n",
      "30744 Traning Loss: tensor(0.8487)\n",
      "30745 Traning Loss: tensor(0.8487)\n",
      "30746 Traning Loss: tensor(0.8487)\n",
      "30747 Traning Loss: tensor(0.8487)\n",
      "30748 Traning Loss: tensor(0.8487)\n",
      "30749 Traning Loss: tensor(0.8487)\n",
      "30750 Traning Loss: tensor(0.8487)\n",
      "30751 Traning Loss: tensor(0.8487)\n",
      "30752 Traning Loss: tensor(0.8487)\n",
      "30753 Traning Loss: tensor(0.8487)\n",
      "30754 Traning Loss: tensor(0.8487)\n",
      "30755 Traning Loss: tensor(0.8487)\n",
      "30756 Traning Loss: tensor(0.8487)\n",
      "30757 Traning Loss: tensor(0.8487)\n",
      "30758 Traning Loss: tensor(0.8487)\n",
      "30759 Traning Loss: tensor(0.8487)\n",
      "30760 Traning Loss: tensor(0.8487)\n",
      "30761 Traning Loss: tensor(0.8487)\n",
      "30762 Traning Loss: tensor(0.8487)\n",
      "30763 Traning Loss: tensor(0.8487)\n",
      "30764 Traning Loss: tensor(0.8487)\n",
      "30765 Traning Loss: tensor(0.8487)\n",
      "30766 Traning Loss: tensor(0.8487)\n",
      "30767 Traning Loss: tensor(0.8487)\n",
      "30768 Traning Loss: tensor(0.8487)\n",
      "30769 Traning Loss: tensor(0.8487)\n",
      "30770 Traning Loss: tensor(0.8487)\n",
      "30771 Traning Loss: tensor(0.8487)\n",
      "30772 Traning Loss: tensor(0.8487)\n",
      "30773 Traning Loss: tensor(0.8487)\n",
      "30774 Traning Loss: tensor(0.8487)\n",
      "30775 Traning Loss: tensor(0.8487)\n",
      "30776 Traning Loss: tensor(0.8487)\n",
      "30777 Traning Loss: tensor(0.8487)\n",
      "30778 Traning Loss: tensor(0.8487)\n",
      "30779 Traning Loss: tensor(0.8487)\n",
      "30780 Traning Loss: tensor(0.8487)\n",
      "30781 Traning Loss: tensor(0.8487)\n",
      "30782 Traning Loss: tensor(0.8487)\n",
      "30783 Traning Loss: tensor(0.8487)\n",
      "30784 Traning Loss: tensor(0.8487)\n",
      "30785 Traning Loss: tensor(0.8487)\n",
      "30786 Traning Loss: tensor(0.8487)\n",
      "30787 Traning Loss: tensor(0.8487)\n",
      "30788 Traning Loss: tensor(0.8487)\n",
      "30789 Traning Loss: tensor(0.8487)\n",
      "30790 Traning Loss: tensor(0.8487)\n",
      "30791 Traning Loss: tensor(0.8487)\n",
      "30792 Traning Loss: tensor(0.8487)\n",
      "30793 Traning Loss: tensor(0.8487)\n",
      "30794 Traning Loss: tensor(0.8487)\n",
      "30795 Traning Loss: tensor(0.8487)\n",
      "30796 Traning Loss: tensor(0.8487)\n",
      "30797 Traning Loss: tensor(0.8487)\n",
      "30798 Traning Loss: tensor(0.8487)\n",
      "30799 Traning Loss: tensor(0.8487)\n",
      "30800 Traning Loss: tensor(0.8487)\n",
      "30801 Traning Loss: tensor(0.8487)\n",
      "30802 Traning Loss: tensor(0.8487)\n",
      "30803 Traning Loss: tensor(0.8487)\n",
      "30804 Traning Loss: tensor(0.8487)\n",
      "30805 Traning Loss: tensor(0.8487)\n",
      "30806 Traning Loss: tensor(0.8487)\n",
      "30807 Traning Loss: tensor(0.8487)\n",
      "30808 Traning Loss: tensor(0.8487)\n",
      "30809 Traning Loss: tensor(0.8487)\n",
      "30810 Traning Loss: tensor(0.8487)\n",
      "30811 Traning Loss: tensor(0.8487)\n",
      "30812 Traning Loss: tensor(0.8487)\n",
      "30813 Traning Loss: tensor(0.8487)\n",
      "30814 Traning Loss: tensor(0.8487)\n",
      "30815 Traning Loss: tensor(0.8487)\n",
      "30816 Traning Loss: tensor(0.8487)\n",
      "30817 Traning Loss: tensor(0.8487)\n",
      "30818 Traning Loss: tensor(0.8487)\n",
      "30819 Traning Loss: tensor(0.8487)\n",
      "30820 Traning Loss: tensor(0.8487)\n",
      "30821 Traning Loss: tensor(0.8487)\n",
      "30822 Traning Loss: tensor(0.8487)\n",
      "30823 Traning Loss: tensor(0.8487)\n",
      "30824 Traning Loss: tensor(0.8487)\n",
      "30825 Traning Loss: tensor(0.8487)\n",
      "30826 Traning Loss: tensor(0.8487)\n",
      "30827 Traning Loss: tensor(0.8487)\n",
      "30828 Traning Loss: tensor(0.8487)\n",
      "30829 Traning Loss: tensor(0.8487)\n",
      "30830 Traning Loss: tensor(0.8487)\n",
      "30831 Traning Loss: tensor(0.8487)\n",
      "30832 Traning Loss: tensor(0.8487)\n",
      "30833 Traning Loss: tensor(0.8487)\n",
      "30834 Traning Loss: tensor(0.8487)\n",
      "30835 Traning Loss: tensor(0.8487)\n",
      "30836 Traning Loss: tensor(0.8487)\n",
      "30837 Traning Loss: tensor(0.8487)\n",
      "30838 Traning Loss: tensor(0.8487)\n",
      "30839 Traning Loss: tensor(0.8487)\n",
      "30840 Traning Loss: tensor(0.8487)\n",
      "30841 Traning Loss: tensor(0.8487)\n",
      "30842 Traning Loss: tensor(0.8487)\n",
      "30843 Traning Loss: tensor(0.8487)\n",
      "30844 Traning Loss: tensor(0.8487)\n",
      "30845 Traning Loss: tensor(0.8487)\n",
      "30846 Traning Loss: tensor(0.8487)\n",
      "30847 Traning Loss: tensor(0.8487)\n",
      "30848 Traning Loss: tensor(0.8487)\n",
      "30849 Traning Loss: tensor(0.8487)\n",
      "30850 Traning Loss: tensor(0.8487)\n",
      "30851 Traning Loss: tensor(0.8487)\n",
      "30852 Traning Loss: tensor(0.8487)\n",
      "30853 Traning Loss: tensor(0.8487)\n",
      "30854 Traning Loss: tensor(0.8487)\n",
      "30855 Traning Loss: tensor(0.8487)\n",
      "30856 Traning Loss: tensor(0.8487)\n",
      "30857 Traning Loss: tensor(0.8487)\n",
      "30858 Traning Loss: tensor(0.8487)\n",
      "30859 Traning Loss: tensor(0.8487)\n",
      "30860 Traning Loss: tensor(0.8487)\n",
      "30861 Traning Loss: tensor(0.8487)\n",
      "30862 Traning Loss: tensor(0.8487)\n",
      "30863 Traning Loss: tensor(0.8487)\n",
      "30864 Traning Loss: tensor(0.8487)\n",
      "30865 Traning Loss: tensor(0.8487)\n",
      "30866 Traning Loss: tensor(0.8487)\n",
      "30867 Traning Loss: tensor(0.8487)\n",
      "30868 Traning Loss: tensor(0.8487)\n",
      "30869 Traning Loss: tensor(0.8487)\n",
      "30870 Traning Loss: tensor(0.8487)\n",
      "30871 Traning Loss: tensor(0.8487)\n",
      "30872 Traning Loss: tensor(0.8487)\n",
      "30873 Traning Loss: tensor(0.8487)\n",
      "30874 Traning Loss: tensor(0.8487)\n",
      "30875 Traning Loss: tensor(0.8487)\n",
      "30876 Traning Loss: tensor(0.8487)\n",
      "30877 Traning Loss: tensor(0.8487)\n",
      "30878 Traning Loss: tensor(0.8487)\n",
      "30879 Traning Loss: tensor(0.8487)\n",
      "30880 Traning Loss: tensor(0.8487)\n",
      "30881 Traning Loss: tensor(0.8487)\n",
      "30882 Traning Loss: tensor(0.8487)\n",
      "30883 Traning Loss: tensor(0.8487)\n",
      "30884 Traning Loss: tensor(0.8487)\n",
      "30885 Traning Loss: tensor(0.8487)\n",
      "30886 Traning Loss: tensor(0.8487)\n",
      "30887 Traning Loss: tensor(0.8487)\n",
      "30888 Traning Loss: tensor(0.8487)\n",
      "30889 Traning Loss: tensor(0.8487)\n",
      "30890 Traning Loss: tensor(0.8487)\n",
      "30891 Traning Loss: tensor(0.8487)\n",
      "30892 Traning Loss: tensor(0.8487)\n",
      "30893 Traning Loss: tensor(0.8487)\n",
      "30894 Traning Loss: tensor(0.8487)\n",
      "30895 Traning Loss: tensor(0.8487)\n",
      "30896 Traning Loss: tensor(0.8487)\n",
      "30897 Traning Loss: tensor(0.8487)\n",
      "30898 Traning Loss: tensor(0.8487)\n",
      "30899 Traning Loss: tensor(0.8487)\n",
      "30900 Traning Loss: tensor(0.8487)\n",
      "30901 Traning Loss: tensor(0.8487)\n",
      "30902 Traning Loss: tensor(0.8487)\n",
      "30903 Traning Loss: tensor(0.8487)\n",
      "30904 Traning Loss: tensor(0.8487)\n",
      "30905 Traning Loss: tensor(0.8487)\n",
      "30906 Traning Loss: tensor(0.8487)\n",
      "30907 Traning Loss: tensor(0.8487)\n",
      "30908 Traning Loss: tensor(0.8487)\n",
      "30909 Traning Loss: tensor(0.8487)\n",
      "30910 Traning Loss: tensor(0.8487)\n",
      "30911 Traning Loss: tensor(0.8487)\n",
      "30912 Traning Loss: tensor(0.8487)\n",
      "30913 Traning Loss: tensor(0.8487)\n",
      "30914 Traning Loss: tensor(0.8487)\n",
      "30915 Traning Loss: tensor(0.8487)\n",
      "30916 Traning Loss: tensor(0.8487)\n",
      "30917 Traning Loss: tensor(0.8487)\n",
      "30918 Traning Loss: tensor(0.8487)\n",
      "30919 Traning Loss: tensor(0.8487)\n",
      "30920 Traning Loss: tensor(0.8487)\n",
      "30921 Traning Loss: tensor(0.8487)\n",
      "30922 Traning Loss: tensor(0.8487)\n",
      "30923 Traning Loss: tensor(0.8487)\n",
      "30924 Traning Loss: tensor(0.8487)\n",
      "30925 Traning Loss: tensor(0.8487)\n",
      "30926 Traning Loss: tensor(0.8487)\n",
      "30927 Traning Loss: tensor(0.8487)\n",
      "30928 Traning Loss: tensor(0.8487)\n",
      "30929 Traning Loss: tensor(0.8487)\n",
      "30930 Traning Loss: tensor(0.8487)\n",
      "30931 Traning Loss: tensor(0.8487)\n",
      "30932 Traning Loss: tensor(0.8487)\n",
      "30933 Traning Loss: tensor(0.8487)\n",
      "30934 Traning Loss: tensor(0.8487)\n",
      "30935 Traning Loss: tensor(0.8487)\n",
      "30936 Traning Loss: tensor(0.8487)\n",
      "30937 Traning Loss: tensor(0.8487)\n",
      "30938 Traning Loss: tensor(0.8487)\n",
      "30939 Traning Loss: tensor(0.8487)\n",
      "30940 Traning Loss: tensor(0.8487)\n",
      "30941 Traning Loss: tensor(0.8487)\n",
      "30942 Traning Loss: tensor(0.8487)\n",
      "30943 Traning Loss: tensor(0.8487)\n",
      "30944 Traning Loss: tensor(0.8487)\n",
      "30945 Traning Loss: tensor(0.8487)\n",
      "30946 Traning Loss: tensor(0.8488)\n",
      "30947 Traning Loss: tensor(0.8488)\n",
      "30948 Traning Loss: tensor(0.8488)\n",
      "30949 Traning Loss: tensor(0.8488)\n",
      "30950 Traning Loss: tensor(0.8487)\n",
      "30951 Traning Loss: tensor(0.8487)\n",
      "30952 Traning Loss: tensor(0.8487)\n",
      "30953 Traning Loss: tensor(0.8487)\n",
      "30954 Traning Loss: tensor(0.8487)\n",
      "30955 Traning Loss: tensor(0.8487)\n",
      "30956 Traning Loss: tensor(0.8487)\n",
      "30957 Traning Loss: tensor(0.8487)\n",
      "30958 Traning Loss: tensor(0.8487)\n",
      "30959 Traning Loss: tensor(0.8487)\n",
      "30960 Traning Loss: tensor(0.8487)\n",
      "30961 Traning Loss: tensor(0.8487)\n",
      "30962 Traning Loss: tensor(0.8487)\n",
      "30963 Traning Loss: tensor(0.8487)\n",
      "30964 Traning Loss: tensor(0.8487)\n",
      "30965 Traning Loss: tensor(0.8487)\n",
      "30966 Traning Loss: tensor(0.8487)\n",
      "30967 Traning Loss: tensor(0.8487)\n",
      "30968 Traning Loss: tensor(0.8487)\n",
      "30969 Traning Loss: tensor(0.8487)\n",
      "30970 Traning Loss: tensor(0.8487)\n",
      "30971 Traning Loss: tensor(0.8487)\n",
      "30972 Traning Loss: tensor(0.8487)\n",
      "30973 Traning Loss: tensor(0.8487)\n",
      "30974 Traning Loss: tensor(0.8487)\n",
      "30975 Traning Loss: tensor(0.8487)\n",
      "30976 Traning Loss: tensor(0.8487)\n",
      "30977 Traning Loss: tensor(0.8487)\n",
      "30978 Traning Loss: tensor(0.8487)\n",
      "30979 Traning Loss: tensor(0.8487)\n",
      "30980 Traning Loss: tensor(0.8487)\n",
      "30981 Traning Loss: tensor(0.8487)\n",
      "30982 Traning Loss: tensor(0.8487)\n",
      "30983 Traning Loss: tensor(0.8487)\n",
      "30984 Traning Loss: tensor(0.8487)\n",
      "30985 Traning Loss: tensor(0.8487)\n",
      "30986 Traning Loss: tensor(0.8487)\n",
      "30987 Traning Loss: tensor(0.8487)\n",
      "30988 Traning Loss: tensor(0.8487)\n",
      "30989 Traning Loss: tensor(0.8487)\n",
      "30990 Traning Loss: tensor(0.8487)\n",
      "30991 Traning Loss: tensor(0.8487)\n",
      "30992 Traning Loss: tensor(0.8487)\n",
      "30993 Traning Loss: tensor(0.8487)\n",
      "30994 Traning Loss: tensor(0.8487)\n",
      "30995 Traning Loss: tensor(0.8487)\n",
      "30996 Traning Loss: tensor(0.8487)\n",
      "30997 Traning Loss: tensor(0.8487)\n",
      "30998 Traning Loss: tensor(0.8487)\n",
      "30999 Traning Loss: tensor(0.8487)\n",
      "31000 Traning Loss: tensor(0.8487)\n",
      "31001 Traning Loss: tensor(0.8487)\n",
      "31002 Traning Loss: tensor(0.8487)\n",
      "31003 Traning Loss: tensor(0.8487)\n",
      "31004 Traning Loss: tensor(0.8487)\n",
      "31005 Traning Loss: tensor(0.8487)\n",
      "31006 Traning Loss: tensor(0.8487)\n",
      "31007 Traning Loss: tensor(0.8487)\n",
      "31008 Traning Loss: tensor(0.8487)\n",
      "31009 Traning Loss: tensor(0.8487)\n",
      "31010 Traning Loss: tensor(0.8487)\n",
      "31011 Traning Loss: tensor(0.8487)\n",
      "31012 Traning Loss: tensor(0.8487)\n",
      "31013 Traning Loss: tensor(0.8487)\n",
      "31014 Traning Loss: tensor(0.8487)\n",
      "31015 Traning Loss: tensor(0.8487)\n",
      "31016 Traning Loss: tensor(0.8487)\n",
      "31017 Traning Loss: tensor(0.8487)\n",
      "31018 Traning Loss: tensor(0.8487)\n",
      "31019 Traning Loss: tensor(0.8487)\n",
      "31020 Traning Loss: tensor(0.8487)\n",
      "31021 Traning Loss: tensor(0.8487)\n",
      "31022 Traning Loss: tensor(0.8487)\n",
      "31023 Traning Loss: tensor(0.8487)\n",
      "31024 Traning Loss: tensor(0.8487)\n",
      "31025 Traning Loss: tensor(0.8487)\n",
      "31026 Traning Loss: tensor(0.8487)\n",
      "31027 Traning Loss: tensor(0.8487)\n",
      "31028 Traning Loss: tensor(0.8487)\n",
      "31029 Traning Loss: tensor(0.8487)\n",
      "31030 Traning Loss: tensor(0.8487)\n",
      "31031 Traning Loss: tensor(0.8487)\n",
      "31032 Traning Loss: tensor(0.8487)\n",
      "31033 Traning Loss: tensor(0.8487)\n",
      "31034 Traning Loss: tensor(0.8487)\n",
      "31035 Traning Loss: tensor(0.8487)\n",
      "31036 Traning Loss: tensor(0.8487)\n",
      "31037 Traning Loss: tensor(0.8487)\n",
      "31038 Traning Loss: tensor(0.8487)\n",
      "31039 Traning Loss: tensor(0.8487)\n",
      "31040 Traning Loss: tensor(0.8487)\n",
      "31041 Traning Loss: tensor(0.8487)\n",
      "31042 Traning Loss: tensor(0.8487)\n",
      "31043 Traning Loss: tensor(0.8487)\n",
      "31044 Traning Loss: tensor(0.8487)\n",
      "31045 Traning Loss: tensor(0.8487)\n",
      "31046 Traning Loss: tensor(0.8487)\n",
      "31047 Traning Loss: tensor(0.8487)\n",
      "31048 Traning Loss: tensor(0.8487)\n",
      "31049 Traning Loss: tensor(0.8487)\n",
      "31050 Traning Loss: tensor(0.8487)\n",
      "31051 Traning Loss: tensor(0.8487)\n",
      "31052 Traning Loss: tensor(0.8487)\n",
      "31053 Traning Loss: tensor(0.8487)\n",
      "31054 Traning Loss: tensor(0.8487)\n",
      "31055 Traning Loss: tensor(0.8487)\n",
      "31056 Traning Loss: tensor(0.8487)\n",
      "31057 Traning Loss: tensor(0.8487)\n",
      "31058 Traning Loss: tensor(0.8487)\n",
      "31059 Traning Loss: tensor(0.8487)\n",
      "31060 Traning Loss: tensor(0.8487)\n",
      "31061 Traning Loss: tensor(0.8487)\n",
      "31062 Traning Loss: tensor(0.8487)\n",
      "31063 Traning Loss: tensor(0.8487)\n",
      "31064 Traning Loss: tensor(0.8487)\n",
      "31065 Traning Loss: tensor(0.8487)\n",
      "31066 Traning Loss: tensor(0.8487)\n",
      "31067 Traning Loss: tensor(0.8487)\n",
      "31068 Traning Loss: tensor(0.8487)\n",
      "31069 Traning Loss: tensor(0.8487)\n",
      "31070 Traning Loss: tensor(0.8487)\n",
      "31071 Traning Loss: tensor(0.8487)\n",
      "31072 Traning Loss: tensor(0.8487)\n",
      "31073 Traning Loss: tensor(0.8487)\n",
      "31074 Traning Loss: tensor(0.8487)\n",
      "31075 Traning Loss: tensor(0.8487)\n",
      "31076 Traning Loss: tensor(0.8487)\n",
      "31077 Traning Loss: tensor(0.8487)\n",
      "31078 Traning Loss: tensor(0.8487)\n",
      "31079 Traning Loss: tensor(0.8487)\n",
      "31080 Traning Loss: tensor(0.8487)\n",
      "31081 Traning Loss: tensor(0.8487)\n",
      "31082 Traning Loss: tensor(0.8487)\n",
      "31083 Traning Loss: tensor(0.8487)\n",
      "31084 Traning Loss: tensor(0.8487)\n",
      "31085 Traning Loss: tensor(0.8487)\n",
      "31086 Traning Loss: tensor(0.8487)\n",
      "31087 Traning Loss: tensor(0.8487)\n",
      "31088 Traning Loss: tensor(0.8487)\n",
      "31089 Traning Loss: tensor(0.8487)\n",
      "31090 Traning Loss: tensor(0.8487)\n",
      "31091 Traning Loss: tensor(0.8487)\n",
      "31092 Traning Loss: tensor(0.8487)\n",
      "31093 Traning Loss: tensor(0.8487)\n",
      "31094 Traning Loss: tensor(0.8487)\n",
      "31095 Traning Loss: tensor(0.8487)\n",
      "31096 Traning Loss: tensor(0.8487)\n",
      "31097 Traning Loss: tensor(0.8487)\n",
      "31098 Traning Loss: tensor(0.8487)\n",
      "31099 Traning Loss: tensor(0.8487)\n",
      "31100 Traning Loss: tensor(0.8487)\n",
      "31101 Traning Loss: tensor(0.8487)\n",
      "31102 Traning Loss: tensor(0.8487)\n",
      "31103 Traning Loss: tensor(0.8487)\n",
      "31104 Traning Loss: tensor(0.8487)\n",
      "31105 Traning Loss: tensor(0.8487)\n",
      "31106 Traning Loss: tensor(0.8487)\n",
      "31107 Traning Loss: tensor(0.8487)\n",
      "31108 Traning Loss: tensor(0.8487)\n",
      "31109 Traning Loss: tensor(0.8487)\n",
      "31110 Traning Loss: tensor(0.8487)\n",
      "31111 Traning Loss: tensor(0.8487)\n",
      "31112 Traning Loss: tensor(0.8487)\n",
      "31113 Traning Loss: tensor(0.8487)\n",
      "31114 Traning Loss: tensor(0.8487)\n",
      "31115 Traning Loss: tensor(0.8487)\n",
      "31116 Traning Loss: tensor(0.8487)\n",
      "31117 Traning Loss: tensor(0.8487)\n",
      "31118 Traning Loss: tensor(0.8487)\n",
      "31119 Traning Loss: tensor(0.8487)\n",
      "31120 Traning Loss: tensor(0.8487)\n",
      "31121 Traning Loss: tensor(0.8487)\n",
      "31122 Traning Loss: tensor(0.8487)\n",
      "31123 Traning Loss: tensor(0.8487)\n",
      "31124 Traning Loss: tensor(0.8487)\n",
      "31125 Traning Loss: tensor(0.8487)\n",
      "31126 Traning Loss: tensor(0.8487)\n",
      "31127 Traning Loss: tensor(0.8487)\n",
      "31128 Traning Loss: tensor(0.8487)\n",
      "31129 Traning Loss: tensor(0.8487)\n",
      "31130 Traning Loss: tensor(0.8487)\n",
      "31131 Traning Loss: tensor(0.8487)\n",
      "31132 Traning Loss: tensor(0.8487)\n",
      "31133 Traning Loss: tensor(0.8487)\n",
      "31134 Traning Loss: tensor(0.8487)\n",
      "31135 Traning Loss: tensor(0.8487)\n",
      "31136 Traning Loss: tensor(0.8487)\n",
      "31137 Traning Loss: tensor(0.8487)\n",
      "31138 Traning Loss: tensor(0.8487)\n",
      "31139 Traning Loss: tensor(0.8487)\n",
      "31140 Traning Loss: tensor(0.8487)\n",
      "31141 Traning Loss: tensor(0.8487)\n",
      "31142 Traning Loss: tensor(0.8487)\n",
      "31143 Traning Loss: tensor(0.8487)\n",
      "31144 Traning Loss: tensor(0.8487)\n",
      "31145 Traning Loss: tensor(0.8487)\n",
      "31146 Traning Loss: tensor(0.8487)\n",
      "31147 Traning Loss: tensor(0.8487)\n",
      "31148 Traning Loss: tensor(0.8487)\n",
      "31149 Traning Loss: tensor(0.8487)\n",
      "31150 Traning Loss: tensor(0.8487)\n",
      "31151 Traning Loss: tensor(0.8487)\n",
      "31152 Traning Loss: tensor(0.8487)\n",
      "31153 Traning Loss: tensor(0.8487)\n",
      "31154 Traning Loss: tensor(0.8487)\n",
      "31155 Traning Loss: tensor(0.8487)\n",
      "31156 Traning Loss: tensor(0.8487)\n",
      "31157 Traning Loss: tensor(0.8487)\n",
      "31158 Traning Loss: tensor(0.8487)\n",
      "31159 Traning Loss: tensor(0.8487)\n",
      "31160 Traning Loss: tensor(0.8487)\n",
      "31161 Traning Loss: tensor(0.8487)\n",
      "31162 Traning Loss: tensor(0.8487)\n",
      "31163 Traning Loss: tensor(0.8487)\n",
      "31164 Traning Loss: tensor(0.8487)\n",
      "31165 Traning Loss: tensor(0.8487)\n",
      "31166 Traning Loss: tensor(0.8487)\n",
      "31167 Traning Loss: tensor(0.8487)\n",
      "31168 Traning Loss: tensor(0.8487)\n",
      "31169 Traning Loss: tensor(0.8487)\n",
      "31170 Traning Loss: tensor(0.8487)\n",
      "31171 Traning Loss: tensor(0.8487)\n",
      "31172 Traning Loss: tensor(0.8487)\n",
      "31173 Traning Loss: tensor(0.8487)\n",
      "31174 Traning Loss: tensor(0.8487)\n",
      "31175 Traning Loss: tensor(0.8487)\n",
      "31176 Traning Loss: tensor(0.8487)\n",
      "31177 Traning Loss: tensor(0.8487)\n",
      "31178 Traning Loss: tensor(0.8487)\n",
      "31179 Traning Loss: tensor(0.8487)\n",
      "31180 Traning Loss: tensor(0.8487)\n",
      "31181 Traning Loss: tensor(0.8487)\n",
      "31182 Traning Loss: tensor(0.8487)\n",
      "31183 Traning Loss: tensor(0.8487)\n",
      "31184 Traning Loss: tensor(0.8487)\n",
      "31185 Traning Loss: tensor(0.8487)\n",
      "31186 Traning Loss: tensor(0.8487)\n",
      "31187 Traning Loss: tensor(0.8487)\n",
      "31188 Traning Loss: tensor(0.8487)\n",
      "31189 Traning Loss: tensor(0.8487)\n",
      "31190 Traning Loss: tensor(0.8487)\n",
      "31191 Traning Loss: tensor(0.8487)\n",
      "31192 Traning Loss: tensor(0.8487)\n",
      "31193 Traning Loss: tensor(0.8488)\n",
      "31194 Traning Loss: tensor(0.8488)\n",
      "31195 Traning Loss: tensor(0.8488)\n",
      "31196 Traning Loss: tensor(0.8488)\n",
      "31197 Traning Loss: tensor(0.8488)\n",
      "31198 Traning Loss: tensor(0.8487)\n",
      "31199 Traning Loss: tensor(0.8487)\n",
      "31200 Traning Loss: tensor(0.8487)\n",
      "31201 Traning Loss: tensor(0.8487)\n",
      "31202 Traning Loss: tensor(0.8487)\n",
      "31203 Traning Loss: tensor(0.8487)\n",
      "31204 Traning Loss: tensor(0.8487)\n",
      "31205 Traning Loss: tensor(0.8487)\n",
      "31206 Traning Loss: tensor(0.8487)\n",
      "31207 Traning Loss: tensor(0.8487)\n",
      "31208 Traning Loss: tensor(0.8487)\n",
      "31209 Traning Loss: tensor(0.8487)\n",
      "31210 Traning Loss: tensor(0.8487)\n",
      "31211 Traning Loss: tensor(0.8487)\n",
      "31212 Traning Loss: tensor(0.8487)\n",
      "31213 Traning Loss: tensor(0.8487)\n",
      "31214 Traning Loss: tensor(0.8487)\n",
      "31215 Traning Loss: tensor(0.8487)\n",
      "31216 Traning Loss: tensor(0.8487)\n",
      "31217 Traning Loss: tensor(0.8487)\n",
      "31218 Traning Loss: tensor(0.8487)\n",
      "31219 Traning Loss: tensor(0.8487)\n",
      "31220 Traning Loss: tensor(0.8487)\n",
      "31221 Traning Loss: tensor(0.8487)\n",
      "31222 Traning Loss: tensor(0.8487)\n",
      "31223 Traning Loss: tensor(0.8487)\n",
      "31224 Traning Loss: tensor(0.8487)\n",
      "31225 Traning Loss: tensor(0.8487)\n",
      "31226 Traning Loss: tensor(0.8487)\n",
      "31227 Traning Loss: tensor(0.8487)\n",
      "31228 Traning Loss: tensor(0.8487)\n",
      "31229 Traning Loss: tensor(0.8487)\n",
      "31230 Traning Loss: tensor(0.8487)\n",
      "31231 Traning Loss: tensor(0.8487)\n",
      "31232 Traning Loss: tensor(0.8487)\n",
      "31233 Traning Loss: tensor(0.8487)\n",
      "31234 Traning Loss: tensor(0.8487)\n",
      "31235 Traning Loss: tensor(0.8487)\n",
      "31236 Traning Loss: tensor(0.8487)\n",
      "31237 Traning Loss: tensor(0.8487)\n",
      "31238 Traning Loss: tensor(0.8487)\n",
      "31239 Traning Loss: tensor(0.8487)\n",
      "31240 Traning Loss: tensor(0.8487)\n",
      "31241 Traning Loss: tensor(0.8487)\n",
      "31242 Traning Loss: tensor(0.8487)\n",
      "31243 Traning Loss: tensor(0.8487)\n",
      "31244 Traning Loss: tensor(0.8487)\n",
      "31245 Traning Loss: tensor(0.8487)\n",
      "31246 Traning Loss: tensor(0.8487)\n",
      "31247 Traning Loss: tensor(0.8487)\n",
      "31248 Traning Loss: tensor(0.8487)\n",
      "31249 Traning Loss: tensor(0.8487)\n",
      "31250 Traning Loss: tensor(0.8487)\n",
      "31251 Traning Loss: tensor(0.8487)\n",
      "31252 Traning Loss: tensor(0.8487)\n",
      "31253 Traning Loss: tensor(0.8487)\n",
      "31254 Traning Loss: tensor(0.8487)\n",
      "31255 Traning Loss: tensor(0.8487)\n",
      "31256 Traning Loss: tensor(0.8487)\n",
      "31257 Traning Loss: tensor(0.8487)\n",
      "31258 Traning Loss: tensor(0.8487)\n",
      "31259 Traning Loss: tensor(0.8487)\n",
      "31260 Traning Loss: tensor(0.8487)\n",
      "31261 Traning Loss: tensor(0.8487)\n",
      "31262 Traning Loss: tensor(0.8487)\n",
      "31263 Traning Loss: tensor(0.8487)\n",
      "31264 Traning Loss: tensor(0.8487)\n",
      "31265 Traning Loss: tensor(0.8487)\n",
      "31266 Traning Loss: tensor(0.8487)\n",
      "31267 Traning Loss: tensor(0.8487)\n",
      "31268 Traning Loss: tensor(0.8487)\n",
      "31269 Traning Loss: tensor(0.8487)\n",
      "31270 Traning Loss: tensor(0.8487)\n",
      "31271 Traning Loss: tensor(0.8487)\n",
      "31272 Traning Loss: tensor(0.8487)\n",
      "31273 Traning Loss: tensor(0.8487)\n",
      "31274 Traning Loss: tensor(0.8487)\n",
      "31275 Traning Loss: tensor(0.8487)\n",
      "31276 Traning Loss: tensor(0.8487)\n",
      "31277 Traning Loss: tensor(0.8487)\n",
      "31278 Traning Loss: tensor(0.8487)\n",
      "31279 Traning Loss: tensor(0.8487)\n",
      "31280 Traning Loss: tensor(0.8487)\n",
      "31281 Traning Loss: tensor(0.8487)\n",
      "31282 Traning Loss: tensor(0.8487)\n",
      "31283 Traning Loss: tensor(0.8487)\n",
      "31284 Traning Loss: tensor(0.8487)\n",
      "31285 Traning Loss: tensor(0.8487)\n",
      "31286 Traning Loss: tensor(0.8487)\n",
      "31287 Traning Loss: tensor(0.8487)\n",
      "31288 Traning Loss: tensor(0.8487)\n",
      "31289 Traning Loss: tensor(0.8487)\n",
      "31290 Traning Loss: tensor(0.8487)\n",
      "31291 Traning Loss: tensor(0.8487)\n",
      "31292 Traning Loss: tensor(0.8487)\n",
      "31293 Traning Loss: tensor(0.8487)\n",
      "31294 Traning Loss: tensor(0.8487)\n",
      "31295 Traning Loss: tensor(0.8487)\n",
      "31296 Traning Loss: tensor(0.8487)\n",
      "31297 Traning Loss: tensor(0.8487)\n",
      "31298 Traning Loss: tensor(0.8487)\n",
      "31299 Traning Loss: tensor(0.8487)\n",
      "31300 Traning Loss: tensor(0.8487)\n",
      "31301 Traning Loss: tensor(0.8487)\n",
      "31302 Traning Loss: tensor(0.8487)\n",
      "31303 Traning Loss: tensor(0.8487)\n",
      "31304 Traning Loss: tensor(0.8487)\n",
      "31305 Traning Loss: tensor(0.8487)\n",
      "31306 Traning Loss: tensor(0.8487)\n",
      "31307 Traning Loss: tensor(0.8487)\n",
      "31308 Traning Loss: tensor(0.8487)\n",
      "31309 Traning Loss: tensor(0.8487)\n",
      "31310 Traning Loss: tensor(0.8487)\n",
      "31311 Traning Loss: tensor(0.8487)\n",
      "31312 Traning Loss: tensor(0.8487)\n",
      "31313 Traning Loss: tensor(0.8487)\n",
      "31314 Traning Loss: tensor(0.8487)\n",
      "31315 Traning Loss: tensor(0.8487)\n",
      "31316 Traning Loss: tensor(0.8487)\n",
      "31317 Traning Loss: tensor(0.8487)\n",
      "31318 Traning Loss: tensor(0.8487)\n",
      "31319 Traning Loss: tensor(0.8487)\n",
      "31320 Traning Loss: tensor(0.8487)\n",
      "31321 Traning Loss: tensor(0.8487)\n",
      "31322 Traning Loss: tensor(0.8487)\n",
      "31323 Traning Loss: tensor(0.8487)\n",
      "31324 Traning Loss: tensor(0.8487)\n",
      "31325 Traning Loss: tensor(0.8487)\n",
      "31326 Traning Loss: tensor(0.8487)\n",
      "31327 Traning Loss: tensor(0.8487)\n",
      "31328 Traning Loss: tensor(0.8487)\n",
      "31329 Traning Loss: tensor(0.8487)\n",
      "31330 Traning Loss: tensor(0.8487)\n",
      "31331 Traning Loss: tensor(0.8487)\n",
      "31332 Traning Loss: tensor(0.8487)\n",
      "31333 Traning Loss: tensor(0.8487)\n",
      "31334 Traning Loss: tensor(0.8487)\n",
      "31335 Traning Loss: tensor(0.8487)\n",
      "31336 Traning Loss: tensor(0.8487)\n",
      "31337 Traning Loss: tensor(0.8487)\n",
      "31338 Traning Loss: tensor(0.8487)\n",
      "31339 Traning Loss: tensor(0.8487)\n",
      "31340 Traning Loss: tensor(0.8487)\n",
      "31341 Traning Loss: tensor(0.8487)\n",
      "31342 Traning Loss: tensor(0.8487)\n",
      "31343 Traning Loss: tensor(0.8487)\n",
      "31344 Traning Loss: tensor(0.8487)\n",
      "31345 Traning Loss: tensor(0.8487)\n",
      "31346 Traning Loss: tensor(0.8487)\n",
      "31347 Traning Loss: tensor(0.8487)\n",
      "31348 Traning Loss: tensor(0.8487)\n",
      "31349 Traning Loss: tensor(0.8487)\n",
      "31350 Traning Loss: tensor(0.8487)\n",
      "31351 Traning Loss: tensor(0.8487)\n",
      "31352 Traning Loss: tensor(0.8487)\n",
      "31353 Traning Loss: tensor(0.8487)\n",
      "31354 Traning Loss: tensor(0.8487)\n",
      "31355 Traning Loss: tensor(0.8487)\n",
      "31356 Traning Loss: tensor(0.8487)\n",
      "31357 Traning Loss: tensor(0.8487)\n",
      "31358 Traning Loss: tensor(0.8487)\n",
      "31359 Traning Loss: tensor(0.8487)\n",
      "31360 Traning Loss: tensor(0.8487)\n",
      "31361 Traning Loss: tensor(0.8487)\n",
      "31362 Traning Loss: tensor(0.8487)\n",
      "31363 Traning Loss: tensor(0.8487)\n",
      "31364 Traning Loss: tensor(0.8487)\n",
      "31365 Traning Loss: tensor(0.8487)\n",
      "31366 Traning Loss: tensor(0.8487)\n",
      "31367 Traning Loss: tensor(0.8487)\n",
      "31368 Traning Loss: tensor(0.8487)\n",
      "31369 Traning Loss: tensor(0.8487)\n",
      "31370 Traning Loss: tensor(0.8487)\n",
      "31371 Traning Loss: tensor(0.8487)\n",
      "31372 Traning Loss: tensor(0.8487)\n",
      "31373 Traning Loss: tensor(0.8487)\n",
      "31374 Traning Loss: tensor(0.8487)\n",
      "31375 Traning Loss: tensor(0.8487)\n",
      "31376 Traning Loss: tensor(0.8487)\n",
      "31377 Traning Loss: tensor(0.8487)\n",
      "31378 Traning Loss: tensor(0.8487)\n",
      "31379 Traning Loss: tensor(0.8487)\n",
      "31380 Traning Loss: tensor(0.8487)\n",
      "31381 Traning Loss: tensor(0.8487)\n",
      "31382 Traning Loss: tensor(0.8487)\n",
      "31383 Traning Loss: tensor(0.8487)\n",
      "31384 Traning Loss: tensor(0.8487)\n",
      "31385 Traning Loss: tensor(0.8487)\n",
      "31386 Traning Loss: tensor(0.8487)\n",
      "31387 Traning Loss: tensor(0.8487)\n",
      "31388 Traning Loss: tensor(0.8487)\n",
      "31389 Traning Loss: tensor(0.8487)\n",
      "31390 Traning Loss: tensor(0.8487)\n",
      "31391 Traning Loss: tensor(0.8487)\n",
      "31392 Traning Loss: tensor(0.8487)\n",
      "31393 Traning Loss: tensor(0.8487)\n",
      "31394 Traning Loss: tensor(0.8487)\n",
      "31395 Traning Loss: tensor(0.8487)\n",
      "31396 Traning Loss: tensor(0.8487)\n",
      "31397 Traning Loss: tensor(0.8487)\n",
      "31398 Traning Loss: tensor(0.8487)\n",
      "31399 Traning Loss: tensor(0.8487)\n",
      "31400 Traning Loss: tensor(0.8487)\n",
      "31401 Traning Loss: tensor(0.8487)\n",
      "31402 Traning Loss: tensor(0.8487)\n",
      "31403 Traning Loss: tensor(0.8487)\n",
      "31404 Traning Loss: tensor(0.8487)\n",
      "31405 Traning Loss: tensor(0.8487)\n",
      "31406 Traning Loss: tensor(0.8487)\n",
      "31407 Traning Loss: tensor(0.8487)\n",
      "31408 Traning Loss: tensor(0.8487)\n",
      "31409 Traning Loss: tensor(0.8487)\n",
      "31410 Traning Loss: tensor(0.8487)\n",
      "31411 Traning Loss: tensor(0.8487)\n",
      "31412 Traning Loss: tensor(0.8487)\n",
      "31413 Traning Loss: tensor(0.8487)\n",
      "31414 Traning Loss: tensor(0.8487)\n",
      "31415 Traning Loss: tensor(0.8487)\n",
      "31416 Traning Loss: tensor(0.8487)\n",
      "31417 Traning Loss: tensor(0.8487)\n",
      "31418 Traning Loss: tensor(0.8487)\n",
      "31419 Traning Loss: tensor(0.8487)\n",
      "31420 Traning Loss: tensor(0.8487)\n",
      "31421 Traning Loss: tensor(0.8487)\n",
      "31422 Traning Loss: tensor(0.8487)\n",
      "31423 Traning Loss: tensor(0.8487)\n",
      "31424 Traning Loss: tensor(0.8487)\n",
      "31425 Traning Loss: tensor(0.8487)\n",
      "31426 Traning Loss: tensor(0.8487)\n",
      "31427 Traning Loss: tensor(0.8487)\n",
      "31428 Traning Loss: tensor(0.8487)\n",
      "31429 Traning Loss: tensor(0.8487)\n",
      "31430 Traning Loss: tensor(0.8487)\n",
      "31431 Traning Loss: tensor(0.8487)\n",
      "31432 Traning Loss: tensor(0.8487)\n",
      "31433 Traning Loss: tensor(0.8487)\n",
      "31434 Traning Loss: tensor(0.8487)\n",
      "31435 Traning Loss: tensor(0.8488)\n",
      "31436 Traning Loss: tensor(0.8488)\n",
      "31437 Traning Loss: tensor(0.8488)\n",
      "31438 Traning Loss: tensor(0.8488)\n",
      "31439 Traning Loss: tensor(0.8488)\n",
      "31440 Traning Loss: tensor(0.8487)\n",
      "31441 Traning Loss: tensor(0.8487)\n",
      "31442 Traning Loss: tensor(0.8487)\n",
      "31443 Traning Loss: tensor(0.8487)\n",
      "31444 Traning Loss: tensor(0.8487)\n",
      "31445 Traning Loss: tensor(0.8487)\n",
      "31446 Traning Loss: tensor(0.8487)\n",
      "31447 Traning Loss: tensor(0.8487)\n",
      "31448 Traning Loss: tensor(0.8487)\n",
      "31449 Traning Loss: tensor(0.8487)\n",
      "31450 Traning Loss: tensor(0.8487)\n",
      "31451 Traning Loss: tensor(0.8487)\n",
      "31452 Traning Loss: tensor(0.8487)\n",
      "31453 Traning Loss: tensor(0.8487)\n",
      "31454 Traning Loss: tensor(0.8487)\n",
      "31455 Traning Loss: tensor(0.8487)\n",
      "31456 Traning Loss: tensor(0.8487)\n",
      "31457 Traning Loss: tensor(0.8487)\n",
      "31458 Traning Loss: tensor(0.8487)\n",
      "31459 Traning Loss: tensor(0.8487)\n",
      "31460 Traning Loss: tensor(0.8487)\n",
      "31461 Traning Loss: tensor(0.8487)\n",
      "31462 Traning Loss: tensor(0.8487)\n",
      "31463 Traning Loss: tensor(0.8487)\n",
      "31464 Traning Loss: tensor(0.8487)\n",
      "31465 Traning Loss: tensor(0.8487)\n",
      "31466 Traning Loss: tensor(0.8487)\n",
      "31467 Traning Loss: tensor(0.8487)\n",
      "31468 Traning Loss: tensor(0.8487)\n",
      "31469 Traning Loss: tensor(0.8487)\n",
      "31470 Traning Loss: tensor(0.8487)\n",
      "31471 Traning Loss: tensor(0.8487)\n",
      "31472 Traning Loss: tensor(0.8487)\n",
      "31473 Traning Loss: tensor(0.8487)\n",
      "31474 Traning Loss: tensor(0.8487)\n",
      "31475 Traning Loss: tensor(0.8487)\n",
      "31476 Traning Loss: tensor(0.8487)\n",
      "31477 Traning Loss: tensor(0.8487)\n",
      "31478 Traning Loss: tensor(0.8487)\n",
      "31479 Traning Loss: tensor(0.8487)\n",
      "31480 Traning Loss: tensor(0.8487)\n",
      "31481 Traning Loss: tensor(0.8487)\n",
      "31482 Traning Loss: tensor(0.8487)\n",
      "31483 Traning Loss: tensor(0.8487)\n",
      "31484 Traning Loss: tensor(0.8487)\n",
      "31485 Traning Loss: tensor(0.8487)\n",
      "31486 Traning Loss: tensor(0.8487)\n",
      "31487 Traning Loss: tensor(0.8487)\n",
      "31488 Traning Loss: tensor(0.8487)\n",
      "31489 Traning Loss: tensor(0.8487)\n",
      "31490 Traning Loss: tensor(0.8487)\n",
      "31491 Traning Loss: tensor(0.8487)\n",
      "31492 Traning Loss: tensor(0.8487)\n",
      "31493 Traning Loss: tensor(0.8487)\n",
      "31494 Traning Loss: tensor(0.8487)\n",
      "31495 Traning Loss: tensor(0.8487)\n",
      "31496 Traning Loss: tensor(0.8487)\n",
      "31497 Traning Loss: tensor(0.8487)\n",
      "31498 Traning Loss: tensor(0.8487)\n",
      "31499 Traning Loss: tensor(0.8487)\n",
      "31500 Traning Loss: tensor(0.8487)\n",
      "31501 Traning Loss: tensor(0.8487)\n",
      "31502 Traning Loss: tensor(0.8487)\n",
      "31503 Traning Loss: tensor(0.8487)\n",
      "31504 Traning Loss: tensor(0.8487)\n",
      "31505 Traning Loss: tensor(0.8487)\n",
      "31506 Traning Loss: tensor(0.8487)\n",
      "31507 Traning Loss: tensor(0.8487)\n",
      "31508 Traning Loss: tensor(0.8487)\n",
      "31509 Traning Loss: tensor(0.8487)\n",
      "31510 Traning Loss: tensor(0.8487)\n",
      "31511 Traning Loss: tensor(0.8487)\n",
      "31512 Traning Loss: tensor(0.8487)\n",
      "31513 Traning Loss: tensor(0.8487)\n",
      "31514 Traning Loss: tensor(0.8487)\n",
      "31515 Traning Loss: tensor(0.8487)\n",
      "31516 Traning Loss: tensor(0.8487)\n",
      "31517 Traning Loss: tensor(0.8487)\n",
      "31518 Traning Loss: tensor(0.8487)\n",
      "31519 Traning Loss: tensor(0.8487)\n",
      "31520 Traning Loss: tensor(0.8487)\n",
      "31521 Traning Loss: tensor(0.8487)\n",
      "31522 Traning Loss: tensor(0.8487)\n",
      "31523 Traning Loss: tensor(0.8487)\n",
      "31524 Traning Loss: tensor(0.8487)\n",
      "31525 Traning Loss: tensor(0.8487)\n",
      "31526 Traning Loss: tensor(0.8487)\n",
      "31527 Traning Loss: tensor(0.8487)\n",
      "31528 Traning Loss: tensor(0.8487)\n",
      "31529 Traning Loss: tensor(0.8487)\n",
      "31530 Traning Loss: tensor(0.8487)\n",
      "31531 Traning Loss: tensor(0.8487)\n",
      "31532 Traning Loss: tensor(0.8487)\n",
      "31533 Traning Loss: tensor(0.8487)\n",
      "31534 Traning Loss: tensor(0.8487)\n",
      "31535 Traning Loss: tensor(0.8487)\n",
      "31536 Traning Loss: tensor(0.8487)\n",
      "31537 Traning Loss: tensor(0.8487)\n",
      "31538 Traning Loss: tensor(0.8487)\n",
      "31539 Traning Loss: tensor(0.8487)\n",
      "31540 Traning Loss: tensor(0.8487)\n",
      "31541 Traning Loss: tensor(0.8487)\n",
      "31542 Traning Loss: tensor(0.8487)\n",
      "31543 Traning Loss: tensor(0.8487)\n",
      "31544 Traning Loss: tensor(0.8487)\n",
      "31545 Traning Loss: tensor(0.8487)\n",
      "31546 Traning Loss: tensor(0.8487)\n",
      "31547 Traning Loss: tensor(0.8487)\n",
      "31548 Traning Loss: tensor(0.8487)\n",
      "31549 Traning Loss: tensor(0.8487)\n",
      "31550 Traning Loss: tensor(0.8487)\n",
      "31551 Traning Loss: tensor(0.8487)\n",
      "31552 Traning Loss: tensor(0.8487)\n",
      "31553 Traning Loss: tensor(0.8487)\n",
      "31554 Traning Loss: tensor(0.8487)\n",
      "31555 Traning Loss: tensor(0.8487)\n",
      "31556 Traning Loss: tensor(0.8487)\n",
      "31557 Traning Loss: tensor(0.8487)\n",
      "31558 Traning Loss: tensor(0.8487)\n",
      "31559 Traning Loss: tensor(0.8487)\n",
      "31560 Traning Loss: tensor(0.8487)\n",
      "31561 Traning Loss: tensor(0.8487)\n",
      "31562 Traning Loss: tensor(0.8487)\n",
      "31563 Traning Loss: tensor(0.8487)\n",
      "31564 Traning Loss: tensor(0.8487)\n",
      "31565 Traning Loss: tensor(0.8487)\n",
      "31566 Traning Loss: tensor(0.8487)\n",
      "31567 Traning Loss: tensor(0.8487)\n",
      "31568 Traning Loss: tensor(0.8487)\n",
      "31569 Traning Loss: tensor(0.8487)\n",
      "31570 Traning Loss: tensor(0.8487)\n",
      "31571 Traning Loss: tensor(0.8487)\n",
      "31572 Traning Loss: tensor(0.8487)\n",
      "31573 Traning Loss: tensor(0.8487)\n",
      "31574 Traning Loss: tensor(0.8487)\n",
      "31575 Traning Loss: tensor(0.8487)\n",
      "31576 Traning Loss: tensor(0.8487)\n",
      "31577 Traning Loss: tensor(0.8487)\n",
      "31578 Traning Loss: tensor(0.8487)\n",
      "31579 Traning Loss: tensor(0.8487)\n",
      "31580 Traning Loss: tensor(0.8487)\n",
      "31581 Traning Loss: tensor(0.8487)\n",
      "31582 Traning Loss: tensor(0.8487)\n",
      "31583 Traning Loss: tensor(0.8487)\n",
      "31584 Traning Loss: tensor(0.8487)\n",
      "31585 Traning Loss: tensor(0.8487)\n",
      "31586 Traning Loss: tensor(0.8487)\n",
      "31587 Traning Loss: tensor(0.8487)\n",
      "31588 Traning Loss: tensor(0.8487)\n",
      "31589 Traning Loss: tensor(0.8487)\n",
      "31590 Traning Loss: tensor(0.8487)\n",
      "31591 Traning Loss: tensor(0.8487)\n",
      "31592 Traning Loss: tensor(0.8487)\n",
      "31593 Traning Loss: tensor(0.8487)\n",
      "31594 Traning Loss: tensor(0.8487)\n",
      "31595 Traning Loss: tensor(0.8487)\n",
      "31596 Traning Loss: tensor(0.8487)\n",
      "31597 Traning Loss: tensor(0.8487)\n",
      "31598 Traning Loss: tensor(0.8487)\n",
      "31599 Traning Loss: tensor(0.8487)\n",
      "31600 Traning Loss: tensor(0.8487)\n",
      "31601 Traning Loss: tensor(0.8487)\n",
      "31602 Traning Loss: tensor(0.8487)\n",
      "31603 Traning Loss: tensor(0.8487)\n",
      "31604 Traning Loss: tensor(0.8487)\n",
      "31605 Traning Loss: tensor(0.8487)\n",
      "31606 Traning Loss: tensor(0.8487)\n",
      "31607 Traning Loss: tensor(0.8487)\n",
      "31608 Traning Loss: tensor(0.8487)\n",
      "31609 Traning Loss: tensor(0.8487)\n",
      "31610 Traning Loss: tensor(0.8487)\n",
      "31611 Traning Loss: tensor(0.8487)\n",
      "31612 Traning Loss: tensor(0.8487)\n",
      "31613 Traning Loss: tensor(0.8487)\n",
      "31614 Traning Loss: tensor(0.8487)\n",
      "31615 Traning Loss: tensor(0.8487)\n",
      "31616 Traning Loss: tensor(0.8487)\n",
      "31617 Traning Loss: tensor(0.8487)\n",
      "31618 Traning Loss: tensor(0.8487)\n",
      "31619 Traning Loss: tensor(0.8487)\n",
      "31620 Traning Loss: tensor(0.8487)\n",
      "31621 Traning Loss: tensor(0.8487)\n",
      "31622 Traning Loss: tensor(0.8487)\n",
      "31623 Traning Loss: tensor(0.8487)\n",
      "31624 Traning Loss: tensor(0.8487)\n",
      "31625 Traning Loss: tensor(0.8487)\n",
      "31626 Traning Loss: tensor(0.8487)\n",
      "31627 Traning Loss: tensor(0.8487)\n",
      "31628 Traning Loss: tensor(0.8487)\n",
      "31629 Traning Loss: tensor(0.8487)\n",
      "31630 Traning Loss: tensor(0.8487)\n",
      "31631 Traning Loss: tensor(0.8487)\n",
      "31632 Traning Loss: tensor(0.8487)\n",
      "31633 Traning Loss: tensor(0.8487)\n",
      "31634 Traning Loss: tensor(0.8487)\n",
      "31635 Traning Loss: tensor(0.8487)\n",
      "31636 Traning Loss: tensor(0.8487)\n",
      "31637 Traning Loss: tensor(0.8487)\n",
      "31638 Traning Loss: tensor(0.8487)\n",
      "31639 Traning Loss: tensor(0.8487)\n",
      "31640 Traning Loss: tensor(0.8487)\n",
      "31641 Traning Loss: tensor(0.8487)\n",
      "31642 Traning Loss: tensor(0.8487)\n",
      "31643 Traning Loss: tensor(0.8487)\n",
      "31644 Traning Loss: tensor(0.8487)\n",
      "31645 Traning Loss: tensor(0.8487)\n",
      "31646 Traning Loss: tensor(0.8487)\n",
      "31647 Traning Loss: tensor(0.8487)\n",
      "31648 Traning Loss: tensor(0.8487)\n",
      "31649 Traning Loss: tensor(0.8487)\n",
      "31650 Traning Loss: tensor(0.8487)\n",
      "31651 Traning Loss: tensor(0.8487)\n",
      "31652 Traning Loss: tensor(0.8487)\n",
      "31653 Traning Loss: tensor(0.8487)\n",
      "31654 Traning Loss: tensor(0.8487)\n",
      "31655 Traning Loss: tensor(0.8487)\n",
      "31656 Traning Loss: tensor(0.8487)\n",
      "31657 Traning Loss: tensor(0.8487)\n",
      "31658 Traning Loss: tensor(0.8487)\n",
      "31659 Traning Loss: tensor(0.8487)\n",
      "31660 Traning Loss: tensor(0.8487)\n",
      "31661 Traning Loss: tensor(0.8487)\n",
      "31662 Traning Loss: tensor(0.8487)\n",
      "31663 Traning Loss: tensor(0.8487)\n",
      "31664 Traning Loss: tensor(0.8487)\n",
      "31665 Traning Loss: tensor(0.8487)\n",
      "31666 Traning Loss: tensor(0.8487)\n",
      "31667 Traning Loss: tensor(0.8487)\n",
      "31668 Traning Loss: tensor(0.8487)\n",
      "31669 Traning Loss: tensor(0.8487)\n",
      "31670 Traning Loss: tensor(0.8487)\n",
      "31671 Traning Loss: tensor(0.8487)\n",
      "31672 Traning Loss: tensor(0.8487)\n",
      "31673 Traning Loss: tensor(0.8487)\n",
      "31674 Traning Loss: tensor(0.8487)\n",
      "31675 Traning Loss: tensor(0.8487)\n",
      "31676 Traning Loss: tensor(0.8487)\n",
      "31677 Traning Loss: tensor(0.8487)\n",
      "31678 Traning Loss: tensor(0.8487)\n",
      "31679 Traning Loss: tensor(0.8487)\n",
      "31680 Traning Loss: tensor(0.8487)\n",
      "31681 Traning Loss: tensor(0.8487)\n",
      "31682 Traning Loss: tensor(0.8487)\n",
      "31683 Traning Loss: tensor(0.8487)\n",
      "31684 Traning Loss: tensor(0.8487)\n",
      "31685 Traning Loss: tensor(0.8487)\n",
      "31686 Traning Loss: tensor(0.8487)\n",
      "31687 Traning Loss: tensor(0.8487)\n",
      "31688 Traning Loss: tensor(0.8487)\n",
      "31689 Traning Loss: tensor(0.8487)\n",
      "31690 Traning Loss: tensor(0.8487)\n",
      "31691 Traning Loss: tensor(0.8487)\n",
      "31692 Traning Loss: tensor(0.8487)\n",
      "31693 Traning Loss: tensor(0.8487)\n",
      "31694 Traning Loss: tensor(0.8487)\n",
      "31695 Traning Loss: tensor(0.8487)\n",
      "31696 Traning Loss: tensor(0.8487)\n",
      "31697 Traning Loss: tensor(0.8487)\n",
      "31698 Traning Loss: tensor(0.8487)\n",
      "31699 Traning Loss: tensor(0.8487)\n",
      "31700 Traning Loss: tensor(0.8487)\n",
      "31701 Traning Loss: tensor(0.8487)\n",
      "31702 Traning Loss: tensor(0.8487)\n",
      "31703 Traning Loss: tensor(0.8487)\n",
      "31704 Traning Loss: tensor(0.8487)\n",
      "31705 Traning Loss: tensor(0.8487)\n",
      "31706 Traning Loss: tensor(0.8487)\n",
      "31707 Traning Loss: tensor(0.8487)\n",
      "31708 Traning Loss: tensor(0.8487)\n",
      "31709 Traning Loss: tensor(0.8488)\n",
      "31710 Traning Loss: tensor(0.8488)\n",
      "31711 Traning Loss: tensor(0.8488)\n",
      "31712 Traning Loss: tensor(0.8488)\n",
      "31713 Traning Loss: tensor(0.8488)\n",
      "31714 Traning Loss: tensor(0.8487)\n",
      "31715 Traning Loss: tensor(0.8487)\n",
      "31716 Traning Loss: tensor(0.8487)\n",
      "31717 Traning Loss: tensor(0.8487)\n",
      "31718 Traning Loss: tensor(0.8487)\n",
      "31719 Traning Loss: tensor(0.8487)\n",
      "31720 Traning Loss: tensor(0.8487)\n",
      "31721 Traning Loss: tensor(0.8487)\n",
      "31722 Traning Loss: tensor(0.8487)\n",
      "31723 Traning Loss: tensor(0.8487)\n",
      "31724 Traning Loss: tensor(0.8487)\n",
      "31725 Traning Loss: tensor(0.8487)\n",
      "31726 Traning Loss: tensor(0.8487)\n",
      "31727 Traning Loss: tensor(0.8487)\n",
      "31728 Traning Loss: tensor(0.8487)\n",
      "31729 Traning Loss: tensor(0.8487)\n",
      "31730 Traning Loss: tensor(0.8487)\n",
      "31731 Traning Loss: tensor(0.8487)\n",
      "31732 Traning Loss: tensor(0.8487)\n",
      "31733 Traning Loss: tensor(0.8487)\n",
      "31734 Traning Loss: tensor(0.8487)\n",
      "31735 Traning Loss: tensor(0.8487)\n",
      "31736 Traning Loss: tensor(0.8487)\n",
      "31737 Traning Loss: tensor(0.8487)\n",
      "31738 Traning Loss: tensor(0.8487)\n",
      "31739 Traning Loss: tensor(0.8487)\n",
      "31740 Traning Loss: tensor(0.8487)\n",
      "31741 Traning Loss: tensor(0.8487)\n",
      "31742 Traning Loss: tensor(0.8487)\n",
      "31743 Traning Loss: tensor(0.8487)\n",
      "31744 Traning Loss: tensor(0.8487)\n",
      "31745 Traning Loss: tensor(0.8487)\n",
      "31746 Traning Loss: tensor(0.8487)\n",
      "31747 Traning Loss: tensor(0.8487)\n",
      "31748 Traning Loss: tensor(0.8487)\n",
      "31749 Traning Loss: tensor(0.8487)\n",
      "31750 Traning Loss: tensor(0.8487)\n",
      "31751 Traning Loss: tensor(0.8487)\n",
      "31752 Traning Loss: tensor(0.8487)\n",
      "31753 Traning Loss: tensor(0.8487)\n",
      "31754 Traning Loss: tensor(0.8487)\n",
      "31755 Traning Loss: tensor(0.8487)\n",
      "31756 Traning Loss: tensor(0.8487)\n",
      "31757 Traning Loss: tensor(0.8487)\n",
      "31758 Traning Loss: tensor(0.8487)\n",
      "31759 Traning Loss: tensor(0.8487)\n",
      "31760 Traning Loss: tensor(0.8487)\n",
      "31761 Traning Loss: tensor(0.8487)\n",
      "31762 Traning Loss: tensor(0.8487)\n",
      "31763 Traning Loss: tensor(0.8487)\n",
      "31764 Traning Loss: tensor(0.8487)\n",
      "31765 Traning Loss: tensor(0.8487)\n",
      "31766 Traning Loss: tensor(0.8487)\n",
      "31767 Traning Loss: tensor(0.8487)\n",
      "31768 Traning Loss: tensor(0.8487)\n",
      "31769 Traning Loss: tensor(0.8487)\n",
      "31770 Traning Loss: tensor(0.8487)\n",
      "31771 Traning Loss: tensor(0.8487)\n",
      "31772 Traning Loss: tensor(0.8487)\n",
      "31773 Traning Loss: tensor(0.8487)\n",
      "31774 Traning Loss: tensor(0.8487)\n",
      "31775 Traning Loss: tensor(0.8487)\n",
      "31776 Traning Loss: tensor(0.8487)\n",
      "31777 Traning Loss: tensor(0.8487)\n",
      "31778 Traning Loss: tensor(0.8487)\n",
      "31779 Traning Loss: tensor(0.8487)\n",
      "31780 Traning Loss: tensor(0.8487)\n",
      "31781 Traning Loss: tensor(0.8487)\n",
      "31782 Traning Loss: tensor(0.8487)\n",
      "31783 Traning Loss: tensor(0.8487)\n",
      "31784 Traning Loss: tensor(0.8487)\n",
      "31785 Traning Loss: tensor(0.8487)\n",
      "31786 Traning Loss: tensor(0.8487)\n",
      "31787 Traning Loss: tensor(0.8487)\n",
      "31788 Traning Loss: tensor(0.8487)\n",
      "31789 Traning Loss: tensor(0.8487)\n",
      "31790 Traning Loss: tensor(0.8487)\n",
      "31791 Traning Loss: tensor(0.8487)\n",
      "31792 Traning Loss: tensor(0.8487)\n",
      "31793 Traning Loss: tensor(0.8487)\n",
      "31794 Traning Loss: tensor(0.8487)\n",
      "31795 Traning Loss: tensor(0.8487)\n",
      "31796 Traning Loss: tensor(0.8487)\n",
      "31797 Traning Loss: tensor(0.8487)\n",
      "31798 Traning Loss: tensor(0.8487)\n",
      "31799 Traning Loss: tensor(0.8487)\n",
      "31800 Traning Loss: tensor(0.8487)\n",
      "31801 Traning Loss: tensor(0.8487)\n",
      "31802 Traning Loss: tensor(0.8487)\n",
      "31803 Traning Loss: tensor(0.8487)\n",
      "31804 Traning Loss: tensor(0.8487)\n",
      "31805 Traning Loss: tensor(0.8487)\n",
      "31806 Traning Loss: tensor(0.8487)\n",
      "31807 Traning Loss: tensor(0.8487)\n",
      "31808 Traning Loss: tensor(0.8487)\n",
      "31809 Traning Loss: tensor(0.8487)\n",
      "31810 Traning Loss: tensor(0.8487)\n",
      "31811 Traning Loss: tensor(0.8487)\n",
      "31812 Traning Loss: tensor(0.8487)\n",
      "31813 Traning Loss: tensor(0.8487)\n",
      "31814 Traning Loss: tensor(0.8487)\n",
      "31815 Traning Loss: tensor(0.8487)\n",
      "31816 Traning Loss: tensor(0.8487)\n",
      "31817 Traning Loss: tensor(0.8487)\n",
      "31818 Traning Loss: tensor(0.8487)\n",
      "31819 Traning Loss: tensor(0.8487)\n",
      "31820 Traning Loss: tensor(0.8487)\n",
      "31821 Traning Loss: tensor(0.8487)\n",
      "31822 Traning Loss: tensor(0.8487)\n",
      "31823 Traning Loss: tensor(0.8487)\n",
      "31824 Traning Loss: tensor(0.8487)\n",
      "31825 Traning Loss: tensor(0.8487)\n",
      "31826 Traning Loss: tensor(0.8487)\n",
      "31827 Traning Loss: tensor(0.8487)\n",
      "31828 Traning Loss: tensor(0.8487)\n",
      "31829 Traning Loss: tensor(0.8487)\n",
      "31830 Traning Loss: tensor(0.8487)\n",
      "31831 Traning Loss: tensor(0.8487)\n",
      "31832 Traning Loss: tensor(0.8487)\n",
      "31833 Traning Loss: tensor(0.8487)\n",
      "31834 Traning Loss: tensor(0.8487)\n",
      "31835 Traning Loss: tensor(0.8487)\n",
      "31836 Traning Loss: tensor(0.8487)\n",
      "31837 Traning Loss: tensor(0.8487)\n",
      "31838 Traning Loss: tensor(0.8487)\n",
      "31839 Traning Loss: tensor(0.8487)\n",
      "31840 Traning Loss: tensor(0.8487)\n",
      "31841 Traning Loss: tensor(0.8487)\n",
      "31842 Traning Loss: tensor(0.8487)\n",
      "31843 Traning Loss: tensor(0.8487)\n",
      "31844 Traning Loss: tensor(0.8487)\n",
      "31845 Traning Loss: tensor(0.8487)\n",
      "31846 Traning Loss: tensor(0.8487)\n",
      "31847 Traning Loss: tensor(0.8487)\n",
      "31848 Traning Loss: tensor(0.8487)\n",
      "31849 Traning Loss: tensor(0.8487)\n",
      "31850 Traning Loss: tensor(0.8487)\n",
      "31851 Traning Loss: tensor(0.8487)\n",
      "31852 Traning Loss: tensor(0.8487)\n",
      "31853 Traning Loss: tensor(0.8487)\n",
      "31854 Traning Loss: tensor(0.8487)\n",
      "31855 Traning Loss: tensor(0.8487)\n",
      "31856 Traning Loss: tensor(0.8487)\n",
      "31857 Traning Loss: tensor(0.8487)\n",
      "31858 Traning Loss: tensor(0.8487)\n",
      "31859 Traning Loss: tensor(0.8487)\n",
      "31860 Traning Loss: tensor(0.8487)\n",
      "31861 Traning Loss: tensor(0.8487)\n",
      "31862 Traning Loss: tensor(0.8487)\n",
      "31863 Traning Loss: tensor(0.8487)\n",
      "31864 Traning Loss: tensor(0.8487)\n",
      "31865 Traning Loss: tensor(0.8487)\n",
      "31866 Traning Loss: tensor(0.8487)\n",
      "31867 Traning Loss: tensor(0.8487)\n",
      "31868 Traning Loss: tensor(0.8487)\n",
      "31869 Traning Loss: tensor(0.8487)\n",
      "31870 Traning Loss: tensor(0.8487)\n",
      "31871 Traning Loss: tensor(0.8487)\n",
      "31872 Traning Loss: tensor(0.8487)\n",
      "31873 Traning Loss: tensor(0.8487)\n",
      "31874 Traning Loss: tensor(0.8487)\n",
      "31875 Traning Loss: tensor(0.8487)\n",
      "31876 Traning Loss: tensor(0.8487)\n",
      "31877 Traning Loss: tensor(0.8487)\n",
      "31878 Traning Loss: tensor(0.8487)\n",
      "31879 Traning Loss: tensor(0.8487)\n",
      "31880 Traning Loss: tensor(0.8487)\n",
      "31881 Traning Loss: tensor(0.8487)\n",
      "31882 Traning Loss: tensor(0.8487)\n",
      "31883 Traning Loss: tensor(0.8487)\n",
      "31884 Traning Loss: tensor(0.8487)\n",
      "31885 Traning Loss: tensor(0.8487)\n",
      "31886 Traning Loss: tensor(0.8487)\n",
      "31887 Traning Loss: tensor(0.8487)\n",
      "31888 Traning Loss: tensor(0.8487)\n",
      "31889 Traning Loss: tensor(0.8487)\n",
      "31890 Traning Loss: tensor(0.8487)\n",
      "31891 Traning Loss: tensor(0.8487)\n",
      "31892 Traning Loss: tensor(0.8487)\n",
      "31893 Traning Loss: tensor(0.8487)\n",
      "31894 Traning Loss: tensor(0.8487)\n",
      "31895 Traning Loss: tensor(0.8487)\n",
      "31896 Traning Loss: tensor(0.8487)\n",
      "31897 Traning Loss: tensor(0.8487)\n",
      "31898 Traning Loss: tensor(0.8487)\n",
      "31899 Traning Loss: tensor(0.8487)\n",
      "31900 Traning Loss: tensor(0.8487)\n",
      "31901 Traning Loss: tensor(0.8487)\n",
      "31902 Traning Loss: tensor(0.8487)\n",
      "31903 Traning Loss: tensor(0.8487)\n",
      "31904 Traning Loss: tensor(0.8487)\n",
      "31905 Traning Loss: tensor(0.8487)\n",
      "31906 Traning Loss: tensor(0.8487)\n",
      "31907 Traning Loss: tensor(0.8487)\n",
      "31908 Traning Loss: tensor(0.8487)\n",
      "31909 Traning Loss: tensor(0.8487)\n",
      "31910 Traning Loss: tensor(0.8487)\n",
      "31911 Traning Loss: tensor(0.8487)\n",
      "31912 Traning Loss: tensor(0.8487)\n",
      "31913 Traning Loss: tensor(0.8487)\n",
      "31914 Traning Loss: tensor(0.8487)\n",
      "31915 Traning Loss: tensor(0.8487)\n",
      "31916 Traning Loss: tensor(0.8487)\n",
      "31917 Traning Loss: tensor(0.8487)\n",
      "31918 Traning Loss: tensor(0.8487)\n",
      "31919 Traning Loss: tensor(0.8487)\n",
      "31920 Traning Loss: tensor(0.8487)\n",
      "31921 Traning Loss: tensor(0.8487)\n",
      "31922 Traning Loss: tensor(0.8487)\n",
      "31923 Traning Loss: tensor(0.8487)\n",
      "31924 Traning Loss: tensor(0.8487)\n",
      "31925 Traning Loss: tensor(0.8487)\n",
      "31926 Traning Loss: tensor(0.8487)\n",
      "31927 Traning Loss: tensor(0.8487)\n",
      "31928 Traning Loss: tensor(0.8487)\n",
      "31929 Traning Loss: tensor(0.8487)\n",
      "31930 Traning Loss: tensor(0.8487)\n",
      "31931 Traning Loss: tensor(0.8487)\n",
      "31932 Traning Loss: tensor(0.8487)\n",
      "31933 Traning Loss: tensor(0.8487)\n",
      "31934 Traning Loss: tensor(0.8487)\n",
      "31935 Traning Loss: tensor(0.8487)\n",
      "31936 Traning Loss: tensor(0.8487)\n",
      "31937 Traning Loss: tensor(0.8487)\n",
      "31938 Traning Loss: tensor(0.8487)\n",
      "31939 Traning Loss: tensor(0.8487)\n",
      "31940 Traning Loss: tensor(0.8487)\n",
      "31941 Traning Loss: tensor(0.8487)\n",
      "31942 Traning Loss: tensor(0.8487)\n",
      "31943 Traning Loss: tensor(0.8487)\n",
      "31944 Traning Loss: tensor(0.8487)\n",
      "31945 Traning Loss: tensor(0.8487)\n",
      "31946 Traning Loss: tensor(0.8487)\n",
      "31947 Traning Loss: tensor(0.8487)\n",
      "31948 Traning Loss: tensor(0.8487)\n",
      "31949 Traning Loss: tensor(0.8487)\n",
      "31950 Traning Loss: tensor(0.8487)\n",
      "31951 Traning Loss: tensor(0.8487)\n",
      "31952 Traning Loss: tensor(0.8487)\n",
      "31953 Traning Loss: tensor(0.8487)\n",
      "31954 Traning Loss: tensor(0.8487)\n",
      "31955 Traning Loss: tensor(0.8487)\n",
      "31956 Traning Loss: tensor(0.8487)\n",
      "31957 Traning Loss: tensor(0.8487)\n",
      "31958 Traning Loss: tensor(0.8487)\n",
      "31959 Traning Loss: tensor(0.8487)\n",
      "31960 Traning Loss: tensor(0.8487)\n",
      "31961 Traning Loss: tensor(0.8487)\n",
      "31962 Traning Loss: tensor(0.8487)\n",
      "31963 Traning Loss: tensor(0.8487)\n",
      "31964 Traning Loss: tensor(0.8487)\n",
      "31965 Traning Loss: tensor(0.8487)\n",
      "31966 Traning Loss: tensor(0.8487)\n",
      "31967 Traning Loss: tensor(0.8487)\n",
      "31968 Traning Loss: tensor(0.8487)\n",
      "31969 Traning Loss: tensor(0.8487)\n",
      "31970 Traning Loss: tensor(0.8487)\n",
      "31971 Traning Loss: tensor(0.8487)\n",
      "31972 Traning Loss: tensor(0.8487)\n",
      "31973 Traning Loss: tensor(0.8487)\n",
      "31974 Traning Loss: tensor(0.8487)\n",
      "31975 Traning Loss: tensor(0.8487)\n",
      "31976 Traning Loss: tensor(0.8487)\n",
      "31977 Traning Loss: tensor(0.8487)\n",
      "31978 Traning Loss: tensor(0.8487)\n",
      "31979 Traning Loss: tensor(0.8487)\n",
      "31980 Traning Loss: tensor(0.8488)\n",
      "31981 Traning Loss: tensor(0.8488)\n",
      "31982 Traning Loss: tensor(0.8488)\n",
      "31983 Traning Loss: tensor(0.8488)\n",
      "31984 Traning Loss: tensor(0.8488)\n",
      "31985 Traning Loss: tensor(0.8488)\n",
      "31986 Traning Loss: tensor(0.8487)\n",
      "31987 Traning Loss: tensor(0.8487)\n",
      "31988 Traning Loss: tensor(0.8487)\n",
      "31989 Traning Loss: tensor(0.8488)\n",
      "31990 Traning Loss: tensor(0.8488)\n",
      "31991 Traning Loss: tensor(0.8487)\n",
      "31992 Traning Loss: tensor(0.8487)\n",
      "31993 Traning Loss: tensor(0.8487)\n",
      "31994 Traning Loss: tensor(0.8487)\n",
      "31995 Traning Loss: tensor(0.8487)\n",
      "31996 Traning Loss: tensor(0.8487)\n",
      "31997 Traning Loss: tensor(0.8487)\n",
      "31998 Traning Loss: tensor(0.8487)\n",
      "31999 Traning Loss: tensor(0.8487)\n",
      "32000 Traning Loss: tensor(0.8487)\n",
      "32001 Traning Loss: tensor(0.8487)\n",
      "32002 Traning Loss: tensor(0.8487)\n",
      "32003 Traning Loss: tensor(0.8487)\n",
      "32004 Traning Loss: tensor(0.8487)\n",
      "32005 Traning Loss: tensor(0.8487)\n",
      "32006 Traning Loss: tensor(0.8487)\n",
      "32007 Traning Loss: tensor(0.8487)\n",
      "32008 Traning Loss: tensor(0.8487)\n",
      "32009 Traning Loss: tensor(0.8487)\n",
      "32010 Traning Loss: tensor(0.8487)\n",
      "32011 Traning Loss: tensor(0.8487)\n",
      "32012 Traning Loss: tensor(0.8487)\n",
      "32013 Traning Loss: tensor(0.8487)\n",
      "32014 Traning Loss: tensor(0.8487)\n",
      "32015 Traning Loss: tensor(0.8487)\n",
      "32016 Traning Loss: tensor(0.8487)\n",
      "32017 Traning Loss: tensor(0.8487)\n",
      "32018 Traning Loss: tensor(0.8487)\n",
      "32019 Traning Loss: tensor(0.8487)\n",
      "32020 Traning Loss: tensor(0.8487)\n",
      "32021 Traning Loss: tensor(0.8487)\n",
      "32022 Traning Loss: tensor(0.8487)\n",
      "32023 Traning Loss: tensor(0.8487)\n",
      "32024 Traning Loss: tensor(0.8487)\n",
      "32025 Traning Loss: tensor(0.8487)\n",
      "32026 Traning Loss: tensor(0.8487)\n",
      "32027 Traning Loss: tensor(0.8487)\n",
      "32028 Traning Loss: tensor(0.8487)\n",
      "32029 Traning Loss: tensor(0.8487)\n",
      "32030 Traning Loss: tensor(0.8487)\n",
      "32031 Traning Loss: tensor(0.8487)\n",
      "32032 Traning Loss: tensor(0.8487)\n",
      "32033 Traning Loss: tensor(0.8487)\n",
      "32034 Traning Loss: tensor(0.8487)\n",
      "32035 Traning Loss: tensor(0.8487)\n",
      "32036 Traning Loss: tensor(0.8487)\n",
      "32037 Traning Loss: tensor(0.8487)\n",
      "32038 Traning Loss: tensor(0.8487)\n",
      "32039 Traning Loss: tensor(0.8487)\n",
      "32040 Traning Loss: tensor(0.8487)\n",
      "32041 Traning Loss: tensor(0.8487)\n",
      "32042 Traning Loss: tensor(0.8487)\n",
      "32043 Traning Loss: tensor(0.8487)\n",
      "32044 Traning Loss: tensor(0.8487)\n",
      "32045 Traning Loss: tensor(0.8487)\n",
      "32046 Traning Loss: tensor(0.8487)\n",
      "32047 Traning Loss: tensor(0.8487)\n",
      "32048 Traning Loss: tensor(0.8487)\n",
      "32049 Traning Loss: tensor(0.8487)\n",
      "32050 Traning Loss: tensor(0.8487)\n",
      "32051 Traning Loss: tensor(0.8487)\n",
      "32052 Traning Loss: tensor(0.8487)\n",
      "32053 Traning Loss: tensor(0.8487)\n",
      "32054 Traning Loss: tensor(0.8487)\n",
      "32055 Traning Loss: tensor(0.8487)\n",
      "32056 Traning Loss: tensor(0.8487)\n",
      "32057 Traning Loss: tensor(0.8487)\n",
      "32058 Traning Loss: tensor(0.8487)\n",
      "32059 Traning Loss: tensor(0.8487)\n",
      "32060 Traning Loss: tensor(0.8487)\n",
      "32061 Traning Loss: tensor(0.8487)\n",
      "32062 Traning Loss: tensor(0.8487)\n",
      "32063 Traning Loss: tensor(0.8487)\n",
      "32064 Traning Loss: tensor(0.8487)\n",
      "32065 Traning Loss: tensor(0.8487)\n",
      "32066 Traning Loss: tensor(0.8487)\n",
      "32067 Traning Loss: tensor(0.8487)\n",
      "32068 Traning Loss: tensor(0.8487)\n",
      "32069 Traning Loss: tensor(0.8487)\n",
      "32070 Traning Loss: tensor(0.8487)\n",
      "32071 Traning Loss: tensor(0.8487)\n",
      "32072 Traning Loss: tensor(0.8487)\n",
      "32073 Traning Loss: tensor(0.8487)\n",
      "32074 Traning Loss: tensor(0.8487)\n",
      "32075 Traning Loss: tensor(0.8487)\n",
      "32076 Traning Loss: tensor(0.8487)\n",
      "32077 Traning Loss: tensor(0.8487)\n",
      "32078 Traning Loss: tensor(0.8487)\n",
      "32079 Traning Loss: tensor(0.8487)\n",
      "32080 Traning Loss: tensor(0.8487)\n",
      "32081 Traning Loss: tensor(0.8487)\n",
      "32082 Traning Loss: tensor(0.8487)\n",
      "32083 Traning Loss: tensor(0.8487)\n",
      "32084 Traning Loss: tensor(0.8487)\n",
      "32085 Traning Loss: tensor(0.8487)\n",
      "32086 Traning Loss: tensor(0.8487)\n",
      "32087 Traning Loss: tensor(0.8487)\n",
      "32088 Traning Loss: tensor(0.8487)\n",
      "32089 Traning Loss: tensor(0.8487)\n",
      "32090 Traning Loss: tensor(0.8487)\n",
      "32091 Traning Loss: tensor(0.8487)\n",
      "32092 Traning Loss: tensor(0.8487)\n",
      "32093 Traning Loss: tensor(0.8487)\n",
      "32094 Traning Loss: tensor(0.8487)\n",
      "32095 Traning Loss: tensor(0.8487)\n",
      "32096 Traning Loss: tensor(0.8487)\n",
      "32097 Traning Loss: tensor(0.8487)\n",
      "32098 Traning Loss: tensor(0.8487)\n",
      "32099 Traning Loss: tensor(0.8487)\n",
      "32100 Traning Loss: tensor(0.8487)\n",
      "32101 Traning Loss: tensor(0.8487)\n",
      "32102 Traning Loss: tensor(0.8487)\n",
      "32103 Traning Loss: tensor(0.8487)\n",
      "32104 Traning Loss: tensor(0.8487)\n",
      "32105 Traning Loss: tensor(0.8487)\n",
      "32106 Traning Loss: tensor(0.8487)\n",
      "32107 Traning Loss: tensor(0.8487)\n",
      "32108 Traning Loss: tensor(0.8487)\n",
      "32109 Traning Loss: tensor(0.8487)\n",
      "32110 Traning Loss: tensor(0.8487)\n",
      "32111 Traning Loss: tensor(0.8487)\n",
      "32112 Traning Loss: tensor(0.8487)\n",
      "32113 Traning Loss: tensor(0.8487)\n",
      "32114 Traning Loss: tensor(0.8487)\n",
      "32115 Traning Loss: tensor(0.8487)\n",
      "32116 Traning Loss: tensor(0.8487)\n",
      "32117 Traning Loss: tensor(0.8487)\n",
      "32118 Traning Loss: tensor(0.8487)\n",
      "32119 Traning Loss: tensor(0.8487)\n",
      "32120 Traning Loss: tensor(0.8487)\n",
      "32121 Traning Loss: tensor(0.8487)\n",
      "32122 Traning Loss: tensor(0.8487)\n",
      "32123 Traning Loss: tensor(0.8487)\n",
      "32124 Traning Loss: tensor(0.8487)\n",
      "32125 Traning Loss: tensor(0.8487)\n",
      "32126 Traning Loss: tensor(0.8487)\n",
      "32127 Traning Loss: tensor(0.8487)\n",
      "32128 Traning Loss: tensor(0.8487)\n",
      "32129 Traning Loss: tensor(0.8487)\n",
      "32130 Traning Loss: tensor(0.8487)\n",
      "32131 Traning Loss: tensor(0.8487)\n",
      "32132 Traning Loss: tensor(0.8487)\n",
      "32133 Traning Loss: tensor(0.8487)\n",
      "32134 Traning Loss: tensor(0.8487)\n",
      "32135 Traning Loss: tensor(0.8487)\n",
      "32136 Traning Loss: tensor(0.8487)\n",
      "32137 Traning Loss: tensor(0.8487)\n",
      "32138 Traning Loss: tensor(0.8487)\n",
      "32139 Traning Loss: tensor(0.8487)\n",
      "32140 Traning Loss: tensor(0.8487)\n",
      "32141 Traning Loss: tensor(0.8487)\n",
      "32142 Traning Loss: tensor(0.8487)\n",
      "32143 Traning Loss: tensor(0.8487)\n",
      "32144 Traning Loss: tensor(0.8487)\n",
      "32145 Traning Loss: tensor(0.8487)\n",
      "32146 Traning Loss: tensor(0.8487)\n",
      "32147 Traning Loss: tensor(0.8487)\n",
      "32148 Traning Loss: tensor(0.8487)\n",
      "32149 Traning Loss: tensor(0.8487)\n",
      "32150 Traning Loss: tensor(0.8487)\n",
      "32151 Traning Loss: tensor(0.8487)\n",
      "32152 Traning Loss: tensor(0.8487)\n",
      "32153 Traning Loss: tensor(0.8487)\n",
      "32154 Traning Loss: tensor(0.8487)\n",
      "32155 Traning Loss: tensor(0.8487)\n",
      "32156 Traning Loss: tensor(0.8487)\n",
      "32157 Traning Loss: tensor(0.8487)\n",
      "32158 Traning Loss: tensor(0.8487)\n",
      "32159 Traning Loss: tensor(0.8487)\n",
      "32160 Traning Loss: tensor(0.8487)\n",
      "32161 Traning Loss: tensor(0.8487)\n",
      "32162 Traning Loss: tensor(0.8487)\n",
      "32163 Traning Loss: tensor(0.8487)\n",
      "32164 Traning Loss: tensor(0.8487)\n",
      "32165 Traning Loss: tensor(0.8487)\n",
      "32166 Traning Loss: tensor(0.8487)\n",
      "32167 Traning Loss: tensor(0.8487)\n",
      "32168 Traning Loss: tensor(0.8487)\n",
      "32169 Traning Loss: tensor(0.8487)\n",
      "32170 Traning Loss: tensor(0.8487)\n",
      "32171 Traning Loss: tensor(0.8487)\n",
      "32172 Traning Loss: tensor(0.8487)\n",
      "32173 Traning Loss: tensor(0.8487)\n",
      "32174 Traning Loss: tensor(0.8487)\n",
      "32175 Traning Loss: tensor(0.8487)\n",
      "32176 Traning Loss: tensor(0.8487)\n",
      "32177 Traning Loss: tensor(0.8487)\n",
      "32178 Traning Loss: tensor(0.8487)\n",
      "32179 Traning Loss: tensor(0.8487)\n",
      "32180 Traning Loss: tensor(0.8487)\n",
      "32181 Traning Loss: tensor(0.8487)\n",
      "32182 Traning Loss: tensor(0.8487)\n",
      "32183 Traning Loss: tensor(0.8487)\n",
      "32184 Traning Loss: tensor(0.8487)\n",
      "32185 Traning Loss: tensor(0.8487)\n",
      "32186 Traning Loss: tensor(0.8487)\n",
      "32187 Traning Loss: tensor(0.8487)\n",
      "32188 Traning Loss: tensor(0.8487)\n",
      "32189 Traning Loss: tensor(0.8487)\n",
      "32190 Traning Loss: tensor(0.8487)\n",
      "32191 Traning Loss: tensor(0.8487)\n",
      "32192 Traning Loss: tensor(0.8487)\n",
      "32193 Traning Loss: tensor(0.8487)\n",
      "32194 Traning Loss: tensor(0.8487)\n",
      "32195 Traning Loss: tensor(0.8487)\n",
      "32196 Traning Loss: tensor(0.8487)\n",
      "32197 Traning Loss: tensor(0.8487)\n",
      "32198 Traning Loss: tensor(0.8487)\n",
      "32199 Traning Loss: tensor(0.8487)\n",
      "32200 Traning Loss: tensor(0.8487)\n",
      "32201 Traning Loss: tensor(0.8487)\n",
      "32202 Traning Loss: tensor(0.8487)\n",
      "32203 Traning Loss: tensor(0.8487)\n",
      "32204 Traning Loss: tensor(0.8487)\n",
      "32205 Traning Loss: tensor(0.8487)\n",
      "32206 Traning Loss: tensor(0.8487)\n",
      "32207 Traning Loss: tensor(0.8487)\n",
      "32208 Traning Loss: tensor(0.8487)\n",
      "32209 Traning Loss: tensor(0.8487)\n",
      "32210 Traning Loss: tensor(0.8487)\n",
      "32211 Traning Loss: tensor(0.8487)\n",
      "32212 Traning Loss: tensor(0.8487)\n",
      "32213 Traning Loss: tensor(0.8487)\n",
      "32214 Traning Loss: tensor(0.8487)\n",
      "32215 Traning Loss: tensor(0.8487)\n",
      "32216 Traning Loss: tensor(0.8487)\n",
      "32217 Traning Loss: tensor(0.8487)\n",
      "32218 Traning Loss: tensor(0.8487)\n",
      "32219 Traning Loss: tensor(0.8487)\n",
      "32220 Traning Loss: tensor(0.8487)\n",
      "32221 Traning Loss: tensor(0.8487)\n",
      "32222 Traning Loss: tensor(0.8487)\n",
      "32223 Traning Loss: tensor(0.8487)\n",
      "32224 Traning Loss: tensor(0.8487)\n",
      "32225 Traning Loss: tensor(0.8487)\n",
      "32226 Traning Loss: tensor(0.8487)\n",
      "32227 Traning Loss: tensor(0.8487)\n",
      "32228 Traning Loss: tensor(0.8487)\n",
      "32229 Traning Loss: tensor(0.8487)\n",
      "32230 Traning Loss: tensor(0.8487)\n",
      "32231 Traning Loss: tensor(0.8487)\n",
      "32232 Traning Loss: tensor(0.8487)\n",
      "32233 Traning Loss: tensor(0.8487)\n",
      "32234 Traning Loss: tensor(0.8487)\n",
      "32235 Traning Loss: tensor(0.8487)\n",
      "32236 Traning Loss: tensor(0.8487)\n",
      "32237 Traning Loss: tensor(0.8487)\n",
      "32238 Traning Loss: tensor(0.8487)\n",
      "32239 Traning Loss: tensor(0.8487)\n",
      "32240 Traning Loss: tensor(0.8487)\n",
      "32241 Traning Loss: tensor(0.8487)\n",
      "32242 Traning Loss: tensor(0.8487)\n",
      "32243 Traning Loss: tensor(0.8487)\n",
      "32244 Traning Loss: tensor(0.8487)\n",
      "32245 Traning Loss: tensor(0.8487)\n",
      "32246 Traning Loss: tensor(0.8487)\n",
      "32247 Traning Loss: tensor(0.8487)\n",
      "32248 Traning Loss: tensor(0.8487)\n",
      "32249 Traning Loss: tensor(0.8487)\n",
      "32250 Traning Loss: tensor(0.8487)\n",
      "32251 Traning Loss: tensor(0.8487)\n",
      "32252 Traning Loss: tensor(0.8487)\n",
      "32253 Traning Loss: tensor(0.8487)\n",
      "32254 Traning Loss: tensor(0.8487)\n",
      "32255 Traning Loss: tensor(0.8487)\n",
      "32256 Traning Loss: tensor(0.8487)\n",
      "32257 Traning Loss: tensor(0.8487)\n",
      "32258 Traning Loss: tensor(0.8487)\n",
      "32259 Traning Loss: tensor(0.8487)\n",
      "32260 Traning Loss: tensor(0.8487)\n",
      "32261 Traning Loss: tensor(0.8487)\n",
      "32262 Traning Loss: tensor(0.8487)\n",
      "32263 Traning Loss: tensor(0.8487)\n",
      "32264 Traning Loss: tensor(0.8487)\n",
      "32265 Traning Loss: tensor(0.8487)\n",
      "32266 Traning Loss: tensor(0.8487)\n",
      "32267 Traning Loss: tensor(0.8487)\n",
      "32268 Traning Loss: tensor(0.8487)\n",
      "32269 Traning Loss: tensor(0.8487)\n",
      "32270 Traning Loss: tensor(0.8487)\n",
      "32271 Traning Loss: tensor(0.8487)\n",
      "32272 Traning Loss: tensor(0.8487)\n",
      "32273 Traning Loss: tensor(0.8487)\n",
      "32274 Traning Loss: tensor(0.8487)\n",
      "32275 Traning Loss: tensor(0.8487)\n",
      "32276 Traning Loss: tensor(0.8487)\n",
      "32277 Traning Loss: tensor(0.8487)\n",
      "32278 Traning Loss: tensor(0.8487)\n",
      "32279 Traning Loss: tensor(0.8487)\n",
      "32280 Traning Loss: tensor(0.8487)\n",
      "32281 Traning Loss: tensor(0.8487)\n",
      "32282 Traning Loss: tensor(0.8487)\n",
      "32283 Traning Loss: tensor(0.8487)\n",
      "32284 Traning Loss: tensor(0.8487)\n",
      "32285 Traning Loss: tensor(0.8487)\n",
      "32286 Traning Loss: tensor(0.8487)\n",
      "32287 Traning Loss: tensor(0.8487)\n",
      "32288 Traning Loss: tensor(0.8487)\n",
      "32289 Traning Loss: tensor(0.8487)\n",
      "32290 Traning Loss: tensor(0.8487)\n",
      "32291 Traning Loss: tensor(0.8487)\n",
      "32292 Traning Loss: tensor(0.8487)\n",
      "32293 Traning Loss: tensor(0.8487)\n",
      "32294 Traning Loss: tensor(0.8487)\n",
      "32295 Traning Loss: tensor(0.8487)\n",
      "32296 Traning Loss: tensor(0.8487)\n",
      "32297 Traning Loss: tensor(0.8487)\n",
      "32298 Traning Loss: tensor(0.8487)\n",
      "32299 Traning Loss: tensor(0.8487)\n",
      "32300 Traning Loss: tensor(0.8487)\n",
      "32301 Traning Loss: tensor(0.8487)\n",
      "32302 Traning Loss: tensor(0.8487)\n",
      "32303 Traning Loss: tensor(0.8487)\n",
      "32304 Traning Loss: tensor(0.8487)\n",
      "32305 Traning Loss: tensor(0.8487)\n",
      "32306 Traning Loss: tensor(0.8487)\n",
      "32307 Traning Loss: tensor(0.8487)\n",
      "32308 Traning Loss: tensor(0.8487)\n",
      "32309 Traning Loss: tensor(0.8487)\n",
      "32310 Traning Loss: tensor(0.8487)\n",
      "32311 Traning Loss: tensor(0.8487)\n",
      "32312 Traning Loss: tensor(0.8487)\n",
      "32313 Traning Loss: tensor(0.8487)\n",
      "32314 Traning Loss: tensor(0.8487)\n",
      "32315 Traning Loss: tensor(0.8487)\n",
      "32316 Traning Loss: tensor(0.8487)\n",
      "32317 Traning Loss: tensor(0.8487)\n",
      "32318 Traning Loss: tensor(0.8487)\n",
      "32319 Traning Loss: tensor(0.8487)\n",
      "32320 Traning Loss: tensor(0.8487)\n",
      "32321 Traning Loss: tensor(0.8487)\n",
      "32322 Traning Loss: tensor(0.8487)\n",
      "32323 Traning Loss: tensor(0.8487)\n",
      "32324 Traning Loss: tensor(0.8487)\n",
      "32325 Traning Loss: tensor(0.8487)\n",
      "32326 Traning Loss: tensor(0.8487)\n",
      "32327 Traning Loss: tensor(0.8487)\n",
      "32328 Traning Loss: tensor(0.8487)\n",
      "32329 Traning Loss: tensor(0.8487)\n",
      "32330 Traning Loss: tensor(0.8487)\n",
      "32331 Traning Loss: tensor(0.8487)\n",
      "32332 Traning Loss: tensor(0.8487)\n",
      "32333 Traning Loss: tensor(0.8487)\n",
      "32334 Traning Loss: tensor(0.8487)\n",
      "32335 Traning Loss: tensor(0.8487)\n",
      "32336 Traning Loss: tensor(0.8487)\n",
      "32337 Traning Loss: tensor(0.8487)\n",
      "32338 Traning Loss: tensor(0.8488)\n",
      "32339 Traning Loss: tensor(0.8488)\n",
      "32340 Traning Loss: tensor(0.8488)\n",
      "32341 Traning Loss: tensor(0.8488)\n",
      "32342 Traning Loss: tensor(0.8488)\n",
      "32343 Traning Loss: tensor(0.8487)\n",
      "32344 Traning Loss: tensor(0.8487)\n",
      "32345 Traning Loss: tensor(0.8487)\n",
      "32346 Traning Loss: tensor(0.8487)\n",
      "32347 Traning Loss: tensor(0.8487)\n",
      "32348 Traning Loss: tensor(0.8487)\n",
      "32349 Traning Loss: tensor(0.8487)\n",
      "32350 Traning Loss: tensor(0.8487)\n",
      "32351 Traning Loss: tensor(0.8487)\n",
      "32352 Traning Loss: tensor(0.8487)\n",
      "32353 Traning Loss: tensor(0.8487)\n",
      "32354 Traning Loss: tensor(0.8487)\n",
      "32355 Traning Loss: tensor(0.8487)\n",
      "32356 Traning Loss: tensor(0.8487)\n",
      "32357 Traning Loss: tensor(0.8487)\n",
      "32358 Traning Loss: tensor(0.8487)\n",
      "32359 Traning Loss: tensor(0.8487)\n",
      "32360 Traning Loss: tensor(0.8487)\n",
      "32361 Traning Loss: tensor(0.8487)\n",
      "32362 Traning Loss: tensor(0.8487)\n",
      "32363 Traning Loss: tensor(0.8487)\n",
      "32364 Traning Loss: tensor(0.8487)\n",
      "32365 Traning Loss: tensor(0.8487)\n",
      "32366 Traning Loss: tensor(0.8487)\n",
      "32367 Traning Loss: tensor(0.8487)\n",
      "32368 Traning Loss: tensor(0.8487)\n",
      "32369 Traning Loss: tensor(0.8487)\n",
      "32370 Traning Loss: tensor(0.8487)\n",
      "32371 Traning Loss: tensor(0.8487)\n",
      "32372 Traning Loss: tensor(0.8487)\n",
      "32373 Traning Loss: tensor(0.8487)\n",
      "32374 Traning Loss: tensor(0.8487)\n",
      "32375 Traning Loss: tensor(0.8487)\n",
      "32376 Traning Loss: tensor(0.8487)\n",
      "32377 Traning Loss: tensor(0.8487)\n",
      "32378 Traning Loss: tensor(0.8487)\n",
      "32379 Traning Loss: tensor(0.8487)\n",
      "32380 Traning Loss: tensor(0.8487)\n",
      "32381 Traning Loss: tensor(0.8487)\n",
      "32382 Traning Loss: tensor(0.8487)\n",
      "32383 Traning Loss: tensor(0.8487)\n",
      "32384 Traning Loss: tensor(0.8487)\n",
      "32385 Traning Loss: tensor(0.8487)\n",
      "32386 Traning Loss: tensor(0.8487)\n",
      "32387 Traning Loss: tensor(0.8487)\n",
      "32388 Traning Loss: tensor(0.8487)\n",
      "32389 Traning Loss: tensor(0.8487)\n",
      "32390 Traning Loss: tensor(0.8487)\n",
      "32391 Traning Loss: tensor(0.8487)\n",
      "32392 Traning Loss: tensor(0.8487)\n",
      "32393 Traning Loss: tensor(0.8487)\n",
      "32394 Traning Loss: tensor(0.8487)\n",
      "32395 Traning Loss: tensor(0.8487)\n",
      "32396 Traning Loss: tensor(0.8487)\n",
      "32397 Traning Loss: tensor(0.8487)\n",
      "32398 Traning Loss: tensor(0.8487)\n",
      "32399 Traning Loss: tensor(0.8487)\n",
      "32400 Traning Loss: tensor(0.8487)\n",
      "32401 Traning Loss: tensor(0.8487)\n",
      "32402 Traning Loss: tensor(0.8487)\n",
      "32403 Traning Loss: tensor(0.8487)\n",
      "32404 Traning Loss: tensor(0.8487)\n",
      "32405 Traning Loss: tensor(0.8487)\n",
      "32406 Traning Loss: tensor(0.8487)\n",
      "32407 Traning Loss: tensor(0.8487)\n",
      "32408 Traning Loss: tensor(0.8487)\n",
      "32409 Traning Loss: tensor(0.8487)\n",
      "32410 Traning Loss: tensor(0.8487)\n",
      "32411 Traning Loss: tensor(0.8487)\n",
      "32412 Traning Loss: tensor(0.8487)\n",
      "32413 Traning Loss: tensor(0.8487)\n",
      "32414 Traning Loss: tensor(0.8487)\n",
      "32415 Traning Loss: tensor(0.8487)\n",
      "32416 Traning Loss: tensor(0.8487)\n",
      "32417 Traning Loss: tensor(0.8487)\n",
      "32418 Traning Loss: tensor(0.8487)\n",
      "32419 Traning Loss: tensor(0.8487)\n",
      "32420 Traning Loss: tensor(0.8487)\n",
      "32421 Traning Loss: tensor(0.8487)\n",
      "32422 Traning Loss: tensor(0.8487)\n",
      "32423 Traning Loss: tensor(0.8487)\n",
      "32424 Traning Loss: tensor(0.8487)\n",
      "32425 Traning Loss: tensor(0.8487)\n",
      "32426 Traning Loss: tensor(0.8487)\n",
      "32427 Traning Loss: tensor(0.8487)\n",
      "32428 Traning Loss: tensor(0.8487)\n",
      "32429 Traning Loss: tensor(0.8487)\n",
      "32430 Traning Loss: tensor(0.8487)\n",
      "32431 Traning Loss: tensor(0.8487)\n",
      "32432 Traning Loss: tensor(0.8487)\n",
      "32433 Traning Loss: tensor(0.8487)\n",
      "32434 Traning Loss: tensor(0.8487)\n",
      "32435 Traning Loss: tensor(0.8487)\n",
      "32436 Traning Loss: tensor(0.8487)\n",
      "32437 Traning Loss: tensor(0.8487)\n",
      "32438 Traning Loss: tensor(0.8487)\n",
      "32439 Traning Loss: tensor(0.8487)\n",
      "32440 Traning Loss: tensor(0.8487)\n",
      "32441 Traning Loss: tensor(0.8487)\n",
      "32442 Traning Loss: tensor(0.8487)\n",
      "32443 Traning Loss: tensor(0.8487)\n",
      "32444 Traning Loss: tensor(0.8487)\n",
      "32445 Traning Loss: tensor(0.8487)\n",
      "32446 Traning Loss: tensor(0.8487)\n",
      "32447 Traning Loss: tensor(0.8487)\n",
      "32448 Traning Loss: tensor(0.8487)\n",
      "32449 Traning Loss: tensor(0.8487)\n",
      "32450 Traning Loss: tensor(0.8487)\n",
      "32451 Traning Loss: tensor(0.8487)\n",
      "32452 Traning Loss: tensor(0.8487)\n",
      "32453 Traning Loss: tensor(0.8487)\n",
      "32454 Traning Loss: tensor(0.8487)\n",
      "32455 Traning Loss: tensor(0.8487)\n",
      "32456 Traning Loss: tensor(0.8487)\n",
      "32457 Traning Loss: tensor(0.8487)\n",
      "32458 Traning Loss: tensor(0.8487)\n",
      "32459 Traning Loss: tensor(0.8487)\n",
      "32460 Traning Loss: tensor(0.8487)\n",
      "32461 Traning Loss: tensor(0.8487)\n",
      "32462 Traning Loss: tensor(0.8487)\n",
      "32463 Traning Loss: tensor(0.8487)\n",
      "32464 Traning Loss: tensor(0.8487)\n",
      "32465 Traning Loss: tensor(0.8487)\n",
      "32466 Traning Loss: tensor(0.8487)\n",
      "32467 Traning Loss: tensor(0.8487)\n",
      "32468 Traning Loss: tensor(0.8487)\n",
      "32469 Traning Loss: tensor(0.8487)\n",
      "32470 Traning Loss: tensor(0.8487)\n",
      "32471 Traning Loss: tensor(0.8487)\n",
      "32472 Traning Loss: tensor(0.8487)\n",
      "32473 Traning Loss: tensor(0.8487)\n",
      "32474 Traning Loss: tensor(0.8487)\n",
      "32475 Traning Loss: tensor(0.8487)\n",
      "32476 Traning Loss: tensor(0.8487)\n",
      "32477 Traning Loss: tensor(0.8487)\n",
      "32478 Traning Loss: tensor(0.8487)\n",
      "32479 Traning Loss: tensor(0.8487)\n",
      "32480 Traning Loss: tensor(0.8487)\n",
      "32481 Traning Loss: tensor(0.8487)\n",
      "32482 Traning Loss: tensor(0.8487)\n",
      "32483 Traning Loss: tensor(0.8487)\n",
      "32484 Traning Loss: tensor(0.8487)\n",
      "32485 Traning Loss: tensor(0.8487)\n",
      "32486 Traning Loss: tensor(0.8487)\n",
      "32487 Traning Loss: tensor(0.8487)\n",
      "32488 Traning Loss: tensor(0.8487)\n",
      "32489 Traning Loss: tensor(0.8487)\n",
      "32490 Traning Loss: tensor(0.8487)\n",
      "32491 Traning Loss: tensor(0.8487)\n",
      "32492 Traning Loss: tensor(0.8487)\n",
      "32493 Traning Loss: tensor(0.8487)\n",
      "32494 Traning Loss: tensor(0.8487)\n",
      "32495 Traning Loss: tensor(0.8487)\n",
      "32496 Traning Loss: tensor(0.8487)\n",
      "32497 Traning Loss: tensor(0.8487)\n",
      "32498 Traning Loss: tensor(0.8487)\n",
      "32499 Traning Loss: tensor(0.8487)\n",
      "32500 Traning Loss: tensor(0.8487)\n",
      "32501 Traning Loss: tensor(0.8487)\n",
      "32502 Traning Loss: tensor(0.8487)\n",
      "32503 Traning Loss: tensor(0.8487)\n",
      "32504 Traning Loss: tensor(0.8487)\n",
      "32505 Traning Loss: tensor(0.8487)\n",
      "32506 Traning Loss: tensor(0.8487)\n",
      "32507 Traning Loss: tensor(0.8487)\n",
      "32508 Traning Loss: tensor(0.8487)\n",
      "32509 Traning Loss: tensor(0.8487)\n",
      "32510 Traning Loss: tensor(0.8487)\n",
      "32511 Traning Loss: tensor(0.8487)\n",
      "32512 Traning Loss: tensor(0.8487)\n",
      "32513 Traning Loss: tensor(0.8487)\n",
      "32514 Traning Loss: tensor(0.8487)\n",
      "32515 Traning Loss: tensor(0.8487)\n",
      "32516 Traning Loss: tensor(0.8487)\n",
      "32517 Traning Loss: tensor(0.8487)\n",
      "32518 Traning Loss: tensor(0.8487)\n",
      "32519 Traning Loss: tensor(0.8487)\n",
      "32520 Traning Loss: tensor(0.8487)\n",
      "32521 Traning Loss: tensor(0.8487)\n",
      "32522 Traning Loss: tensor(0.8487)\n",
      "32523 Traning Loss: tensor(0.8487)\n",
      "32524 Traning Loss: tensor(0.8487)\n",
      "32525 Traning Loss: tensor(0.8487)\n",
      "32526 Traning Loss: tensor(0.8487)\n",
      "32527 Traning Loss: tensor(0.8487)\n",
      "32528 Traning Loss: tensor(0.8487)\n",
      "32529 Traning Loss: tensor(0.8487)\n",
      "32530 Traning Loss: tensor(0.8487)\n",
      "32531 Traning Loss: tensor(0.8487)\n",
      "32532 Traning Loss: tensor(0.8487)\n",
      "32533 Traning Loss: tensor(0.8487)\n",
      "32534 Traning Loss: tensor(0.8487)\n",
      "32535 Traning Loss: tensor(0.8487)\n",
      "32536 Traning Loss: tensor(0.8487)\n",
      "32537 Traning Loss: tensor(0.8487)\n",
      "32538 Traning Loss: tensor(0.8487)\n",
      "32539 Traning Loss: tensor(0.8487)\n",
      "32540 Traning Loss: tensor(0.8487)\n",
      "32541 Traning Loss: tensor(0.8487)\n",
      "32542 Traning Loss: tensor(0.8487)\n",
      "32543 Traning Loss: tensor(0.8487)\n",
      "32544 Traning Loss: tensor(0.8487)\n",
      "32545 Traning Loss: tensor(0.8487)\n",
      "32546 Traning Loss: tensor(0.8487)\n",
      "32547 Traning Loss: tensor(0.8487)\n",
      "32548 Traning Loss: tensor(0.8487)\n",
      "32549 Traning Loss: tensor(0.8487)\n",
      "32550 Traning Loss: tensor(0.8487)\n",
      "32551 Traning Loss: tensor(0.8487)\n",
      "32552 Traning Loss: tensor(0.8487)\n",
      "32553 Traning Loss: tensor(0.8487)\n",
      "32554 Traning Loss: tensor(0.8487)\n",
      "32555 Traning Loss: tensor(0.8487)\n",
      "32556 Traning Loss: tensor(0.8487)\n",
      "32557 Traning Loss: tensor(0.8487)\n",
      "32558 Traning Loss: tensor(0.8487)\n",
      "32559 Traning Loss: tensor(0.8487)\n",
      "32560 Traning Loss: tensor(0.8487)\n",
      "32561 Traning Loss: tensor(0.8487)\n",
      "32562 Traning Loss: tensor(0.8487)\n",
      "32563 Traning Loss: tensor(0.8487)\n",
      "32564 Traning Loss: tensor(0.8487)\n",
      "32565 Traning Loss: tensor(0.8487)\n",
      "32566 Traning Loss: tensor(0.8487)\n",
      "32567 Traning Loss: tensor(0.8487)\n",
      "32568 Traning Loss: tensor(0.8487)\n",
      "32569 Traning Loss: tensor(0.8487)\n",
      "32570 Traning Loss: tensor(0.8487)\n",
      "32571 Traning Loss: tensor(0.8487)\n",
      "32572 Traning Loss: tensor(0.8487)\n",
      "32573 Traning Loss: tensor(0.8487)\n",
      "32574 Traning Loss: tensor(0.8487)\n",
      "32575 Traning Loss: tensor(0.8487)\n",
      "32576 Traning Loss: tensor(0.8487)\n",
      "32577 Traning Loss: tensor(0.8487)\n",
      "32578 Traning Loss: tensor(0.8487)\n",
      "32579 Traning Loss: tensor(0.8487)\n",
      "32580 Traning Loss: tensor(0.8487)\n",
      "32581 Traning Loss: tensor(0.8488)\n",
      "32582 Traning Loss: tensor(0.8488)\n",
      "32583 Traning Loss: tensor(0.8488)\n",
      "32584 Traning Loss: tensor(0.8488)\n",
      "32585 Traning Loss: tensor(0.8487)\n",
      "32586 Traning Loss: tensor(0.8487)\n",
      "32587 Traning Loss: tensor(0.8487)\n",
      "32588 Traning Loss: tensor(0.8487)\n",
      "32589 Traning Loss: tensor(0.8487)\n",
      "32590 Traning Loss: tensor(0.8487)\n",
      "32591 Traning Loss: tensor(0.8487)\n",
      "32592 Traning Loss: tensor(0.8487)\n",
      "32593 Traning Loss: tensor(0.8487)\n",
      "32594 Traning Loss: tensor(0.8487)\n",
      "32595 Traning Loss: tensor(0.8487)\n",
      "32596 Traning Loss: tensor(0.8487)\n",
      "32597 Traning Loss: tensor(0.8487)\n",
      "32598 Traning Loss: tensor(0.8487)\n",
      "32599 Traning Loss: tensor(0.8487)\n",
      "32600 Traning Loss: tensor(0.8487)\n",
      "32601 Traning Loss: tensor(0.8487)\n",
      "32602 Traning Loss: tensor(0.8487)\n",
      "32603 Traning Loss: tensor(0.8487)\n",
      "32604 Traning Loss: tensor(0.8487)\n",
      "32605 Traning Loss: tensor(0.8487)\n",
      "32606 Traning Loss: tensor(0.8487)\n",
      "32607 Traning Loss: tensor(0.8487)\n",
      "32608 Traning Loss: tensor(0.8487)\n",
      "32609 Traning Loss: tensor(0.8487)\n",
      "32610 Traning Loss: tensor(0.8487)\n",
      "32611 Traning Loss: tensor(0.8487)\n",
      "32612 Traning Loss: tensor(0.8487)\n",
      "32613 Traning Loss: tensor(0.8487)\n",
      "32614 Traning Loss: tensor(0.8487)\n",
      "32615 Traning Loss: tensor(0.8487)\n",
      "32616 Traning Loss: tensor(0.8487)\n",
      "32617 Traning Loss: tensor(0.8487)\n",
      "32618 Traning Loss: tensor(0.8487)\n",
      "32619 Traning Loss: tensor(0.8487)\n",
      "32620 Traning Loss: tensor(0.8487)\n",
      "32621 Traning Loss: tensor(0.8487)\n",
      "32622 Traning Loss: tensor(0.8487)\n",
      "32623 Traning Loss: tensor(0.8487)\n",
      "32624 Traning Loss: tensor(0.8487)\n",
      "32625 Traning Loss: tensor(0.8487)\n",
      "32626 Traning Loss: tensor(0.8487)\n",
      "32627 Traning Loss: tensor(0.8487)\n",
      "32628 Traning Loss: tensor(0.8487)\n",
      "32629 Traning Loss: tensor(0.8487)\n",
      "32630 Traning Loss: tensor(0.8487)\n",
      "32631 Traning Loss: tensor(0.8487)\n",
      "32632 Traning Loss: tensor(0.8487)\n",
      "32633 Traning Loss: tensor(0.8487)\n",
      "32634 Traning Loss: tensor(0.8487)\n",
      "32635 Traning Loss: tensor(0.8487)\n",
      "32636 Traning Loss: tensor(0.8487)\n",
      "32637 Traning Loss: tensor(0.8487)\n",
      "32638 Traning Loss: tensor(0.8487)\n",
      "32639 Traning Loss: tensor(0.8487)\n",
      "32640 Traning Loss: tensor(0.8487)\n",
      "32641 Traning Loss: tensor(0.8487)\n",
      "32642 Traning Loss: tensor(0.8487)\n",
      "32643 Traning Loss: tensor(0.8487)\n",
      "32644 Traning Loss: tensor(0.8487)\n",
      "32645 Traning Loss: tensor(0.8487)\n",
      "32646 Traning Loss: tensor(0.8487)\n",
      "32647 Traning Loss: tensor(0.8487)\n",
      "32648 Traning Loss: tensor(0.8487)\n",
      "32649 Traning Loss: tensor(0.8487)\n",
      "32650 Traning Loss: tensor(0.8487)\n",
      "32651 Traning Loss: tensor(0.8487)\n",
      "32652 Traning Loss: tensor(0.8487)\n",
      "32653 Traning Loss: tensor(0.8487)\n",
      "32654 Traning Loss: tensor(0.8487)\n",
      "32655 Traning Loss: tensor(0.8487)\n",
      "32656 Traning Loss: tensor(0.8487)\n",
      "32657 Traning Loss: tensor(0.8487)\n",
      "32658 Traning Loss: tensor(0.8487)\n",
      "32659 Traning Loss: tensor(0.8487)\n",
      "32660 Traning Loss: tensor(0.8487)\n",
      "32661 Traning Loss: tensor(0.8487)\n",
      "32662 Traning Loss: tensor(0.8487)\n",
      "32663 Traning Loss: tensor(0.8487)\n",
      "32664 Traning Loss: tensor(0.8487)\n",
      "32665 Traning Loss: tensor(0.8487)\n",
      "32666 Traning Loss: tensor(0.8487)\n",
      "32667 Traning Loss: tensor(0.8487)\n",
      "32668 Traning Loss: tensor(0.8487)\n",
      "32669 Traning Loss: tensor(0.8487)\n",
      "32670 Traning Loss: tensor(0.8487)\n",
      "32671 Traning Loss: tensor(0.8487)\n",
      "32672 Traning Loss: tensor(0.8487)\n",
      "32673 Traning Loss: tensor(0.8487)\n",
      "32674 Traning Loss: tensor(0.8487)\n",
      "32675 Traning Loss: tensor(0.8487)\n",
      "32676 Traning Loss: tensor(0.8487)\n",
      "32677 Traning Loss: tensor(0.8487)\n",
      "32678 Traning Loss: tensor(0.8487)\n",
      "32679 Traning Loss: tensor(0.8487)\n",
      "32680 Traning Loss: tensor(0.8487)\n",
      "32681 Traning Loss: tensor(0.8487)\n",
      "32682 Traning Loss: tensor(0.8487)\n",
      "32683 Traning Loss: tensor(0.8487)\n",
      "32684 Traning Loss: tensor(0.8487)\n",
      "32685 Traning Loss: tensor(0.8487)\n",
      "32686 Traning Loss: tensor(0.8487)\n",
      "32687 Traning Loss: tensor(0.8487)\n",
      "32688 Traning Loss: tensor(0.8487)\n",
      "32689 Traning Loss: tensor(0.8487)\n",
      "32690 Traning Loss: tensor(0.8487)\n",
      "32691 Traning Loss: tensor(0.8487)\n",
      "32692 Traning Loss: tensor(0.8487)\n",
      "32693 Traning Loss: tensor(0.8487)\n",
      "32694 Traning Loss: tensor(0.8487)\n",
      "32695 Traning Loss: tensor(0.8487)\n",
      "32696 Traning Loss: tensor(0.8487)\n",
      "32697 Traning Loss: tensor(0.8487)\n",
      "32698 Traning Loss: tensor(0.8487)\n",
      "32699 Traning Loss: tensor(0.8487)\n",
      "32700 Traning Loss: tensor(0.8487)\n",
      "32701 Traning Loss: tensor(0.8487)\n",
      "32702 Traning Loss: tensor(0.8487)\n",
      "32703 Traning Loss: tensor(0.8487)\n",
      "32704 Traning Loss: tensor(0.8487)\n",
      "32705 Traning Loss: tensor(0.8487)\n",
      "32706 Traning Loss: tensor(0.8487)\n",
      "32707 Traning Loss: tensor(0.8487)\n",
      "32708 Traning Loss: tensor(0.8487)\n",
      "32709 Traning Loss: tensor(0.8487)\n",
      "32710 Traning Loss: tensor(0.8487)\n",
      "32711 Traning Loss: tensor(0.8487)\n",
      "32712 Traning Loss: tensor(0.8487)\n",
      "32713 Traning Loss: tensor(0.8487)\n",
      "32714 Traning Loss: tensor(0.8487)\n",
      "32715 Traning Loss: tensor(0.8487)\n",
      "32716 Traning Loss: tensor(0.8487)\n",
      "32717 Traning Loss: tensor(0.8487)\n",
      "32718 Traning Loss: tensor(0.8487)\n",
      "32719 Traning Loss: tensor(0.8487)\n",
      "32720 Traning Loss: tensor(0.8487)\n",
      "32721 Traning Loss: tensor(0.8487)\n",
      "32722 Traning Loss: tensor(0.8487)\n",
      "32723 Traning Loss: tensor(0.8487)\n",
      "32724 Traning Loss: tensor(0.8487)\n",
      "32725 Traning Loss: tensor(0.8487)\n",
      "32726 Traning Loss: tensor(0.8487)\n",
      "32727 Traning Loss: tensor(0.8487)\n",
      "32728 Traning Loss: tensor(0.8487)\n",
      "32729 Traning Loss: tensor(0.8487)\n",
      "32730 Traning Loss: tensor(0.8487)\n",
      "32731 Traning Loss: tensor(0.8487)\n",
      "32732 Traning Loss: tensor(0.8487)\n",
      "32733 Traning Loss: tensor(0.8487)\n",
      "32734 Traning Loss: tensor(0.8487)\n",
      "32735 Traning Loss: tensor(0.8487)\n",
      "32736 Traning Loss: tensor(0.8487)\n",
      "32737 Traning Loss: tensor(0.8487)\n",
      "32738 Traning Loss: tensor(0.8487)\n",
      "32739 Traning Loss: tensor(0.8487)\n",
      "32740 Traning Loss: tensor(0.8487)\n",
      "32741 Traning Loss: tensor(0.8487)\n",
      "32742 Traning Loss: tensor(0.8487)\n",
      "32743 Traning Loss: tensor(0.8487)\n",
      "32744 Traning Loss: tensor(0.8487)\n",
      "32745 Traning Loss: tensor(0.8487)\n",
      "32746 Traning Loss: tensor(0.8487)\n",
      "32747 Traning Loss: tensor(0.8487)\n",
      "32748 Traning Loss: tensor(0.8487)\n",
      "32749 Traning Loss: tensor(0.8487)\n",
      "32750 Traning Loss: tensor(0.8487)\n",
      "32751 Traning Loss: tensor(0.8487)\n",
      "32752 Traning Loss: tensor(0.8487)\n",
      "32753 Traning Loss: tensor(0.8487)\n",
      "32754 Traning Loss: tensor(0.8487)\n",
      "32755 Traning Loss: tensor(0.8487)\n",
      "32756 Traning Loss: tensor(0.8487)\n",
      "32757 Traning Loss: tensor(0.8487)\n",
      "32758 Traning Loss: tensor(0.8487)\n",
      "32759 Traning Loss: tensor(0.8487)\n",
      "32760 Traning Loss: tensor(0.8487)\n",
      "32761 Traning Loss: tensor(0.8487)\n",
      "32762 Traning Loss: tensor(0.8487)\n",
      "32763 Traning Loss: tensor(0.8487)\n",
      "32764 Traning Loss: tensor(0.8487)\n",
      "32765 Traning Loss: tensor(0.8487)\n",
      "32766 Traning Loss: tensor(0.8487)\n",
      "32767 Traning Loss: tensor(0.8487)\n",
      "32768 Traning Loss: tensor(0.8487)\n",
      "32769 Traning Loss: tensor(0.8487)\n",
      "32770 Traning Loss: tensor(0.8487)\n",
      "32771 Traning Loss: tensor(0.8487)\n",
      "32772 Traning Loss: tensor(0.8487)\n",
      "32773 Traning Loss: tensor(0.8487)\n",
      "32774 Traning Loss: tensor(0.8487)\n",
      "32775 Traning Loss: tensor(0.8487)\n",
      "32776 Traning Loss: tensor(0.8487)\n",
      "32777 Traning Loss: tensor(0.8487)\n",
      "32778 Traning Loss: tensor(0.8487)\n",
      "32779 Traning Loss: tensor(0.8487)\n",
      "32780 Traning Loss: tensor(0.8487)\n",
      "32781 Traning Loss: tensor(0.8487)\n",
      "32782 Traning Loss: tensor(0.8487)\n",
      "32783 Traning Loss: tensor(0.8487)\n",
      "32784 Traning Loss: tensor(0.8487)\n",
      "32785 Traning Loss: tensor(0.8487)\n",
      "32786 Traning Loss: tensor(0.8487)\n",
      "32787 Traning Loss: tensor(0.8487)\n",
      "32788 Traning Loss: tensor(0.8487)\n",
      "32789 Traning Loss: tensor(0.8487)\n",
      "32790 Traning Loss: tensor(0.8487)\n",
      "32791 Traning Loss: tensor(0.8487)\n",
      "32792 Traning Loss: tensor(0.8487)\n",
      "32793 Traning Loss: tensor(0.8487)\n",
      "32794 Traning Loss: tensor(0.8487)\n",
      "32795 Traning Loss: tensor(0.8487)\n",
      "32796 Traning Loss: tensor(0.8487)\n",
      "32797 Traning Loss: tensor(0.8487)\n",
      "32798 Traning Loss: tensor(0.8487)\n",
      "32799 Traning Loss: tensor(0.8487)\n",
      "32800 Traning Loss: tensor(0.8487)\n",
      "32801 Traning Loss: tensor(0.8487)\n",
      "32802 Traning Loss: tensor(0.8487)\n",
      "32803 Traning Loss: tensor(0.8487)\n",
      "32804 Traning Loss: tensor(0.8487)\n",
      "32805 Traning Loss: tensor(0.8487)\n",
      "32806 Traning Loss: tensor(0.8487)\n",
      "32807 Traning Loss: tensor(0.8487)\n",
      "32808 Traning Loss: tensor(0.8487)\n",
      "32809 Traning Loss: tensor(0.8487)\n",
      "32810 Traning Loss: tensor(0.8488)\n",
      "32811 Traning Loss: tensor(0.8488)\n",
      "32812 Traning Loss: tensor(0.8488)\n",
      "32813 Traning Loss: tensor(0.8488)\n",
      "32814 Traning Loss: tensor(0.8488)\n",
      "32815 Traning Loss: tensor(0.8487)\n",
      "32816 Traning Loss: tensor(0.8487)\n",
      "32817 Traning Loss: tensor(0.8487)\n",
      "32818 Traning Loss: tensor(0.8487)\n",
      "32819 Traning Loss: tensor(0.8487)\n",
      "32820 Traning Loss: tensor(0.8487)\n",
      "32821 Traning Loss: tensor(0.8487)\n",
      "32822 Traning Loss: tensor(0.8487)\n",
      "32823 Traning Loss: tensor(0.8487)\n",
      "32824 Traning Loss: tensor(0.8487)\n",
      "32825 Traning Loss: tensor(0.8487)\n",
      "32826 Traning Loss: tensor(0.8487)\n",
      "32827 Traning Loss: tensor(0.8487)\n",
      "32828 Traning Loss: tensor(0.8487)\n",
      "32829 Traning Loss: tensor(0.8487)\n",
      "32830 Traning Loss: tensor(0.8487)\n",
      "32831 Traning Loss: tensor(0.8487)\n",
      "32832 Traning Loss: tensor(0.8487)\n",
      "32833 Traning Loss: tensor(0.8487)\n",
      "32834 Traning Loss: tensor(0.8487)\n",
      "32835 Traning Loss: tensor(0.8487)\n",
      "32836 Traning Loss: tensor(0.8487)\n",
      "32837 Traning Loss: tensor(0.8487)\n",
      "32838 Traning Loss: tensor(0.8487)\n",
      "32839 Traning Loss: tensor(0.8487)\n",
      "32840 Traning Loss: tensor(0.8487)\n",
      "32841 Traning Loss: tensor(0.8487)\n",
      "32842 Traning Loss: tensor(0.8487)\n",
      "32843 Traning Loss: tensor(0.8487)\n",
      "32844 Traning Loss: tensor(0.8487)\n",
      "32845 Traning Loss: tensor(0.8487)\n",
      "32846 Traning Loss: tensor(0.8487)\n",
      "32847 Traning Loss: tensor(0.8487)\n",
      "32848 Traning Loss: tensor(0.8487)\n",
      "32849 Traning Loss: tensor(0.8487)\n",
      "32850 Traning Loss: tensor(0.8487)\n",
      "32851 Traning Loss: tensor(0.8487)\n",
      "32852 Traning Loss: tensor(0.8487)\n",
      "32853 Traning Loss: tensor(0.8487)\n",
      "32854 Traning Loss: tensor(0.8487)\n",
      "32855 Traning Loss: tensor(0.8487)\n",
      "32856 Traning Loss: tensor(0.8487)\n",
      "32857 Traning Loss: tensor(0.8487)\n",
      "32858 Traning Loss: tensor(0.8487)\n",
      "32859 Traning Loss: tensor(0.8487)\n",
      "32860 Traning Loss: tensor(0.8487)\n",
      "32861 Traning Loss: tensor(0.8487)\n",
      "32862 Traning Loss: tensor(0.8487)\n",
      "32863 Traning Loss: tensor(0.8487)\n",
      "32864 Traning Loss: tensor(0.8487)\n",
      "32865 Traning Loss: tensor(0.8487)\n",
      "32866 Traning Loss: tensor(0.8487)\n",
      "32867 Traning Loss: tensor(0.8487)\n",
      "32868 Traning Loss: tensor(0.8487)\n",
      "32869 Traning Loss: tensor(0.8487)\n",
      "32870 Traning Loss: tensor(0.8487)\n",
      "32871 Traning Loss: tensor(0.8487)\n",
      "32872 Traning Loss: tensor(0.8487)\n",
      "32873 Traning Loss: tensor(0.8487)\n",
      "32874 Traning Loss: tensor(0.8487)\n",
      "32875 Traning Loss: tensor(0.8487)\n",
      "32876 Traning Loss: tensor(0.8487)\n",
      "32877 Traning Loss: tensor(0.8487)\n",
      "32878 Traning Loss: tensor(0.8487)\n",
      "32879 Traning Loss: tensor(0.8487)\n",
      "32880 Traning Loss: tensor(0.8487)\n",
      "32881 Traning Loss: tensor(0.8487)\n",
      "32882 Traning Loss: tensor(0.8487)\n",
      "32883 Traning Loss: tensor(0.8487)\n",
      "32884 Traning Loss: tensor(0.8487)\n",
      "32885 Traning Loss: tensor(0.8487)\n",
      "32886 Traning Loss: tensor(0.8487)\n",
      "32887 Traning Loss: tensor(0.8487)\n",
      "32888 Traning Loss: tensor(0.8487)\n",
      "32889 Traning Loss: tensor(0.8487)\n",
      "32890 Traning Loss: tensor(0.8487)\n",
      "32891 Traning Loss: tensor(0.8487)\n",
      "32892 Traning Loss: tensor(0.8487)\n",
      "32893 Traning Loss: tensor(0.8487)\n",
      "32894 Traning Loss: tensor(0.8487)\n",
      "32895 Traning Loss: tensor(0.8487)\n",
      "32896 Traning Loss: tensor(0.8487)\n",
      "32897 Traning Loss: tensor(0.8487)\n",
      "32898 Traning Loss: tensor(0.8487)\n",
      "32899 Traning Loss: tensor(0.8487)\n",
      "32900 Traning Loss: tensor(0.8487)\n",
      "32901 Traning Loss: tensor(0.8487)\n",
      "32902 Traning Loss: tensor(0.8487)\n",
      "32903 Traning Loss: tensor(0.8487)\n",
      "32904 Traning Loss: tensor(0.8487)\n",
      "32905 Traning Loss: tensor(0.8487)\n",
      "32906 Traning Loss: tensor(0.8487)\n",
      "32907 Traning Loss: tensor(0.8487)\n",
      "32908 Traning Loss: tensor(0.8487)\n",
      "32909 Traning Loss: tensor(0.8487)\n",
      "32910 Traning Loss: tensor(0.8487)\n",
      "32911 Traning Loss: tensor(0.8487)\n",
      "32912 Traning Loss: tensor(0.8487)\n",
      "32913 Traning Loss: tensor(0.8487)\n",
      "32914 Traning Loss: tensor(0.8487)\n",
      "32915 Traning Loss: tensor(0.8487)\n",
      "32916 Traning Loss: tensor(0.8487)\n",
      "32917 Traning Loss: tensor(0.8487)\n",
      "32918 Traning Loss: tensor(0.8487)\n",
      "32919 Traning Loss: tensor(0.8487)\n",
      "32920 Traning Loss: tensor(0.8487)\n",
      "32921 Traning Loss: tensor(0.8487)\n",
      "32922 Traning Loss: tensor(0.8487)\n",
      "32923 Traning Loss: tensor(0.8487)\n",
      "32924 Traning Loss: tensor(0.8487)\n",
      "32925 Traning Loss: tensor(0.8487)\n",
      "32926 Traning Loss: tensor(0.8487)\n",
      "32927 Traning Loss: tensor(0.8487)\n",
      "32928 Traning Loss: tensor(0.8487)\n",
      "32929 Traning Loss: tensor(0.8487)\n",
      "32930 Traning Loss: tensor(0.8487)\n",
      "32931 Traning Loss: tensor(0.8487)\n",
      "32932 Traning Loss: tensor(0.8487)\n",
      "32933 Traning Loss: tensor(0.8487)\n",
      "32934 Traning Loss: tensor(0.8487)\n",
      "32935 Traning Loss: tensor(0.8487)\n",
      "32936 Traning Loss: tensor(0.8487)\n",
      "32937 Traning Loss: tensor(0.8487)\n",
      "32938 Traning Loss: tensor(0.8487)\n",
      "32939 Traning Loss: tensor(0.8487)\n",
      "32940 Traning Loss: tensor(0.8487)\n",
      "32941 Traning Loss: tensor(0.8487)\n",
      "32942 Traning Loss: tensor(0.8487)\n",
      "32943 Traning Loss: tensor(0.8487)\n",
      "32944 Traning Loss: tensor(0.8487)\n",
      "32945 Traning Loss: tensor(0.8487)\n",
      "32946 Traning Loss: tensor(0.8487)\n",
      "32947 Traning Loss: tensor(0.8487)\n",
      "32948 Traning Loss: tensor(0.8487)\n",
      "32949 Traning Loss: tensor(0.8487)\n",
      "32950 Traning Loss: tensor(0.8487)\n",
      "32951 Traning Loss: tensor(0.8487)\n",
      "32952 Traning Loss: tensor(0.8487)\n",
      "32953 Traning Loss: tensor(0.8487)\n",
      "32954 Traning Loss: tensor(0.8487)\n",
      "32955 Traning Loss: tensor(0.8487)\n",
      "32956 Traning Loss: tensor(0.8487)\n",
      "32957 Traning Loss: tensor(0.8487)\n",
      "32958 Traning Loss: tensor(0.8487)\n",
      "32959 Traning Loss: tensor(0.8487)\n",
      "32960 Traning Loss: tensor(0.8487)\n",
      "32961 Traning Loss: tensor(0.8487)\n",
      "32962 Traning Loss: tensor(0.8487)\n",
      "32963 Traning Loss: tensor(0.8487)\n",
      "32964 Traning Loss: tensor(0.8487)\n",
      "32965 Traning Loss: tensor(0.8487)\n",
      "32966 Traning Loss: tensor(0.8487)\n",
      "32967 Traning Loss: tensor(0.8487)\n",
      "32968 Traning Loss: tensor(0.8487)\n",
      "32969 Traning Loss: tensor(0.8487)\n",
      "32970 Traning Loss: tensor(0.8487)\n",
      "32971 Traning Loss: tensor(0.8487)\n",
      "32972 Traning Loss: tensor(0.8487)\n",
      "32973 Traning Loss: tensor(0.8487)\n",
      "32974 Traning Loss: tensor(0.8487)\n",
      "32975 Traning Loss: tensor(0.8487)\n",
      "32976 Traning Loss: tensor(0.8487)\n",
      "32977 Traning Loss: tensor(0.8487)\n",
      "32978 Traning Loss: tensor(0.8487)\n",
      "32979 Traning Loss: tensor(0.8487)\n",
      "32980 Traning Loss: tensor(0.8487)\n",
      "32981 Traning Loss: tensor(0.8487)\n",
      "32982 Traning Loss: tensor(0.8487)\n",
      "32983 Traning Loss: tensor(0.8487)\n",
      "32984 Traning Loss: tensor(0.8487)\n",
      "32985 Traning Loss: tensor(0.8487)\n",
      "32986 Traning Loss: tensor(0.8487)\n",
      "32987 Traning Loss: tensor(0.8487)\n",
      "32988 Traning Loss: tensor(0.8487)\n",
      "32989 Traning Loss: tensor(0.8487)\n",
      "32990 Traning Loss: tensor(0.8487)\n",
      "32991 Traning Loss: tensor(0.8487)\n",
      "32992 Traning Loss: tensor(0.8487)\n",
      "32993 Traning Loss: tensor(0.8487)\n",
      "32994 Traning Loss: tensor(0.8487)\n",
      "32995 Traning Loss: tensor(0.8487)\n",
      "32996 Traning Loss: tensor(0.8487)\n",
      "32997 Traning Loss: tensor(0.8487)\n",
      "32998 Traning Loss: tensor(0.8487)\n",
      "32999 Traning Loss: tensor(0.8487)\n",
      "33000 Traning Loss: tensor(0.8487)\n",
      "33001 Traning Loss: tensor(0.8487)\n",
      "33002 Traning Loss: tensor(0.8487)\n",
      "33003 Traning Loss: tensor(0.8487)\n",
      "33004 Traning Loss: tensor(0.8487)\n",
      "33005 Traning Loss: tensor(0.8487)\n",
      "33006 Traning Loss: tensor(0.8487)\n",
      "33007 Traning Loss: tensor(0.8487)\n",
      "33008 Traning Loss: tensor(0.8487)\n",
      "33009 Traning Loss: tensor(0.8487)\n",
      "33010 Traning Loss: tensor(0.8487)\n",
      "33011 Traning Loss: tensor(0.8487)\n",
      "33012 Traning Loss: tensor(0.8487)\n",
      "33013 Traning Loss: tensor(0.8487)\n",
      "33014 Traning Loss: tensor(0.8487)\n",
      "33015 Traning Loss: tensor(0.8487)\n",
      "33016 Traning Loss: tensor(0.8487)\n",
      "33017 Traning Loss: tensor(0.8487)\n",
      "33018 Traning Loss: tensor(0.8487)\n",
      "33019 Traning Loss: tensor(0.8487)\n",
      "33020 Traning Loss: tensor(0.8487)\n",
      "33021 Traning Loss: tensor(0.8487)\n",
      "33022 Traning Loss: tensor(0.8487)\n",
      "33023 Traning Loss: tensor(0.8487)\n",
      "33024 Traning Loss: tensor(0.8487)\n",
      "33025 Traning Loss: tensor(0.8487)\n",
      "33026 Traning Loss: tensor(0.8487)\n",
      "33027 Traning Loss: tensor(0.8487)\n",
      "33028 Traning Loss: tensor(0.8487)\n",
      "33029 Traning Loss: tensor(0.8487)\n",
      "33030 Traning Loss: tensor(0.8487)\n",
      "33031 Traning Loss: tensor(0.8487)\n",
      "33032 Traning Loss: tensor(0.8487)\n",
      "33033 Traning Loss: tensor(0.8487)\n",
      "33034 Traning Loss: tensor(0.8487)\n",
      "33035 Traning Loss: tensor(0.8487)\n",
      "33036 Traning Loss: tensor(0.8487)\n",
      "33037 Traning Loss: tensor(0.8487)\n",
      "33038 Traning Loss: tensor(0.8487)\n",
      "33039 Traning Loss: tensor(0.8487)\n",
      "33040 Traning Loss: tensor(0.8487)\n",
      "33041 Traning Loss: tensor(0.8487)\n",
      "33042 Traning Loss: tensor(0.8487)\n",
      "33043 Traning Loss: tensor(0.8487)\n",
      "33044 Traning Loss: tensor(0.8487)\n",
      "33045 Traning Loss: tensor(0.8487)\n",
      "33046 Traning Loss: tensor(0.8487)\n",
      "33047 Traning Loss: tensor(0.8487)\n",
      "33048 Traning Loss: tensor(0.8487)\n",
      "33049 Traning Loss: tensor(0.8487)\n",
      "33050 Traning Loss: tensor(0.8487)\n",
      "33051 Traning Loss: tensor(0.8487)\n",
      "33052 Traning Loss: tensor(0.8487)\n",
      "33053 Traning Loss: tensor(0.8487)\n",
      "33054 Traning Loss: tensor(0.8487)\n",
      "33055 Traning Loss: tensor(0.8487)\n",
      "33056 Traning Loss: tensor(0.8487)\n",
      "33057 Traning Loss: tensor(0.8487)\n",
      "33058 Traning Loss: tensor(0.8487)\n",
      "33059 Traning Loss: tensor(0.8487)\n",
      "33060 Traning Loss: tensor(0.8487)\n",
      "33061 Traning Loss: tensor(0.8487)\n",
      "33062 Traning Loss: tensor(0.8487)\n",
      "33063 Traning Loss: tensor(0.8487)\n",
      "33064 Traning Loss: tensor(0.8487)\n",
      "33065 Traning Loss: tensor(0.8488)\n",
      "33066 Traning Loss: tensor(0.8488)\n",
      "33067 Traning Loss: tensor(0.8488)\n",
      "33068 Traning Loss: tensor(0.8488)\n",
      "33069 Traning Loss: tensor(0.8488)\n",
      "33070 Traning Loss: tensor(0.8487)\n",
      "33071 Traning Loss: tensor(0.8487)\n",
      "33072 Traning Loss: tensor(0.8487)\n",
      "33073 Traning Loss: tensor(0.8487)\n",
      "33074 Traning Loss: tensor(0.8487)\n",
      "33075 Traning Loss: tensor(0.8487)\n",
      "33076 Traning Loss: tensor(0.8487)\n",
      "33077 Traning Loss: tensor(0.8487)\n",
      "33078 Traning Loss: tensor(0.8487)\n",
      "33079 Traning Loss: tensor(0.8487)\n",
      "33080 Traning Loss: tensor(0.8487)\n",
      "33081 Traning Loss: tensor(0.8487)\n",
      "33082 Traning Loss: tensor(0.8487)\n",
      "33083 Traning Loss: tensor(0.8487)\n",
      "33084 Traning Loss: tensor(0.8487)\n",
      "33085 Traning Loss: tensor(0.8487)\n",
      "33086 Traning Loss: tensor(0.8487)\n",
      "33087 Traning Loss: tensor(0.8487)\n",
      "33088 Traning Loss: tensor(0.8487)\n",
      "33089 Traning Loss: tensor(0.8487)\n",
      "33090 Traning Loss: tensor(0.8487)\n",
      "33091 Traning Loss: tensor(0.8487)\n",
      "33092 Traning Loss: tensor(0.8487)\n",
      "33093 Traning Loss: tensor(0.8487)\n",
      "33094 Traning Loss: tensor(0.8487)\n",
      "33095 Traning Loss: tensor(0.8487)\n",
      "33096 Traning Loss: tensor(0.8487)\n",
      "33097 Traning Loss: tensor(0.8487)\n",
      "33098 Traning Loss: tensor(0.8487)\n",
      "33099 Traning Loss: tensor(0.8487)\n",
      "33100 Traning Loss: tensor(0.8487)\n",
      "33101 Traning Loss: tensor(0.8487)\n",
      "33102 Traning Loss: tensor(0.8487)\n",
      "33103 Traning Loss: tensor(0.8487)\n",
      "33104 Traning Loss: tensor(0.8487)\n",
      "33105 Traning Loss: tensor(0.8487)\n",
      "33106 Traning Loss: tensor(0.8487)\n",
      "33107 Traning Loss: tensor(0.8487)\n",
      "33108 Traning Loss: tensor(0.8487)\n",
      "33109 Traning Loss: tensor(0.8487)\n",
      "33110 Traning Loss: tensor(0.8487)\n",
      "33111 Traning Loss: tensor(0.8487)\n",
      "33112 Traning Loss: tensor(0.8487)\n",
      "33113 Traning Loss: tensor(0.8487)\n",
      "33114 Traning Loss: tensor(0.8487)\n",
      "33115 Traning Loss: tensor(0.8487)\n",
      "33116 Traning Loss: tensor(0.8487)\n",
      "33117 Traning Loss: tensor(0.8487)\n",
      "33118 Traning Loss: tensor(0.8487)\n",
      "33119 Traning Loss: tensor(0.8487)\n",
      "33120 Traning Loss: tensor(0.8487)\n",
      "33121 Traning Loss: tensor(0.8487)\n",
      "33122 Traning Loss: tensor(0.8487)\n",
      "33123 Traning Loss: tensor(0.8487)\n",
      "33124 Traning Loss: tensor(0.8487)\n",
      "33125 Traning Loss: tensor(0.8487)\n",
      "33126 Traning Loss: tensor(0.8487)\n",
      "33127 Traning Loss: tensor(0.8487)\n",
      "33128 Traning Loss: tensor(0.8487)\n",
      "33129 Traning Loss: tensor(0.8487)\n",
      "33130 Traning Loss: tensor(0.8487)\n",
      "33131 Traning Loss: tensor(0.8487)\n",
      "33132 Traning Loss: tensor(0.8487)\n",
      "33133 Traning Loss: tensor(0.8487)\n",
      "33134 Traning Loss: tensor(0.8487)\n",
      "33135 Traning Loss: tensor(0.8487)\n",
      "33136 Traning Loss: tensor(0.8487)\n",
      "33137 Traning Loss: tensor(0.8487)\n",
      "33138 Traning Loss: tensor(0.8487)\n",
      "33139 Traning Loss: tensor(0.8487)\n",
      "33140 Traning Loss: tensor(0.8487)\n",
      "33141 Traning Loss: tensor(0.8487)\n",
      "33142 Traning Loss: tensor(0.8487)\n",
      "33143 Traning Loss: tensor(0.8487)\n",
      "33144 Traning Loss: tensor(0.8487)\n",
      "33145 Traning Loss: tensor(0.8487)\n",
      "33146 Traning Loss: tensor(0.8487)\n",
      "33147 Traning Loss: tensor(0.8487)\n",
      "33148 Traning Loss: tensor(0.8487)\n",
      "33149 Traning Loss: tensor(0.8487)\n",
      "33150 Traning Loss: tensor(0.8487)\n",
      "33151 Traning Loss: tensor(0.8487)\n",
      "33152 Traning Loss: tensor(0.8487)\n",
      "33153 Traning Loss: tensor(0.8487)\n",
      "33154 Traning Loss: tensor(0.8487)\n",
      "33155 Traning Loss: tensor(0.8487)\n",
      "33156 Traning Loss: tensor(0.8487)\n",
      "33157 Traning Loss: tensor(0.8487)\n",
      "33158 Traning Loss: tensor(0.8487)\n",
      "33159 Traning Loss: tensor(0.8487)\n",
      "33160 Traning Loss: tensor(0.8487)\n",
      "33161 Traning Loss: tensor(0.8487)\n",
      "33162 Traning Loss: tensor(0.8487)\n",
      "33163 Traning Loss: tensor(0.8487)\n",
      "33164 Traning Loss: tensor(0.8487)\n",
      "33165 Traning Loss: tensor(0.8487)\n",
      "33166 Traning Loss: tensor(0.8487)\n",
      "33167 Traning Loss: tensor(0.8487)\n",
      "33168 Traning Loss: tensor(0.8487)\n",
      "33169 Traning Loss: tensor(0.8487)\n",
      "33170 Traning Loss: tensor(0.8487)\n",
      "33171 Traning Loss: tensor(0.8487)\n",
      "33172 Traning Loss: tensor(0.8487)\n",
      "33173 Traning Loss: tensor(0.8487)\n",
      "33174 Traning Loss: tensor(0.8487)\n",
      "33175 Traning Loss: tensor(0.8487)\n",
      "33176 Traning Loss: tensor(0.8487)\n",
      "33177 Traning Loss: tensor(0.8487)\n",
      "33178 Traning Loss: tensor(0.8487)\n",
      "33179 Traning Loss: tensor(0.8487)\n",
      "33180 Traning Loss: tensor(0.8487)\n",
      "33181 Traning Loss: tensor(0.8487)\n",
      "33182 Traning Loss: tensor(0.8487)\n",
      "33183 Traning Loss: tensor(0.8487)\n",
      "33184 Traning Loss: tensor(0.8487)\n",
      "33185 Traning Loss: tensor(0.8487)\n",
      "33186 Traning Loss: tensor(0.8487)\n",
      "33187 Traning Loss: tensor(0.8487)\n",
      "33188 Traning Loss: tensor(0.8487)\n",
      "33189 Traning Loss: tensor(0.8487)\n",
      "33190 Traning Loss: tensor(0.8487)\n",
      "33191 Traning Loss: tensor(0.8487)\n",
      "33192 Traning Loss: tensor(0.8487)\n",
      "33193 Traning Loss: tensor(0.8487)\n",
      "33194 Traning Loss: tensor(0.8487)\n",
      "33195 Traning Loss: tensor(0.8487)\n",
      "33196 Traning Loss: tensor(0.8487)\n",
      "33197 Traning Loss: tensor(0.8487)\n",
      "33198 Traning Loss: tensor(0.8487)\n",
      "33199 Traning Loss: tensor(0.8487)\n",
      "33200 Traning Loss: tensor(0.8487)\n",
      "33201 Traning Loss: tensor(0.8487)\n",
      "33202 Traning Loss: tensor(0.8487)\n",
      "33203 Traning Loss: tensor(0.8487)\n",
      "33204 Traning Loss: tensor(0.8487)\n",
      "33205 Traning Loss: tensor(0.8487)\n",
      "33206 Traning Loss: tensor(0.8487)\n",
      "33207 Traning Loss: tensor(0.8487)\n",
      "33208 Traning Loss: tensor(0.8487)\n",
      "33209 Traning Loss: tensor(0.8487)\n",
      "33210 Traning Loss: tensor(0.8487)\n",
      "33211 Traning Loss: tensor(0.8487)\n",
      "33212 Traning Loss: tensor(0.8487)\n",
      "33213 Traning Loss: tensor(0.8487)\n",
      "33214 Traning Loss: tensor(0.8487)\n",
      "33215 Traning Loss: tensor(0.8487)\n",
      "33216 Traning Loss: tensor(0.8487)\n",
      "33217 Traning Loss: tensor(0.8487)\n",
      "33218 Traning Loss: tensor(0.8487)\n",
      "33219 Traning Loss: tensor(0.8487)\n",
      "33220 Traning Loss: tensor(0.8487)\n",
      "33221 Traning Loss: tensor(0.8487)\n",
      "33222 Traning Loss: tensor(0.8487)\n",
      "33223 Traning Loss: tensor(0.8487)\n",
      "33224 Traning Loss: tensor(0.8487)\n",
      "33225 Traning Loss: tensor(0.8487)\n",
      "33226 Traning Loss: tensor(0.8487)\n",
      "33227 Traning Loss: tensor(0.8487)\n",
      "33228 Traning Loss: tensor(0.8487)\n",
      "33229 Traning Loss: tensor(0.8487)\n",
      "33230 Traning Loss: tensor(0.8487)\n",
      "33231 Traning Loss: tensor(0.8487)\n",
      "33232 Traning Loss: tensor(0.8487)\n",
      "33233 Traning Loss: tensor(0.8487)\n",
      "33234 Traning Loss: tensor(0.8487)\n",
      "33235 Traning Loss: tensor(0.8487)\n",
      "33236 Traning Loss: tensor(0.8487)\n",
      "33237 Traning Loss: tensor(0.8487)\n",
      "33238 Traning Loss: tensor(0.8487)\n",
      "33239 Traning Loss: tensor(0.8487)\n",
      "33240 Traning Loss: tensor(0.8487)\n",
      "33241 Traning Loss: tensor(0.8487)\n",
      "33242 Traning Loss: tensor(0.8487)\n",
      "33243 Traning Loss: tensor(0.8487)\n",
      "33244 Traning Loss: tensor(0.8487)\n",
      "33245 Traning Loss: tensor(0.8487)\n",
      "33246 Traning Loss: tensor(0.8487)\n",
      "33247 Traning Loss: tensor(0.8487)\n",
      "33248 Traning Loss: tensor(0.8487)\n",
      "33249 Traning Loss: tensor(0.8487)\n",
      "33250 Traning Loss: tensor(0.8487)\n",
      "33251 Traning Loss: tensor(0.8487)\n",
      "33252 Traning Loss: tensor(0.8487)\n",
      "33253 Traning Loss: tensor(0.8487)\n",
      "33254 Traning Loss: tensor(0.8487)\n",
      "33255 Traning Loss: tensor(0.8487)\n",
      "33256 Traning Loss: tensor(0.8487)\n",
      "33257 Traning Loss: tensor(0.8487)\n",
      "33258 Traning Loss: tensor(0.8487)\n",
      "33259 Traning Loss: tensor(0.8487)\n",
      "33260 Traning Loss: tensor(0.8487)\n",
      "33261 Traning Loss: tensor(0.8487)\n",
      "33262 Traning Loss: tensor(0.8487)\n",
      "33263 Traning Loss: tensor(0.8487)\n",
      "33264 Traning Loss: tensor(0.8487)\n",
      "33265 Traning Loss: tensor(0.8487)\n",
      "33266 Traning Loss: tensor(0.8487)\n",
      "33267 Traning Loss: tensor(0.8487)\n",
      "33268 Traning Loss: tensor(0.8487)\n",
      "33269 Traning Loss: tensor(0.8487)\n",
      "33270 Traning Loss: tensor(0.8487)\n",
      "33271 Traning Loss: tensor(0.8487)\n",
      "33272 Traning Loss: tensor(0.8487)\n",
      "33273 Traning Loss: tensor(0.8487)\n",
      "33274 Traning Loss: tensor(0.8487)\n",
      "33275 Traning Loss: tensor(0.8487)\n",
      "33276 Traning Loss: tensor(0.8487)\n",
      "33277 Traning Loss: tensor(0.8487)\n",
      "33278 Traning Loss: tensor(0.8487)\n",
      "33279 Traning Loss: tensor(0.8487)\n",
      "33280 Traning Loss: tensor(0.8487)\n",
      "33281 Traning Loss: tensor(0.8487)\n",
      "33282 Traning Loss: tensor(0.8487)\n",
      "33283 Traning Loss: tensor(0.8487)\n",
      "33284 Traning Loss: tensor(0.8487)\n",
      "33285 Traning Loss: tensor(0.8487)\n",
      "33286 Traning Loss: tensor(0.8487)\n",
      "33287 Traning Loss: tensor(0.8487)\n",
      "33288 Traning Loss: tensor(0.8487)\n",
      "33289 Traning Loss: tensor(0.8487)\n",
      "33290 Traning Loss: tensor(0.8487)\n",
      "33291 Traning Loss: tensor(0.8487)\n",
      "33292 Traning Loss: tensor(0.8487)\n",
      "33293 Traning Loss: tensor(0.8487)\n",
      "33294 Traning Loss: tensor(0.8487)\n",
      "33295 Traning Loss: tensor(0.8487)\n",
      "33296 Traning Loss: tensor(0.8487)\n",
      "33297 Traning Loss: tensor(0.8487)\n",
      "33298 Traning Loss: tensor(0.8487)\n",
      "33299 Traning Loss: tensor(0.8487)\n",
      "33300 Traning Loss: tensor(0.8487)\n",
      "33301 Traning Loss: tensor(0.8487)\n",
      "33302 Traning Loss: tensor(0.8487)\n",
      "33303 Traning Loss: tensor(0.8487)\n",
      "33304 Traning Loss: tensor(0.8487)\n",
      "33305 Traning Loss: tensor(0.8487)\n",
      "33306 Traning Loss: tensor(0.8487)\n",
      "33307 Traning Loss: tensor(0.8487)\n",
      "33308 Traning Loss: tensor(0.8487)\n",
      "33309 Traning Loss: tensor(0.8487)\n",
      "33310 Traning Loss: tensor(0.8487)\n",
      "33311 Traning Loss: tensor(0.8487)\n",
      "33312 Traning Loss: tensor(0.8487)\n",
      "33313 Traning Loss: tensor(0.8487)\n",
      "33314 Traning Loss: tensor(0.8487)\n",
      "33315 Traning Loss: tensor(0.8487)\n",
      "33316 Traning Loss: tensor(0.8487)\n",
      "33317 Traning Loss: tensor(0.8487)\n",
      "33318 Traning Loss: tensor(0.8487)\n",
      "33319 Traning Loss: tensor(0.8487)\n",
      "33320 Traning Loss: tensor(0.8487)\n",
      "33321 Traning Loss: tensor(0.8487)\n",
      "33322 Traning Loss: tensor(0.8487)\n",
      "33323 Traning Loss: tensor(0.8487)\n",
      "33324 Traning Loss: tensor(0.8487)\n",
      "33325 Traning Loss: tensor(0.8487)\n",
      "33326 Traning Loss: tensor(0.8487)\n",
      "33327 Traning Loss: tensor(0.8487)\n",
      "33328 Traning Loss: tensor(0.8487)\n",
      "33329 Traning Loss: tensor(0.8487)\n",
      "33330 Traning Loss: tensor(0.8487)\n",
      "33331 Traning Loss: tensor(0.8487)\n",
      "33332 Traning Loss: tensor(0.8488)\n",
      "33333 Traning Loss: tensor(0.8488)\n",
      "33334 Traning Loss: tensor(0.8488)\n",
      "33335 Traning Loss: tensor(0.8488)\n",
      "33336 Traning Loss: tensor(0.8488)\n",
      "33337 Traning Loss: tensor(0.8487)\n",
      "33338 Traning Loss: tensor(0.8487)\n",
      "33339 Traning Loss: tensor(0.8487)\n",
      "33340 Traning Loss: tensor(0.8487)\n",
      "33341 Traning Loss: tensor(0.8487)\n",
      "33342 Traning Loss: tensor(0.8487)\n",
      "33343 Traning Loss: tensor(0.8487)\n",
      "33344 Traning Loss: tensor(0.8487)\n",
      "33345 Traning Loss: tensor(0.8487)\n",
      "33346 Traning Loss: tensor(0.8487)\n",
      "33347 Traning Loss: tensor(0.8487)\n",
      "33348 Traning Loss: tensor(0.8487)\n",
      "33349 Traning Loss: tensor(0.8487)\n",
      "33350 Traning Loss: tensor(0.8487)\n",
      "33351 Traning Loss: tensor(0.8487)\n",
      "33352 Traning Loss: tensor(0.8487)\n",
      "33353 Traning Loss: tensor(0.8487)\n",
      "33354 Traning Loss: tensor(0.8487)\n",
      "33355 Traning Loss: tensor(0.8487)\n",
      "33356 Traning Loss: tensor(0.8487)\n",
      "33357 Traning Loss: tensor(0.8487)\n",
      "33358 Traning Loss: tensor(0.8487)\n",
      "33359 Traning Loss: tensor(0.8487)\n",
      "33360 Traning Loss: tensor(0.8487)\n",
      "33361 Traning Loss: tensor(0.8487)\n",
      "33362 Traning Loss: tensor(0.8487)\n",
      "33363 Traning Loss: tensor(0.8487)\n",
      "33364 Traning Loss: tensor(0.8487)\n",
      "33365 Traning Loss: tensor(0.8487)\n",
      "33366 Traning Loss: tensor(0.8487)\n",
      "33367 Traning Loss: tensor(0.8487)\n",
      "33368 Traning Loss: tensor(0.8487)\n",
      "33369 Traning Loss: tensor(0.8487)\n",
      "33370 Traning Loss: tensor(0.8487)\n",
      "33371 Traning Loss: tensor(0.8487)\n",
      "33372 Traning Loss: tensor(0.8487)\n",
      "33373 Traning Loss: tensor(0.8487)\n",
      "33374 Traning Loss: tensor(0.8487)\n",
      "33375 Traning Loss: tensor(0.8487)\n",
      "33376 Traning Loss: tensor(0.8487)\n",
      "33377 Traning Loss: tensor(0.8487)\n",
      "33378 Traning Loss: tensor(0.8487)\n",
      "33379 Traning Loss: tensor(0.8487)\n",
      "33380 Traning Loss: tensor(0.8487)\n",
      "33381 Traning Loss: tensor(0.8487)\n",
      "33382 Traning Loss: tensor(0.8487)\n",
      "33383 Traning Loss: tensor(0.8487)\n",
      "33384 Traning Loss: tensor(0.8487)\n",
      "33385 Traning Loss: tensor(0.8487)\n",
      "33386 Traning Loss: tensor(0.8487)\n",
      "33387 Traning Loss: tensor(0.8487)\n",
      "33388 Traning Loss: tensor(0.8487)\n",
      "33389 Traning Loss: tensor(0.8487)\n",
      "33390 Traning Loss: tensor(0.8487)\n",
      "33391 Traning Loss: tensor(0.8487)\n",
      "33392 Traning Loss: tensor(0.8487)\n",
      "33393 Traning Loss: tensor(0.8487)\n",
      "33394 Traning Loss: tensor(0.8487)\n",
      "33395 Traning Loss: tensor(0.8487)\n",
      "33396 Traning Loss: tensor(0.8487)\n",
      "33397 Traning Loss: tensor(0.8487)\n",
      "33398 Traning Loss: tensor(0.8487)\n",
      "33399 Traning Loss: tensor(0.8487)\n",
      "33400 Traning Loss: tensor(0.8487)\n",
      "33401 Traning Loss: tensor(0.8487)\n",
      "33402 Traning Loss: tensor(0.8487)\n",
      "33403 Traning Loss: tensor(0.8487)\n",
      "33404 Traning Loss: tensor(0.8487)\n",
      "33405 Traning Loss: tensor(0.8487)\n",
      "33406 Traning Loss: tensor(0.8487)\n",
      "33407 Traning Loss: tensor(0.8487)\n",
      "33408 Traning Loss: tensor(0.8487)\n",
      "33409 Traning Loss: tensor(0.8487)\n",
      "33410 Traning Loss: tensor(0.8487)\n",
      "33411 Traning Loss: tensor(0.8487)\n",
      "33412 Traning Loss: tensor(0.8487)\n",
      "33413 Traning Loss: tensor(0.8487)\n",
      "33414 Traning Loss: tensor(0.8487)\n",
      "33415 Traning Loss: tensor(0.8487)\n",
      "33416 Traning Loss: tensor(0.8487)\n",
      "33417 Traning Loss: tensor(0.8487)\n",
      "33418 Traning Loss: tensor(0.8487)\n",
      "33419 Traning Loss: tensor(0.8487)\n",
      "33420 Traning Loss: tensor(0.8487)\n",
      "33421 Traning Loss: tensor(0.8487)\n",
      "33422 Traning Loss: tensor(0.8487)\n",
      "33423 Traning Loss: tensor(0.8487)\n",
      "33424 Traning Loss: tensor(0.8487)\n",
      "33425 Traning Loss: tensor(0.8487)\n",
      "33426 Traning Loss: tensor(0.8487)\n",
      "33427 Traning Loss: tensor(0.8487)\n",
      "33428 Traning Loss: tensor(0.8487)\n",
      "33429 Traning Loss: tensor(0.8487)\n",
      "33430 Traning Loss: tensor(0.8487)\n",
      "33431 Traning Loss: tensor(0.8487)\n",
      "33432 Traning Loss: tensor(0.8487)\n",
      "33433 Traning Loss: tensor(0.8487)\n",
      "33434 Traning Loss: tensor(0.8487)\n",
      "33435 Traning Loss: tensor(0.8487)\n",
      "33436 Traning Loss: tensor(0.8487)\n",
      "33437 Traning Loss: tensor(0.8487)\n",
      "33438 Traning Loss: tensor(0.8487)\n",
      "33439 Traning Loss: tensor(0.8487)\n",
      "33440 Traning Loss: tensor(0.8487)\n",
      "33441 Traning Loss: tensor(0.8487)\n",
      "33442 Traning Loss: tensor(0.8487)\n",
      "33443 Traning Loss: tensor(0.8487)\n",
      "33444 Traning Loss: tensor(0.8487)\n",
      "33445 Traning Loss: tensor(0.8487)\n",
      "33446 Traning Loss: tensor(0.8487)\n",
      "33447 Traning Loss: tensor(0.8487)\n",
      "33448 Traning Loss: tensor(0.8487)\n",
      "33449 Traning Loss: tensor(0.8487)\n",
      "33450 Traning Loss: tensor(0.8487)\n",
      "33451 Traning Loss: tensor(0.8487)\n",
      "33452 Traning Loss: tensor(0.8487)\n",
      "33453 Traning Loss: tensor(0.8487)\n",
      "33454 Traning Loss: tensor(0.8487)\n",
      "33455 Traning Loss: tensor(0.8487)\n",
      "33456 Traning Loss: tensor(0.8487)\n",
      "33457 Traning Loss: tensor(0.8487)\n",
      "33458 Traning Loss: tensor(0.8487)\n",
      "33459 Traning Loss: tensor(0.8487)\n",
      "33460 Traning Loss: tensor(0.8487)\n",
      "33461 Traning Loss: tensor(0.8487)\n",
      "33462 Traning Loss: tensor(0.8487)\n",
      "33463 Traning Loss: tensor(0.8487)\n",
      "33464 Traning Loss: tensor(0.8487)\n",
      "33465 Traning Loss: tensor(0.8487)\n",
      "33466 Traning Loss: tensor(0.8487)\n",
      "33467 Traning Loss: tensor(0.8487)\n",
      "33468 Traning Loss: tensor(0.8487)\n",
      "33469 Traning Loss: tensor(0.8487)\n",
      "33470 Traning Loss: tensor(0.8487)\n",
      "33471 Traning Loss: tensor(0.8487)\n",
      "33472 Traning Loss: tensor(0.8487)\n",
      "33473 Traning Loss: tensor(0.8487)\n",
      "33474 Traning Loss: tensor(0.8487)\n",
      "33475 Traning Loss: tensor(0.8487)\n",
      "33476 Traning Loss: tensor(0.8487)\n",
      "33477 Traning Loss: tensor(0.8487)\n",
      "33478 Traning Loss: tensor(0.8487)\n",
      "33479 Traning Loss: tensor(0.8487)\n",
      "33480 Traning Loss: tensor(0.8487)\n",
      "33481 Traning Loss: tensor(0.8487)\n",
      "33482 Traning Loss: tensor(0.8487)\n",
      "33483 Traning Loss: tensor(0.8487)\n",
      "33484 Traning Loss: tensor(0.8487)\n",
      "33485 Traning Loss: tensor(0.8487)\n",
      "33486 Traning Loss: tensor(0.8487)\n",
      "33487 Traning Loss: tensor(0.8487)\n",
      "33488 Traning Loss: tensor(0.8487)\n",
      "33489 Traning Loss: tensor(0.8487)\n",
      "33490 Traning Loss: tensor(0.8487)\n",
      "33491 Traning Loss: tensor(0.8487)\n",
      "33492 Traning Loss: tensor(0.8487)\n",
      "33493 Traning Loss: tensor(0.8487)\n",
      "33494 Traning Loss: tensor(0.8487)\n",
      "33495 Traning Loss: tensor(0.8487)\n",
      "33496 Traning Loss: tensor(0.8487)\n",
      "33497 Traning Loss: tensor(0.8487)\n",
      "33498 Traning Loss: tensor(0.8487)\n",
      "33499 Traning Loss: tensor(0.8487)\n",
      "33500 Traning Loss: tensor(0.8487)\n",
      "33501 Traning Loss: tensor(0.8487)\n",
      "33502 Traning Loss: tensor(0.8487)\n",
      "33503 Traning Loss: tensor(0.8487)\n",
      "33504 Traning Loss: tensor(0.8487)\n",
      "33505 Traning Loss: tensor(0.8487)\n",
      "33506 Traning Loss: tensor(0.8487)\n",
      "33507 Traning Loss: tensor(0.8487)\n",
      "33508 Traning Loss: tensor(0.8487)\n",
      "33509 Traning Loss: tensor(0.8487)\n",
      "33510 Traning Loss: tensor(0.8487)\n",
      "33511 Traning Loss: tensor(0.8487)\n",
      "33512 Traning Loss: tensor(0.8487)\n",
      "33513 Traning Loss: tensor(0.8487)\n",
      "33514 Traning Loss: tensor(0.8487)\n",
      "33515 Traning Loss: tensor(0.8487)\n",
      "33516 Traning Loss: tensor(0.8487)\n",
      "33517 Traning Loss: tensor(0.8487)\n",
      "33518 Traning Loss: tensor(0.8487)\n",
      "33519 Traning Loss: tensor(0.8487)\n",
      "33520 Traning Loss: tensor(0.8487)\n",
      "33521 Traning Loss: tensor(0.8487)\n",
      "33522 Traning Loss: tensor(0.8487)\n",
      "33523 Traning Loss: tensor(0.8487)\n",
      "33524 Traning Loss: tensor(0.8487)\n",
      "33525 Traning Loss: tensor(0.8487)\n",
      "33526 Traning Loss: tensor(0.8487)\n",
      "33527 Traning Loss: tensor(0.8487)\n",
      "33528 Traning Loss: tensor(0.8487)\n",
      "33529 Traning Loss: tensor(0.8487)\n",
      "33530 Traning Loss: tensor(0.8487)\n",
      "33531 Traning Loss: tensor(0.8487)\n",
      "33532 Traning Loss: tensor(0.8487)\n",
      "33533 Traning Loss: tensor(0.8487)\n",
      "33534 Traning Loss: tensor(0.8487)\n",
      "33535 Traning Loss: tensor(0.8487)\n",
      "33536 Traning Loss: tensor(0.8487)\n",
      "33537 Traning Loss: tensor(0.8487)\n",
      "33538 Traning Loss: tensor(0.8487)\n",
      "33539 Traning Loss: tensor(0.8487)\n",
      "33540 Traning Loss: tensor(0.8487)\n",
      "33541 Traning Loss: tensor(0.8487)\n",
      "33542 Traning Loss: tensor(0.8487)\n",
      "33543 Traning Loss: tensor(0.8487)\n",
      "33544 Traning Loss: tensor(0.8487)\n",
      "33545 Traning Loss: tensor(0.8487)\n",
      "33546 Traning Loss: tensor(0.8487)\n",
      "33547 Traning Loss: tensor(0.8487)\n",
      "33548 Traning Loss: tensor(0.8487)\n",
      "33549 Traning Loss: tensor(0.8487)\n",
      "33550 Traning Loss: tensor(0.8487)\n",
      "33551 Traning Loss: tensor(0.8487)\n",
      "33552 Traning Loss: tensor(0.8487)\n",
      "33553 Traning Loss: tensor(0.8487)\n",
      "33554 Traning Loss: tensor(0.8487)\n",
      "33555 Traning Loss: tensor(0.8487)\n",
      "33556 Traning Loss: tensor(0.8487)\n",
      "33557 Traning Loss: tensor(0.8487)\n",
      "33558 Traning Loss: tensor(0.8487)\n",
      "33559 Traning Loss: tensor(0.8487)\n",
      "33560 Traning Loss: tensor(0.8487)\n",
      "33561 Traning Loss: tensor(0.8487)\n",
      "33562 Traning Loss: tensor(0.8487)\n",
      "33563 Traning Loss: tensor(0.8487)\n",
      "33564 Traning Loss: tensor(0.8487)\n",
      "33565 Traning Loss: tensor(0.8487)\n",
      "33566 Traning Loss: tensor(0.8487)\n",
      "33567 Traning Loss: tensor(0.8487)\n",
      "33568 Traning Loss: tensor(0.8487)\n",
      "33569 Traning Loss: tensor(0.8487)\n",
      "33570 Traning Loss: tensor(0.8487)\n",
      "33571 Traning Loss: tensor(0.8487)\n",
      "33572 Traning Loss: tensor(0.8487)\n",
      "33573 Traning Loss: tensor(0.8487)\n",
      "33574 Traning Loss: tensor(0.8487)\n",
      "33575 Traning Loss: tensor(0.8487)\n",
      "33576 Traning Loss: tensor(0.8487)\n",
      "33577 Traning Loss: tensor(0.8487)\n",
      "33578 Traning Loss: tensor(0.8487)\n",
      "33579 Traning Loss: tensor(0.8487)\n",
      "33580 Traning Loss: tensor(0.8487)\n",
      "33581 Traning Loss: tensor(0.8487)\n",
      "33582 Traning Loss: tensor(0.8487)\n",
      "33583 Traning Loss: tensor(0.8487)\n",
      "33584 Traning Loss: tensor(0.8487)\n",
      "33585 Traning Loss: tensor(0.8487)\n",
      "33586 Traning Loss: tensor(0.8487)\n",
      "33587 Traning Loss: tensor(0.8487)\n",
      "33588 Traning Loss: tensor(0.8487)\n",
      "33589 Traning Loss: tensor(0.8487)\n",
      "33590 Traning Loss: tensor(0.8487)\n",
      "33591 Traning Loss: tensor(0.8487)\n",
      "33592 Traning Loss: tensor(0.8487)\n",
      "33593 Traning Loss: tensor(0.8487)\n",
      "33594 Traning Loss: tensor(0.8487)\n",
      "33595 Traning Loss: tensor(0.8487)\n",
      "33596 Traning Loss: tensor(0.8487)\n",
      "33597 Traning Loss: tensor(0.8487)\n",
      "33598 Traning Loss: tensor(0.8487)\n",
      "33599 Traning Loss: tensor(0.8487)\n",
      "33600 Traning Loss: tensor(0.8487)\n",
      "33601 Traning Loss: tensor(0.8487)\n",
      "33602 Traning Loss: tensor(0.8487)\n",
      "33603 Traning Loss: tensor(0.8487)\n",
      "33604 Traning Loss: tensor(0.8487)\n",
      "33605 Traning Loss: tensor(0.8487)\n",
      "33606 Traning Loss: tensor(0.8487)\n",
      "33607 Traning Loss: tensor(0.8487)\n",
      "33608 Traning Loss: tensor(0.8487)\n",
      "33609 Traning Loss: tensor(0.8487)\n",
      "33610 Traning Loss: tensor(0.8487)\n",
      "33611 Traning Loss: tensor(0.8487)\n",
      "33612 Traning Loss: tensor(0.8487)\n",
      "33613 Traning Loss: tensor(0.8487)\n",
      "33614 Traning Loss: tensor(0.8487)\n",
      "33615 Traning Loss: tensor(0.8487)\n",
      "33616 Traning Loss: tensor(0.8487)\n",
      "33617 Traning Loss: tensor(0.8488)\n",
      "33618 Traning Loss: tensor(0.8488)\n",
      "33619 Traning Loss: tensor(0.8488)\n",
      "33620 Traning Loss: tensor(0.8488)\n",
      "33621 Traning Loss: tensor(0.8488)\n",
      "33622 Traning Loss: tensor(0.8487)\n",
      "33623 Traning Loss: tensor(0.8487)\n",
      "33624 Traning Loss: tensor(0.8487)\n",
      "33625 Traning Loss: tensor(0.8487)\n",
      "33626 Traning Loss: tensor(0.8488)\n",
      "33627 Traning Loss: tensor(0.8487)\n",
      "33628 Traning Loss: tensor(0.8487)\n",
      "33629 Traning Loss: tensor(0.8487)\n",
      "33630 Traning Loss: tensor(0.8487)\n",
      "33631 Traning Loss: tensor(0.8487)\n",
      "33632 Traning Loss: tensor(0.8487)\n",
      "33633 Traning Loss: tensor(0.8487)\n",
      "33634 Traning Loss: tensor(0.8487)\n",
      "33635 Traning Loss: tensor(0.8487)\n",
      "33636 Traning Loss: tensor(0.8487)\n",
      "33637 Traning Loss: tensor(0.8487)\n",
      "33638 Traning Loss: tensor(0.8487)\n",
      "33639 Traning Loss: tensor(0.8487)\n",
      "33640 Traning Loss: tensor(0.8487)\n",
      "33641 Traning Loss: tensor(0.8487)\n",
      "33642 Traning Loss: tensor(0.8487)\n",
      "33643 Traning Loss: tensor(0.8487)\n",
      "33644 Traning Loss: tensor(0.8487)\n",
      "33645 Traning Loss: tensor(0.8487)\n",
      "33646 Traning Loss: tensor(0.8487)\n",
      "33647 Traning Loss: tensor(0.8487)\n",
      "33648 Traning Loss: tensor(0.8487)\n",
      "33649 Traning Loss: tensor(0.8487)\n",
      "33650 Traning Loss: tensor(0.8487)\n",
      "33651 Traning Loss: tensor(0.8487)\n",
      "33652 Traning Loss: tensor(0.8487)\n",
      "33653 Traning Loss: tensor(0.8487)\n",
      "33654 Traning Loss: tensor(0.8487)\n",
      "33655 Traning Loss: tensor(0.8487)\n",
      "33656 Traning Loss: tensor(0.8487)\n",
      "33657 Traning Loss: tensor(0.8487)\n",
      "33658 Traning Loss: tensor(0.8487)\n",
      "33659 Traning Loss: tensor(0.8487)\n",
      "33660 Traning Loss: tensor(0.8487)\n",
      "33661 Traning Loss: tensor(0.8487)\n",
      "33662 Traning Loss: tensor(0.8487)\n",
      "33663 Traning Loss: tensor(0.8487)\n",
      "33664 Traning Loss: tensor(0.8487)\n",
      "33665 Traning Loss: tensor(0.8487)\n",
      "33666 Traning Loss: tensor(0.8487)\n",
      "33667 Traning Loss: tensor(0.8487)\n",
      "33668 Traning Loss: tensor(0.8487)\n",
      "33669 Traning Loss: tensor(0.8487)\n",
      "33670 Traning Loss: tensor(0.8487)\n",
      "33671 Traning Loss: tensor(0.8487)\n",
      "33672 Traning Loss: tensor(0.8487)\n",
      "33673 Traning Loss: tensor(0.8487)\n",
      "33674 Traning Loss: tensor(0.8487)\n",
      "33675 Traning Loss: tensor(0.8487)\n",
      "33676 Traning Loss: tensor(0.8487)\n",
      "33677 Traning Loss: tensor(0.8487)\n",
      "33678 Traning Loss: tensor(0.8487)\n",
      "33679 Traning Loss: tensor(0.8487)\n",
      "33680 Traning Loss: tensor(0.8487)\n",
      "33681 Traning Loss: tensor(0.8487)\n",
      "33682 Traning Loss: tensor(0.8487)\n",
      "33683 Traning Loss: tensor(0.8487)\n",
      "33684 Traning Loss: tensor(0.8487)\n",
      "33685 Traning Loss: tensor(0.8487)\n",
      "33686 Traning Loss: tensor(0.8487)\n",
      "33687 Traning Loss: tensor(0.8487)\n",
      "33688 Traning Loss: tensor(0.8487)\n",
      "33689 Traning Loss: tensor(0.8487)\n",
      "33690 Traning Loss: tensor(0.8487)\n",
      "33691 Traning Loss: tensor(0.8487)\n",
      "33692 Traning Loss: tensor(0.8487)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# to make the gradients zero\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=10'>11</a>\u001b[0m \u001b[39m# Loss based on boundary conditions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=11'>12</a>\u001b[0m \u001b[39m#pt_x_bc = Variable(torch.Tensor(x_bc).float(), requires_grad=False).to(device)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=12'>13</a>\u001b[0m pt_t_bc \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39;49mTensor(t_bc)\u001b[39m.\u001b[39mfloat(), requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=13'>14</a>\u001b[0m pt_u_bc \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mTensor(u_bc)\u001b[39m.\u001b[39mfloat(), requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/utkarshpratiush/RA_IISc/Inverse-problem-pde/PINN/Lotka_volterra_pinn.ipynb#ch0000006?line=14'>15</a>\u001b[0m pt_v_bc \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mTensor(v_bc)\u001b[39m.\u001b[39mfloat(), requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### (3) Training / Fitting\n",
    "iterations = 199999\n",
    "epoch = 0\n",
    "loss =  torch.tensor(10000)\n",
    "#previous_validation_loss = 99999999.0\n",
    "#for epoch in range(iterations):\n",
    "while True :\n",
    "    epoch += 1\n",
    "    optimizer.zero_grad() # to make the gradients zero\n",
    "    \n",
    "    # Loss based on boundary conditions\n",
    "    #pt_x_bc = Variable(torch.Tensor(x_bc).float(), requires_grad=False).to(device)\n",
    "    pt_t_bc = Variable(torch.Tensor(t_bc).float(), requires_grad=False).to(device)\n",
    "    pt_u_bc = Variable(torch.Tensor(u_bc).float(), requires_grad=False).to(device)\n",
    "    pt_v_bc = Variable(torch.Tensor(v_bc).float(), requires_grad=False).to(device)\n",
    "\n",
    "    \n",
    "    net_u_bc_out = net_x(pt_t_bc) # output of u(x,t)\n",
    "    mse_u_bc = mse_cost_function(net_u_bc_out, pt_u_bc)\n",
    "\n",
    "    net_v_bc_out = net_y(pt_t_bc) # output of u(x,t)\n",
    "    mse_v_bc = mse_cost_function(net_v_bc_out, pt_v_bc)\n",
    "    \n",
    "    # Loss based on PDE\n",
    "    #x_collocation = np.random.uniform(low=0.0, high=2.0, size=(500,1))\n",
    "    t_collocation = np.linspace(0,500,500).reshape((500,1))\n",
    "    all_zeros_1 = np.zeros((500,1))\n",
    "    all_zeros_2 = np.zeros((500,1))\n",
    "    \n",
    "    \n",
    "    #pt_x_collocation = Variable(torch.Tensor(x_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_t_collocation = Variable(torch.Tensor(t_collocation).float(), requires_grad=True).to(device)\n",
    "    pt_all_zeros_1 = Variable(torch.Tensor(all_zeros_1).float(), requires_grad=False).to(device)\n",
    "    pt_all_zeros_2 = Variable(torch.Tensor(all_zeros_1).float(), requires_grad=False).to(device)\n",
    "\n",
    "    \n",
    "    pde_1, pde_2 = f(pt_t_collocation, net_x, net_y) # output of the differential eqn\n",
    "    mse_f_1 = mse_cost_function(pde_1, pt_all_zeros_1)\n",
    "    mse_f_2 = mse_cost_function(pde_2, pt_all_zeros_2)\n",
    "    \n",
    "    # Combining the loss functions\n",
    "    loss = mse_u_bc + mse_v_bc  + mse_f_1 + mse_f_2\n",
    "    \n",
    "    \n",
    "    loss.backward() # This is for computing gradients using backward propagation\n",
    "    optimizer.step() # This is equivalent to : theta_new = theta_old - alpha * derivative of J w.r.t theta\n",
    "\n",
    "    with torch.autograd.no_grad():\n",
    "    \tprint(epoch,\"Traning Loss:\",loss.data)\n",
    "\n",
    "    if (loss.item() <= 0.00005):\n",
    "                        break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_test_collocation = np.random.uniform(low=0.0, high=10.0, size=(500,1))\n",
    "t_test_collocation = np.linspace(0,5000,500).reshape((500,1))\n",
    "pt_t_test_collocation = Variable(torch.Tensor(t_test_collocation).float(), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prey_val = net_x(pt_t_test_collocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predator_val = net_y(pt_t_test_collocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prey_val[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.5559], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predator_val[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8151],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(prey_val.sum(), pt_t_test_collocation, create_graph=True)[0][:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017],\n",
       "        [0.0017]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(predator_val.sum(), pt_t_test_collocation, create_graph=True)[0][:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(prey_val.detach().numpy())\n",
    "plt.plot(predator_val.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.9301]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([3.6346], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[6.1271]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([4.0172], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in net_x.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_test_collocation = np.random.uniform(low=0.0, high=10.0, size=(500,1))\n",
    "t_test_collocation = np.linspace(0,500,500).reshape((500,1))\n",
    "pt_t_test_collocation = Variable(torch.Tensor(t_test_collocation).float(), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = net_x(pt_t_test_collocation)\n",
    "prey_val = x_  + (torch.autograd.grad(x_.sum(), pt_t_test_collocation, create_graph=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00200401])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test_collocation[2] - t_test_collocation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ = net_y(pt_t_test_collocation)\n",
    "predator_val =  v_ + (torch.autograd.grad(v_.sum(), pt_t_test_collocation, create_graph=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(prey_val.detach().numpy())\n",
    "plt.plot(predator_val.detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2f93965a3ca292b7715d96980092ba920b6b7cd48889a529ea1962f3df167c4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pinn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
